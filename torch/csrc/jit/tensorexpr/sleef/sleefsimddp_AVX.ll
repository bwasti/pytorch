; ModuleID = '/home/bwasti/pytorch/sleef/src/libm/sleefsimddp.c'
source_filename = "/home/bwasti/pytorch/sleef/src/libm/sleefsimddp.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

%struct.vdouble2 = type { <4 x double>, <4 x double> }
%struct.dd2 = type { %struct.vdouble2, %struct.vdouble2 }

@.str = private unnamed_addr constant [4 x i8] c"AVX\00", align 1
@rempitabdp = external local_unnamed_addr constant [0 x double], align 8

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_ldexpd4_avx(<4 x double>, <2 x i64>) local_unnamed_addr #0 {
  %3 = bitcast <2 x i64> %1 to <4 x i32>
  %4 = ashr <4 x i32> %3, <i32 31, i32 31, i32 31, i32 31>
  %5 = add <4 x i32> %4, %3
  %6 = ashr <4 x i32> %5, <i32 9, i32 9, i32 9, i32 9>
  %7 = sub nsw <4 x i32> %6, %4
  %8 = shl nsw <4 x i32> %7, <i32 7, i32 7, i32 7, i32 7>
  %9 = shl <4 x i32> %7, <i32 9, i32 9, i32 9, i32 9>
  %10 = sub <4 x i32> %3, %9
  %11 = add nsw <4 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = icmp slt <4 x i32> %7, <i32 -7, i32 -7, i32 -7, i32 -7>
  %14 = sext <4 x i1> %13 to <4 x i32>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = xor <2 x i64> %15, <i64 -1, i64 -1>
  %17 = and <2 x i64> %16, %12
  %18 = bitcast <2 x i64> %17 to <4 x i32>
  %19 = icmp sgt <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = sext <4 x i1> %19 to <4 x i32>
  %21 = bitcast <2 x i64> %17 to <16 x i8>
  %22 = bitcast <4 x i32> %20 to <16 x i8>
  %23 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %21, <16 x i8> <i8 -1, i8 7, i8 0, i8 0, i8 -1, i8 7, i8 0, i8 0, i8 -1, i8 7, i8 0, i8 0, i8 -1, i8 7, i8 0, i8 0>, <16 x i8> %22) #6
  %24 = bitcast <16 x i8> %23 to <4 x i32>
  %25 = shufflevector <4 x i32> %24, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %24, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <4 x i32> %28 to <2 x i64>
  %32 = bitcast <4 x i32> %30 to <2 x i64>
  %33 = shufflevector <2 x i64> %31, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %34 = shufflevector <2 x i64> %32, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %35 = shufflevector <4 x i64> %33, <4 x i64> %34, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fmul <4 x double> %36, %0
  %38 = fmul <4 x double> %37, %36
  %39 = fmul <4 x double> %38, %36
  %40 = fmul <4 x double> %39, %36
  %41 = add <4 x i32> %10, <i32 1023, i32 1023, i32 1023, i32 1023>
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %43 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %44 = and <4 x i32> %42, <i32 0, i32 -1, i32 0, i32 -1>
  %45 = shl <4 x i32> %44, <i32 20, i32 20, i32 20, i32 20>
  %46 = and <4 x i32> %43, <i32 0, i32 -1, i32 0, i32 -1>
  %47 = shl <4 x i32> %46, <i32 20, i32 20, i32 20, i32 20>
  %48 = bitcast <4 x i32> %45 to <2 x i64>
  %49 = bitcast <4 x i32> %47 to <2 x i64>
  %50 = shufflevector <2 x i64> %48, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %51 = shufflevector <2 x i64> %49, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %52 = shufflevector <4 x i64> %50, <4 x i64> %51, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %53 = bitcast <4 x i64> %52 to <4 x double>
  %54 = fmul <4 x double> %40, %53
  ret <4 x double> %54
}

; Function Attrs: nounwind readnone uwtable
define <2 x i64> @Sleef_ilogbd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %4, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %8 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %7, <4 x double> %5) #6
  %9 = bitcast <4 x double> %8 to <4 x i64>
  %10 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %11 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %12 = bitcast <2 x i64> %10 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = bitcast <2 x i64> %11 to <4 x i32>
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %17, <2 x i64> %14, <2 x i32> <i32 2, i32 1>
  %19 = bitcast <2 x i64> %18 to <4 x i32>
  %20 = lshr <4 x i32> %19, <i32 20, i32 20, i32 20, i32 20>
  %21 = and <4 x i64> %6, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %22) #6
  %24 = bitcast <4 x i32> %23 to <16 x i8>
  %25 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %24) #6
  %26 = bitcast <16 x i8> %25 to <4 x i32>
  %27 = sub <4 x i32> %20, %26
  %28 = sitofp <4 x i32> %27 to <4 x double>
  %29 = fcmp oeq <4 x double> %0, zeroinitializer
  %30 = sext <4 x i1> %29 to <4 x i64>
  %31 = bitcast <4 x i64> %30 to <4 x double>
  %32 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %28, <4 x double> <double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000>, <4 x double> %31) #6
  %33 = fcmp uno <4 x double> %0, zeroinitializer
  %34 = sext <4 x i1> %33 to <4 x i64>
  %35 = bitcast <4 x i64> %34 to <4 x double>
  %36 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %32, <4 x double> <double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000>, <4 x double> %35) #6
  %37 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %38 = sext <4 x i1> %37 to <4 x i64>
  %39 = bitcast <4 x i64> %38 to <4 x double>
  %40 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %36, <4 x double> <double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000>, <4 x double> %39) #6
  %41 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %40) #6
  %42 = bitcast <4 x i32> %41 to <2 x i64>
  ret <2 x i64> %42
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture) #1

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sind4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %20, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %14 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %13, i32 8) #6
  %15 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %14) #6
  %16 = fmul <4 x double> %14, <double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18>
  %17 = fadd <4 x double> %16, %0
  %18 = fmul <4 x double> %14, <double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07>
  %19 = fadd <4 x double> %18, %17
  br label %304

; <label>:20:                                     ; preds = %1
  %21 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %22 = bitcast <4 x double> %21 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = and <2 x i64> %24, %23
  %26 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %25, <2 x i64> <i64 -1, i64 -1>) #6
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %51, label %28, !prof !2

; <label>:28:                                     ; preds = %20
  %29 = fmul <4 x double> %0, <double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883>
  %30 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %29, i32 11) #6
  %31 = fmul <4 x double> %30, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %32 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %33 = fsub <4 x double> %32, %31
  %34 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %33, i32 8) #6
  %35 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %34) #6
  %36 = fmul <4 x double> %31, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %37 = fadd <4 x double> %36, %0
  %38 = fmul <4 x double> %34, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %39 = fadd <4 x double> %38, %37
  %40 = fmul <4 x double> %31, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %41 = fadd <4 x double> %40, %39
  %42 = fmul <4 x double> %34, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %43 = fadd <4 x double> %42, %41
  %44 = fmul <4 x double> %31, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %45 = fadd <4 x double> %44, %43
  %46 = fmul <4 x double> %34, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %47 = fadd <4 x double> %46, %45
  %48 = fadd <4 x double> %31, %34
  %49 = fmul <4 x double> %48, <double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A>
  %50 = fadd <4 x double> %49, %47
  br label %304

; <label>:51:                                     ; preds = %20
  %52 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %53 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %54 = bitcast <2 x i64> %52 to <4 x i32>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = bitcast <2 x i64> %53 to <4 x i32>
  %58 = shufflevector <4 x i32> %57, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %59, <2 x i64> %56, <2 x i32> <i32 2, i32 1>
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = lshr <4 x i32> %61, <i32 20, i32 20, i32 20, i32 20>
  %63 = and <4 x i32> %62, <i32 2047, i32 2047, i32 2047, i32 2047>
  %64 = add nsw <4 x i32> %63, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %65 = icmp ugt <4 x i32> %63, <i32 1723, i32 1723, i32 1723, i32 1723>
  %66 = select <4 x i1> %65, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %68 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %69 = and <4 x i32> %67, <i32 0, i32 -1, i32 0, i32 -1>
  %70 = shl <4 x i32> %69, <i32 20, i32 20, i32 20, i32 20>
  %71 = and <4 x i32> %68, <i32 0, i32 -1, i32 0, i32 -1>
  %72 = shl <4 x i32> %71, <i32 20, i32 20, i32 20, i32 20>
  %73 = add <4 x i32> %70, %54
  %74 = add <4 x i32> %72, %57
  %75 = bitcast <4 x i32> %73 to <2 x i64>
  %76 = bitcast <4 x i32> %74 to <2 x i64>
  %77 = shufflevector <2 x i64> %75, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %78 = shufflevector <2 x i64> %76, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %79 = shufflevector <4 x i64> %77, <4 x i64> %78, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = ashr <4 x i32> %64, <i32 31, i32 31, i32 31, i32 31>
  %82 = xor <4 x i32> %81, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %83 = and <4 x i32> %82, %64
  %84 = shl <4 x i32> %83, <i32 2, i32 2, i32 2, i32 2>
  %85 = extractelement <4 x i32> %84, i32 3
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %86
  %88 = load double, double* %87, align 8, !tbaa !3, !noalias !7
  %89 = extractelement <4 x i32> %84, i32 2
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %90
  %92 = load double, double* %91, align 8, !tbaa !3, !noalias !7
  %93 = extractelement <4 x i32> %84, i32 1
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %94
  %96 = load double, double* %95, align 8, !tbaa !3, !noalias !7
  %97 = extractelement <4 x i32> %84, i32 0
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %98
  %100 = load double, double* %99, align 8, !tbaa !3, !noalias !7
  %101 = insertelement <4 x double> undef, double %100, i32 0
  %102 = insertelement <4 x double> %101, double %96, i32 1
  %103 = insertelement <4 x double> %102, double %92, i32 2
  %104 = insertelement <4 x double> %103, double %88, i32 3
  %105 = and <4 x i64> %79, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = fsub <4 x double> %80, %106
  %108 = bitcast <4 x double> %104 to <4 x i64>
  %109 = and <4 x i64> %108, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %110 = bitcast <4 x i64> %109 to <4 x double>
  %111 = fsub <4 x double> %104, %110
  %112 = fmul <4 x double> %104, %80
  %113 = fmul <4 x double> %106, %110
  %114 = bitcast <4 x double> %112 to <4 x i64>
  %115 = xor <4 x i64> %114, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fmul <4 x double> %107, %110
  %118 = fmul <4 x double> %111, %106
  %119 = fmul <4 x double> %107, %111
  %120 = fadd <4 x double> %113, %116
  %121 = fadd <4 x double> %117, %120
  %122 = fadd <4 x double> %118, %121
  %123 = fadd <4 x double> %119, %122
  %124 = fmul <4 x double> %112, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %125 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %124, i32 8) #6
  %126 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %112, i32 8) #6
  %127 = fmul <4 x double> %126, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %128 = fsub <4 x double> %125, %127
  %129 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %128) #6
  %130 = fmul <4 x double> %125, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %131 = fsub <4 x double> %112, %130
  %132 = fadd <4 x double> %131, %123
  %133 = fsub <4 x double> %131, %132
  %134 = fadd <4 x double> %123, %133
  %135 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %86
  %136 = load double, double* %135, align 8, !tbaa !3, !noalias !7
  %137 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %90
  %138 = load double, double* %137, align 8, !tbaa !3, !noalias !7
  %139 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %94
  %140 = load double, double* %139, align 8, !tbaa !3, !noalias !7
  %141 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %98
  %142 = load double, double* %141, align 8, !tbaa !3, !noalias !7
  %143 = insertelement <4 x double> undef, double %142, i32 0
  %144 = insertelement <4 x double> %143, double %140, i32 1
  %145 = insertelement <4 x double> %144, double %138, i32 2
  %146 = insertelement <4 x double> %145, double %136, i32 3
  %147 = bitcast <4 x double> %146 to <4 x i64>
  %148 = and <4 x i64> %147, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <4 x i64> %148 to <4 x double>
  %150 = fsub <4 x double> %146, %149
  %151 = fmul <4 x double> %146, %80
  %152 = fmul <4 x double> %106, %149
  %153 = bitcast <4 x double> %151 to <4 x i64>
  %154 = xor <4 x i64> %153, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %155 = bitcast <4 x i64> %154 to <4 x double>
  %156 = fmul <4 x double> %107, %149
  %157 = fmul <4 x double> %150, %106
  %158 = fmul <4 x double> %107, %150
  %159 = fadd <4 x double> %152, %155
  %160 = fadd <4 x double> %156, %159
  %161 = fadd <4 x double> %157, %160
  %162 = fadd <4 x double> %158, %161
  %163 = fadd <4 x double> %151, %132
  %164 = fsub <4 x double> %163, %132
  %165 = fsub <4 x double> %163, %164
  %166 = fsub <4 x double> %132, %165
  %167 = fsub <4 x double> %151, %164
  %168 = fadd <4 x double> %167, %166
  %169 = fadd <4 x double> %134, %162
  %170 = fadd <4 x double> %168, %169
  %171 = fmul <4 x double> %163, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %172 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %171, i32 8) #6
  %173 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %163, i32 8) #6
  %174 = fmul <4 x double> %173, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %175 = fsub <4 x double> %172, %174
  %176 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %175) #6
  %177 = fmul <4 x double> %172, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %178 = fsub <4 x double> %163, %177
  %179 = add <4 x i32> %176, %129
  %180 = fadd <4 x double> %178, %170
  %181 = fsub <4 x double> %178, %180
  %182 = fadd <4 x double> %170, %181
  %183 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %86
  %184 = load double, double* %183, align 8, !tbaa !3, !noalias !7
  %185 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %90
  %186 = load double, double* %185, align 8, !tbaa !3, !noalias !7
  %187 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %94
  %188 = load double, double* %187, align 8, !tbaa !3, !noalias !7
  %189 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %98
  %190 = load double, double* %189, align 8, !tbaa !3, !noalias !7
  %191 = insertelement <4 x double> undef, double %190, i32 0
  %192 = insertelement <4 x double> %191, double %188, i32 1
  %193 = insertelement <4 x double> %192, double %186, i32 2
  %194 = insertelement <4 x double> %193, double %184, i32 3
  %195 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %86
  %196 = load double, double* %195, align 8, !tbaa !3, !noalias !7
  %197 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %90
  %198 = load double, double* %197, align 8, !tbaa !3, !noalias !7
  %199 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %94
  %200 = load double, double* %199, align 8, !tbaa !3, !noalias !7
  %201 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %98
  %202 = load double, double* %201, align 8, !tbaa !3, !noalias !7
  %203 = insertelement <4 x double> undef, double %202, i32 0
  %204 = insertelement <4 x double> %203, double %200, i32 1
  %205 = insertelement <4 x double> %204, double %198, i32 2
  %206 = insertelement <4 x double> %205, double %196, i32 3
  %207 = bitcast <4 x double> %194 to <4 x i64>
  %208 = and <4 x i64> %207, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %209 = bitcast <4 x i64> %208 to <4 x double>
  %210 = fsub <4 x double> %194, %209
  %211 = fmul <4 x double> %194, %80
  %212 = fmul <4 x double> %106, %209
  %213 = bitcast <4 x double> %211 to <4 x i64>
  %214 = xor <4 x i64> %213, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %215 = bitcast <4 x i64> %214 to <4 x double>
  %216 = fmul <4 x double> %210, %106
  %217 = fmul <4 x double> %107, %209
  %218 = fmul <4 x double> %107, %210
  %219 = fmul <4 x double> %206, %80
  %220 = fadd <4 x double> %212, %215
  %221 = fadd <4 x double> %216, %220
  %222 = fadd <4 x double> %217, %221
  %223 = fadd <4 x double> %218, %222
  %224 = fadd <4 x double> %219, %223
  %225 = fadd <4 x double> %211, %180
  %226 = fsub <4 x double> %225, %180
  %227 = fsub <4 x double> %225, %226
  %228 = fsub <4 x double> %180, %227
  %229 = fsub <4 x double> %211, %226
  %230 = fadd <4 x double> %229, %228
  %231 = fadd <4 x double> %182, %224
  %232 = fadd <4 x double> %230, %231
  %233 = fadd <4 x double> %225, %232
  %234 = fsub <4 x double> %225, %233
  %235 = fadd <4 x double> %232, %234
  %236 = bitcast <4 x double> %233 to <4 x i64>
  %237 = and <4 x i64> %236, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %238 = bitcast <4 x i64> %237 to <4 x double>
  %239 = fsub <4 x double> %233, %238
  %240 = fmul <4 x double> %233, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %241 = fmul <4 x double> %238, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %242 = bitcast <4 x double> %240 to <4 x i64>
  %243 = xor <4 x i64> %242, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %244 = bitcast <4 x i64> %243 to <4 x double>
  %245 = fmul <4 x double> %239, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %246 = fmul <4 x double> %238, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %247 = fmul <4 x double> %239, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %248 = fmul <4 x double> %233, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %249 = fmul <4 x double> %235, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %250 = fadd <4 x double> %241, %244
  %251 = fadd <4 x double> %245, %250
  %252 = fadd <4 x double> %246, %251
  %253 = fadd <4 x double> %247, %252
  %254 = fadd <4 x double> %248, %253
  %255 = fadd <4 x double> %249, %254
  %256 = and <4 x i64> %79, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %257 = bitcast <4 x i64> %256 to <4 x double>
  %258 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %257, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %259 = bitcast <4 x double> %258 to <4 x i64>
  %260 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %240, <4 x double> %80, <4 x double> %258) #6
  %261 = bitcast <4 x double> %255 to <4 x i64>
  %262 = xor <4 x i64> %259, <i64 -1, i64 -1, i64 -1, i64 -1>
  %263 = and <4 x i64> %261, %262
  %264 = shl <4 x i32> %179, <i32 1, i32 1, i32 1, i32 1>
  %265 = and <4 x i32> %264, <i32 6, i32 6, i32 6, i32 6>
  %266 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %260, <4 x double> zeroinitializer, i8 30) #6
  %267 = bitcast <4 x double> %266 to <4 x i64>
  %268 = and <4 x i64> %267, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %269 = bitcast <4 x i64> %268 to <4 x double>
  %270 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %269) #6
  %271 = bitcast <4 x i32> %270 to <16 x i8>
  %272 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0>, <16 x i8> <i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0>, <16 x i8> %271) #6
  %273 = bitcast <16 x i8> %272 to <4 x i32>
  %274 = add <4 x i32> %265, %273
  %275 = ashr <4 x i32> %274, <i32 2, i32 2, i32 2, i32 2>
  %276 = and <4 x i32> %179, <i32 1, i32 1, i32 1, i32 1>
  %277 = icmp ne <4 x i32> %276, zeroinitializer
  %278 = bitcast <4 x double> %260 to <4 x i64>
  %279 = and <4 x i64> %278, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %280 = xor <4 x i64> %279, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %281 = bitcast <4 x i64> %280 to <4 x double>
  %282 = xor <4 x i64> %279, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %283 = bitcast <4 x i64> %282 to <4 x double>
  %284 = bitcast <4 x i64> %263 to <4 x double>
  %285 = fadd <4 x double> %260, %281
  %286 = fsub <4 x double> %285, %260
  %287 = fsub <4 x double> %285, %286
  %288 = fsub <4 x double> %260, %287
  %289 = fsub <4 x double> %281, %286
  %290 = fadd <4 x double> %289, %288
  %291 = fadd <4 x double> %283, %284
  %292 = fadd <4 x double> %290, %291
  %293 = sitofp <4 x i1> %277 to <4 x double>
  %294 = fcmp oeq <4 x double> %293, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %295 = sext <4 x i1> %294 to <4 x i64>
  %296 = bitcast <4 x i64> %295 to <4 x double>
  %297 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %260, <4 x double> %285, <4 x double> %296) #6
  %298 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %284, <4 x double> %292, <4 x double> %296) #6
  %299 = fadd <4 x double> %297, %298
  %300 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %301 = fcmp uno <4 x double> %0, zeroinitializer
  %302 = or <4 x i1> %300, %301
  %303 = select <4 x i1> %302, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %299
  br label %304

; <label>:304:                                    ; preds = %28, %51, %12
  %305 = phi <4 x i32> [ %15, %12 ], [ %35, %28 ], [ %275, %51 ]
  %306 = phi <4 x double> [ %19, %12 ], [ %50, %28 ], [ %303, %51 ]
  %307 = fmul <4 x double> %306, %306
  %308 = and <4 x i32> %305, <i32 1, i32 1, i32 1, i32 1>
  %309 = icmp ne <4 x i32> %308, zeroinitializer
  %310 = sitofp <4 x i1> %309 to <4 x double>
  %311 = fcmp oeq <4 x double> %310, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %312 = select <4 x i1> %311, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %313 = bitcast <4 x double> %306 to <4 x i64>
  %314 = xor <4 x i64> %312, %313
  %315 = bitcast <4 x i64> %314 to <4 x double>
  %316 = fmul <4 x double> %307, %307
  %317 = fmul <4 x double> %316, %316
  %318 = fmul <4 x double> %307, <double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE>
  %319 = fadd <4 x double> %318, <double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592>
  %320 = fmul <4 x double> %307, <double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF>
  %321 = fadd <4 x double> %320, <double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966>
  %322 = fmul <4 x double> %316, %319
  %323 = fadd <4 x double> %321, %322
  %324 = fmul <4 x double> %307, <double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786>
  %325 = fadd <4 x double> %324, <double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50>
  %326 = fmul <4 x double> %307, <double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7>
  %327 = fadd <4 x double> %326, <double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F>
  %328 = fmul <4 x double> %316, %325
  %329 = fadd <4 x double> %327, %328
  %330 = fmul <4 x double> %317, %323
  %331 = fadd <4 x double> %329, %330
  %332 = fmul <4 x double> %307, %331
  %333 = fadd <4 x double> %332, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %334 = fmul <4 x double> %333, %315
  %335 = fmul <4 x double> %307, %334
  %336 = fadd <4 x double> %335, %315
  %337 = xor <4 x i64> %2, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %338 = bitcast <4 x i64> %337 to <4 x double>
  %339 = fcmp oeq <4 x double> %338, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %340 = sext <4 x i1> %339 to <4 x i64>
  %341 = bitcast <4 x i64> %340 to <4 x double>
  %342 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %336, <4 x double> %0, <4 x double> %341) #6
  ret <4 x double> %342
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sind4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %22, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %14 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %13, i32 8) #6
  %15 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %14) #6
  %16 = fmul <4 x double> %14, <double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18>
  %17 = fadd <4 x double> %16, %0
  %18 = fmul <4 x double> %14, <double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07>
  %19 = fadd <4 x double> %18, %17
  %20 = fsub <4 x double> %17, %19
  %21 = fadd <4 x double> %18, %20
  br label %337

; <label>:22:                                     ; preds = %1
  %23 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %24 = bitcast <4 x double> %23 to <4 x i64>
  %25 = shufflevector <4 x i64> %24, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %26 = shufflevector <4 x i64> %24, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %27 = and <2 x i64> %26, %25
  %28 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %27, <2 x i64> <i64 -1, i64 -1>) #6
  %29 = icmp eq i32 %28, 0
  br i1 %29, label %82, label %30, !prof !2

; <label>:30:                                     ; preds = %22
  %31 = fmul <4 x double> %0, <double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883>
  %32 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %31, i32 11) #6
  %33 = fmul <4 x double> %32, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %34 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %35 = fsub <4 x double> %34, %33
  %36 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %35, i32 8) #6
  %37 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %36) #6
  %38 = fmul <4 x double> %33, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %39 = fadd <4 x double> %38, %0
  %40 = fmul <4 x double> %36, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %41 = fadd <4 x double> %40, %39
  %42 = fsub <4 x double> %39, %41
  %43 = fadd <4 x double> %40, %42
  %44 = fmul <4 x double> %33, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %45 = fadd <4 x double> %44, %41
  %46 = fsub <4 x double> %45, %41
  %47 = fsub <4 x double> %45, %46
  %48 = fsub <4 x double> %41, %47
  %49 = fsub <4 x double> %44, %46
  %50 = fadd <4 x double> %49, %48
  %51 = fadd <4 x double> %43, %50
  %52 = fmul <4 x double> %36, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %53 = fadd <4 x double> %52, %45
  %54 = fsub <4 x double> %53, %45
  %55 = fsub <4 x double> %53, %54
  %56 = fsub <4 x double> %45, %55
  %57 = fsub <4 x double> %52, %54
  %58 = fadd <4 x double> %57, %56
  %59 = fadd <4 x double> %58, %51
  %60 = fmul <4 x double> %33, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %61 = fadd <4 x double> %60, %53
  %62 = fsub <4 x double> %61, %53
  %63 = fsub <4 x double> %61, %62
  %64 = fsub <4 x double> %53, %63
  %65 = fsub <4 x double> %60, %62
  %66 = fadd <4 x double> %65, %64
  %67 = fadd <4 x double> %66, %59
  %68 = fmul <4 x double> %36, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %69 = fadd <4 x double> %68, %61
  %70 = fsub <4 x double> %69, %61
  %71 = fsub <4 x double> %69, %70
  %72 = fsub <4 x double> %61, %71
  %73 = fsub <4 x double> %68, %70
  %74 = fadd <4 x double> %73, %72
  %75 = fadd <4 x double> %74, %67
  %76 = fadd <4 x double> %33, %36
  %77 = fmul <4 x double> %76, <double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A>
  %78 = fadd <4 x double> %77, %69
  %79 = fsub <4 x double> %69, %78
  %80 = fadd <4 x double> %77, %79
  %81 = fadd <4 x double> %80, %75
  br label %337

; <label>:82:                                     ; preds = %22
  %83 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %84 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %85 = bitcast <2 x i64> %83 to <4 x i32>
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %87 = bitcast <4 x i32> %86 to <2 x i64>
  %88 = bitcast <2 x i64> %84 to <4 x i32>
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %90 = bitcast <4 x i32> %89 to <2 x i64>
  %91 = shufflevector <2 x i64> %90, <2 x i64> %87, <2 x i32> <i32 2, i32 1>
  %92 = bitcast <2 x i64> %91 to <4 x i32>
  %93 = lshr <4 x i32> %92, <i32 20, i32 20, i32 20, i32 20>
  %94 = and <4 x i32> %93, <i32 2047, i32 2047, i32 2047, i32 2047>
  %95 = add nsw <4 x i32> %94, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %96 = icmp ugt <4 x i32> %94, <i32 1723, i32 1723, i32 1723, i32 1723>
  %97 = select <4 x i1> %96, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %99 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %100 = and <4 x i32> %98, <i32 0, i32 -1, i32 0, i32 -1>
  %101 = shl <4 x i32> %100, <i32 20, i32 20, i32 20, i32 20>
  %102 = and <4 x i32> %99, <i32 0, i32 -1, i32 0, i32 -1>
  %103 = shl <4 x i32> %102, <i32 20, i32 20, i32 20, i32 20>
  %104 = add <4 x i32> %101, %85
  %105 = add <4 x i32> %103, %88
  %106 = bitcast <4 x i32> %104 to <2 x i64>
  %107 = bitcast <4 x i32> %105 to <2 x i64>
  %108 = shufflevector <2 x i64> %106, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %109 = shufflevector <2 x i64> %107, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %110 = shufflevector <4 x i64> %108, <4 x i64> %109, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = ashr <4 x i32> %95, <i32 31, i32 31, i32 31, i32 31>
  %113 = xor <4 x i32> %112, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %114 = and <4 x i32> %113, %95
  %115 = shl <4 x i32> %114, <i32 2, i32 2, i32 2, i32 2>
  %116 = extractelement <4 x i32> %115, i32 3
  %117 = sext i32 %116 to i64
  %118 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %117
  %119 = load double, double* %118, align 8, !tbaa !3, !noalias !10
  %120 = extractelement <4 x i32> %115, i32 2
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %121
  %123 = load double, double* %122, align 8, !tbaa !3, !noalias !10
  %124 = extractelement <4 x i32> %115, i32 1
  %125 = sext i32 %124 to i64
  %126 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %125
  %127 = load double, double* %126, align 8, !tbaa !3, !noalias !10
  %128 = extractelement <4 x i32> %115, i32 0
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %129
  %131 = load double, double* %130, align 8, !tbaa !3, !noalias !10
  %132 = insertelement <4 x double> undef, double %131, i32 0
  %133 = insertelement <4 x double> %132, double %127, i32 1
  %134 = insertelement <4 x double> %133, double %123, i32 2
  %135 = insertelement <4 x double> %134, double %119, i32 3
  %136 = and <4 x i64> %110, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %137 = bitcast <4 x i64> %136 to <4 x double>
  %138 = fsub <4 x double> %111, %137
  %139 = bitcast <4 x double> %135 to <4 x i64>
  %140 = and <4 x i64> %139, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %141 = bitcast <4 x i64> %140 to <4 x double>
  %142 = fsub <4 x double> %135, %141
  %143 = fmul <4 x double> %135, %111
  %144 = fmul <4 x double> %137, %141
  %145 = bitcast <4 x double> %143 to <4 x i64>
  %146 = xor <4 x i64> %145, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %147 = bitcast <4 x i64> %146 to <4 x double>
  %148 = fmul <4 x double> %138, %141
  %149 = fmul <4 x double> %142, %137
  %150 = fmul <4 x double> %138, %142
  %151 = fadd <4 x double> %144, %147
  %152 = fadd <4 x double> %148, %151
  %153 = fadd <4 x double> %149, %152
  %154 = fadd <4 x double> %150, %153
  %155 = fmul <4 x double> %143, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %156 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %155, i32 8) #6
  %157 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %143, i32 8) #6
  %158 = fmul <4 x double> %157, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %159 = fsub <4 x double> %156, %158
  %160 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %159) #6
  %161 = fmul <4 x double> %156, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %162 = fsub <4 x double> %143, %161
  %163 = fadd <4 x double> %162, %154
  %164 = fsub <4 x double> %162, %163
  %165 = fadd <4 x double> %154, %164
  %166 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %117
  %167 = load double, double* %166, align 8, !tbaa !3, !noalias !10
  %168 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %121
  %169 = load double, double* %168, align 8, !tbaa !3, !noalias !10
  %170 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %125
  %171 = load double, double* %170, align 8, !tbaa !3, !noalias !10
  %172 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %129
  %173 = load double, double* %172, align 8, !tbaa !3, !noalias !10
  %174 = insertelement <4 x double> undef, double %173, i32 0
  %175 = insertelement <4 x double> %174, double %171, i32 1
  %176 = insertelement <4 x double> %175, double %169, i32 2
  %177 = insertelement <4 x double> %176, double %167, i32 3
  %178 = bitcast <4 x double> %177 to <4 x i64>
  %179 = and <4 x i64> %178, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %180 = bitcast <4 x i64> %179 to <4 x double>
  %181 = fsub <4 x double> %177, %180
  %182 = fmul <4 x double> %177, %111
  %183 = fmul <4 x double> %137, %180
  %184 = bitcast <4 x double> %182 to <4 x i64>
  %185 = xor <4 x i64> %184, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %186 = bitcast <4 x i64> %185 to <4 x double>
  %187 = fmul <4 x double> %138, %180
  %188 = fmul <4 x double> %181, %137
  %189 = fmul <4 x double> %138, %181
  %190 = fadd <4 x double> %183, %186
  %191 = fadd <4 x double> %187, %190
  %192 = fadd <4 x double> %188, %191
  %193 = fadd <4 x double> %189, %192
  %194 = fadd <4 x double> %182, %163
  %195 = fsub <4 x double> %194, %163
  %196 = fsub <4 x double> %194, %195
  %197 = fsub <4 x double> %163, %196
  %198 = fsub <4 x double> %182, %195
  %199 = fadd <4 x double> %198, %197
  %200 = fadd <4 x double> %165, %193
  %201 = fadd <4 x double> %199, %200
  %202 = fmul <4 x double> %194, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %203 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %202, i32 8) #6
  %204 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %194, i32 8) #6
  %205 = fmul <4 x double> %204, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %206 = fsub <4 x double> %203, %205
  %207 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %206) #6
  %208 = fmul <4 x double> %203, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %209 = fsub <4 x double> %194, %208
  %210 = add <4 x i32> %207, %160
  %211 = fadd <4 x double> %209, %201
  %212 = fsub <4 x double> %209, %211
  %213 = fadd <4 x double> %201, %212
  %214 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %117
  %215 = load double, double* %214, align 8, !tbaa !3, !noalias !10
  %216 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %121
  %217 = load double, double* %216, align 8, !tbaa !3, !noalias !10
  %218 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %125
  %219 = load double, double* %218, align 8, !tbaa !3, !noalias !10
  %220 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %129
  %221 = load double, double* %220, align 8, !tbaa !3, !noalias !10
  %222 = insertelement <4 x double> undef, double %221, i32 0
  %223 = insertelement <4 x double> %222, double %219, i32 1
  %224 = insertelement <4 x double> %223, double %217, i32 2
  %225 = insertelement <4 x double> %224, double %215, i32 3
  %226 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %117
  %227 = load double, double* %226, align 8, !tbaa !3, !noalias !10
  %228 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %121
  %229 = load double, double* %228, align 8, !tbaa !3, !noalias !10
  %230 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %125
  %231 = load double, double* %230, align 8, !tbaa !3, !noalias !10
  %232 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %129
  %233 = load double, double* %232, align 8, !tbaa !3, !noalias !10
  %234 = insertelement <4 x double> undef, double %233, i32 0
  %235 = insertelement <4 x double> %234, double %231, i32 1
  %236 = insertelement <4 x double> %235, double %229, i32 2
  %237 = insertelement <4 x double> %236, double %227, i32 3
  %238 = bitcast <4 x double> %225 to <4 x i64>
  %239 = and <4 x i64> %238, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %240 = bitcast <4 x i64> %239 to <4 x double>
  %241 = fsub <4 x double> %225, %240
  %242 = fmul <4 x double> %225, %111
  %243 = fmul <4 x double> %137, %240
  %244 = bitcast <4 x double> %242 to <4 x i64>
  %245 = xor <4 x i64> %244, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %246 = bitcast <4 x i64> %245 to <4 x double>
  %247 = fmul <4 x double> %241, %137
  %248 = fmul <4 x double> %138, %240
  %249 = fmul <4 x double> %138, %241
  %250 = fmul <4 x double> %237, %111
  %251 = fadd <4 x double> %243, %246
  %252 = fadd <4 x double> %247, %251
  %253 = fadd <4 x double> %248, %252
  %254 = fadd <4 x double> %249, %253
  %255 = fadd <4 x double> %250, %254
  %256 = fadd <4 x double> %242, %211
  %257 = fsub <4 x double> %256, %211
  %258 = fsub <4 x double> %256, %257
  %259 = fsub <4 x double> %211, %258
  %260 = fsub <4 x double> %242, %257
  %261 = fadd <4 x double> %260, %259
  %262 = fadd <4 x double> %213, %255
  %263 = fadd <4 x double> %261, %262
  %264 = fadd <4 x double> %256, %263
  %265 = fsub <4 x double> %256, %264
  %266 = fadd <4 x double> %263, %265
  %267 = bitcast <4 x double> %264 to <4 x i64>
  %268 = and <4 x i64> %267, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %269 = bitcast <4 x i64> %268 to <4 x double>
  %270 = fsub <4 x double> %264, %269
  %271 = fmul <4 x double> %264, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %272 = fmul <4 x double> %269, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %273 = bitcast <4 x double> %271 to <4 x i64>
  %274 = xor <4 x i64> %273, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %275 = bitcast <4 x i64> %274 to <4 x double>
  %276 = fmul <4 x double> %270, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %277 = fmul <4 x double> %269, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %278 = fmul <4 x double> %270, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %279 = fmul <4 x double> %264, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %280 = fmul <4 x double> %266, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %281 = fadd <4 x double> %272, %275
  %282 = fadd <4 x double> %276, %281
  %283 = fadd <4 x double> %277, %282
  %284 = fadd <4 x double> %278, %283
  %285 = fadd <4 x double> %279, %284
  %286 = fadd <4 x double> %280, %285
  %287 = and <4 x i64> %110, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %288 = bitcast <4 x i64> %287 to <4 x double>
  %289 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %288, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %290 = bitcast <4 x double> %289 to <4 x i64>
  %291 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %271, <4 x double> %111, <4 x double> %289) #6
  %292 = bitcast <4 x double> %286 to <4 x i64>
  %293 = xor <4 x i64> %290, <i64 -1, i64 -1, i64 -1, i64 -1>
  %294 = and <4 x i64> %292, %293
  %295 = shl <4 x i32> %210, <i32 1, i32 1, i32 1, i32 1>
  %296 = and <4 x i32> %295, <i32 6, i32 6, i32 6, i32 6>
  %297 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %291, <4 x double> zeroinitializer, i8 30) #6
  %298 = bitcast <4 x double> %297 to <4 x i64>
  %299 = and <4 x i64> %298, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %300 = bitcast <4 x i64> %299 to <4 x double>
  %301 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %300) #6
  %302 = bitcast <4 x i32> %301 to <16 x i8>
  %303 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0, i8 1, i8 0, i8 0, i8 0>, <16 x i8> <i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0, i8 2, i8 0, i8 0, i8 0>, <16 x i8> %302) #6
  %304 = bitcast <16 x i8> %303 to <4 x i32>
  %305 = add <4 x i32> %296, %304
  %306 = ashr <4 x i32> %305, <i32 2, i32 2, i32 2, i32 2>
  %307 = and <4 x i32> %210, <i32 1, i32 1, i32 1, i32 1>
  %308 = icmp ne <4 x i32> %307, zeroinitializer
  %309 = bitcast <4 x double> %291 to <4 x i64>
  %310 = and <4 x i64> %309, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %311 = xor <4 x i64> %310, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %312 = bitcast <4 x i64> %311 to <4 x double>
  %313 = xor <4 x i64> %310, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %314 = bitcast <4 x i64> %313 to <4 x double>
  %315 = bitcast <4 x i64> %294 to <4 x double>
  %316 = fadd <4 x double> %291, %312
  %317 = fsub <4 x double> %316, %291
  %318 = fsub <4 x double> %316, %317
  %319 = fsub <4 x double> %291, %318
  %320 = fsub <4 x double> %312, %317
  %321 = fadd <4 x double> %320, %319
  %322 = fadd <4 x double> %314, %315
  %323 = fadd <4 x double> %321, %322
  %324 = sitofp <4 x i1> %308 to <4 x double>
  %325 = fcmp oeq <4 x double> %324, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %326 = sext <4 x i1> %325 to <4 x i64>
  %327 = bitcast <4 x i64> %326 to <4 x double>
  %328 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %291, <4 x double> %316, <4 x double> %327) #6
  %329 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %315, <4 x double> %323, <4 x double> %327) #6
  %330 = fadd <4 x double> %328, %329
  %331 = fsub <4 x double> %328, %330
  %332 = fadd <4 x double> %329, %331
  %333 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %334 = fcmp uno <4 x double> %0, zeroinitializer
  %335 = or <4 x i1> %333, %334
  %336 = select <4 x i1> %335, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %330
  br label %337

; <label>:337:                                    ; preds = %30, %82, %12
  %338 = phi <4 x double> [ %336, %82 ], [ %78, %30 ], [ %19, %12 ]
  %339 = phi <4 x double> [ %332, %82 ], [ %81, %30 ], [ %21, %12 ]
  %340 = phi <4 x i32> [ %306, %82 ], [ %37, %30 ], [ %15, %12 ]
  %341 = bitcast <4 x double> %338 to <4 x i64>
  %342 = and <4 x i64> %341, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %343 = bitcast <4 x i64> %342 to <4 x double>
  %344 = fsub <4 x double> %338, %343
  %345 = fmul <4 x double> %338, %338
  %346 = fmul <4 x double> %343, %343
  %347 = bitcast <4 x double> %345 to <4 x i64>
  %348 = xor <4 x i64> %347, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %349 = bitcast <4 x i64> %348 to <4 x double>
  %350 = fadd <4 x double> %343, %343
  %351 = fmul <4 x double> %350, %344
  %352 = fmul <4 x double> %344, %344
  %353 = fadd <4 x double> %339, %339
  %354 = fmul <4 x double> %338, %353
  %355 = fadd <4 x double> %346, %349
  %356 = fadd <4 x double> %355, %351
  %357 = fadd <4 x double> %352, %356
  %358 = fadd <4 x double> %354, %357
  %359 = fmul <4 x double> %345, %345
  %360 = fmul <4 x double> %359, %359
  %361 = fmul <4 x double> %345, <double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D>
  %362 = fadd <4 x double> %361, <double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350>
  %363 = fmul <4 x double> %345, <double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67>
  %364 = fadd <4 x double> %363, <double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959>
  %365 = fmul <4 x double> %345, <double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED>
  %366 = fadd <4 x double> %365, <double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225>
  %367 = fmul <4 x double> %359, %364
  %368 = fadd <4 x double> %366, %367
  %369 = fmul <4 x double> %360, %362
  %370 = fadd <4 x double> %369, %368
  %371 = fmul <4 x double> %345, %370
  %372 = fadd <4 x double> %371, <double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9>
  %373 = fmul <4 x double> %345, %372
  %374 = fadd <4 x double> %373, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %375 = fsub <4 x double> <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>, %374
  %376 = fadd <4 x double> %373, %375
  %377 = bitcast <4 x double> %374 to <4 x i64>
  %378 = and <4 x i64> %377, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %379 = bitcast <4 x i64> %378 to <4 x double>
  %380 = fsub <4 x double> %374, %379
  %381 = and <4 x i64> %347, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %382 = bitcast <4 x i64> %381 to <4 x double>
  %383 = fsub <4 x double> %345, %382
  %384 = fmul <4 x double> %345, %374
  %385 = fmul <4 x double> %382, %379
  %386 = bitcast <4 x double> %384 to <4 x i64>
  %387 = xor <4 x i64> %386, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %388 = bitcast <4 x i64> %387 to <4 x double>
  %389 = fmul <4 x double> %380, %382
  %390 = fmul <4 x double> %383, %379
  %391 = fmul <4 x double> %383, %380
  %392 = fmul <4 x double> %358, %374
  %393 = fmul <4 x double> %345, %376
  %394 = fadd <4 x double> %385, %388
  %395 = fadd <4 x double> %389, %394
  %396 = fadd <4 x double> %390, %395
  %397 = fadd <4 x double> %391, %396
  %398 = fadd <4 x double> %392, %397
  %399 = fadd <4 x double> %393, %398
  %400 = fadd <4 x double> %384, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %401 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %400
  %402 = fadd <4 x double> %384, %401
  %403 = fadd <4 x double> %402, %399
  %404 = bitcast <4 x double> %400 to <4 x i64>
  %405 = and <4 x i64> %404, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %406 = bitcast <4 x i64> %405 to <4 x double>
  %407 = fsub <4 x double> %400, %406
  %408 = fmul <4 x double> %339, %406
  %409 = fmul <4 x double> %403, %343
  %410 = fmul <4 x double> %344, %407
  %411 = fmul <4 x double> %407, %343
  %412 = fmul <4 x double> %344, %406
  %413 = fmul <4 x double> %343, %406
  %414 = fadd <4 x double> %408, %409
  %415 = fadd <4 x double> %410, %414
  %416 = fadd <4 x double> %411, %415
  %417 = fadd <4 x double> %412, %416
  %418 = fadd <4 x double> %413, %417
  %419 = and <4 x i32> %340, <i32 1, i32 1, i32 1, i32 1>
  %420 = icmp ne <4 x i32> %419, zeroinitializer
  %421 = sitofp <4 x i1> %420 to <4 x double>
  %422 = fcmp oeq <4 x double> %421, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %423 = select <4 x i1> %422, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %424 = bitcast <4 x double> %418 to <4 x i64>
  %425 = xor <4 x i64> %423, %424
  %426 = bitcast <4 x i64> %425 to <4 x double>
  %427 = fcmp oeq <4 x double> %0, zeroinitializer
  %428 = sext <4 x i1> %427 to <4 x i64>
  %429 = bitcast <4 x i64> %428 to <4 x double>
  %430 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %426, <4 x double> %0, <4 x double> %429) #6
  ret <4 x double> %430
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cosd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %23, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %14 = fadd <4 x double> %13, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %15 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %14, i32 8) #6
  %16 = fmul <4 x double> %15, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %17 = fadd <4 x double> %16, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %17) #6
  %19 = fmul <4 x double> %17, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %20 = fadd <4 x double> %19, %0
  %21 = fmul <4 x double> %17, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %22 = fadd <4 x double> %21, %20
  br label %313

; <label>:23:                                     ; preds = %1
  %24 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %25 = bitcast <4 x double> %24 to <4 x i64>
  %26 = shufflevector <4 x i64> %25, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %27 = shufflevector <4 x i64> %25, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %28 = and <2 x i64> %27, %26
  %29 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %28, <2 x i64> <i64 -1, i64 -1>) #6
  %30 = icmp eq i32 %29, 0
  br i1 %30, label %59, label %31, !prof !2

; <label>:31:                                     ; preds = %23
  %32 = fmul <4 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %33 = fadd <4 x double> %32, <double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883>
  %34 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %33, i32 11) #6
  %35 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %36 = fmul <4 x double> %34, <double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000>
  %37 = fadd <4 x double> %36, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %38 = fadd <4 x double> %35, %37
  %39 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %38) #6
  %40 = fmul <4 x double> %34, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %41 = shl <4 x i32> %39, <i32 1, i32 1, i32 1, i32 1>
  %42 = or <4 x i32> %41, <i32 1, i32 1, i32 1, i32 1>
  %43 = sitofp <4 x i32> %42 to <4 x double>
  %44 = fmul <4 x double> %40, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %45 = fadd <4 x double> %44, %0
  %46 = fmul <4 x double> %43, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %47 = fadd <4 x double> %45, %46
  %48 = fmul <4 x double> %40, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %49 = fadd <4 x double> %48, %47
  %50 = fmul <4 x double> %43, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %51 = fadd <4 x double> %50, %49
  %52 = fmul <4 x double> %40, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %53 = fadd <4 x double> %52, %51
  %54 = fmul <4 x double> %43, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %55 = fadd <4 x double> %54, %53
  %56 = fadd <4 x double> %40, %43
  %57 = fmul <4 x double> %56, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %58 = fadd <4 x double> %57, %55
  br label %313

; <label>:59:                                     ; preds = %23
  %60 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %61 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %62 = bitcast <2 x i64> %60 to <4 x i32>
  %63 = shufflevector <4 x i32> %62, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %64 = bitcast <4 x i32> %63 to <2 x i64>
  %65 = bitcast <2 x i64> %61 to <4 x i32>
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %67 = bitcast <4 x i32> %66 to <2 x i64>
  %68 = shufflevector <2 x i64> %67, <2 x i64> %64, <2 x i32> <i32 2, i32 1>
  %69 = bitcast <2 x i64> %68 to <4 x i32>
  %70 = lshr <4 x i32> %69, <i32 20, i32 20, i32 20, i32 20>
  %71 = and <4 x i32> %70, <i32 2047, i32 2047, i32 2047, i32 2047>
  %72 = add nsw <4 x i32> %71, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %73 = icmp ugt <4 x i32> %71, <i32 1723, i32 1723, i32 1723, i32 1723>
  %74 = select <4 x i1> %73, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %75 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %76 = shufflevector <4 x i32> %74, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %77 = and <4 x i32> %75, <i32 0, i32 -1, i32 0, i32 -1>
  %78 = shl <4 x i32> %77, <i32 20, i32 20, i32 20, i32 20>
  %79 = and <4 x i32> %76, <i32 0, i32 -1, i32 0, i32 -1>
  %80 = shl <4 x i32> %79, <i32 20, i32 20, i32 20, i32 20>
  %81 = add <4 x i32> %78, %62
  %82 = add <4 x i32> %80, %65
  %83 = bitcast <4 x i32> %81 to <2 x i64>
  %84 = bitcast <4 x i32> %82 to <2 x i64>
  %85 = shufflevector <2 x i64> %83, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %86 = shufflevector <2 x i64> %84, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %87 = shufflevector <4 x i64> %85, <4 x i64> %86, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %88 = bitcast <4 x i64> %87 to <4 x double>
  %89 = ashr <4 x i32> %72, <i32 31, i32 31, i32 31, i32 31>
  %90 = xor <4 x i32> %89, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %91 = and <4 x i32> %90, %72
  %92 = shl <4 x i32> %91, <i32 2, i32 2, i32 2, i32 2>
  %93 = extractelement <4 x i32> %92, i32 3
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %94
  %96 = load double, double* %95, align 8, !tbaa !3, !noalias !13
  %97 = extractelement <4 x i32> %92, i32 2
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %98
  %100 = load double, double* %99, align 8, !tbaa !3, !noalias !13
  %101 = extractelement <4 x i32> %92, i32 1
  %102 = sext i32 %101 to i64
  %103 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %102
  %104 = load double, double* %103, align 8, !tbaa !3, !noalias !13
  %105 = extractelement <4 x i32> %92, i32 0
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %106
  %108 = load double, double* %107, align 8, !tbaa !3, !noalias !13
  %109 = insertelement <4 x double> undef, double %108, i32 0
  %110 = insertelement <4 x double> %109, double %104, i32 1
  %111 = insertelement <4 x double> %110, double %100, i32 2
  %112 = insertelement <4 x double> %111, double %96, i32 3
  %113 = and <4 x i64> %87, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %114 = bitcast <4 x i64> %113 to <4 x double>
  %115 = fsub <4 x double> %88, %114
  %116 = bitcast <4 x double> %112 to <4 x i64>
  %117 = and <4 x i64> %116, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %118 = bitcast <4 x i64> %117 to <4 x double>
  %119 = fsub <4 x double> %112, %118
  %120 = fmul <4 x double> %112, %88
  %121 = fmul <4 x double> %114, %118
  %122 = bitcast <4 x double> %120 to <4 x i64>
  %123 = xor <4 x i64> %122, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %124 = bitcast <4 x i64> %123 to <4 x double>
  %125 = fmul <4 x double> %115, %118
  %126 = fmul <4 x double> %119, %114
  %127 = fmul <4 x double> %115, %119
  %128 = fadd <4 x double> %121, %124
  %129 = fadd <4 x double> %125, %128
  %130 = fadd <4 x double> %126, %129
  %131 = fadd <4 x double> %127, %130
  %132 = fmul <4 x double> %120, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %133 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %132, i32 8) #6
  %134 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %120, i32 8) #6
  %135 = fmul <4 x double> %134, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %136 = fsub <4 x double> %133, %135
  %137 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %136) #6
  %138 = fmul <4 x double> %133, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %139 = fsub <4 x double> %120, %138
  %140 = fadd <4 x double> %139, %131
  %141 = fsub <4 x double> %139, %140
  %142 = fadd <4 x double> %131, %141
  %143 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %94
  %144 = load double, double* %143, align 8, !tbaa !3, !noalias !13
  %145 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %98
  %146 = load double, double* %145, align 8, !tbaa !3, !noalias !13
  %147 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %102
  %148 = load double, double* %147, align 8, !tbaa !3, !noalias !13
  %149 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %106
  %150 = load double, double* %149, align 8, !tbaa !3, !noalias !13
  %151 = insertelement <4 x double> undef, double %150, i32 0
  %152 = insertelement <4 x double> %151, double %148, i32 1
  %153 = insertelement <4 x double> %152, double %146, i32 2
  %154 = insertelement <4 x double> %153, double %144, i32 3
  %155 = bitcast <4 x double> %154 to <4 x i64>
  %156 = and <4 x i64> %155, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %157 = bitcast <4 x i64> %156 to <4 x double>
  %158 = fsub <4 x double> %154, %157
  %159 = fmul <4 x double> %154, %88
  %160 = fmul <4 x double> %114, %157
  %161 = bitcast <4 x double> %159 to <4 x i64>
  %162 = xor <4 x i64> %161, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %163 = bitcast <4 x i64> %162 to <4 x double>
  %164 = fmul <4 x double> %115, %157
  %165 = fmul <4 x double> %158, %114
  %166 = fmul <4 x double> %115, %158
  %167 = fadd <4 x double> %160, %163
  %168 = fadd <4 x double> %164, %167
  %169 = fadd <4 x double> %165, %168
  %170 = fadd <4 x double> %166, %169
  %171 = fadd <4 x double> %159, %140
  %172 = fsub <4 x double> %171, %140
  %173 = fsub <4 x double> %171, %172
  %174 = fsub <4 x double> %140, %173
  %175 = fsub <4 x double> %159, %172
  %176 = fadd <4 x double> %175, %174
  %177 = fadd <4 x double> %142, %170
  %178 = fadd <4 x double> %176, %177
  %179 = fmul <4 x double> %171, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %180 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %179, i32 8) #6
  %181 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %171, i32 8) #6
  %182 = fmul <4 x double> %181, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %183 = fsub <4 x double> %180, %182
  %184 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %183) #6
  %185 = fmul <4 x double> %180, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %186 = fsub <4 x double> %171, %185
  %187 = add <4 x i32> %184, %137
  %188 = fadd <4 x double> %186, %178
  %189 = fsub <4 x double> %186, %188
  %190 = fadd <4 x double> %178, %189
  %191 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %94
  %192 = load double, double* %191, align 8, !tbaa !3, !noalias !13
  %193 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %98
  %194 = load double, double* %193, align 8, !tbaa !3, !noalias !13
  %195 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %102
  %196 = load double, double* %195, align 8, !tbaa !3, !noalias !13
  %197 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %106
  %198 = load double, double* %197, align 8, !tbaa !3, !noalias !13
  %199 = insertelement <4 x double> undef, double %198, i32 0
  %200 = insertelement <4 x double> %199, double %196, i32 1
  %201 = insertelement <4 x double> %200, double %194, i32 2
  %202 = insertelement <4 x double> %201, double %192, i32 3
  %203 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %94
  %204 = load double, double* %203, align 8, !tbaa !3, !noalias !13
  %205 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %98
  %206 = load double, double* %205, align 8, !tbaa !3, !noalias !13
  %207 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %102
  %208 = load double, double* %207, align 8, !tbaa !3, !noalias !13
  %209 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %106
  %210 = load double, double* %209, align 8, !tbaa !3, !noalias !13
  %211 = insertelement <4 x double> undef, double %210, i32 0
  %212 = insertelement <4 x double> %211, double %208, i32 1
  %213 = insertelement <4 x double> %212, double %206, i32 2
  %214 = insertelement <4 x double> %213, double %204, i32 3
  %215 = bitcast <4 x double> %202 to <4 x i64>
  %216 = and <4 x i64> %215, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %217 = bitcast <4 x i64> %216 to <4 x double>
  %218 = fsub <4 x double> %202, %217
  %219 = fmul <4 x double> %202, %88
  %220 = fmul <4 x double> %114, %217
  %221 = bitcast <4 x double> %219 to <4 x i64>
  %222 = xor <4 x i64> %221, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %223 = bitcast <4 x i64> %222 to <4 x double>
  %224 = fmul <4 x double> %218, %114
  %225 = fmul <4 x double> %115, %217
  %226 = fmul <4 x double> %115, %218
  %227 = fmul <4 x double> %214, %88
  %228 = fadd <4 x double> %220, %223
  %229 = fadd <4 x double> %224, %228
  %230 = fadd <4 x double> %225, %229
  %231 = fadd <4 x double> %226, %230
  %232 = fadd <4 x double> %227, %231
  %233 = fadd <4 x double> %219, %188
  %234 = fsub <4 x double> %233, %188
  %235 = fsub <4 x double> %233, %234
  %236 = fsub <4 x double> %188, %235
  %237 = fsub <4 x double> %219, %234
  %238 = fadd <4 x double> %237, %236
  %239 = fadd <4 x double> %190, %232
  %240 = fadd <4 x double> %238, %239
  %241 = fadd <4 x double> %233, %240
  %242 = fsub <4 x double> %233, %241
  %243 = fadd <4 x double> %240, %242
  %244 = bitcast <4 x double> %241 to <4 x i64>
  %245 = and <4 x i64> %244, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %246 = bitcast <4 x i64> %245 to <4 x double>
  %247 = fsub <4 x double> %241, %246
  %248 = fmul <4 x double> %241, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %249 = fmul <4 x double> %246, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %250 = bitcast <4 x double> %248 to <4 x i64>
  %251 = xor <4 x i64> %250, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %252 = bitcast <4 x i64> %251 to <4 x double>
  %253 = fmul <4 x double> %247, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %254 = fmul <4 x double> %246, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %255 = fmul <4 x double> %247, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %256 = fmul <4 x double> %241, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %257 = fmul <4 x double> %243, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %258 = fadd <4 x double> %249, %252
  %259 = fadd <4 x double> %253, %258
  %260 = fadd <4 x double> %254, %259
  %261 = fadd <4 x double> %255, %260
  %262 = fadd <4 x double> %256, %261
  %263 = fadd <4 x double> %257, %262
  %264 = and <4 x i64> %87, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %265 = bitcast <4 x i64> %264 to <4 x double>
  %266 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %265, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %267 = bitcast <4 x double> %266 to <4 x i64>
  %268 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %248, <4 x double> %88, <4 x double> %266) #6
  %269 = bitcast <4 x double> %263 to <4 x i64>
  %270 = xor <4 x i64> %267, <i64 -1, i64 -1, i64 -1, i64 -1>
  %271 = and <4 x i64> %269, %270
  %272 = shl <4 x i32> %187, <i32 1, i32 1, i32 1, i32 1>
  %273 = and <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %268, <4 x double> zeroinitializer, i8 30) #6
  %275 = bitcast <4 x double> %274 to <4 x i64>
  %276 = and <4 x i64> %275, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %277 = bitcast <4 x i64> %276 to <4 x double>
  %278 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %277) #6
  %279 = bitcast <4 x i32> %278 to <16 x i8>
  %280 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0>, <16 x i8> <i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0>, <16 x i8> %279) #6
  %281 = bitcast <16 x i8> %280 to <4 x i32>
  %282 = add <4 x i32> %273, %281
  %283 = ashr <4 x i32> %282, <i32 1, i32 1, i32 1, i32 1>
  %284 = and <4 x i32> %187, <i32 1, i32 1, i32 1, i32 1>
  %285 = icmp eq <4 x i32> %284, zeroinitializer
  %286 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> zeroinitializer, <4 x double> %274) #6
  %287 = bitcast <4 x double> %286 to <4 x i64>
  %288 = and <4 x i64> %287, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %289 = xor <4 x i64> %288, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %290 = bitcast <4 x i64> %289 to <4 x double>
  %291 = xor <4 x i64> %288, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %292 = bitcast <4 x i64> %291 to <4 x double>
  %293 = bitcast <4 x i64> %271 to <4 x double>
  %294 = fadd <4 x double> %268, %290
  %295 = fsub <4 x double> %294, %268
  %296 = fsub <4 x double> %294, %295
  %297 = fsub <4 x double> %268, %296
  %298 = fsub <4 x double> %290, %295
  %299 = fadd <4 x double> %298, %297
  %300 = fadd <4 x double> %292, %293
  %301 = fadd <4 x double> %299, %300
  %302 = sitofp <4 x i1> %285 to <4 x double>
  %303 = fcmp oeq <4 x double> %302, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %304 = sext <4 x i1> %303 to <4 x i64>
  %305 = bitcast <4 x i64> %304 to <4 x double>
  %306 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %268, <4 x double> %294, <4 x double> %305) #6
  %307 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %293, <4 x double> %301, <4 x double> %305) #6
  %308 = fadd <4 x double> %306, %307
  %309 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %310 = fcmp uno <4 x double> %0, zeroinitializer
  %311 = or <4 x i1> %309, %310
  %312 = select <4 x i1> %311, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %308
  br label %313

; <label>:313:                                    ; preds = %31, %59, %12
  %314 = phi <4 x i32> [ %18, %12 ], [ %42, %31 ], [ %283, %59 ]
  %315 = phi <4 x double> [ %22, %12 ], [ %58, %31 ], [ %312, %59 ]
  %316 = fmul <4 x double> %315, %315
  %317 = and <4 x i32> %314, <i32 2, i32 2, i32 2, i32 2>
  %318 = icmp eq <4 x i32> %317, zeroinitializer
  %319 = sitofp <4 x i1> %318 to <4 x double>
  %320 = fcmp oeq <4 x double> %319, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %321 = select <4 x i1> %320, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %322 = bitcast <4 x double> %315 to <4 x i64>
  %323 = xor <4 x i64> %321, %322
  %324 = bitcast <4 x i64> %323 to <4 x double>
  %325 = fmul <4 x double> %316, %316
  %326 = fmul <4 x double> %325, %325
  %327 = fmul <4 x double> %316, <double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE>
  %328 = fadd <4 x double> %327, <double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592>
  %329 = fmul <4 x double> %316, <double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF>
  %330 = fadd <4 x double> %329, <double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966>
  %331 = fmul <4 x double> %325, %328
  %332 = fadd <4 x double> %330, %331
  %333 = fmul <4 x double> %316, <double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786>
  %334 = fadd <4 x double> %333, <double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50>
  %335 = fmul <4 x double> %316, <double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7>
  %336 = fadd <4 x double> %335, <double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F>
  %337 = fmul <4 x double> %325, %334
  %338 = fadd <4 x double> %336, %337
  %339 = fmul <4 x double> %326, %332
  %340 = fadd <4 x double> %338, %339
  %341 = fmul <4 x double> %316, %340
  %342 = fadd <4 x double> %341, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %343 = fmul <4 x double> %342, %324
  %344 = fmul <4 x double> %316, %343
  %345 = fadd <4 x double> %344, %324
  ret <4 x double> %345
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cosd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %31, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %14 = fadd <4 x double> %13, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %15 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %14, i32 8) #6
  %16 = fmul <4 x double> %15, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %17 = fadd <4 x double> %16, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %17) #6
  %19 = fmul <4 x double> %17, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %20 = fadd <4 x double> %19, %0
  %21 = fsub <4 x double> %20, %0
  %22 = fsub <4 x double> %20, %21
  %23 = fsub <4 x double> %0, %22
  %24 = fsub <4 x double> %19, %21
  %25 = fadd <4 x double> %24, %23
  %26 = fmul <4 x double> %17, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %27 = fadd <4 x double> %26, %20
  %28 = fsub <4 x double> %20, %27
  %29 = fadd <4 x double> %26, %28
  %30 = fadd <4 x double> %29, %25
  br label %355

; <label>:31:                                     ; preds = %1
  %32 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %33 = bitcast <4 x double> %32 to <4 x i64>
  %34 = shufflevector <4 x i64> %33, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %35 = shufflevector <4 x i64> %33, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %36 = and <2 x i64> %35, %34
  %37 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %36, <2 x i64> <i64 -1, i64 -1>) #6
  %38 = icmp eq i32 %37, 0
  br i1 %38, label %99, label %39, !prof !2

; <label>:39:                                     ; preds = %31
  %40 = fmul <4 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %41 = fadd <4 x double> %40, <double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883>
  %42 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %41, i32 11) #6
  %43 = fmul <4 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %44 = fmul <4 x double> %42, <double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000>
  %45 = fadd <4 x double> %44, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %46 = fadd <4 x double> %43, %45
  %47 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %46) #6
  %48 = fmul <4 x double> %42, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %49 = shl <4 x i32> %47, <i32 1, i32 1, i32 1, i32 1>
  %50 = or <4 x i32> %49, <i32 1, i32 1, i32 1, i32 1>
  %51 = sitofp <4 x i32> %50 to <4 x double>
  %52 = fmul <4 x double> %48, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %53 = fadd <4 x double> %52, %0
  %54 = fmul <4 x double> %51, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %55 = fadd <4 x double> %53, %54
  %56 = fsub <4 x double> %55, %53
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> %53, %57
  %59 = fsub <4 x double> %54, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fmul <4 x double> %48, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %62 = fadd <4 x double> %61, %55
  %63 = fsub <4 x double> %62, %55
  %64 = fsub <4 x double> %62, %63
  %65 = fsub <4 x double> %55, %64
  %66 = fsub <4 x double> %61, %63
  %67 = fadd <4 x double> %66, %65
  %68 = fadd <4 x double> %60, %67
  %69 = fmul <4 x double> %51, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %70 = fadd <4 x double> %69, %62
  %71 = fsub <4 x double> %70, %62
  %72 = fsub <4 x double> %70, %71
  %73 = fsub <4 x double> %62, %72
  %74 = fsub <4 x double> %69, %71
  %75 = fadd <4 x double> %74, %73
  %76 = fadd <4 x double> %75, %68
  %77 = fmul <4 x double> %48, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %78 = fadd <4 x double> %77, %70
  %79 = fsub <4 x double> %78, %70
  %80 = fsub <4 x double> %78, %79
  %81 = fsub <4 x double> %70, %80
  %82 = fsub <4 x double> %77, %79
  %83 = fadd <4 x double> %82, %81
  %84 = fadd <4 x double> %83, %76
  %85 = fmul <4 x double> %51, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %86 = fadd <4 x double> %85, %78
  %87 = fsub <4 x double> %86, %78
  %88 = fsub <4 x double> %86, %87
  %89 = fsub <4 x double> %78, %88
  %90 = fsub <4 x double> %85, %87
  %91 = fadd <4 x double> %90, %89
  %92 = fadd <4 x double> %91, %84
  %93 = fadd <4 x double> %48, %51
  %94 = fmul <4 x double> %93, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %95 = fadd <4 x double> %94, %86
  %96 = fsub <4 x double> %86, %95
  %97 = fadd <4 x double> %94, %96
  %98 = fadd <4 x double> %97, %92
  br label %355

; <label>:99:                                     ; preds = %31
  %100 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %101 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %102 = bitcast <2 x i64> %100 to <4 x i32>
  %103 = shufflevector <4 x i32> %102, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %104 = bitcast <4 x i32> %103 to <2 x i64>
  %105 = bitcast <2 x i64> %101 to <4 x i32>
  %106 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <2 x i64> %107, <2 x i64> %104, <2 x i32> <i32 2, i32 1>
  %109 = bitcast <2 x i64> %108 to <4 x i32>
  %110 = lshr <4 x i32> %109, <i32 20, i32 20, i32 20, i32 20>
  %111 = and <4 x i32> %110, <i32 2047, i32 2047, i32 2047, i32 2047>
  %112 = add nsw <4 x i32> %111, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %113 = icmp ugt <4 x i32> %111, <i32 1723, i32 1723, i32 1723, i32 1723>
  %114 = select <4 x i1> %113, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %115 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %116 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %117 = and <4 x i32> %115, <i32 0, i32 -1, i32 0, i32 -1>
  %118 = shl <4 x i32> %117, <i32 20, i32 20, i32 20, i32 20>
  %119 = and <4 x i32> %116, <i32 0, i32 -1, i32 0, i32 -1>
  %120 = shl <4 x i32> %119, <i32 20, i32 20, i32 20, i32 20>
  %121 = add <4 x i32> %118, %102
  %122 = add <4 x i32> %120, %105
  %123 = bitcast <4 x i32> %121 to <2 x i64>
  %124 = bitcast <4 x i32> %122 to <2 x i64>
  %125 = shufflevector <2 x i64> %123, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %126 = shufflevector <2 x i64> %124, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %127 = shufflevector <4 x i64> %125, <4 x i64> %126, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %128 = bitcast <4 x i64> %127 to <4 x double>
  %129 = ashr <4 x i32> %112, <i32 31, i32 31, i32 31, i32 31>
  %130 = xor <4 x i32> %129, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %131 = and <4 x i32> %130, %112
  %132 = shl <4 x i32> %131, <i32 2, i32 2, i32 2, i32 2>
  %133 = extractelement <4 x i32> %132, i32 3
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %134
  %136 = load double, double* %135, align 8, !tbaa !3, !noalias !16
  %137 = extractelement <4 x i32> %132, i32 2
  %138 = sext i32 %137 to i64
  %139 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %138
  %140 = load double, double* %139, align 8, !tbaa !3, !noalias !16
  %141 = extractelement <4 x i32> %132, i32 1
  %142 = sext i32 %141 to i64
  %143 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %142
  %144 = load double, double* %143, align 8, !tbaa !3, !noalias !16
  %145 = extractelement <4 x i32> %132, i32 0
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %146
  %148 = load double, double* %147, align 8, !tbaa !3, !noalias !16
  %149 = insertelement <4 x double> undef, double %148, i32 0
  %150 = insertelement <4 x double> %149, double %144, i32 1
  %151 = insertelement <4 x double> %150, double %140, i32 2
  %152 = insertelement <4 x double> %151, double %136, i32 3
  %153 = and <4 x i64> %127, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %154 = bitcast <4 x i64> %153 to <4 x double>
  %155 = fsub <4 x double> %128, %154
  %156 = bitcast <4 x double> %152 to <4 x i64>
  %157 = and <4 x i64> %156, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %158 = bitcast <4 x i64> %157 to <4 x double>
  %159 = fsub <4 x double> %152, %158
  %160 = fmul <4 x double> %152, %128
  %161 = fmul <4 x double> %154, %158
  %162 = bitcast <4 x double> %160 to <4 x i64>
  %163 = xor <4 x i64> %162, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %164 = bitcast <4 x i64> %163 to <4 x double>
  %165 = fmul <4 x double> %155, %158
  %166 = fmul <4 x double> %159, %154
  %167 = fmul <4 x double> %155, %159
  %168 = fadd <4 x double> %161, %164
  %169 = fadd <4 x double> %165, %168
  %170 = fadd <4 x double> %166, %169
  %171 = fadd <4 x double> %167, %170
  %172 = fmul <4 x double> %160, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %173 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %172, i32 8) #6
  %174 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %160, i32 8) #6
  %175 = fmul <4 x double> %174, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %176 = fsub <4 x double> %173, %175
  %177 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %176) #6
  %178 = fmul <4 x double> %173, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %179 = fsub <4 x double> %160, %178
  %180 = fadd <4 x double> %179, %171
  %181 = fsub <4 x double> %179, %180
  %182 = fadd <4 x double> %171, %181
  %183 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %134
  %184 = load double, double* %183, align 8, !tbaa !3, !noalias !16
  %185 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %138
  %186 = load double, double* %185, align 8, !tbaa !3, !noalias !16
  %187 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %142
  %188 = load double, double* %187, align 8, !tbaa !3, !noalias !16
  %189 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %146
  %190 = load double, double* %189, align 8, !tbaa !3, !noalias !16
  %191 = insertelement <4 x double> undef, double %190, i32 0
  %192 = insertelement <4 x double> %191, double %188, i32 1
  %193 = insertelement <4 x double> %192, double %186, i32 2
  %194 = insertelement <4 x double> %193, double %184, i32 3
  %195 = bitcast <4 x double> %194 to <4 x i64>
  %196 = and <4 x i64> %195, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %197 = bitcast <4 x i64> %196 to <4 x double>
  %198 = fsub <4 x double> %194, %197
  %199 = fmul <4 x double> %194, %128
  %200 = fmul <4 x double> %154, %197
  %201 = bitcast <4 x double> %199 to <4 x i64>
  %202 = xor <4 x i64> %201, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %203 = bitcast <4 x i64> %202 to <4 x double>
  %204 = fmul <4 x double> %155, %197
  %205 = fmul <4 x double> %198, %154
  %206 = fmul <4 x double> %155, %198
  %207 = fadd <4 x double> %200, %203
  %208 = fadd <4 x double> %204, %207
  %209 = fadd <4 x double> %205, %208
  %210 = fadd <4 x double> %206, %209
  %211 = fadd <4 x double> %199, %180
  %212 = fsub <4 x double> %211, %180
  %213 = fsub <4 x double> %211, %212
  %214 = fsub <4 x double> %180, %213
  %215 = fsub <4 x double> %199, %212
  %216 = fadd <4 x double> %215, %214
  %217 = fadd <4 x double> %182, %210
  %218 = fadd <4 x double> %216, %217
  %219 = fmul <4 x double> %211, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %220 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %219, i32 8) #6
  %221 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %211, i32 8) #6
  %222 = fmul <4 x double> %221, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %223 = fsub <4 x double> %220, %222
  %224 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %223) #6
  %225 = fmul <4 x double> %220, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %226 = fsub <4 x double> %211, %225
  %227 = add <4 x i32> %224, %177
  %228 = fadd <4 x double> %226, %218
  %229 = fsub <4 x double> %226, %228
  %230 = fadd <4 x double> %218, %229
  %231 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %134
  %232 = load double, double* %231, align 8, !tbaa !3, !noalias !16
  %233 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %138
  %234 = load double, double* %233, align 8, !tbaa !3, !noalias !16
  %235 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %142
  %236 = load double, double* %235, align 8, !tbaa !3, !noalias !16
  %237 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %146
  %238 = load double, double* %237, align 8, !tbaa !3, !noalias !16
  %239 = insertelement <4 x double> undef, double %238, i32 0
  %240 = insertelement <4 x double> %239, double %236, i32 1
  %241 = insertelement <4 x double> %240, double %234, i32 2
  %242 = insertelement <4 x double> %241, double %232, i32 3
  %243 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %134
  %244 = load double, double* %243, align 8, !tbaa !3, !noalias !16
  %245 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %138
  %246 = load double, double* %245, align 8, !tbaa !3, !noalias !16
  %247 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %142
  %248 = load double, double* %247, align 8, !tbaa !3, !noalias !16
  %249 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %146
  %250 = load double, double* %249, align 8, !tbaa !3, !noalias !16
  %251 = insertelement <4 x double> undef, double %250, i32 0
  %252 = insertelement <4 x double> %251, double %248, i32 1
  %253 = insertelement <4 x double> %252, double %246, i32 2
  %254 = insertelement <4 x double> %253, double %244, i32 3
  %255 = bitcast <4 x double> %242 to <4 x i64>
  %256 = and <4 x i64> %255, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %257 = bitcast <4 x i64> %256 to <4 x double>
  %258 = fsub <4 x double> %242, %257
  %259 = fmul <4 x double> %242, %128
  %260 = fmul <4 x double> %154, %257
  %261 = bitcast <4 x double> %259 to <4 x i64>
  %262 = xor <4 x i64> %261, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %263 = bitcast <4 x i64> %262 to <4 x double>
  %264 = fmul <4 x double> %258, %154
  %265 = fmul <4 x double> %155, %257
  %266 = fmul <4 x double> %155, %258
  %267 = fmul <4 x double> %254, %128
  %268 = fadd <4 x double> %260, %263
  %269 = fadd <4 x double> %264, %268
  %270 = fadd <4 x double> %265, %269
  %271 = fadd <4 x double> %266, %270
  %272 = fadd <4 x double> %267, %271
  %273 = fadd <4 x double> %259, %228
  %274 = fsub <4 x double> %273, %228
  %275 = fsub <4 x double> %273, %274
  %276 = fsub <4 x double> %228, %275
  %277 = fsub <4 x double> %259, %274
  %278 = fadd <4 x double> %277, %276
  %279 = fadd <4 x double> %230, %272
  %280 = fadd <4 x double> %278, %279
  %281 = fadd <4 x double> %273, %280
  %282 = fsub <4 x double> %273, %281
  %283 = fadd <4 x double> %280, %282
  %284 = bitcast <4 x double> %281 to <4 x i64>
  %285 = and <4 x i64> %284, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %286 = bitcast <4 x i64> %285 to <4 x double>
  %287 = fsub <4 x double> %281, %286
  %288 = fmul <4 x double> %281, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %289 = fmul <4 x double> %286, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %290 = bitcast <4 x double> %288 to <4 x i64>
  %291 = xor <4 x i64> %290, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %292 = bitcast <4 x i64> %291 to <4 x double>
  %293 = fmul <4 x double> %287, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %294 = fmul <4 x double> %286, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %295 = fmul <4 x double> %287, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %296 = fmul <4 x double> %281, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %297 = fmul <4 x double> %283, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %298 = fadd <4 x double> %289, %292
  %299 = fadd <4 x double> %293, %298
  %300 = fadd <4 x double> %294, %299
  %301 = fadd <4 x double> %295, %300
  %302 = fadd <4 x double> %296, %301
  %303 = fadd <4 x double> %297, %302
  %304 = and <4 x i64> %127, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %305 = bitcast <4 x i64> %304 to <4 x double>
  %306 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %305, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %307 = bitcast <4 x double> %306 to <4 x i64>
  %308 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %288, <4 x double> %128, <4 x double> %306) #6
  %309 = bitcast <4 x double> %303 to <4 x i64>
  %310 = xor <4 x i64> %307, <i64 -1, i64 -1, i64 -1, i64 -1>
  %311 = and <4 x i64> %309, %310
  %312 = shl <4 x i32> %227, <i32 1, i32 1, i32 1, i32 1>
  %313 = and <4 x i32> %312, <i32 6, i32 6, i32 6, i32 6>
  %314 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %308, <4 x double> zeroinitializer, i8 30) #6
  %315 = bitcast <4 x double> %314 to <4 x i64>
  %316 = and <4 x i64> %315, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %317 = bitcast <4 x i64> %316 to <4 x double>
  %318 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %317) #6
  %319 = bitcast <4 x i32> %318 to <16 x i8>
  %320 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0, i8 7, i8 0, i8 0, i8 0>, <16 x i8> <i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0, i8 8, i8 0, i8 0, i8 0>, <16 x i8> %319) #6
  %321 = bitcast <16 x i8> %320 to <4 x i32>
  %322 = add <4 x i32> %313, %321
  %323 = ashr <4 x i32> %322, <i32 1, i32 1, i32 1, i32 1>
  %324 = and <4 x i32> %227, <i32 1, i32 1, i32 1, i32 1>
  %325 = icmp eq <4 x i32> %324, zeroinitializer
  %326 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> zeroinitializer, <4 x double> %314) #6
  %327 = bitcast <4 x double> %326 to <4 x i64>
  %328 = and <4 x i64> %327, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %329 = xor <4 x i64> %328, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %330 = bitcast <4 x i64> %329 to <4 x double>
  %331 = xor <4 x i64> %328, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %332 = bitcast <4 x i64> %331 to <4 x double>
  %333 = bitcast <4 x i64> %311 to <4 x double>
  %334 = fadd <4 x double> %308, %330
  %335 = fsub <4 x double> %334, %308
  %336 = fsub <4 x double> %334, %335
  %337 = fsub <4 x double> %308, %336
  %338 = fsub <4 x double> %330, %335
  %339 = fadd <4 x double> %338, %337
  %340 = fadd <4 x double> %332, %333
  %341 = fadd <4 x double> %339, %340
  %342 = sitofp <4 x i1> %325 to <4 x double>
  %343 = fcmp oeq <4 x double> %342, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %344 = sext <4 x i1> %343 to <4 x i64>
  %345 = bitcast <4 x i64> %344 to <4 x double>
  %346 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %308, <4 x double> %334, <4 x double> %345) #6
  %347 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %333, <4 x double> %341, <4 x double> %345) #6
  %348 = fadd <4 x double> %346, %347
  %349 = fsub <4 x double> %346, %348
  %350 = fadd <4 x double> %347, %349
  %351 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %352 = fcmp uno <4 x double> %0, zeroinitializer
  %353 = or <4 x i1> %351, %352
  %354 = select <4 x i1> %353, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %348
  br label %355

; <label>:355:                                    ; preds = %39, %99, %12
  %356 = phi <4 x double> [ %354, %99 ], [ %95, %39 ], [ %27, %12 ]
  %357 = phi <4 x double> [ %350, %99 ], [ %98, %39 ], [ %30, %12 ]
  %358 = phi <4 x i32> [ %323, %99 ], [ %50, %39 ], [ %18, %12 ]
  %359 = bitcast <4 x double> %356 to <4 x i64>
  %360 = and <4 x i64> %359, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %361 = bitcast <4 x i64> %360 to <4 x double>
  %362 = fsub <4 x double> %356, %361
  %363 = fmul <4 x double> %356, %356
  %364 = fmul <4 x double> %361, %361
  %365 = bitcast <4 x double> %363 to <4 x i64>
  %366 = xor <4 x i64> %365, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %367 = bitcast <4 x i64> %366 to <4 x double>
  %368 = fadd <4 x double> %361, %361
  %369 = fmul <4 x double> %368, %362
  %370 = fmul <4 x double> %362, %362
  %371 = fadd <4 x double> %357, %357
  %372 = fmul <4 x double> %356, %371
  %373 = fadd <4 x double> %364, %367
  %374 = fadd <4 x double> %373, %369
  %375 = fadd <4 x double> %370, %374
  %376 = fadd <4 x double> %372, %375
  %377 = fmul <4 x double> %363, %363
  %378 = fmul <4 x double> %377, %377
  %379 = fmul <4 x double> %363, <double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D>
  %380 = fadd <4 x double> %379, <double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350>
  %381 = fmul <4 x double> %363, <double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67>
  %382 = fadd <4 x double> %381, <double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959>
  %383 = fmul <4 x double> %363, <double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED>
  %384 = fadd <4 x double> %383, <double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225>
  %385 = fmul <4 x double> %377, %382
  %386 = fadd <4 x double> %384, %385
  %387 = fmul <4 x double> %378, %380
  %388 = fadd <4 x double> %387, %386
  %389 = fmul <4 x double> %363, %388
  %390 = fadd <4 x double> %389, <double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9>
  %391 = fmul <4 x double> %363, %390
  %392 = fadd <4 x double> %391, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %393 = fsub <4 x double> <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>, %392
  %394 = fadd <4 x double> %391, %393
  %395 = bitcast <4 x double> %392 to <4 x i64>
  %396 = and <4 x i64> %395, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %397 = bitcast <4 x i64> %396 to <4 x double>
  %398 = fsub <4 x double> %392, %397
  %399 = and <4 x i64> %365, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %400 = bitcast <4 x i64> %399 to <4 x double>
  %401 = fsub <4 x double> %363, %400
  %402 = fmul <4 x double> %363, %392
  %403 = fmul <4 x double> %400, %397
  %404 = bitcast <4 x double> %402 to <4 x i64>
  %405 = xor <4 x i64> %404, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %406 = bitcast <4 x i64> %405 to <4 x double>
  %407 = fmul <4 x double> %398, %400
  %408 = fmul <4 x double> %401, %397
  %409 = fmul <4 x double> %401, %398
  %410 = fmul <4 x double> %376, %392
  %411 = fmul <4 x double> %363, %394
  %412 = fadd <4 x double> %403, %406
  %413 = fadd <4 x double> %407, %412
  %414 = fadd <4 x double> %408, %413
  %415 = fadd <4 x double> %409, %414
  %416 = fadd <4 x double> %410, %415
  %417 = fadd <4 x double> %411, %416
  %418 = fadd <4 x double> %402, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %419 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %418
  %420 = fadd <4 x double> %402, %419
  %421 = fadd <4 x double> %420, %417
  %422 = bitcast <4 x double> %418 to <4 x i64>
  %423 = and <4 x i64> %422, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %424 = bitcast <4 x i64> %423 to <4 x double>
  %425 = fsub <4 x double> %418, %424
  %426 = fmul <4 x double> %357, %424
  %427 = fmul <4 x double> %421, %361
  %428 = fmul <4 x double> %362, %425
  %429 = fmul <4 x double> %425, %361
  %430 = fmul <4 x double> %362, %424
  %431 = fmul <4 x double> %361, %424
  %432 = fadd <4 x double> %426, %427
  %433 = fadd <4 x double> %428, %432
  %434 = fadd <4 x double> %429, %433
  %435 = fadd <4 x double> %430, %434
  %436 = fadd <4 x double> %431, %435
  %437 = and <4 x i32> %358, <i32 2, i32 2, i32 2, i32 2>
  %438 = icmp eq <4 x i32> %437, zeroinitializer
  %439 = sitofp <4 x i1> %438 to <4 x double>
  %440 = fcmp oeq <4 x double> %439, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %441 = select <4 x i1> %440, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %442 = bitcast <4 x double> %436 to <4 x i64>
  %443 = xor <4 x i64> %441, %442
  %444 = bitcast <4 x i64> %443 to <4 x double>
  ret <4 x double> %444
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincosd4_u35avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = bitcast <4 x double> %1 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = and <2 x i64> %9, %8
  %11 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %10, <2 x i64> <i64 -1, i64 -1>) #6
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %21, label %13, !prof !2

; <label>:13:                                     ; preds = %2
  %14 = fmul <4 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %15 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %14, i32 8) #6
  %16 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %15) #6
  %17 = fmul <4 x double> %15, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %18 = fadd <4 x double> %17, %1
  %19 = fmul <4 x double> %15, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %20 = fadd <4 x double> %19, %18
  br label %271

; <label>:21:                                     ; preds = %2
  %22 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %23 = bitcast <4 x double> %22 to <4 x i64>
  %24 = shufflevector <4 x i64> %23, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %25 = shufflevector <4 x i64> %23, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %26 = and <2 x i64> %25, %24
  %27 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %26, <2 x i64> <i64 -1, i64 -1>) #6
  %28 = icmp eq i32 %27, 0
  br i1 %28, label %52, label %29, !prof !2

; <label>:29:                                     ; preds = %21
  %30 = fmul <4 x double> %1, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %31 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %30, i32 11) #6
  %32 = fmul <4 x double> %31, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %33 = fmul <4 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %34 = fsub <4 x double> %33, %32
  %35 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %34, i32 8) #6
  %36 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %35) #6
  %37 = fmul <4 x double> %32, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %38 = fadd <4 x double> %37, %1
  %39 = fmul <4 x double> %35, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %40 = fadd <4 x double> %39, %38
  %41 = fmul <4 x double> %32, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %42 = fadd <4 x double> %41, %40
  %43 = fmul <4 x double> %35, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %44 = fadd <4 x double> %43, %42
  %45 = fmul <4 x double> %32, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %46 = fadd <4 x double> %45, %44
  %47 = fmul <4 x double> %35, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %48 = fadd <4 x double> %47, %46
  %49 = fadd <4 x double> %32, %35
  %50 = fmul <4 x double> %49, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %51 = fadd <4 x double> %50, %48
  br label %271

; <label>:52:                                     ; preds = %21
  %53 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %54 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %55 = bitcast <2 x i64> %53 to <4 x i32>
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = bitcast <2 x i64> %54 to <4 x i32>
  %59 = shufflevector <4 x i32> %58, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %60 = bitcast <4 x i32> %59 to <2 x i64>
  %61 = shufflevector <2 x i64> %60, <2 x i64> %57, <2 x i32> <i32 2, i32 1>
  %62 = bitcast <2 x i64> %61 to <4 x i32>
  %63 = lshr <4 x i32> %62, <i32 20, i32 20, i32 20, i32 20>
  %64 = and <4 x i32> %63, <i32 2047, i32 2047, i32 2047, i32 2047>
  %65 = add nsw <4 x i32> %64, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %66 = icmp ugt <4 x i32> %64, <i32 1723, i32 1723, i32 1723, i32 1723>
  %67 = select <4 x i1> %66, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %69 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %70 = and <4 x i32> %68, <i32 0, i32 -1, i32 0, i32 -1>
  %71 = shl <4 x i32> %70, <i32 20, i32 20, i32 20, i32 20>
  %72 = and <4 x i32> %69, <i32 0, i32 -1, i32 0, i32 -1>
  %73 = shl <4 x i32> %72, <i32 20, i32 20, i32 20, i32 20>
  %74 = add <4 x i32> %71, %55
  %75 = add <4 x i32> %73, %58
  %76 = bitcast <4 x i32> %74 to <2 x i64>
  %77 = bitcast <4 x i32> %75 to <2 x i64>
  %78 = shufflevector <2 x i64> %76, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %79 = shufflevector <2 x i64> %77, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %80 = shufflevector <4 x i64> %78, <4 x i64> %79, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %81 = bitcast <4 x i64> %80 to <4 x double>
  %82 = ashr <4 x i32> %65, <i32 31, i32 31, i32 31, i32 31>
  %83 = xor <4 x i32> %82, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %84 = and <4 x i32> %83, %65
  %85 = shl <4 x i32> %84, <i32 2, i32 2, i32 2, i32 2>
  %86 = extractelement <4 x i32> %85, i32 3
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %87
  %89 = load double, double* %88, align 8, !tbaa !3, !noalias !19
  %90 = extractelement <4 x i32> %85, i32 2
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %91
  %93 = load double, double* %92, align 8, !tbaa !3, !noalias !19
  %94 = extractelement <4 x i32> %85, i32 1
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %95
  %97 = load double, double* %96, align 8, !tbaa !3, !noalias !19
  %98 = extractelement <4 x i32> %85, i32 0
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %99
  %101 = load double, double* %100, align 8, !tbaa !3, !noalias !19
  %102 = insertelement <4 x double> undef, double %101, i32 0
  %103 = insertelement <4 x double> %102, double %97, i32 1
  %104 = insertelement <4 x double> %103, double %93, i32 2
  %105 = insertelement <4 x double> %104, double %89, i32 3
  %106 = and <4 x i64> %80, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %107 = bitcast <4 x i64> %106 to <4 x double>
  %108 = fsub <4 x double> %81, %107
  %109 = bitcast <4 x double> %105 to <4 x i64>
  %110 = and <4 x i64> %109, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = fsub <4 x double> %105, %111
  %113 = fmul <4 x double> %105, %81
  %114 = fmul <4 x double> %107, %111
  %115 = bitcast <4 x double> %113 to <4 x i64>
  %116 = xor <4 x i64> %115, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %117 = bitcast <4 x i64> %116 to <4 x double>
  %118 = fmul <4 x double> %108, %111
  %119 = fmul <4 x double> %112, %107
  %120 = fmul <4 x double> %108, %112
  %121 = fadd <4 x double> %114, %117
  %122 = fadd <4 x double> %118, %121
  %123 = fadd <4 x double> %119, %122
  %124 = fadd <4 x double> %120, %123
  %125 = fmul <4 x double> %113, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %126 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %125, i32 8) #6
  %127 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %113, i32 8) #6
  %128 = fmul <4 x double> %127, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %129 = fsub <4 x double> %126, %128
  %130 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %129) #6
  %131 = fmul <4 x double> %126, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %132 = fsub <4 x double> %113, %131
  %133 = fadd <4 x double> %132, %124
  %134 = fsub <4 x double> %132, %133
  %135 = fadd <4 x double> %124, %134
  %136 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %87
  %137 = load double, double* %136, align 8, !tbaa !3, !noalias !19
  %138 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %91
  %139 = load double, double* %138, align 8, !tbaa !3, !noalias !19
  %140 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %95
  %141 = load double, double* %140, align 8, !tbaa !3, !noalias !19
  %142 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %99
  %143 = load double, double* %142, align 8, !tbaa !3, !noalias !19
  %144 = insertelement <4 x double> undef, double %143, i32 0
  %145 = insertelement <4 x double> %144, double %141, i32 1
  %146 = insertelement <4 x double> %145, double %139, i32 2
  %147 = insertelement <4 x double> %146, double %137, i32 3
  %148 = bitcast <4 x double> %147 to <4 x i64>
  %149 = and <4 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fsub <4 x double> %147, %150
  %152 = fmul <4 x double> %147, %81
  %153 = fmul <4 x double> %107, %150
  %154 = bitcast <4 x double> %152 to <4 x i64>
  %155 = xor <4 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fmul <4 x double> %108, %150
  %158 = fmul <4 x double> %151, %107
  %159 = fmul <4 x double> %108, %151
  %160 = fadd <4 x double> %153, %156
  %161 = fadd <4 x double> %157, %160
  %162 = fadd <4 x double> %158, %161
  %163 = fadd <4 x double> %159, %162
  %164 = fadd <4 x double> %152, %133
  %165 = fsub <4 x double> %164, %133
  %166 = fsub <4 x double> %164, %165
  %167 = fsub <4 x double> %133, %166
  %168 = fsub <4 x double> %152, %165
  %169 = fadd <4 x double> %168, %167
  %170 = fadd <4 x double> %135, %163
  %171 = fadd <4 x double> %169, %170
  %172 = fmul <4 x double> %164, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %173 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %172, i32 8) #6
  %174 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %164, i32 8) #6
  %175 = fmul <4 x double> %174, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %176 = fsub <4 x double> %173, %175
  %177 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %176) #6
  %178 = fmul <4 x double> %173, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %179 = fsub <4 x double> %164, %178
  %180 = add <4 x i32> %177, %130
  %181 = fadd <4 x double> %179, %171
  %182 = fsub <4 x double> %179, %181
  %183 = fadd <4 x double> %171, %182
  %184 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %87
  %185 = load double, double* %184, align 8, !tbaa !3, !noalias !19
  %186 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %91
  %187 = load double, double* %186, align 8, !tbaa !3, !noalias !19
  %188 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %95
  %189 = load double, double* %188, align 8, !tbaa !3, !noalias !19
  %190 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %99
  %191 = load double, double* %190, align 8, !tbaa !3, !noalias !19
  %192 = insertelement <4 x double> undef, double %191, i32 0
  %193 = insertelement <4 x double> %192, double %189, i32 1
  %194 = insertelement <4 x double> %193, double %187, i32 2
  %195 = insertelement <4 x double> %194, double %185, i32 3
  %196 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %87
  %197 = load double, double* %196, align 8, !tbaa !3, !noalias !19
  %198 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %91
  %199 = load double, double* %198, align 8, !tbaa !3, !noalias !19
  %200 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %95
  %201 = load double, double* %200, align 8, !tbaa !3, !noalias !19
  %202 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %99
  %203 = load double, double* %202, align 8, !tbaa !3, !noalias !19
  %204 = insertelement <4 x double> undef, double %203, i32 0
  %205 = insertelement <4 x double> %204, double %201, i32 1
  %206 = insertelement <4 x double> %205, double %199, i32 2
  %207 = insertelement <4 x double> %206, double %197, i32 3
  %208 = bitcast <4 x double> %195 to <4 x i64>
  %209 = and <4 x i64> %208, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %210 = bitcast <4 x i64> %209 to <4 x double>
  %211 = fsub <4 x double> %195, %210
  %212 = fmul <4 x double> %195, %81
  %213 = fmul <4 x double> %107, %210
  %214 = bitcast <4 x double> %212 to <4 x i64>
  %215 = xor <4 x i64> %214, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %216 = bitcast <4 x i64> %215 to <4 x double>
  %217 = fmul <4 x double> %211, %107
  %218 = fmul <4 x double> %108, %210
  %219 = fmul <4 x double> %108, %211
  %220 = fmul <4 x double> %207, %81
  %221 = fadd <4 x double> %213, %216
  %222 = fadd <4 x double> %217, %221
  %223 = fadd <4 x double> %218, %222
  %224 = fadd <4 x double> %219, %223
  %225 = fadd <4 x double> %220, %224
  %226 = fadd <4 x double> %212, %181
  %227 = fsub <4 x double> %226, %181
  %228 = fsub <4 x double> %226, %227
  %229 = fsub <4 x double> %181, %228
  %230 = fsub <4 x double> %212, %227
  %231 = fadd <4 x double> %230, %229
  %232 = fadd <4 x double> %183, %225
  %233 = fadd <4 x double> %231, %232
  %234 = fadd <4 x double> %226, %233
  %235 = fsub <4 x double> %226, %234
  %236 = fadd <4 x double> %233, %235
  %237 = bitcast <4 x double> %234 to <4 x i64>
  %238 = and <4 x i64> %237, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %239 = bitcast <4 x i64> %238 to <4 x double>
  %240 = fsub <4 x double> %234, %239
  %241 = fmul <4 x double> %234, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %242 = fmul <4 x double> %239, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %243 = bitcast <4 x double> %241 to <4 x i64>
  %244 = xor <4 x i64> %243, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %245 = bitcast <4 x i64> %244 to <4 x double>
  %246 = fmul <4 x double> %240, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %247 = fmul <4 x double> %239, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %248 = fmul <4 x double> %240, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %249 = fmul <4 x double> %234, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %250 = fmul <4 x double> %236, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %251 = fadd <4 x double> %242, %245
  %252 = fadd <4 x double> %246, %251
  %253 = fadd <4 x double> %247, %252
  %254 = fadd <4 x double> %248, %253
  %255 = fadd <4 x double> %249, %254
  %256 = fadd <4 x double> %250, %255
  %257 = and <4 x i64> %80, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %258 = bitcast <4 x i64> %257 to <4 x double>
  %259 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %258, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %260 = bitcast <4 x double> %259 to <4 x i64>
  %261 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %241, <4 x double> %81, <4 x double> %259) #6
  %262 = bitcast <4 x double> %256 to <4 x i64>
  %263 = xor <4 x i64> %260, <i64 -1, i64 -1, i64 -1, i64 -1>
  %264 = and <4 x i64> %262, %263
  %265 = bitcast <4 x i64> %264 to <4 x double>
  %266 = fadd <4 x double> %261, %265
  %267 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %268 = fcmp uno <4 x double> %1, zeroinitializer
  %269 = or <4 x i1> %267, %268
  %270 = select <4 x i1> %269, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %266
  br label %271

; <label>:271:                                    ; preds = %29, %52, %13
  %272 = phi <4 x i32> [ %16, %13 ], [ %36, %29 ], [ %180, %52 ]
  %273 = phi <4 x double> [ %20, %13 ], [ %51, %29 ], [ %270, %52 ]
  %274 = fmul <4 x double> %273, %273
  %275 = fmul <4 x double> %274, <double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B>
  %276 = fadd <4 x double> %275, <double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8>
  %277 = fmul <4 x double> %274, %276
  %278 = fadd <4 x double> %277, <double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C>
  %279 = fmul <4 x double> %274, %278
  %280 = fadd <4 x double> %279, <double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A>
  %281 = fmul <4 x double> %274, %280
  %282 = fadd <4 x double> %281, <double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135>
  %283 = fmul <4 x double> %274, %282
  %284 = fadd <4 x double> %283, <double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542>
  %285 = fmul <4 x double> %274, %284
  %286 = fmul <4 x double> %273, %285
  %287 = fadd <4 x double> %273, %286
  %288 = xor <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %289 = bitcast <4 x i64> %288 to <4 x double>
  %290 = fcmp oeq <4 x double> %289, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %291 = sext <4 x i1> %290 to <4 x i64>
  %292 = bitcast <4 x i64> %291 to <4 x double>
  %293 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %287, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %292) #6
  %294 = fmul <4 x double> %274, <double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE>
  %295 = fadd <4 x double> %294, <double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05>
  %296 = fmul <4 x double> %274, %295
  %297 = fadd <4 x double> %296, <double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C>
  %298 = fmul <4 x double> %274, %297
  %299 = fadd <4 x double> %298, <double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025>
  %300 = fmul <4 x double> %274, %299
  %301 = fadd <4 x double> %300, <double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96>
  %302 = fmul <4 x double> %274, %301
  %303 = fadd <4 x double> %302, <double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545>
  %304 = fmul <4 x double> %274, %303
  %305 = fadd <4 x double> %304, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %306 = fmul <4 x double> %274, %305
  %307 = fadd <4 x double> %306, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %308 = and <4 x i32> %272, <i32 1, i32 1, i32 1, i32 1>
  %309 = icmp eq <4 x i32> %308, zeroinitializer
  %310 = sitofp <4 x i1> %309 to <4 x double>
  %311 = fcmp oeq <4 x double> %310, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %312 = sext <4 x i1> %311 to <4 x i64>
  %313 = bitcast <4 x i64> %312 to <4 x double>
  %314 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %307, <4 x double> %293, <4 x double> %313) #6
  %315 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %293, <4 x double> %307, <4 x double> %313) #6
  %316 = and <4 x i32> %272, <i32 2, i32 2, i32 2, i32 2>
  %317 = icmp ne <4 x i32> %316, zeroinitializer
  %318 = sitofp <4 x i1> %317 to <4 x double>
  %319 = fcmp oeq <4 x double> %318, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %320 = select <4 x i1> %319, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %321 = bitcast <4 x double> %314 to <4 x i64>
  %322 = xor <4 x i64> %320, %321
  %323 = add <4 x i32> %272, <i32 1, i32 1, i32 1, i32 1>
  %324 = and <4 x i32> %323, <i32 2, i32 2, i32 2, i32 2>
  %325 = icmp ne <4 x i32> %324, zeroinitializer
  %326 = sitofp <4 x i1> %325 to <4 x double>
  %327 = fcmp oeq <4 x double> %326, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %328 = select <4 x i1> %327, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %329 = bitcast <4 x double> %315 to <4 x i64>
  %330 = xor <4 x i64> %328, %329
  %331 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %322, <4 x i64>* %331, align 32
  %332 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %333 = bitcast <4 x double>* %332 to <4 x i64>*
  store <4 x i64> %330, <4 x i64>* %333, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincosd4_u10avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = bitcast <4 x double> %1 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = and <2 x i64> %9, %8
  %11 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %10, <2 x i64> <i64 -1, i64 -1>) #6
  %12 = icmp eq i32 %11, 0
  br i1 %12, label %24, label %13, !prof !2

; <label>:13:                                     ; preds = %2
  %14 = fmul <4 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %15 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %14, i32 8) #6
  %16 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %15) #6
  %17 = fmul <4 x double> %15, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %18 = fadd <4 x double> %17, %1
  %19 = fmul <4 x double> %15, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %20 = fadd <4 x double> %19, %18
  %21 = fsub <4 x double> %18, %20
  %22 = fadd <4 x double> %19, %21
  %23 = bitcast <4 x double> %22 to <4 x i64>
  br label %306

; <label>:24:                                     ; preds = %2
  %25 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %26 = bitcast <4 x double> %25 to <4 x i64>
  %27 = shufflevector <4 x i64> %26, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %28 = shufflevector <4 x i64> %26, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %29 = and <2 x i64> %28, %27
  %30 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %29, <2 x i64> <i64 -1, i64 -1>) #6
  %31 = icmp eq i32 %30, 0
  br i1 %31, label %85, label %32, !prof !2

; <label>:32:                                     ; preds = %24
  %33 = fmul <4 x double> %1, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %34 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %33, i32 11) #6
  %35 = fmul <4 x double> %34, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %36 = fmul <4 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %37 = fsub <4 x double> %36, %35
  %38 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %37, i32 8) #6
  %39 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %38) #6
  %40 = fmul <4 x double> %35, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %41 = fadd <4 x double> %40, %1
  %42 = fmul <4 x double> %38, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %43 = fadd <4 x double> %42, %41
  %44 = fsub <4 x double> %41, %43
  %45 = fadd <4 x double> %42, %44
  %46 = fmul <4 x double> %35, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %47 = fadd <4 x double> %46, %43
  %48 = fsub <4 x double> %47, %43
  %49 = fsub <4 x double> %47, %48
  %50 = fsub <4 x double> %43, %49
  %51 = fsub <4 x double> %46, %48
  %52 = fadd <4 x double> %51, %50
  %53 = fadd <4 x double> %45, %52
  %54 = fmul <4 x double> %38, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %55 = fadd <4 x double> %54, %47
  %56 = fsub <4 x double> %55, %47
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> %47, %57
  %59 = fsub <4 x double> %54, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fadd <4 x double> %60, %53
  %62 = fmul <4 x double> %35, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %63 = fadd <4 x double> %62, %55
  %64 = fsub <4 x double> %63, %55
  %65 = fsub <4 x double> %63, %64
  %66 = fsub <4 x double> %55, %65
  %67 = fsub <4 x double> %62, %64
  %68 = fadd <4 x double> %67, %66
  %69 = fadd <4 x double> %68, %61
  %70 = fmul <4 x double> %38, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %71 = fadd <4 x double> %70, %63
  %72 = fsub <4 x double> %71, %63
  %73 = fsub <4 x double> %71, %72
  %74 = fsub <4 x double> %63, %73
  %75 = fsub <4 x double> %70, %72
  %76 = fadd <4 x double> %75, %74
  %77 = fadd <4 x double> %76, %69
  %78 = fadd <4 x double> %35, %38
  %79 = fmul <4 x double> %78, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %80 = fadd <4 x double> %79, %71
  %81 = fsub <4 x double> %71, %80
  %82 = fadd <4 x double> %79, %81
  %83 = fadd <4 x double> %82, %77
  %84 = bitcast <4 x double> %83 to <4 x i64>
  br label %306

; <label>:85:                                     ; preds = %24
  %86 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %87 = shufflevector <4 x i64> %3, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %88 = bitcast <2 x i64> %86 to <4 x i32>
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %90 = bitcast <4 x i32> %89 to <2 x i64>
  %91 = bitcast <2 x i64> %87 to <4 x i32>
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = shufflevector <2 x i64> %93, <2 x i64> %90, <2 x i32> <i32 2, i32 1>
  %95 = bitcast <2 x i64> %94 to <4 x i32>
  %96 = lshr <4 x i32> %95, <i32 20, i32 20, i32 20, i32 20>
  %97 = and <4 x i32> %96, <i32 2047, i32 2047, i32 2047, i32 2047>
  %98 = add nsw <4 x i32> %97, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %99 = icmp ugt <4 x i32> %97, <i32 1723, i32 1723, i32 1723, i32 1723>
  %100 = select <4 x i1> %99, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %102 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %103 = and <4 x i32> %101, <i32 0, i32 -1, i32 0, i32 -1>
  %104 = shl <4 x i32> %103, <i32 20, i32 20, i32 20, i32 20>
  %105 = and <4 x i32> %102, <i32 0, i32 -1, i32 0, i32 -1>
  %106 = shl <4 x i32> %105, <i32 20, i32 20, i32 20, i32 20>
  %107 = add <4 x i32> %104, %88
  %108 = add <4 x i32> %106, %91
  %109 = bitcast <4 x i32> %107 to <2 x i64>
  %110 = bitcast <4 x i32> %108 to <2 x i64>
  %111 = shufflevector <2 x i64> %109, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %112 = shufflevector <2 x i64> %110, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %113 = shufflevector <4 x i64> %111, <4 x i64> %112, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %114 = bitcast <4 x i64> %113 to <4 x double>
  %115 = ashr <4 x i32> %98, <i32 31, i32 31, i32 31, i32 31>
  %116 = xor <4 x i32> %115, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %117 = and <4 x i32> %116, %98
  %118 = shl <4 x i32> %117, <i32 2, i32 2, i32 2, i32 2>
  %119 = extractelement <4 x i32> %118, i32 3
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %120
  %122 = load double, double* %121, align 8, !tbaa !3, !noalias !22
  %123 = extractelement <4 x i32> %118, i32 2
  %124 = sext i32 %123 to i64
  %125 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %124
  %126 = load double, double* %125, align 8, !tbaa !3, !noalias !22
  %127 = extractelement <4 x i32> %118, i32 1
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %128
  %130 = load double, double* %129, align 8, !tbaa !3, !noalias !22
  %131 = extractelement <4 x i32> %118, i32 0
  %132 = sext i32 %131 to i64
  %133 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %132
  %134 = load double, double* %133, align 8, !tbaa !3, !noalias !22
  %135 = insertelement <4 x double> undef, double %134, i32 0
  %136 = insertelement <4 x double> %135, double %130, i32 1
  %137 = insertelement <4 x double> %136, double %126, i32 2
  %138 = insertelement <4 x double> %137, double %122, i32 3
  %139 = and <4 x i64> %113, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = fsub <4 x double> %114, %140
  %142 = bitcast <4 x double> %138 to <4 x i64>
  %143 = and <4 x i64> %142, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = fsub <4 x double> %138, %144
  %146 = fmul <4 x double> %138, %114
  %147 = fmul <4 x double> %140, %144
  %148 = bitcast <4 x double> %146 to <4 x i64>
  %149 = xor <4 x i64> %148, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fmul <4 x double> %141, %144
  %152 = fmul <4 x double> %145, %140
  %153 = fmul <4 x double> %141, %145
  %154 = fadd <4 x double> %147, %150
  %155 = fadd <4 x double> %151, %154
  %156 = fadd <4 x double> %152, %155
  %157 = fadd <4 x double> %153, %156
  %158 = fmul <4 x double> %146, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %159 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %158, i32 8) #6
  %160 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %146, i32 8) #6
  %161 = fmul <4 x double> %160, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %162 = fsub <4 x double> %159, %161
  %163 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %162) #6
  %164 = fmul <4 x double> %159, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %165 = fsub <4 x double> %146, %164
  %166 = fadd <4 x double> %165, %157
  %167 = fsub <4 x double> %165, %166
  %168 = fadd <4 x double> %157, %167
  %169 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %120
  %170 = load double, double* %169, align 8, !tbaa !3, !noalias !22
  %171 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %124
  %172 = load double, double* %171, align 8, !tbaa !3, !noalias !22
  %173 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %128
  %174 = load double, double* %173, align 8, !tbaa !3, !noalias !22
  %175 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %132
  %176 = load double, double* %175, align 8, !tbaa !3, !noalias !22
  %177 = insertelement <4 x double> undef, double %176, i32 0
  %178 = insertelement <4 x double> %177, double %174, i32 1
  %179 = insertelement <4 x double> %178, double %172, i32 2
  %180 = insertelement <4 x double> %179, double %170, i32 3
  %181 = bitcast <4 x double> %180 to <4 x i64>
  %182 = and <4 x i64> %181, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %183 = bitcast <4 x i64> %182 to <4 x double>
  %184 = fsub <4 x double> %180, %183
  %185 = fmul <4 x double> %180, %114
  %186 = fmul <4 x double> %140, %183
  %187 = bitcast <4 x double> %185 to <4 x i64>
  %188 = xor <4 x i64> %187, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %189 = bitcast <4 x i64> %188 to <4 x double>
  %190 = fmul <4 x double> %141, %183
  %191 = fmul <4 x double> %184, %140
  %192 = fmul <4 x double> %141, %184
  %193 = fadd <4 x double> %186, %189
  %194 = fadd <4 x double> %190, %193
  %195 = fadd <4 x double> %191, %194
  %196 = fadd <4 x double> %192, %195
  %197 = fadd <4 x double> %185, %166
  %198 = fsub <4 x double> %197, %166
  %199 = fsub <4 x double> %197, %198
  %200 = fsub <4 x double> %166, %199
  %201 = fsub <4 x double> %185, %198
  %202 = fadd <4 x double> %201, %200
  %203 = fadd <4 x double> %168, %196
  %204 = fadd <4 x double> %202, %203
  %205 = fmul <4 x double> %197, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %206 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %205, i32 8) #6
  %207 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %197, i32 8) #6
  %208 = fmul <4 x double> %207, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %209 = fsub <4 x double> %206, %208
  %210 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %209) #6
  %211 = fmul <4 x double> %206, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %212 = fsub <4 x double> %197, %211
  %213 = add <4 x i32> %210, %163
  %214 = fadd <4 x double> %212, %204
  %215 = fsub <4 x double> %212, %214
  %216 = fadd <4 x double> %204, %215
  %217 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %120
  %218 = load double, double* %217, align 8, !tbaa !3, !noalias !22
  %219 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %124
  %220 = load double, double* %219, align 8, !tbaa !3, !noalias !22
  %221 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %128
  %222 = load double, double* %221, align 8, !tbaa !3, !noalias !22
  %223 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %132
  %224 = load double, double* %223, align 8, !tbaa !3, !noalias !22
  %225 = insertelement <4 x double> undef, double %224, i32 0
  %226 = insertelement <4 x double> %225, double %222, i32 1
  %227 = insertelement <4 x double> %226, double %220, i32 2
  %228 = insertelement <4 x double> %227, double %218, i32 3
  %229 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %120
  %230 = load double, double* %229, align 8, !tbaa !3, !noalias !22
  %231 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %124
  %232 = load double, double* %231, align 8, !tbaa !3, !noalias !22
  %233 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %128
  %234 = load double, double* %233, align 8, !tbaa !3, !noalias !22
  %235 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %132
  %236 = load double, double* %235, align 8, !tbaa !3, !noalias !22
  %237 = insertelement <4 x double> undef, double %236, i32 0
  %238 = insertelement <4 x double> %237, double %234, i32 1
  %239 = insertelement <4 x double> %238, double %232, i32 2
  %240 = insertelement <4 x double> %239, double %230, i32 3
  %241 = bitcast <4 x double> %228 to <4 x i64>
  %242 = and <4 x i64> %241, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %243 = bitcast <4 x i64> %242 to <4 x double>
  %244 = fsub <4 x double> %228, %243
  %245 = fmul <4 x double> %228, %114
  %246 = fmul <4 x double> %140, %243
  %247 = bitcast <4 x double> %245 to <4 x i64>
  %248 = xor <4 x i64> %247, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %249 = bitcast <4 x i64> %248 to <4 x double>
  %250 = fmul <4 x double> %244, %140
  %251 = fmul <4 x double> %141, %243
  %252 = fmul <4 x double> %141, %244
  %253 = fmul <4 x double> %240, %114
  %254 = fadd <4 x double> %246, %249
  %255 = fadd <4 x double> %250, %254
  %256 = fadd <4 x double> %251, %255
  %257 = fadd <4 x double> %252, %256
  %258 = fadd <4 x double> %253, %257
  %259 = fadd <4 x double> %245, %214
  %260 = fsub <4 x double> %259, %214
  %261 = fsub <4 x double> %259, %260
  %262 = fsub <4 x double> %214, %261
  %263 = fsub <4 x double> %245, %260
  %264 = fadd <4 x double> %263, %262
  %265 = fadd <4 x double> %216, %258
  %266 = fadd <4 x double> %264, %265
  %267 = fadd <4 x double> %259, %266
  %268 = fsub <4 x double> %259, %267
  %269 = fadd <4 x double> %266, %268
  %270 = bitcast <4 x double> %267 to <4 x i64>
  %271 = and <4 x i64> %270, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %272 = bitcast <4 x i64> %271 to <4 x double>
  %273 = fsub <4 x double> %267, %272
  %274 = fmul <4 x double> %267, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %275 = fmul <4 x double> %272, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %276 = bitcast <4 x double> %274 to <4 x i64>
  %277 = xor <4 x i64> %276, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %278 = bitcast <4 x i64> %277 to <4 x double>
  %279 = fmul <4 x double> %273, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %280 = fmul <4 x double> %272, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %281 = fmul <4 x double> %273, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %282 = fmul <4 x double> %267, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %283 = fmul <4 x double> %269, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %284 = fadd <4 x double> %275, %278
  %285 = fadd <4 x double> %279, %284
  %286 = fadd <4 x double> %280, %285
  %287 = fadd <4 x double> %281, %286
  %288 = fadd <4 x double> %282, %287
  %289 = fadd <4 x double> %283, %288
  %290 = and <4 x i64> %113, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %291 = bitcast <4 x i64> %290 to <4 x double>
  %292 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %291, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %293 = bitcast <4 x double> %292 to <4 x i64>
  %294 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %274, <4 x double> %114, <4 x double> %292) #6
  %295 = bitcast <4 x double> %289 to <4 x i64>
  %296 = xor <4 x i64> %293, <i64 -1, i64 -1, i64 -1, i64 -1>
  %297 = and <4 x i64> %295, %296
  %298 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %299 = fcmp uno <4 x double> %1, zeroinitializer
  %300 = or <4 x i1> %298, %299
  %301 = sext <4 x i1> %300 to <4 x i64>
  %302 = bitcast <4 x double> %294 to <4 x i64>
  %303 = or <4 x i64> %302, %301
  %304 = bitcast <4 x i64> %303 to <4 x double>
  %305 = or <4 x i64> %297, %301
  br label %306

; <label>:306:                                    ; preds = %32, %85, %13
  %307 = phi <4 x double> [ %304, %85 ], [ %80, %32 ], [ %20, %13 ]
  %308 = phi <4 x i64> [ %305, %85 ], [ %84, %32 ], [ %23, %13 ]
  %309 = phi <4 x i32> [ %213, %85 ], [ %39, %32 ], [ %16, %13 ]
  %310 = bitcast <4 x i64> %308 to <4 x double>
  %311 = bitcast <4 x double> %307 to <4 x i64>
  %312 = and <4 x i64> %311, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %313 = bitcast <4 x i64> %312 to <4 x double>
  %314 = fsub <4 x double> %307, %313
  %315 = fmul <4 x double> %310, %313
  %316 = fmul <4 x double> %314, %314
  %317 = fmul <4 x double> %314, %313
  %318 = fadd <4 x double> %317, %317
  %319 = fmul <4 x double> %313, %313
  %320 = fadd <4 x double> %315, %315
  %321 = fadd <4 x double> %320, %316
  %322 = fadd <4 x double> %321, %318
  %323 = fadd <4 x double> %319, %322
  %324 = fmul <4 x double> %323, <double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B>
  %325 = fadd <4 x double> %324, <double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8>
  %326 = fmul <4 x double> %323, %325
  %327 = fadd <4 x double> %326, <double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C>
  %328 = fmul <4 x double> %323, %327
  %329 = fadd <4 x double> %328, <double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A>
  %330 = fmul <4 x double> %323, %329
  %331 = fadd <4 x double> %330, <double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135>
  %332 = fmul <4 x double> %323, %331
  %333 = fadd <4 x double> %332, <double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542>
  %334 = fmul <4 x double> %307, %323
  %335 = fmul <4 x double> %334, %333
  %336 = fadd <4 x double> %307, %335
  %337 = fsub <4 x double> %307, %336
  %338 = fadd <4 x double> %335, %337
  %339 = fadd <4 x double> %338, %310
  %340 = fadd <4 x double> %336, %339
  %341 = xor <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %342 = bitcast <4 x i64> %341 to <4 x double>
  %343 = fcmp oeq <4 x double> %342, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %344 = sext <4 x i1> %343 to <4 x i64>
  %345 = bitcast <4 x i64> %344 to <4 x double>
  %346 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %340, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %345) #6
  %347 = fmul <4 x double> %323, <double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE>
  %348 = fadd <4 x double> %347, <double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05>
  %349 = fmul <4 x double> %323, %348
  %350 = fadd <4 x double> %349, <double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C>
  %351 = fmul <4 x double> %323, %350
  %352 = fadd <4 x double> %351, <double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025>
  %353 = fmul <4 x double> %323, %352
  %354 = fadd <4 x double> %353, <double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96>
  %355 = fmul <4 x double> %323, %354
  %356 = fadd <4 x double> %355, <double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545>
  %357 = fmul <4 x double> %323, %356
  %358 = fadd <4 x double> %357, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %359 = bitcast <4 x double> %323 to <4 x i64>
  %360 = and <4 x i64> %359, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %361 = bitcast <4 x i64> %360 to <4 x double>
  %362 = fsub <4 x double> %323, %361
  %363 = bitcast <4 x double> %358 to <4 x i64>
  %364 = and <4 x i64> %363, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %365 = bitcast <4 x i64> %364 to <4 x double>
  %366 = fsub <4 x double> %358, %365
  %367 = fmul <4 x double> %323, %358
  %368 = fmul <4 x double> %361, %365
  %369 = bitcast <4 x double> %367 to <4 x i64>
  %370 = xor <4 x i64> %369, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %371 = bitcast <4 x i64> %370 to <4 x double>
  %372 = fmul <4 x double> %362, %365
  %373 = fmul <4 x double> %366, %361
  %374 = fmul <4 x double> %362, %366
  %375 = fadd <4 x double> %368, %371
  %376 = fadd <4 x double> %372, %375
  %377 = fadd <4 x double> %373, %376
  %378 = fadd <4 x double> %374, %377
  %379 = fadd <4 x double> %367, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %380 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %379
  %381 = fadd <4 x double> %367, %380
  %382 = fadd <4 x double> %381, %378
  %383 = fadd <4 x double> %379, %382
  %384 = and <4 x i32> %309, <i32 1, i32 1, i32 1, i32 1>
  %385 = icmp eq <4 x i32> %384, zeroinitializer
  %386 = sitofp <4 x i1> %385 to <4 x double>
  %387 = fcmp oeq <4 x double> %386, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %388 = sext <4 x i1> %387 to <4 x i64>
  %389 = bitcast <4 x i64> %388 to <4 x double>
  %390 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %383, <4 x double> %346, <4 x double> %389) #6
  %391 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %346, <4 x double> %383, <4 x double> %389) #6
  %392 = and <4 x i32> %309, <i32 2, i32 2, i32 2, i32 2>
  %393 = icmp ne <4 x i32> %392, zeroinitializer
  %394 = sitofp <4 x i1> %393 to <4 x double>
  %395 = fcmp oeq <4 x double> %394, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %396 = select <4 x i1> %395, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %397 = bitcast <4 x double> %390 to <4 x i64>
  %398 = xor <4 x i64> %396, %397
  %399 = add <4 x i32> %309, <i32 1, i32 1, i32 1, i32 1>
  %400 = and <4 x i32> %399, <i32 2, i32 2, i32 2, i32 2>
  %401 = icmp ne <4 x i32> %400, zeroinitializer
  %402 = sitofp <4 x i1> %401 to <4 x double>
  %403 = fcmp oeq <4 x double> %402, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %404 = select <4 x i1> %403, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %405 = bitcast <4 x double> %391 to <4 x i64>
  %406 = xor <4 x i64> %404, %405
  %407 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %398, <4 x i64>* %407, align 32
  %408 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %409 = bitcast <4 x double>* %408 to <4 x i64>*
  store <4 x i64> %406, <4 x i64>* %409, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincospid4_u05avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = fmul <4 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = lshr <4 x i32> %4, <i32 31, i32 31, i32 31, i32 31>
  %6 = xor <4 x i32> %5, <i32 1, i32 1, i32 1, i32 1>
  %7 = add <4 x i32> %6, %4
  %8 = and <4 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %3, %9
  %11 = fmul <4 x double> %10, %10
  %12 = bitcast <4 x double> %10 to <4 x i64>
  %13 = and <4 x i64> %12, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %14 = bitcast <4 x i64> %13 to <4 x double>
  %15 = fsub <4 x double> %10, %14
  %16 = fmul <4 x double> %14, %14
  %17 = bitcast <4 x double> %11 to <4 x i64>
  %18 = xor <4 x i64> %17, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %19 = bitcast <4 x i64> %18 to <4 x double>
  %20 = fmul <4 x double> %15, %14
  %21 = fmul <4 x double> %15, %15
  %22 = fadd <4 x double> %16, %19
  %23 = fadd <4 x double> %20, %22
  %24 = fadd <4 x double> %20, %23
  %25 = fadd <4 x double> %21, %24
  %26 = fmul <4 x double> %11, <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>
  %27 = fadd <4 x double> %26, <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>
  %28 = fmul <4 x double> %11, %27
  %29 = fadd <4 x double> %28, <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>
  %30 = fmul <4 x double> %11, %29
  %31 = fadd <4 x double> %30, <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>
  %32 = fmul <4 x double> %11, %31
  %33 = fadd <4 x double> %32, <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>
  %34 = fmul <4 x double> %11, %33
  %35 = fadd <4 x double> %34, <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>
  %36 = fmul <4 x double> %11, %35
  %37 = fadd <4 x double> %36, <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>
  %38 = fsub <4 x double> %37, %36
  %39 = fsub <4 x double> %37, %38
  %40 = fsub <4 x double> %36, %39
  %41 = fsub <4 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>, %38
  %42 = fadd <4 x double> %41, %40
  %43 = fadd <4 x double> %42, <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>
  %44 = and <4 x i64> %17, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %45 = bitcast <4 x i64> %44 to <4 x double>
  %46 = fsub <4 x double> %11, %45
  %47 = bitcast <4 x double> %37 to <4 x i64>
  %48 = and <4 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <4 x i64> %48 to <4 x double>
  %50 = fsub <4 x double> %37, %49
  %51 = fmul <4 x double> %11, %37
  %52 = fmul <4 x double> %45, %49
  %53 = bitcast <4 x double> %51 to <4 x i64>
  %54 = xor <4 x i64> %53, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %55 = bitcast <4 x i64> %54 to <4 x double>
  %56 = fmul <4 x double> %46, %49
  %57 = fmul <4 x double> %50, %45
  %58 = fmul <4 x double> %46, %50
  %59 = fmul <4 x double> %11, %43
  %60 = fmul <4 x double> %25, %37
  %61 = fadd <4 x double> %52, %55
  %62 = fadd <4 x double> %56, %61
  %63 = fadd <4 x double> %57, %62
  %64 = fadd <4 x double> %58, %63
  %65 = fadd <4 x double> %59, %64
  %66 = fadd <4 x double> %60, %65
  %67 = fadd <4 x double> %51, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %68 = fsub <4 x double> %67, %51
  %69 = fsub <4 x double> %67, %68
  %70 = fsub <4 x double> %51, %69
  %71 = fsub <4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %68
  %72 = fadd <4 x double> %71, %70
  %73 = fadd <4 x double> %66, <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>
  %74 = fadd <4 x double> %72, %73
  %75 = bitcast <4 x double> %67 to <4 x i64>
  %76 = and <4 x i64> %75, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %77 = bitcast <4 x i64> %76 to <4 x double>
  %78 = fsub <4 x double> %67, %77
  %79 = fmul <4 x double> %10, %67
  %80 = fmul <4 x double> %14, %77
  %81 = bitcast <4 x double> %79 to <4 x i64>
  %82 = xor <4 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <4 x i64> %82 to <4 x double>
  %84 = fmul <4 x double> %78, %14
  %85 = fmul <4 x double> %15, %77
  %86 = fmul <4 x double> %15, %78
  %87 = fmul <4 x double> %10, %74
  %88 = fadd <4 x double> %80, %83
  %89 = fadd <4 x double> %84, %88
  %90 = fadd <4 x double> %85, %89
  %91 = fadd <4 x double> %86, %90
  %92 = fadd <4 x double> %91, %87
  %93 = fadd <4 x double> %79, %92
  %94 = bitcast <4 x double> %1 to <4 x i64>
  %95 = xor <4 x i64> %94, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %96 = bitcast <4 x i64> %95 to <4 x double>
  %97 = fcmp oeq <4 x double> %96, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %98 = sext <4 x i1> %97 to <4 x i64>
  %99 = bitcast <4 x i64> %98 to <4 x double>
  %100 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %93, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %99) #6
  %101 = fmul <4 x double> %11, <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>
  %102 = fadd <4 x double> %101, <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>
  %103 = fmul <4 x double> %11, %102
  %104 = fadd <4 x double> %103, <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>
  %105 = fmul <4 x double> %11, %104
  %106 = fadd <4 x double> %105, <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>
  %107 = fmul <4 x double> %11, %106
  %108 = fadd <4 x double> %107, <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>
  %109 = fmul <4 x double> %11, %108
  %110 = fadd <4 x double> %109, <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>
  %111 = fmul <4 x double> %11, %110
  %112 = fadd <4 x double> %111, <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>
  %113 = fsub <4 x double> %112, %111
  %114 = fsub <4 x double> %112, %113
  %115 = fsub <4 x double> %111, %114
  %116 = fsub <4 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, %113
  %117 = fadd <4 x double> %116, %115
  %118 = fadd <4 x double> %117, <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>
  %119 = bitcast <4 x double> %112 to <4 x i64>
  %120 = and <4 x i64> %119, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %121 = bitcast <4 x i64> %120 to <4 x double>
  %122 = fsub <4 x double> %112, %121
  %123 = fmul <4 x double> %11, %112
  %124 = fmul <4 x double> %45, %121
  %125 = bitcast <4 x double> %123 to <4 x i64>
  %126 = xor <4 x i64> %125, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %127 = bitcast <4 x i64> %126 to <4 x double>
  %128 = fmul <4 x double> %46, %121
  %129 = fmul <4 x double> %122, %45
  %130 = fmul <4 x double> %46, %122
  %131 = fmul <4 x double> %11, %118
  %132 = fmul <4 x double> %25, %112
  %133 = fadd <4 x double> %124, %127
  %134 = fadd <4 x double> %128, %133
  %135 = fadd <4 x double> %129, %134
  %136 = fadd <4 x double> %130, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %132, %137
  %139 = fadd <4 x double> %123, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %140 = fsub <4 x double> %139, %123
  %141 = fsub <4 x double> %139, %140
  %142 = fsub <4 x double> %123, %141
  %143 = fsub <4 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, %140
  %144 = fadd <4 x double> %143, %142
  %145 = fadd <4 x double> %138, <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>
  %146 = fadd <4 x double> %144, %145
  %147 = bitcast <4 x double> %139 to <4 x i64>
  %148 = and <4 x i64> %147, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <4 x i64> %148 to <4 x double>
  %150 = fsub <4 x double> %139, %149
  %151 = fmul <4 x double> %11, %139
  %152 = fmul <4 x double> %45, %149
  %153 = bitcast <4 x double> %151 to <4 x i64>
  %154 = xor <4 x i64> %153, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %155 = bitcast <4 x i64> %154 to <4 x double>
  %156 = fmul <4 x double> %150, %45
  %157 = fmul <4 x double> %46, %149
  %158 = fmul <4 x double> %46, %150
  %159 = fmul <4 x double> %25, %139
  %160 = fmul <4 x double> %11, %146
  %161 = fadd <4 x double> %152, %155
  %162 = fadd <4 x double> %156, %161
  %163 = fadd <4 x double> %157, %162
  %164 = fadd <4 x double> %158, %163
  %165 = fadd <4 x double> %159, %164
  %166 = fadd <4 x double> %165, %160
  %167 = fadd <4 x double> %151, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %168 = fsub <4 x double> %167, %151
  %169 = fsub <4 x double> %167, %168
  %170 = fsub <4 x double> %151, %169
  %171 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %168
  %172 = fadd <4 x double> %171, %170
  %173 = fadd <4 x double> %172, %166
  %174 = fadd <4 x double> %167, %173
  %175 = and <4 x i32> %7, <i32 2, i32 2, i32 2, i32 2>
  %176 = icmp eq <4 x i32> %175, zeroinitializer
  %177 = sitofp <4 x i1> %176 to <4 x double>
  %178 = fcmp oeq <4 x double> %177, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %179 = sext <4 x i1> %178 to <4 x i64>
  %180 = bitcast <4 x i64> %179 to <4 x double>
  %181 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %174, <4 x double> %100, <4 x double> %180) #6
  %182 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> %174, <4 x double> %180) #6
  %183 = and <4 x i32> %7, <i32 4, i32 4, i32 4, i32 4>
  %184 = icmp ne <4 x i32> %183, zeroinitializer
  %185 = sitofp <4 x i1> %184 to <4 x double>
  %186 = fcmp oeq <4 x double> %185, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %187 = select <4 x i1> %186, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %188 = bitcast <4 x double> %181 to <4 x i64>
  %189 = xor <4 x i64> %187, %188
  %190 = add <4 x i32> %8, <i32 2, i32 2, i32 2, i32 2>
  %191 = and <4 x i32> %190, <i32 4, i32 4, i32 4, i32 4>
  %192 = icmp ne <4 x i32> %191, zeroinitializer
  %193 = sitofp <4 x i1> %192 to <4 x double>
  %194 = fcmp oeq <4 x double> %193, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %195 = select <4 x i1> %194, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %196 = bitcast <4 x double> %182 to <4 x i64>
  %197 = xor <4 x i64> %195, %196
  %198 = bitcast <4 x i64> %197 to <4 x double>
  %199 = and <4 x i64> %94, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %200 = bitcast <4 x i64> %199 to <4 x double>
  %201 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %200, <4 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i8 30) #6
  %202 = bitcast <4 x double> %201 to <4 x i64>
  %203 = xor <4 x i64> %202, <i64 -1, i64 -1, i64 -1, i64 -1>
  %204 = and <4 x i64> %189, %203
  %205 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %198, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %201) #6
  %206 = fcmp oeq <4 x double> %200, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %207 = sext <4 x i1> %206 to <4 x i64>
  %208 = or <4 x i64> %204, %207
  %209 = bitcast <4 x double> %205 to <4 x i64>
  %210 = or <4 x i64> %209, %207
  %211 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %208, <4 x i64>* %211, align 32
  %212 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %213 = bitcast <4 x double>* %212 to <4 x i64>*
  store <4 x i64> %210, <4 x i64>* %213, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincospid4_u35avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = fmul <4 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = lshr <4 x i32> %4, <i32 31, i32 31, i32 31, i32 31>
  %6 = xor <4 x i32> %5, <i32 1, i32 1, i32 1, i32 1>
  %7 = add <4 x i32> %6, %4
  %8 = and <4 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %3, %9
  %11 = fmul <4 x double> %10, %10
  %12 = fmul <4 x double> %11, <double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C>
  %13 = fadd <4 x double> %12, <double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5>
  %14 = fmul <4 x double> %11, %13
  %15 = fadd <4 x double> %14, <double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C>
  %16 = fmul <4 x double> %11, %15
  %17 = fadd <4 x double> %16, <double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE>
  %18 = fmul <4 x double> %11, %17
  %19 = fadd <4 x double> %18, <double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5>
  %20 = fmul <4 x double> %11, %19
  %21 = fadd <4 x double> %20, <double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43>
  %22 = fmul <4 x double> %11, %21
  %23 = fadd <4 x double> %22, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %24 = fmul <4 x double> %10, %23
  %25 = fmul <4 x double> %11, <double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3>
  %26 = fadd <4 x double> %25, <double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD>
  %27 = fmul <4 x double> %11, %26
  %28 = fadd <4 x double> %27, <double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707>
  %29 = fmul <4 x double> %11, %28
  %30 = fadd <4 x double> %29, <double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332>
  %31 = fmul <4 x double> %11, %30
  %32 = fadd <4 x double> %31, <double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF>
  %33 = fmul <4 x double> %11, %32
  %34 = fadd <4 x double> %33, <double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA>
  %35 = fmul <4 x double> %11, %34
  %36 = fadd <4 x double> %35, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %37 = fmul <4 x double> %11, %36
  %38 = fadd <4 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %39 = and <4 x i32> %7, <i32 2, i32 2, i32 2, i32 2>
  %40 = icmp eq <4 x i32> %39, zeroinitializer
  %41 = sitofp <4 x i1> %40 to <4 x double>
  %42 = fcmp oeq <4 x double> %41, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %43 = sext <4 x i1> %42 to <4 x i64>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %38, <4 x double> %24, <4 x double> %44) #6
  %46 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %24, <4 x double> %38, <4 x double> %44) #6
  %47 = and <4 x i32> %7, <i32 4, i32 4, i32 4, i32 4>
  %48 = icmp ne <4 x i32> %47, zeroinitializer
  %49 = sitofp <4 x i1> %48 to <4 x double>
  %50 = fcmp oeq <4 x double> %49, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %51 = select <4 x i1> %50, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %52 = bitcast <4 x double> %45 to <4 x i64>
  %53 = xor <4 x i64> %51, %52
  %54 = add <4 x i32> %8, <i32 2, i32 2, i32 2, i32 2>
  %55 = and <4 x i32> %54, <i32 4, i32 4, i32 4, i32 4>
  %56 = icmp ne <4 x i32> %55, zeroinitializer
  %57 = sitofp <4 x i1> %56 to <4 x double>
  %58 = fcmp oeq <4 x double> %57, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %59 = select <4 x i1> %58, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %60 = bitcast <4 x double> %46 to <4 x i64>
  %61 = xor <4 x i64> %59, %60
  %62 = bitcast <4 x double> %1 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %64, <4 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i8 30) #6
  %66 = bitcast <4 x double> %65 to <4 x i64>
  %67 = xor <4 x i64> %66, <i64 -1, i64 -1, i64 -1, i64 -1>
  %68 = and <4 x i64> %53, %67
  %69 = and <4 x i64> %61, %67
  %70 = fcmp oeq <4 x double> %64, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %71 = sext <4 x i1> %70 to <4 x i64>
  %72 = or <4 x i64> %68, %71
  %73 = or <4 x i64> %69, %71
  %74 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %72, <4 x i64>* %74, align 32
  %75 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %76 = bitcast <4 x double>* %75 to <4 x i64>*
  store <4 x i64> %73, <4 x i64>* %76, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_modfd4_avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = fmul <4 x double> %1, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = sitofp <4 x i32> %4 to <4 x double>
  %6 = fmul <4 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <4 x double> %1, %6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %7) #6
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %7, %9
  %11 = bitcast <4 x double> %1 to <4 x i64>
  %12 = and <4 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %13, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 30) #6
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> zeroinitializer, <4 x double> %14) #6
  %16 = bitcast <4 x double> %15 to <4 x i64>
  %17 = and <4 x i64> %16, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %18 = and <4 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %19 = or <4 x i64> %17, %18
  %20 = fsub <4 x double> %1, %15
  %21 = bitcast <4 x double> %20 to <4 x i64>
  %22 = and <4 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = or <4 x i64> %22, %18
  %24 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %19, <4 x i64>* %24, align 32
  %25 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %26 = bitcast <4 x double>* %25 to <4 x i64>*
  store <4 x i64> %23, <4 x i64>* %26, align 32
  ret void
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sinpid4_u05avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = lshr <4 x i32> %3, <i32 31, i32 31, i32 31, i32 31>
  %5 = xor <4 x i32> %4, <i32 1, i32 1, i32 1, i32 1>
  %6 = add <4 x i32> %5, %3
  %7 = and <4 x i32> %6, <i32 2, i32 2, i32 2, i32 2>
  %8 = icmp ne <4 x i32> %7, zeroinitializer
  %9 = sitofp <4 x i1> %8 to <4 x double>
  %10 = fcmp oeq <4 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %11 = sext <4 x i1> %10 to <4 x i64>
  %12 = and <4 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2>
  %13 = sitofp <4 x i32> %12 to <4 x double>
  %14 = fsub <4 x double> %2, %13
  %15 = fmul <4 x double> %14, %14
  %16 = bitcast <4 x double> %14 to <4 x i64>
  %17 = and <4 x i64> %16, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = fsub <4 x double> %14, %18
  %20 = fmul <4 x double> %18, %18
  %21 = bitcast <4 x double> %15 to <4 x i64>
  %22 = xor <4 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = fmul <4 x double> %19, %18
  %25 = fmul <4 x double> %19, %19
  %26 = fadd <4 x double> %20, %23
  %27 = fadd <4 x double> %24, %26
  %28 = fadd <4 x double> %24, %27
  %29 = fadd <4 x double> %25, %28
  %30 = bitcast <4 x i64> %11 to <4 x double>
  %31 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>, <4 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <4 x double> %30) #6
  %32 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>, <4 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <4 x double> %30) #6
  %33 = fmul <4 x double> %31, %15
  %34 = fadd <4 x double> %32, %33
  %35 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>, <4 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <4 x double> %30) #6
  %36 = fmul <4 x double> %15, %34
  %37 = fadd <4 x double> %35, %36
  %38 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>, <4 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <4 x double> %30) #6
  %39 = fmul <4 x double> %15, %37
  %40 = fadd <4 x double> %38, %39
  %41 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>, <4 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <4 x double> %30) #6
  %42 = fmul <4 x double> %15, %40
  %43 = fadd <4 x double> %41, %42
  %44 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>, <4 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <4 x double> %30) #6
  %45 = fmul <4 x double> %15, %43
  %46 = fadd <4 x double> %44, %45
  %47 = fmul <4 x double> %15, %46
  %48 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>, <4 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <4 x double> %30) #6
  %49 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>, <4 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <4 x double> %30) #6
  %50 = fadd <4 x double> %48, %47
  %51 = fsub <4 x double> %50, %47
  %52 = fsub <4 x double> %50, %51
  %53 = fsub <4 x double> %47, %52
  %54 = fsub <4 x double> %48, %51
  %55 = fadd <4 x double> %54, %53
  %56 = fadd <4 x double> %49, %55
  %57 = and <4 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fsub <4 x double> %15, %58
  %60 = bitcast <4 x double> %50 to <4 x i64>
  %61 = and <4 x i64> %60, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %62 = bitcast <4 x i64> %61 to <4 x double>
  %63 = fsub <4 x double> %50, %62
  %64 = fmul <4 x double> %15, %50
  %65 = fmul <4 x double> %58, %62
  %66 = bitcast <4 x double> %64 to <4 x i64>
  %67 = xor <4 x i64> %66, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fmul <4 x double> %59, %62
  %70 = fmul <4 x double> %63, %58
  %71 = fmul <4 x double> %59, %63
  %72 = fmul <4 x double> %15, %56
  %73 = fmul <4 x double> %29, %50
  %74 = fadd <4 x double> %65, %68
  %75 = fadd <4 x double> %69, %74
  %76 = fadd <4 x double> %70, %75
  %77 = fadd <4 x double> %71, %76
  %78 = fadd <4 x double> %72, %77
  %79 = fadd <4 x double> %73, %78
  %80 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, <4 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <4 x double> %30) #6
  %81 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>, <4 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <4 x double> %30) #6
  %82 = fadd <4 x double> %80, %64
  %83 = fsub <4 x double> %82, %64
  %84 = fsub <4 x double> %82, %83
  %85 = fsub <4 x double> %64, %84
  %86 = fsub <4 x double> %80, %83
  %87 = fadd <4 x double> %86, %85
  %88 = fadd <4 x double> %81, %79
  %89 = fadd <4 x double> %87, %88
  %90 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %14, <4 x double> %15, <4 x double> %30) #6
  %91 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %29, <4 x double> %30) #6
  %92 = bitcast <4 x double> %82 to <4 x i64>
  %93 = and <4 x i64> %92, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %94 = bitcast <4 x i64> %93 to <4 x double>
  %95 = fsub <4 x double> %82, %94
  %96 = bitcast <4 x double> %90 to <4 x i64>
  %97 = and <4 x i64> %96, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %98 = bitcast <4 x i64> %97 to <4 x double>
  %99 = fsub <4 x double> %90, %98
  %100 = fmul <4 x double> %90, %82
  %101 = fmul <4 x double> %98, %94
  %102 = bitcast <4 x double> %100 to <4 x i64>
  %103 = xor <4 x i64> %102, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %104 = bitcast <4 x i64> %103 to <4 x double>
  %105 = fmul <4 x double> %95, %98
  %106 = fmul <4 x double> %99, %94
  %107 = fmul <4 x double> %99, %95
  %108 = fmul <4 x double> %91, %82
  %109 = fmul <4 x double> %90, %89
  %110 = fadd <4 x double> %101, %104
  %111 = fadd <4 x double> %105, %110
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %108, %113
  %115 = fadd <4 x double> %114, %109
  %116 = fadd <4 x double> %100, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %117 = fsub <4 x double> %116, %100
  %118 = fsub <4 x double> %116, %117
  %119 = fsub <4 x double> %100, %118
  %120 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %121 = fadd <4 x double> %120, %119
  %122 = fadd <4 x double> %121, %115
  %123 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> %116, <4 x double> %30) #6
  %124 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %115, <4 x double> %122, <4 x double> %30) #6
  %125 = and <4 x i32> %6, <i32 4, i32 4, i32 4, i32 4>
  %126 = icmp ne <4 x i32> %125, zeroinitializer
  %127 = sitofp <4 x i1> %126 to <4 x double>
  %128 = fcmp oeq <4 x double> %127, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %129 = select <4 x i1> %128, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %130 = bitcast <4 x double> %123 to <4 x i64>
  %131 = xor <4 x i64> %129, %130
  %132 = bitcast <4 x double> %124 to <4 x i64>
  %133 = xor <4 x i64> %129, %132
  %134 = bitcast <4 x i64> %131 to <4 x double>
  %135 = bitcast <4 x i64> %133 to <4 x double>
  %136 = fadd <4 x double> %134, %135
  %137 = bitcast <4 x double> %0 to <4 x i64>
  %138 = xor <4 x i64> %137, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %139 = bitcast <4 x i64> %138 to <4 x double>
  %140 = fcmp oeq <4 x double> %139, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %141 = sext <4 x i1> %140 to <4 x i64>
  %142 = bitcast <4 x i64> %141 to <4 x double>
  %143 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %136, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %142) #6
  %144 = and <4 x i64> %137, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %145 = bitcast <4 x i64> %144 to <4 x double>
  %146 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %145, <4 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i8 30) #6
  %147 = bitcast <4 x double> %146 to <4 x i64>
  %148 = bitcast <4 x double> %143 to <4 x i64>
  %149 = xor <4 x i64> %147, <i64 -1, i64 -1, i64 -1, i64 -1>
  %150 = and <4 x i64> %149, %148
  %151 = fcmp oeq <4 x double> %145, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %152 = bitcast <4 x i64> %150 to <4 x double>
  %153 = select <4 x i1> %151, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %152
  ret <4 x double> %153
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cospid4_u05avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = lshr <4 x i32> %3, <i32 31, i32 31, i32 31, i32 31>
  %5 = xor <4 x i32> %4, <i32 1, i32 1, i32 1, i32 1>
  %6 = add <4 x i32> %5, %3
  %7 = and <4 x i32> %6, <i32 2, i32 2, i32 2, i32 2>
  %8 = icmp eq <4 x i32> %7, zeroinitializer
  %9 = sitofp <4 x i1> %8 to <4 x double>
  %10 = fcmp oeq <4 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %11 = sext <4 x i1> %10 to <4 x i64>
  %12 = and <4 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2>
  %13 = sitofp <4 x i32> %12 to <4 x double>
  %14 = fsub <4 x double> %2, %13
  %15 = fmul <4 x double> %14, %14
  %16 = bitcast <4 x double> %14 to <4 x i64>
  %17 = and <4 x i64> %16, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = fsub <4 x double> %14, %18
  %20 = fmul <4 x double> %18, %18
  %21 = bitcast <4 x double> %15 to <4 x i64>
  %22 = xor <4 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = fmul <4 x double> %19, %18
  %25 = fmul <4 x double> %19, %19
  %26 = fadd <4 x double> %20, %23
  %27 = fadd <4 x double> %24, %26
  %28 = fadd <4 x double> %24, %27
  %29 = fadd <4 x double> %25, %28
  %30 = bitcast <4 x i64> %11 to <4 x double>
  %31 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>, <4 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <4 x double> %30) #6
  %32 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>, <4 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <4 x double> %30) #6
  %33 = fmul <4 x double> %31, %15
  %34 = fadd <4 x double> %32, %33
  %35 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>, <4 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <4 x double> %30) #6
  %36 = fmul <4 x double> %15, %34
  %37 = fadd <4 x double> %35, %36
  %38 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>, <4 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <4 x double> %30) #6
  %39 = fmul <4 x double> %15, %37
  %40 = fadd <4 x double> %38, %39
  %41 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>, <4 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <4 x double> %30) #6
  %42 = fmul <4 x double> %15, %40
  %43 = fadd <4 x double> %41, %42
  %44 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>, <4 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <4 x double> %30) #6
  %45 = fmul <4 x double> %15, %43
  %46 = fadd <4 x double> %44, %45
  %47 = fmul <4 x double> %15, %46
  %48 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>, <4 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <4 x double> %30) #6
  %49 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>, <4 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <4 x double> %30) #6
  %50 = fadd <4 x double> %48, %47
  %51 = fsub <4 x double> %50, %47
  %52 = fsub <4 x double> %50, %51
  %53 = fsub <4 x double> %47, %52
  %54 = fsub <4 x double> %48, %51
  %55 = fadd <4 x double> %54, %53
  %56 = fadd <4 x double> %49, %55
  %57 = and <4 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fsub <4 x double> %15, %58
  %60 = bitcast <4 x double> %50 to <4 x i64>
  %61 = and <4 x i64> %60, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %62 = bitcast <4 x i64> %61 to <4 x double>
  %63 = fsub <4 x double> %50, %62
  %64 = fmul <4 x double> %15, %50
  %65 = fmul <4 x double> %58, %62
  %66 = bitcast <4 x double> %64 to <4 x i64>
  %67 = xor <4 x i64> %66, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fmul <4 x double> %59, %62
  %70 = fmul <4 x double> %63, %58
  %71 = fmul <4 x double> %59, %63
  %72 = fmul <4 x double> %15, %56
  %73 = fmul <4 x double> %29, %50
  %74 = fadd <4 x double> %65, %68
  %75 = fadd <4 x double> %69, %74
  %76 = fadd <4 x double> %70, %75
  %77 = fadd <4 x double> %71, %76
  %78 = fadd <4 x double> %72, %77
  %79 = fadd <4 x double> %73, %78
  %80 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, <4 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <4 x double> %30) #6
  %81 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>, <4 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <4 x double> %30) #6
  %82 = fadd <4 x double> %80, %64
  %83 = fsub <4 x double> %82, %64
  %84 = fsub <4 x double> %82, %83
  %85 = fsub <4 x double> %64, %84
  %86 = fsub <4 x double> %80, %83
  %87 = fadd <4 x double> %86, %85
  %88 = fadd <4 x double> %81, %79
  %89 = fadd <4 x double> %87, %88
  %90 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %14, <4 x double> %15, <4 x double> %30) #6
  %91 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %29, <4 x double> %30) #6
  %92 = bitcast <4 x double> %82 to <4 x i64>
  %93 = and <4 x i64> %92, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %94 = bitcast <4 x i64> %93 to <4 x double>
  %95 = fsub <4 x double> %82, %94
  %96 = bitcast <4 x double> %90 to <4 x i64>
  %97 = and <4 x i64> %96, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %98 = bitcast <4 x i64> %97 to <4 x double>
  %99 = fsub <4 x double> %90, %98
  %100 = fmul <4 x double> %90, %82
  %101 = fmul <4 x double> %98, %94
  %102 = bitcast <4 x double> %100 to <4 x i64>
  %103 = xor <4 x i64> %102, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %104 = bitcast <4 x i64> %103 to <4 x double>
  %105 = fmul <4 x double> %95, %98
  %106 = fmul <4 x double> %99, %94
  %107 = fmul <4 x double> %99, %95
  %108 = fmul <4 x double> %91, %82
  %109 = fmul <4 x double> %90, %89
  %110 = fadd <4 x double> %101, %104
  %111 = fadd <4 x double> %105, %110
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %108, %113
  %115 = fadd <4 x double> %114, %109
  %116 = fadd <4 x double> %100, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %117 = fsub <4 x double> %116, %100
  %118 = fsub <4 x double> %116, %117
  %119 = fsub <4 x double> %100, %118
  %120 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %121 = fadd <4 x double> %120, %119
  %122 = fadd <4 x double> %121, %115
  %123 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> %116, <4 x double> %30) #6
  %124 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %115, <4 x double> %122, <4 x double> %30) #6
  %125 = add <4 x i32> %12, <i32 2, i32 2, i32 2, i32 2>
  %126 = and <4 x i32> %125, <i32 4, i32 4, i32 4, i32 4>
  %127 = icmp ne <4 x i32> %126, zeroinitializer
  %128 = sitofp <4 x i1> %127 to <4 x double>
  %129 = fcmp oeq <4 x double> %128, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %130 = select <4 x i1> %129, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %131 = bitcast <4 x double> %123 to <4 x i64>
  %132 = xor <4 x i64> %130, %131
  %133 = bitcast <4 x double> %124 to <4 x i64>
  %134 = xor <4 x i64> %130, %133
  %135 = bitcast <4 x i64> %132 to <4 x double>
  %136 = bitcast <4 x i64> %134 to <4 x double>
  %137 = fadd <4 x double> %135, %136
  %138 = bitcast <4 x double> %0 to <4 x i64>
  %139 = and <4 x i64> %138, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %140, <4 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i8 30) #6
  %142 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %137, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %141) #6
  %143 = fcmp oeq <4 x double> %140, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %144 = select <4 x i1> %143, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %142
  ret <4 x double> %144
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_tand4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %20, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %14 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %13, i32 8) #6
  %15 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %14) #6
  %16 = fmul <4 x double> %14, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %17 = fadd <4 x double> %16, %0
  %18 = fmul <4 x double> %14, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %19 = fadd <4 x double> %18, %17
  br label %270

; <label>:20:                                     ; preds = %1
  %21 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06>, i8 17) #6
  %22 = bitcast <4 x double> %21 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = and <2 x i64> %24, %23
  %26 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %25, <2 x i64> <i64 -1, i64 -1>) #6
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %51, label %28, !prof !2

; <label>:28:                                     ; preds = %20
  %29 = fmul <4 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %30 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %29, i32 11) #6
  %31 = fmul <4 x double> %30, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %32 = fmul <4 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %33 = fsub <4 x double> %32, %31
  %34 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %33, i32 8) #6
  %35 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %34) #6
  %36 = fmul <4 x double> %31, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %37 = fadd <4 x double> %36, %0
  %38 = fmul <4 x double> %34, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %39 = fadd <4 x double> %38, %37
  %40 = fmul <4 x double> %31, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %41 = fadd <4 x double> %40, %39
  %42 = fmul <4 x double> %34, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %43 = fadd <4 x double> %42, %41
  %44 = fmul <4 x double> %31, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %45 = fadd <4 x double> %44, %43
  %46 = fmul <4 x double> %34, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %47 = fadd <4 x double> %46, %45
  %48 = fadd <4 x double> %31, %34
  %49 = fmul <4 x double> %48, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %50 = fadd <4 x double> %49, %47
  br label %270

; <label>:51:                                     ; preds = %20
  %52 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %53 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %54 = bitcast <2 x i64> %52 to <4 x i32>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = bitcast <2 x i64> %53 to <4 x i32>
  %58 = shufflevector <4 x i32> %57, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %59 = bitcast <4 x i32> %58 to <2 x i64>
  %60 = shufflevector <2 x i64> %59, <2 x i64> %56, <2 x i32> <i32 2, i32 1>
  %61 = bitcast <2 x i64> %60 to <4 x i32>
  %62 = lshr <4 x i32> %61, <i32 20, i32 20, i32 20, i32 20>
  %63 = and <4 x i32> %62, <i32 2047, i32 2047, i32 2047, i32 2047>
  %64 = add nsw <4 x i32> %63, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %65 = icmp ugt <4 x i32> %63, <i32 1723, i32 1723, i32 1723, i32 1723>
  %66 = select <4 x i1> %65, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %68 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %69 = and <4 x i32> %67, <i32 0, i32 -1, i32 0, i32 -1>
  %70 = shl <4 x i32> %69, <i32 20, i32 20, i32 20, i32 20>
  %71 = and <4 x i32> %68, <i32 0, i32 -1, i32 0, i32 -1>
  %72 = shl <4 x i32> %71, <i32 20, i32 20, i32 20, i32 20>
  %73 = add <4 x i32> %70, %54
  %74 = add <4 x i32> %72, %57
  %75 = bitcast <4 x i32> %73 to <2 x i64>
  %76 = bitcast <4 x i32> %74 to <2 x i64>
  %77 = shufflevector <2 x i64> %75, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %78 = shufflevector <2 x i64> %76, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %79 = shufflevector <4 x i64> %77, <4 x i64> %78, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = ashr <4 x i32> %64, <i32 31, i32 31, i32 31, i32 31>
  %82 = xor <4 x i32> %81, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %83 = and <4 x i32> %82, %64
  %84 = shl <4 x i32> %83, <i32 2, i32 2, i32 2, i32 2>
  %85 = extractelement <4 x i32> %84, i32 3
  %86 = sext i32 %85 to i64
  %87 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %86
  %88 = load double, double* %87, align 8, !tbaa !3, !noalias !25
  %89 = extractelement <4 x i32> %84, i32 2
  %90 = sext i32 %89 to i64
  %91 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %90
  %92 = load double, double* %91, align 8, !tbaa !3, !noalias !25
  %93 = extractelement <4 x i32> %84, i32 1
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %94
  %96 = load double, double* %95, align 8, !tbaa !3, !noalias !25
  %97 = extractelement <4 x i32> %84, i32 0
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %98
  %100 = load double, double* %99, align 8, !tbaa !3, !noalias !25
  %101 = insertelement <4 x double> undef, double %100, i32 0
  %102 = insertelement <4 x double> %101, double %96, i32 1
  %103 = insertelement <4 x double> %102, double %92, i32 2
  %104 = insertelement <4 x double> %103, double %88, i32 3
  %105 = and <4 x i64> %79, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = fsub <4 x double> %80, %106
  %108 = bitcast <4 x double> %104 to <4 x i64>
  %109 = and <4 x i64> %108, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %110 = bitcast <4 x i64> %109 to <4 x double>
  %111 = fsub <4 x double> %104, %110
  %112 = fmul <4 x double> %104, %80
  %113 = fmul <4 x double> %106, %110
  %114 = bitcast <4 x double> %112 to <4 x i64>
  %115 = xor <4 x i64> %114, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fmul <4 x double> %107, %110
  %118 = fmul <4 x double> %111, %106
  %119 = fmul <4 x double> %107, %111
  %120 = fadd <4 x double> %113, %116
  %121 = fadd <4 x double> %117, %120
  %122 = fadd <4 x double> %118, %121
  %123 = fadd <4 x double> %119, %122
  %124 = fmul <4 x double> %112, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %125 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %124, i32 8) #6
  %126 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %112, i32 8) #6
  %127 = fmul <4 x double> %126, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %128 = fsub <4 x double> %125, %127
  %129 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %128) #6
  %130 = fmul <4 x double> %125, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %131 = fsub <4 x double> %112, %130
  %132 = fadd <4 x double> %131, %123
  %133 = fsub <4 x double> %131, %132
  %134 = fadd <4 x double> %123, %133
  %135 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %86
  %136 = load double, double* %135, align 8, !tbaa !3, !noalias !25
  %137 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %90
  %138 = load double, double* %137, align 8, !tbaa !3, !noalias !25
  %139 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %94
  %140 = load double, double* %139, align 8, !tbaa !3, !noalias !25
  %141 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %98
  %142 = load double, double* %141, align 8, !tbaa !3, !noalias !25
  %143 = insertelement <4 x double> undef, double %142, i32 0
  %144 = insertelement <4 x double> %143, double %140, i32 1
  %145 = insertelement <4 x double> %144, double %138, i32 2
  %146 = insertelement <4 x double> %145, double %136, i32 3
  %147 = bitcast <4 x double> %146 to <4 x i64>
  %148 = and <4 x i64> %147, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <4 x i64> %148 to <4 x double>
  %150 = fsub <4 x double> %146, %149
  %151 = fmul <4 x double> %146, %80
  %152 = fmul <4 x double> %106, %149
  %153 = bitcast <4 x double> %151 to <4 x i64>
  %154 = xor <4 x i64> %153, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %155 = bitcast <4 x i64> %154 to <4 x double>
  %156 = fmul <4 x double> %107, %149
  %157 = fmul <4 x double> %150, %106
  %158 = fmul <4 x double> %107, %150
  %159 = fadd <4 x double> %152, %155
  %160 = fadd <4 x double> %156, %159
  %161 = fadd <4 x double> %157, %160
  %162 = fadd <4 x double> %158, %161
  %163 = fadd <4 x double> %151, %132
  %164 = fsub <4 x double> %163, %132
  %165 = fsub <4 x double> %163, %164
  %166 = fsub <4 x double> %132, %165
  %167 = fsub <4 x double> %151, %164
  %168 = fadd <4 x double> %167, %166
  %169 = fadd <4 x double> %134, %162
  %170 = fadd <4 x double> %168, %169
  %171 = fmul <4 x double> %163, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %172 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %171, i32 8) #6
  %173 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %163, i32 8) #6
  %174 = fmul <4 x double> %173, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %175 = fsub <4 x double> %172, %174
  %176 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %175) #6
  %177 = fmul <4 x double> %172, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %178 = fsub <4 x double> %163, %177
  %179 = add <4 x i32> %176, %129
  %180 = fadd <4 x double> %178, %170
  %181 = fsub <4 x double> %178, %180
  %182 = fadd <4 x double> %170, %181
  %183 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %86
  %184 = load double, double* %183, align 8, !tbaa !3, !noalias !25
  %185 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %90
  %186 = load double, double* %185, align 8, !tbaa !3, !noalias !25
  %187 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %94
  %188 = load double, double* %187, align 8, !tbaa !3, !noalias !25
  %189 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %98
  %190 = load double, double* %189, align 8, !tbaa !3, !noalias !25
  %191 = insertelement <4 x double> undef, double %190, i32 0
  %192 = insertelement <4 x double> %191, double %188, i32 1
  %193 = insertelement <4 x double> %192, double %186, i32 2
  %194 = insertelement <4 x double> %193, double %184, i32 3
  %195 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %86
  %196 = load double, double* %195, align 8, !tbaa !3, !noalias !25
  %197 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %90
  %198 = load double, double* %197, align 8, !tbaa !3, !noalias !25
  %199 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %94
  %200 = load double, double* %199, align 8, !tbaa !3, !noalias !25
  %201 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %98
  %202 = load double, double* %201, align 8, !tbaa !3, !noalias !25
  %203 = insertelement <4 x double> undef, double %202, i32 0
  %204 = insertelement <4 x double> %203, double %200, i32 1
  %205 = insertelement <4 x double> %204, double %198, i32 2
  %206 = insertelement <4 x double> %205, double %196, i32 3
  %207 = bitcast <4 x double> %194 to <4 x i64>
  %208 = and <4 x i64> %207, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %209 = bitcast <4 x i64> %208 to <4 x double>
  %210 = fsub <4 x double> %194, %209
  %211 = fmul <4 x double> %194, %80
  %212 = fmul <4 x double> %106, %209
  %213 = bitcast <4 x double> %211 to <4 x i64>
  %214 = xor <4 x i64> %213, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %215 = bitcast <4 x i64> %214 to <4 x double>
  %216 = fmul <4 x double> %210, %106
  %217 = fmul <4 x double> %107, %209
  %218 = fmul <4 x double> %107, %210
  %219 = fmul <4 x double> %206, %80
  %220 = fadd <4 x double> %212, %215
  %221 = fadd <4 x double> %216, %220
  %222 = fadd <4 x double> %217, %221
  %223 = fadd <4 x double> %218, %222
  %224 = fadd <4 x double> %219, %223
  %225 = fadd <4 x double> %211, %180
  %226 = fsub <4 x double> %225, %180
  %227 = fsub <4 x double> %225, %226
  %228 = fsub <4 x double> %180, %227
  %229 = fsub <4 x double> %211, %226
  %230 = fadd <4 x double> %229, %228
  %231 = fadd <4 x double> %182, %224
  %232 = fadd <4 x double> %230, %231
  %233 = fadd <4 x double> %225, %232
  %234 = fsub <4 x double> %225, %233
  %235 = fadd <4 x double> %232, %234
  %236 = bitcast <4 x double> %233 to <4 x i64>
  %237 = and <4 x i64> %236, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %238 = bitcast <4 x i64> %237 to <4 x double>
  %239 = fsub <4 x double> %233, %238
  %240 = fmul <4 x double> %233, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %241 = fmul <4 x double> %238, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %242 = bitcast <4 x double> %240 to <4 x i64>
  %243 = xor <4 x i64> %242, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %244 = bitcast <4 x i64> %243 to <4 x double>
  %245 = fmul <4 x double> %239, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %246 = fmul <4 x double> %238, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %247 = fmul <4 x double> %239, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %248 = fmul <4 x double> %233, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %249 = fmul <4 x double> %235, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %250 = fadd <4 x double> %241, %244
  %251 = fadd <4 x double> %245, %250
  %252 = fadd <4 x double> %246, %251
  %253 = fadd <4 x double> %247, %252
  %254 = fadd <4 x double> %248, %253
  %255 = fadd <4 x double> %249, %254
  %256 = and <4 x i64> %79, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %257 = bitcast <4 x i64> %256 to <4 x double>
  %258 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %257, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %259 = bitcast <4 x double> %258 to <4 x i64>
  %260 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %240, <4 x double> %80, <4 x double> %258) #6
  %261 = bitcast <4 x double> %255 to <4 x i64>
  %262 = xor <4 x i64> %259, <i64 -1, i64 -1, i64 -1, i64 -1>
  %263 = and <4 x i64> %261, %262
  %264 = bitcast <4 x i64> %263 to <4 x double>
  %265 = fadd <4 x double> %260, %264
  %266 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %267 = fcmp uno <4 x double> %0, zeroinitializer
  %268 = or <4 x i1> %266, %267
  %269 = select <4 x i1> %268, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %265
  br label %270

; <label>:270:                                    ; preds = %28, %51, %12
  %271 = phi <4 x i32> [ %15, %12 ], [ %35, %28 ], [ %179, %51 ]
  %272 = phi <4 x double> [ %19, %12 ], [ %50, %28 ], [ %269, %51 ]
  %273 = fmul <4 x double> %272, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %274 = fmul <4 x double> %273, %273
  %275 = fmul <4 x double> %274, %274
  %276 = fmul <4 x double> %275, %275
  %277 = fmul <4 x double> %274, <double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED>
  %278 = fadd <4 x double> %277, <double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF>
  %279 = fmul <4 x double> %274, <double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93>
  %280 = fadd <4 x double> %279, <double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959>
  %281 = fmul <4 x double> %275, %278
  %282 = fadd <4 x double> %280, %281
  %283 = fmul <4 x double> %274, <double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090>
  %284 = fadd <4 x double> %283, <double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5>
  %285 = fmul <4 x double> %274, <double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06>
  %286 = fadd <4 x double> %285, <double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933>
  %287 = fmul <4 x double> %275, %284
  %288 = fadd <4 x double> %286, %287
  %289 = fmul <4 x double> %276, %282
  %290 = fadd <4 x double> %288, %289
  %291 = fmul <4 x double> %274, %290
  %292 = fadd <4 x double> %291, <double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568>
  %293 = fmul <4 x double> %273, %292
  %294 = fmul <4 x double> %274, %293
  %295 = fadd <4 x double> %273, %294
  %296 = fmul <4 x double> %295, %295
  %297 = fadd <4 x double> %296, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %298 = fmul <4 x double> %295, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %299 = and <4 x i32> %271, <i32 1, i32 1, i32 1, i32 1>
  %300 = icmp ne <4 x i32> %299, zeroinitializer
  %301 = sitofp <4 x i1> %300 to <4 x double>
  %302 = fcmp oeq <4 x double> %301, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %303 = sext <4 x i1> %302 to <4 x i64>
  %304 = bitcast <4 x double> %297 to <4 x i64>
  %305 = xor <4 x i64> %304, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %306 = bitcast <4 x i64> %305 to <4 x double>
  %307 = bitcast <4 x i64> %303 to <4 x double>
  %308 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %298, <4 x double> %306, <4 x double> %307) #6
  %309 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %297, <4 x double> %298, <4 x double> %307) #6
  %310 = fdiv <4 x double> %308, %309
  %311 = fcmp oeq <4 x double> %0, zeroinitializer
  %312 = sext <4 x i1> %311 to <4 x i64>
  %313 = bitcast <4 x i64> %312 to <4 x double>
  %314 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %310, <4 x double> %0, <4 x double> %313) #6
  ret <4 x double> %314
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_tand4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %8 = shufflevector <4 x i64> %6, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %9 = and <2 x i64> %8, %7
  %10 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %9, <2 x i64> <i64 -1, i64 -1>) #6
  %11 = icmp eq i32 %10, 0
  br i1 %11, label %23, label %12, !prof !2

; <label>:12:                                     ; preds = %1
  %13 = fmul <4 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %14 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %13, i32 8) #6
  %15 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %14) #6
  %16 = fmul <4 x double> %14, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %17 = fadd <4 x double> %16, %0
  %18 = fmul <4 x double> %14, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %19 = fadd <4 x double> %18, %17
  %20 = fsub <4 x double> %17, %19
  %21 = fadd <4 x double> %18, %20
  %22 = bitcast <4 x double> %21 to <4 x i64>
  br label %331

; <label>:23:                                     ; preds = %1
  %24 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i8 17) #6
  %25 = bitcast <4 x double> %24 to <4 x i64>
  %26 = shufflevector <4 x i64> %25, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %27 = shufflevector <4 x i64> %25, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %28 = and <2 x i64> %27, %26
  %29 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %28, <2 x i64> <i64 -1, i64 -1>) #6
  %30 = icmp eq i32 %29, 0
  br i1 %30, label %110, label %31, !prof !2

; <label>:31:                                     ; preds = %23
  %32 = fmul <4 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %33 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %32, i32 11) #6
  %34 = fmul <4 x double> %33, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %35 = and <4 x i64> %2, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fsub <4 x double> %0, %36
  %38 = fmul <4 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %39 = fmul <4 x double> %36, <double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000>
  %40 = bitcast <4 x double> %38 to <4 x i64>
  %41 = xor <4 x i64> %40, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = fmul <4 x double> %36, <double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000>
  %44 = fmul <4 x double> %37, <double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000>
  %45 = fmul <4 x double> %37, <double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000>
  %46 = fmul <4 x double> %0, <double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056>
  %47 = fadd <4 x double> %39, %42
  %48 = fadd <4 x double> %43, %47
  %49 = fadd <4 x double> %44, %48
  %50 = fadd <4 x double> %45, %49
  %51 = fadd <4 x double> %46, %50
  %52 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %53 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>, <4 x double> %52) #6
  %54 = fsub <4 x double> %53, %34
  %55 = fadd <4 x double> %38, %54
  %56 = fsub <4 x double> %55, %38
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> %38, %57
  %59 = fsub <4 x double> %54, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fadd <4 x double> %51, %60
  %62 = fadd <4 x double> %55, %61
  %63 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %62, i32 11) #6
  %64 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %63) #6
  %65 = fmul <4 x double> %34, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %66 = fadd <4 x double> %65, %0
  %67 = fmul <4 x double> %63, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %68 = fadd <4 x double> %66, %67
  %69 = fsub <4 x double> %66, %68
  %70 = fadd <4 x double> %67, %69
  %71 = fmul <4 x double> %34, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %72 = fadd <4 x double> %71, %68
  %73 = fsub <4 x double> %72, %68
  %74 = fsub <4 x double> %72, %73
  %75 = fsub <4 x double> %68, %74
  %76 = fsub <4 x double> %71, %73
  %77 = fadd <4 x double> %76, %75
  %78 = fadd <4 x double> %70, %77
  %79 = fmul <4 x double> %63, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %80 = fadd <4 x double> %79, %72
  %81 = fsub <4 x double> %80, %72
  %82 = fsub <4 x double> %80, %81
  %83 = fsub <4 x double> %72, %82
  %84 = fsub <4 x double> %79, %81
  %85 = fadd <4 x double> %84, %83
  %86 = fadd <4 x double> %85, %78
  %87 = fmul <4 x double> %34, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %88 = fadd <4 x double> %87, %80
  %89 = fsub <4 x double> %88, %80
  %90 = fsub <4 x double> %88, %89
  %91 = fsub <4 x double> %80, %90
  %92 = fsub <4 x double> %87, %89
  %93 = fadd <4 x double> %92, %91
  %94 = fadd <4 x double> %93, %86
  %95 = fmul <4 x double> %63, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %96 = fadd <4 x double> %95, %88
  %97 = fsub <4 x double> %96, %88
  %98 = fsub <4 x double> %96, %97
  %99 = fsub <4 x double> %88, %98
  %100 = fsub <4 x double> %95, %97
  %101 = fadd <4 x double> %100, %99
  %102 = fadd <4 x double> %101, %94
  %103 = fadd <4 x double> %34, %63
  %104 = fmul <4 x double> %103, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %105 = fadd <4 x double> %104, %96
  %106 = fsub <4 x double> %96, %105
  %107 = fadd <4 x double> %104, %106
  %108 = fadd <4 x double> %107, %102
  %109 = bitcast <4 x double> %108 to <4 x i64>
  br label %331

; <label>:110:                                    ; preds = %23
  %111 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %112 = shufflevector <4 x i64> %2, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %113 = bitcast <2 x i64> %111 to <4 x i32>
  %114 = shufflevector <4 x i32> %113, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %115 = bitcast <4 x i32> %114 to <2 x i64>
  %116 = bitcast <2 x i64> %112 to <4 x i32>
  %117 = shufflevector <4 x i32> %116, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <2 x i64> %118, <2 x i64> %115, <2 x i32> <i32 2, i32 1>
  %120 = bitcast <2 x i64> %119 to <4 x i32>
  %121 = lshr <4 x i32> %120, <i32 20, i32 20, i32 20, i32 20>
  %122 = and <4 x i32> %121, <i32 2047, i32 2047, i32 2047, i32 2047>
  %123 = add nsw <4 x i32> %122, <i32 -1078, i32 -1078, i32 -1078, i32 -1078>
  %124 = icmp ugt <4 x i32> %122, <i32 1723, i32 1723, i32 1723, i32 1723>
  %125 = select <4 x i1> %124, <4 x i32> <i32 -64, i32 -64, i32 -64, i32 -64>, <4 x i32> zeroinitializer
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %127 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %128 = and <4 x i32> %126, <i32 0, i32 -1, i32 0, i32 -1>
  %129 = shl <4 x i32> %128, <i32 20, i32 20, i32 20, i32 20>
  %130 = and <4 x i32> %127, <i32 0, i32 -1, i32 0, i32 -1>
  %131 = shl <4 x i32> %130, <i32 20, i32 20, i32 20, i32 20>
  %132 = add <4 x i32> %129, %113
  %133 = add <4 x i32> %131, %116
  %134 = bitcast <4 x i32> %132 to <2 x i64>
  %135 = bitcast <4 x i32> %133 to <2 x i64>
  %136 = shufflevector <2 x i64> %134, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %137 = shufflevector <2 x i64> %135, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %138 = shufflevector <4 x i64> %136, <4 x i64> %137, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %139 = bitcast <4 x i64> %138 to <4 x double>
  %140 = ashr <4 x i32> %123, <i32 31, i32 31, i32 31, i32 31>
  %141 = xor <4 x i32> %140, <i32 1073741823, i32 1073741823, i32 1073741823, i32 1073741823>
  %142 = and <4 x i32> %141, %123
  %143 = shl <4 x i32> %142, <i32 2, i32 2, i32 2, i32 2>
  %144 = extractelement <4 x i32> %143, i32 3
  %145 = sext i32 %144 to i64
  %146 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %145
  %147 = load double, double* %146, align 8, !tbaa !3, !noalias !28
  %148 = extractelement <4 x i32> %143, i32 2
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %149
  %151 = load double, double* %150, align 8, !tbaa !3, !noalias !28
  %152 = extractelement <4 x i32> %143, i32 1
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %153
  %155 = load double, double* %154, align 8, !tbaa !3, !noalias !28
  %156 = extractelement <4 x i32> %143, i32 0
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds [0 x double], [0 x double]* @rempitabdp, i64 0, i64 %157
  %159 = load double, double* %158, align 8, !tbaa !3, !noalias !28
  %160 = insertelement <4 x double> undef, double %159, i32 0
  %161 = insertelement <4 x double> %160, double %155, i32 1
  %162 = insertelement <4 x double> %161, double %151, i32 2
  %163 = insertelement <4 x double> %162, double %147, i32 3
  %164 = and <4 x i64> %138, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %165 = bitcast <4 x i64> %164 to <4 x double>
  %166 = fsub <4 x double> %139, %165
  %167 = bitcast <4 x double> %163 to <4 x i64>
  %168 = and <4 x i64> %167, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %169 = bitcast <4 x i64> %168 to <4 x double>
  %170 = fsub <4 x double> %163, %169
  %171 = fmul <4 x double> %163, %139
  %172 = fmul <4 x double> %165, %169
  %173 = bitcast <4 x double> %171 to <4 x i64>
  %174 = xor <4 x i64> %173, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %175 = bitcast <4 x i64> %174 to <4 x double>
  %176 = fmul <4 x double> %166, %169
  %177 = fmul <4 x double> %170, %165
  %178 = fmul <4 x double> %166, %170
  %179 = fadd <4 x double> %172, %175
  %180 = fadd <4 x double> %176, %179
  %181 = fadd <4 x double> %177, %180
  %182 = fadd <4 x double> %178, %181
  %183 = fmul <4 x double> %171, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %184 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %183, i32 8) #6
  %185 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %171, i32 8) #6
  %186 = fmul <4 x double> %185, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %187 = fsub <4 x double> %184, %186
  %188 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %187) #6
  %189 = fmul <4 x double> %184, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %190 = fsub <4 x double> %171, %189
  %191 = fadd <4 x double> %190, %182
  %192 = fsub <4 x double> %190, %191
  %193 = fadd <4 x double> %182, %192
  %194 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %145
  %195 = load double, double* %194, align 8, !tbaa !3, !noalias !28
  %196 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %149
  %197 = load double, double* %196, align 8, !tbaa !3, !noalias !28
  %198 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %153
  %199 = load double, double* %198, align 8, !tbaa !3, !noalias !28
  %200 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1), i64 %157
  %201 = load double, double* %200, align 8, !tbaa !3, !noalias !28
  %202 = insertelement <4 x double> undef, double %201, i32 0
  %203 = insertelement <4 x double> %202, double %199, i32 1
  %204 = insertelement <4 x double> %203, double %197, i32 2
  %205 = insertelement <4 x double> %204, double %195, i32 3
  %206 = bitcast <4 x double> %205 to <4 x i64>
  %207 = and <4 x i64> %206, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %208 = bitcast <4 x i64> %207 to <4 x double>
  %209 = fsub <4 x double> %205, %208
  %210 = fmul <4 x double> %205, %139
  %211 = fmul <4 x double> %165, %208
  %212 = bitcast <4 x double> %210 to <4 x i64>
  %213 = xor <4 x i64> %212, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %214 = bitcast <4 x i64> %213 to <4 x double>
  %215 = fmul <4 x double> %166, %208
  %216 = fmul <4 x double> %209, %165
  %217 = fmul <4 x double> %166, %209
  %218 = fadd <4 x double> %211, %214
  %219 = fadd <4 x double> %215, %218
  %220 = fadd <4 x double> %216, %219
  %221 = fadd <4 x double> %217, %220
  %222 = fadd <4 x double> %210, %191
  %223 = fsub <4 x double> %222, %191
  %224 = fsub <4 x double> %222, %223
  %225 = fsub <4 x double> %191, %224
  %226 = fsub <4 x double> %210, %223
  %227 = fadd <4 x double> %226, %225
  %228 = fadd <4 x double> %193, %221
  %229 = fadd <4 x double> %227, %228
  %230 = fmul <4 x double> %222, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %231 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %230, i32 8) #6
  %232 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %222, i32 8) #6
  %233 = fmul <4 x double> %232, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %234 = fsub <4 x double> %231, %233
  %235 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %234) #6
  %236 = fmul <4 x double> %231, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %237 = fsub <4 x double> %222, %236
  %238 = add <4 x i32> %235, %188
  %239 = fadd <4 x double> %237, %229
  %240 = fsub <4 x double> %237, %239
  %241 = fadd <4 x double> %229, %240
  %242 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %145
  %243 = load double, double* %242, align 8, !tbaa !3, !noalias !28
  %244 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %149
  %245 = load double, double* %244, align 8, !tbaa !3, !noalias !28
  %246 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %153
  %247 = load double, double* %246, align 8, !tbaa !3, !noalias !28
  %248 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2), i64 %157
  %249 = load double, double* %248, align 8, !tbaa !3, !noalias !28
  %250 = insertelement <4 x double> undef, double %249, i32 0
  %251 = insertelement <4 x double> %250, double %247, i32 1
  %252 = insertelement <4 x double> %251, double %245, i32 2
  %253 = insertelement <4 x double> %252, double %243, i32 3
  %254 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %145
  %255 = load double, double* %254, align 8, !tbaa !3, !noalias !28
  %256 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %149
  %257 = load double, double* %256, align 8, !tbaa !3, !noalias !28
  %258 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %153
  %259 = load double, double* %258, align 8, !tbaa !3, !noalias !28
  %260 = getelementptr inbounds double, double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3), i64 %157
  %261 = load double, double* %260, align 8, !tbaa !3, !noalias !28
  %262 = insertelement <4 x double> undef, double %261, i32 0
  %263 = insertelement <4 x double> %262, double %259, i32 1
  %264 = insertelement <4 x double> %263, double %257, i32 2
  %265 = insertelement <4 x double> %264, double %255, i32 3
  %266 = bitcast <4 x double> %253 to <4 x i64>
  %267 = and <4 x i64> %266, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %268 = bitcast <4 x i64> %267 to <4 x double>
  %269 = fsub <4 x double> %253, %268
  %270 = fmul <4 x double> %253, %139
  %271 = fmul <4 x double> %165, %268
  %272 = bitcast <4 x double> %270 to <4 x i64>
  %273 = xor <4 x i64> %272, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %274 = bitcast <4 x i64> %273 to <4 x double>
  %275 = fmul <4 x double> %269, %165
  %276 = fmul <4 x double> %166, %268
  %277 = fmul <4 x double> %166, %269
  %278 = fmul <4 x double> %265, %139
  %279 = fadd <4 x double> %271, %274
  %280 = fadd <4 x double> %275, %279
  %281 = fadd <4 x double> %276, %280
  %282 = fadd <4 x double> %277, %281
  %283 = fadd <4 x double> %278, %282
  %284 = fadd <4 x double> %270, %239
  %285 = fsub <4 x double> %284, %239
  %286 = fsub <4 x double> %284, %285
  %287 = fsub <4 x double> %239, %286
  %288 = fsub <4 x double> %270, %285
  %289 = fadd <4 x double> %288, %287
  %290 = fadd <4 x double> %241, %283
  %291 = fadd <4 x double> %289, %290
  %292 = fadd <4 x double> %284, %291
  %293 = fsub <4 x double> %284, %292
  %294 = fadd <4 x double> %291, %293
  %295 = bitcast <4 x double> %292 to <4 x i64>
  %296 = and <4 x i64> %295, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %297 = bitcast <4 x i64> %296 to <4 x double>
  %298 = fsub <4 x double> %292, %297
  %299 = fmul <4 x double> %292, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %300 = fmul <4 x double> %297, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %301 = bitcast <4 x double> %299 to <4 x i64>
  %302 = xor <4 x i64> %301, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %303 = bitcast <4 x i64> %302 to <4 x double>
  %304 = fmul <4 x double> %298, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %305 = fmul <4 x double> %297, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %306 = fmul <4 x double> %298, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %307 = fmul <4 x double> %292, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %308 = fmul <4 x double> %294, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %309 = fadd <4 x double> %300, %303
  %310 = fadd <4 x double> %304, %309
  %311 = fadd <4 x double> %305, %310
  %312 = fadd <4 x double> %306, %311
  %313 = fadd <4 x double> %307, %312
  %314 = fadd <4 x double> %308, %313
  %315 = and <4 x i64> %138, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %316 = bitcast <4 x i64> %315 to <4 x double>
  %317 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %316, <4 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i8 17) #6
  %318 = bitcast <4 x double> %317 to <4 x i64>
  %319 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %299, <4 x double> %139, <4 x double> %317) #6
  %320 = bitcast <4 x double> %314 to <4 x i64>
  %321 = xor <4 x i64> %318, <i64 -1, i64 -1, i64 -1, i64 -1>
  %322 = and <4 x i64> %320, %321
  %323 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %324 = fcmp uno <4 x double> %0, zeroinitializer
  %325 = or <4 x i1> %323, %324
  %326 = sext <4 x i1> %325 to <4 x i64>
  %327 = bitcast <4 x double> %319 to <4 x i64>
  %328 = or <4 x i64> %327, %326
  %329 = bitcast <4 x i64> %328 to <4 x double>
  %330 = or <4 x i64> %322, %326
  br label %331

; <label>:331:                                    ; preds = %31, %110, %12
  %332 = phi <4 x double> [ %329, %110 ], [ %105, %31 ], [ %19, %12 ]
  %333 = phi <4 x i64> [ %330, %110 ], [ %109, %31 ], [ %22, %12 ]
  %334 = phi <4 x i32> [ %238, %110 ], [ %64, %31 ], [ %15, %12 ]
  %335 = bitcast <4 x i64> %333 to <4 x double>
  %336 = fmul <4 x double> %332, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %337 = fmul <4 x double> %335, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %338 = bitcast <4 x double> %336 to <4 x i64>
  %339 = and <4 x i64> %338, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %340 = bitcast <4 x i64> %339 to <4 x double>
  %341 = fsub <4 x double> %336, %340
  %342 = fmul <4 x double> %336, %336
  %343 = fmul <4 x double> %340, %340
  %344 = bitcast <4 x double> %342 to <4 x i64>
  %345 = xor <4 x i64> %344, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %346 = bitcast <4 x i64> %345 to <4 x double>
  %347 = fadd <4 x double> %340, %340
  %348 = fmul <4 x double> %347, %341
  %349 = fmul <4 x double> %341, %341
  %350 = fadd <4 x double> %337, %337
  %351 = fmul <4 x double> %336, %350
  %352 = fadd <4 x double> %343, %346
  %353 = fadd <4 x double> %352, %348
  %354 = fadd <4 x double> %349, %353
  %355 = fadd <4 x double> %351, %354
  %356 = fmul <4 x double> %342, %342
  %357 = fmul <4 x double> %356, %356
  %358 = fmul <4 x double> %342, <double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED>
  %359 = fadd <4 x double> %358, <double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF>
  %360 = fmul <4 x double> %342, <double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93>
  %361 = fadd <4 x double> %360, <double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959>
  %362 = fmul <4 x double> %356, %359
  %363 = fadd <4 x double> %361, %362
  %364 = fmul <4 x double> %342, <double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090>
  %365 = fadd <4 x double> %364, <double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5>
  %366 = fmul <4 x double> %342, <double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06>
  %367 = fadd <4 x double> %366, <double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933>
  %368 = fmul <4 x double> %356, %365
  %369 = fadd <4 x double> %367, %368
  %370 = fmul <4 x double> %357, %363
  %371 = fadd <4 x double> %369, %370
  %372 = fmul <4 x double> %342, %371
  %373 = fadd <4 x double> %372, <double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568>
  %374 = and <4 x i64> %344, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %375 = bitcast <4 x i64> %374 to <4 x double>
  %376 = fsub <4 x double> %342, %375
  %377 = fmul <4 x double> %336, %342
  %378 = fmul <4 x double> %340, %375
  %379 = bitcast <4 x double> %377 to <4 x i64>
  %380 = xor <4 x i64> %379, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %381 = bitcast <4 x i64> %380 to <4 x double>
  %382 = fmul <4 x double> %376, %340
  %383 = fmul <4 x double> %341, %375
  %384 = fmul <4 x double> %341, %376
  %385 = fmul <4 x double> %342, %337
  %386 = fmul <4 x double> %336, %355
  %387 = fadd <4 x double> %378, %381
  %388 = fadd <4 x double> %382, %387
  %389 = fadd <4 x double> %383, %388
  %390 = fadd <4 x double> %384, %389
  %391 = fadd <4 x double> %385, %390
  %392 = fadd <4 x double> %386, %391
  %393 = and <4 x i64> %379, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %394 = bitcast <4 x i64> %393 to <4 x double>
  %395 = fsub <4 x double> %377, %394
  %396 = bitcast <4 x double> %373 to <4 x i64>
  %397 = and <4 x i64> %396, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %398 = bitcast <4 x i64> %397 to <4 x double>
  %399 = fsub <4 x double> %373, %398
  %400 = fmul <4 x double> %377, %373
  %401 = fmul <4 x double> %394, %398
  %402 = bitcast <4 x double> %400 to <4 x i64>
  %403 = xor <4 x i64> %402, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %404 = bitcast <4 x i64> %403 to <4 x double>
  %405 = fmul <4 x double> %395, %398
  %406 = fmul <4 x double> %399, %394
  %407 = fmul <4 x double> %395, %399
  %408 = fmul <4 x double> %373, %392
  %409 = fadd <4 x double> %401, %404
  %410 = fadd <4 x double> %405, %409
  %411 = fadd <4 x double> %406, %410
  %412 = fadd <4 x double> %407, %411
  %413 = fadd <4 x double> %408, %412
  %414 = fadd <4 x double> %336, %400
  %415 = fsub <4 x double> %336, %414
  %416 = fadd <4 x double> %400, %415
  %417 = fadd <4 x double> %337, %416
  %418 = fadd <4 x double> %417, %413
  %419 = bitcast <4 x double> %414 to <4 x i64>
  %420 = and <4 x i64> %419, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %421 = bitcast <4 x i64> %420 to <4 x double>
  %422 = fsub <4 x double> %414, %421
  %423 = fmul <4 x double> %414, %414
  %424 = fmul <4 x double> %421, %421
  %425 = bitcast <4 x double> %423 to <4 x i64>
  %426 = xor <4 x i64> %425, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %427 = bitcast <4 x i64> %426 to <4 x double>
  %428 = fadd <4 x double> %421, %421
  %429 = fmul <4 x double> %428, %422
  %430 = fmul <4 x double> %422, %422
  %431 = fadd <4 x double> %418, %418
  %432 = fmul <4 x double> %414, %431
  %433 = fadd <4 x double> %424, %427
  %434 = fadd <4 x double> %433, %429
  %435 = fadd <4 x double> %430, %434
  %436 = fadd <4 x double> %435, %432
  %437 = fadd <4 x double> %423, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %438 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %437
  %439 = fadd <4 x double> %423, %438
  %440 = fadd <4 x double> %439, %436
  %441 = fmul <4 x double> %414, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %442 = fmul <4 x double> %418, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %443 = and <4 x i32> %334, <i32 1, i32 1, i32 1, i32 1>
  %444 = icmp ne <4 x i32> %443, zeroinitializer
  %445 = sitofp <4 x i1> %444 to <4 x double>
  %446 = fcmp oeq <4 x double> %445, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %447 = sext <4 x i1> %446 to <4 x i64>
  %448 = bitcast <4 x double> %437 to <4 x i64>
  %449 = xor <4 x i64> %448, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %450 = bitcast <4 x double> %440 to <4 x i64>
  %451 = xor <4 x i64> %450, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %452 = bitcast <4 x i64> %449 to <4 x double>
  %453 = bitcast <4 x i64> %451 to <4 x double>
  %454 = bitcast <4 x i64> %447 to <4 x double>
  %455 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %441, <4 x double> %452, <4 x double> %454) #6
  %456 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %442, <4 x double> %453, <4 x double> %454) #6
  %457 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %437, <4 x double> %441, <4 x double> %454) #6
  %458 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %440, <4 x double> %442, <4 x double> %454) #6
  %459 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %457
  %460 = bitcast <4 x double> %457 to <4 x i64>
  %461 = and <4 x i64> %460, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %462 = bitcast <4 x i64> %461 to <4 x double>
  %463 = fsub <4 x double> %457, %462
  %464 = bitcast <4 x double> %459 to <4 x i64>
  %465 = and <4 x i64> %464, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %466 = bitcast <4 x i64> %465 to <4 x double>
  %467 = fsub <4 x double> %459, %466
  %468 = bitcast <4 x double> %455 to <4 x i64>
  %469 = and <4 x i64> %468, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %470 = bitcast <4 x i64> %469 to <4 x double>
  %471 = fsub <4 x double> %455, %470
  %472 = fmul <4 x double> %455, %459
  %473 = fmul <4 x double> %470, %466
  %474 = fsub <4 x double> %473, %472
  %475 = fmul <4 x double> %467, %470
  %476 = fmul <4 x double> %471, %466
  %477 = fmul <4 x double> %471, %467
  %478 = fmul <4 x double> %462, %466
  %479 = fmul <4 x double> %467, %462
  %480 = fmul <4 x double> %463, %466
  %481 = fmul <4 x double> %463, %467
  %482 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %478
  %483 = fsub <4 x double> %482, %479
  %484 = fsub <4 x double> %483, %480
  %485 = fsub <4 x double> %484, %481
  %486 = fmul <4 x double> %472, %485
  %487 = fadd <4 x double> %474, %475
  %488 = fadd <4 x double> %476, %487
  %489 = fadd <4 x double> %477, %488
  %490 = fadd <4 x double> %489, %486
  %491 = fmul <4 x double> %458, %472
  %492 = fsub <4 x double> %456, %491
  %493 = fmul <4 x double> %459, %492
  %494 = fadd <4 x double> %493, %490
  %495 = fadd <4 x double> %472, %494
  %496 = fcmp oeq <4 x double> %0, zeroinitializer
  %497 = sext <4 x i1> %496 to <4 x i64>
  %498 = bitcast <4 x i64> %497 to <4 x double>
  %499 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %495, <4 x double> %0, <4 x double> %498) #6
  ret <4 x double> %499
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_atan2d4_u35avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %8 = xor <4 x i64> %7, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %9 = bitcast <4 x i64> %8 to <4 x double>
  %10 = fcmp oeq <4 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %11 = select <4 x i1> %10, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> zeroinitializer
  %12 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %11) #6
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = and <2 x i64> %13, <i64 -4294967298, i64 -4294967298>
  %15 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %16 = bitcast <4 x i64> %15 to <4 x double>
  %17 = bitcast <2 x i64> %14 to <4 x i32>
  %18 = add <4 x i32> %17, <i32 1, i32 1, i32 1, i32 1>
  %19 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %16, <4 x double> %5, i8 17) #6
  %20 = bitcast <4 x double> %19 to <4 x i64>
  %21 = and <4 x i64> %20, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %22) #6
  %24 = bitcast <2 x i64> %14 to <16 x i8>
  %25 = bitcast <4 x i32> %18 to <16 x i8>
  %26 = bitcast <4 x i32> %23 to <16 x i8>
  %27 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %24, <16 x i8> %25, <16 x i8> %26) #6
  %28 = or <4 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %29 = bitcast <4 x i64> %28 to <4 x double>
  %30 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %29, <4 x double> %19) #6
  %31 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %16, <4 x double> %5) #6
  %32 = fdiv <4 x double> %30, %31
  %33 = fmul <4 x double> %32, %32
  %34 = fmul <4 x double> %33, %33
  %35 = fmul <4 x double> %34, %34
  %36 = fmul <4 x double> %35, %35
  %37 = fmul <4 x double> %36, %36
  %38 = fmul <4 x double> %33, <double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF>
  %39 = fadd <4 x double> %38, <double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA>
  %40 = fmul <4 x double> %34, <double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F>
  %41 = fadd <4 x double> %40, %39
  %42 = fmul <4 x double> %33, <double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20>
  %43 = fadd <4 x double> %42, <double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56>
  %44 = fmul <4 x double> %33, <double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286>
  %45 = fadd <4 x double> %44, <double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC>
  %46 = fmul <4 x double> %34, %43
  %47 = fadd <4 x double> %45, %46
  %48 = fmul <4 x double> %33, <double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E>
  %49 = fadd <4 x double> %48, <double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638>
  %50 = fmul <4 x double> %33, <double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE>
  %51 = fadd <4 x double> %50, <double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA>
  %52 = fmul <4 x double> %34, %49
  %53 = fadd <4 x double> %51, %52
  %54 = fmul <4 x double> %35, %47
  %55 = fadd <4 x double> %53, %54
  %56 = fmul <4 x double> %33, <double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622>
  %57 = fadd <4 x double> %56, <double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0>
  %58 = fmul <4 x double> %33, <double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1>
  %59 = fadd <4 x double> %58, <double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8>
  %60 = fmul <4 x double> %34, %57
  %61 = fadd <4 x double> %59, %60
  %62 = fmul <4 x double> %33, <double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F>
  %63 = fadd <4 x double> %62, <double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB>
  %64 = fmul <4 x double> %33, <double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD>
  %65 = fadd <4 x double> %64, <double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5>
  %66 = fmul <4 x double> %34, %63
  %67 = fadd <4 x double> %65, %66
  %68 = fmul <4 x double> %35, %61
  %69 = fadd <4 x double> %67, %68
  %70 = fmul <4 x double> %36, %55
  %71 = fadd <4 x double> %69, %70
  %72 = fmul <4 x double> %41, %37
  %73 = fadd <4 x double> %72, %71
  %74 = fmul <4 x double> %33, %73
  %75 = fmul <4 x double> %32, %74
  %76 = fadd <4 x double> %32, %75
  %77 = bitcast <16 x i8> %27 to <4 x i32>
  %78 = sitofp <4 x i32> %77 to <4 x double>
  %79 = fmul <4 x double> %78, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %80 = fadd <4 x double> %79, %76
  %81 = bitcast <4 x double> %80 to <4 x i64>
  %82 = xor <4 x i64> %7, %81
  %83 = bitcast <4 x i64> %82 to <4 x double>
  %84 = fcmp oeq <4 x double> %16, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %85 = fcmp oeq <4 x double> %1, zeroinitializer
  %86 = or <4 x i1> %84, %85
  %87 = sext <4 x i1> %86 to <4 x i64>
  %88 = or <4 x i64> %7, <i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352>
  %89 = bitcast <4 x i64> %88 to <4 x double>
  %90 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %89
  %91 = select <4 x i1> %84, <4 x double> %90, <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %92 = bitcast <4 x i64> %87 to <4 x double>
  %93 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %83, <4 x double> %91, <4 x double> %92) #6
  %94 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %95 = sext <4 x i1> %94 to <4 x i64>
  %96 = or <4 x i64> %7, <i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856>
  %97 = bitcast <4 x i64> %96 to <4 x double>
  %98 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %97
  %99 = select <4 x i1> %84, <4 x double> %98, <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %100 = bitcast <4 x i64> %95 to <4 x double>
  %101 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %93, <4 x double> %99, <4 x double> %100) #6
  %102 = fcmp oeq <4 x double> %0, zeroinitializer
  %103 = sext <4 x i1> %102 to <4 x i64>
  %104 = select <4 x i1> %10, <4 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, <4 x double> zeroinitializer
  %105 = bitcast <4 x i64> %103 to <4 x double>
  %106 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %101, <4 x double> %104, <4 x double> %105) #6
  %107 = fcmp uno <4 x double> %0, %1
  %108 = bitcast <4 x double> %106 to <4 x i64>
  %109 = and <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %110 = xor <4 x i64> %109, %108
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = select <4 x i1> %107, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %111
  ret <4 x double> %112
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_atan2d4_u10avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %1 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001>, i8 17) #6
  %7 = fmul <4 x double> %1, <double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000>
  %8 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %1, <4 x double> %7, <4 x double> %6) #6
  %9 = fmul <4 x double> %0, <double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %9, <4 x double> %6) #6
  %11 = bitcast <4 x double> %10 to <4 x i64>
  %12 = and <4 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = bitcast <4 x double> %8 to <4 x i64>
  %15 = and <4 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %16 = xor <4 x i64> %15, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %17 = bitcast <4 x i64> %16 to <4 x double>
  %18 = fcmp oeq <4 x double> %17, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %19 = select <4 x i1> %18, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> zeroinitializer
  %20 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %19) #6
  %21 = bitcast <4 x i32> %20 to <2 x i64>
  %22 = and <2 x i64> %21, <i64 -4294967298, i64 -4294967298>
  %23 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> zeroinitializer, i8 17) #6
  %24 = bitcast <4 x double> %23 to <4 x i64>
  %25 = and <4 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = xor <4 x i64> %25, %14
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = bitcast <4 x i64> %25 to <4 x double>
  %29 = bitcast <2 x i64> %22 to <4 x i32>
  %30 = add <4 x i32> %29, <i32 1, i32 1, i32 1, i32 1>
  %31 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %27, <4 x double> %13, i8 17) #6
  %32 = bitcast <4 x double> %31 to <4 x i64>
  %33 = and <4 x i64> %32, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %34 = bitcast <4 x i64> %33 to <4 x double>
  %35 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %34) #6
  %36 = bitcast <2 x i64> %22 to <16 x i8>
  %37 = bitcast <4 x i32> %30 to <16 x i8>
  %38 = bitcast <4 x i32> %35 to <16 x i8>
  %39 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %36, <16 x i8> %37, <16 x i8> %38) #6
  %40 = xor <4 x i64> %26, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %41 = xor <4 x i64> %25, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <4 x i64> %40 to <4 x double>
  %43 = bitcast <4 x i64> %41 to <4 x double>
  %44 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %13, <4 x double> %42, <4 x double> %31) #6
  %45 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %43, <4 x double> %31) #6
  %46 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %27, <4 x double> %13, <4 x double> %31) #6
  %47 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %28, <4 x double> zeroinitializer, <4 x double> %31) #6
  %48 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %46
  %49 = bitcast <4 x double> %46 to <4 x i64>
  %50 = and <4 x i64> %49, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %51 = bitcast <4 x i64> %50 to <4 x double>
  %52 = fsub <4 x double> %46, %51
  %53 = bitcast <4 x double> %48 to <4 x i64>
  %54 = and <4 x i64> %53, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %55 = bitcast <4 x i64> %54 to <4 x double>
  %56 = fsub <4 x double> %48, %55
  %57 = bitcast <4 x double> %44 to <4 x i64>
  %58 = and <4 x i64> %57, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %59 = bitcast <4 x i64> %58 to <4 x double>
  %60 = fsub <4 x double> %44, %59
  %61 = fmul <4 x double> %44, %48
  %62 = fmul <4 x double> %59, %55
  %63 = fsub <4 x double> %62, %61
  %64 = fmul <4 x double> %56, %59
  %65 = fmul <4 x double> %60, %55
  %66 = fmul <4 x double> %60, %56
  %67 = fmul <4 x double> %51, %55
  %68 = fmul <4 x double> %56, %51
  %69 = fmul <4 x double> %52, %55
  %70 = fmul <4 x double> %52, %56
  %71 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %67
  %72 = fsub <4 x double> %71, %68
  %73 = fsub <4 x double> %72, %69
  %74 = fsub <4 x double> %73, %70
  %75 = fmul <4 x double> %61, %74
  %76 = fadd <4 x double> %63, %64
  %77 = fadd <4 x double> %65, %76
  %78 = fadd <4 x double> %66, %77
  %79 = fadd <4 x double> %78, %75
  %80 = fmul <4 x double> %47, %61
  %81 = fsub <4 x double> %45, %80
  %82 = fmul <4 x double> %48, %81
  %83 = fadd <4 x double> %82, %79
  %84 = bitcast <4 x double> %61 to <4 x i64>
  %85 = and <4 x i64> %84, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fsub <4 x double> %61, %86
  %88 = fmul <4 x double> %61, %61
  %89 = fmul <4 x double> %86, %86
  %90 = bitcast <4 x double> %88 to <4 x i64>
  %91 = xor <4 x i64> %90, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %92 = bitcast <4 x i64> %91 to <4 x double>
  %93 = fadd <4 x double> %86, %86
  %94 = fmul <4 x double> %93, %87
  %95 = fmul <4 x double> %87, %87
  %96 = fadd <4 x double> %83, %83
  %97 = fmul <4 x double> %61, %96
  %98 = fadd <4 x double> %89, %92
  %99 = fadd <4 x double> %98, %94
  %100 = fadd <4 x double> %95, %99
  %101 = fadd <4 x double> %100, %97
  %102 = fadd <4 x double> %88, %101
  %103 = fsub <4 x double> %88, %102
  %104 = fadd <4 x double> %101, %103
  %105 = fmul <4 x double> %102, %102
  %106 = fmul <4 x double> %105, %105
  %107 = fmul <4 x double> %106, %106
  %108 = fmul <4 x double> %102, <double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72>
  %109 = fadd <4 x double> %108, <double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE>
  %110 = fmul <4 x double> %102, <double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98>
  %111 = fadd <4 x double> %110, <double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE>
  %112 = fmul <4 x double> %105, %109
  %113 = fadd <4 x double> %111, %112
  %114 = fmul <4 x double> %102, <double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3>
  %115 = fadd <4 x double> %114, <double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5>
  %116 = fmul <4 x double> %102, <double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320>
  %117 = fadd <4 x double> %116, <double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7>
  %118 = fmul <4 x double> %105, %115
  %119 = fadd <4 x double> %117, %118
  %120 = fmul <4 x double> %106, %113
  %121 = fadd <4 x double> %119, %120
  %122 = fmul <4 x double> %102, <double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD>
  %123 = fadd <4 x double> %122, <double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577>
  %124 = fmul <4 x double> %102, <double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6>
  %125 = fadd <4 x double> %124, <double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E>
  %126 = fmul <4 x double> %105, %123
  %127 = fadd <4 x double> %125, %126
  %128 = fmul <4 x double> %102, <double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B>
  %129 = fadd <4 x double> %128, <double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6>
  %130 = fmul <4 x double> %102, <double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10>
  %131 = fadd <4 x double> %130, <double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC>
  %132 = fmul <4 x double> %105, %129
  %133 = fadd <4 x double> %131, %132
  %134 = fmul <4 x double> %106, %127
  %135 = fadd <4 x double> %133, %134
  %136 = fmul <4 x double> %107, %121
  %137 = fadd <4 x double> %135, %136
  %138 = fmul <4 x double> %102, %137
  %139 = fadd <4 x double> %138, <double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B>
  %140 = fmul <4 x double> %102, %139
  %141 = fadd <4 x double> %140, <double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7>
  %142 = fmul <4 x double> %102, %141
  %143 = fadd <4 x double> %142, <double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0>
  %144 = fmul <4 x double> %102, %143
  %145 = fadd <4 x double> %144, <double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A>
  %146 = bitcast <4 x double> %102 to <4 x i64>
  %147 = and <4 x i64> %146, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = fsub <4 x double> %102, %148
  %150 = fmul <4 x double> %61, %102
  %151 = fmul <4 x double> %86, %148
  %152 = bitcast <4 x double> %150 to <4 x i64>
  %153 = xor <4 x i64> %152, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %154 = bitcast <4 x i64> %153 to <4 x double>
  %155 = fmul <4 x double> %87, %148
  %156 = fmul <4 x double> %149, %86
  %157 = fmul <4 x double> %87, %149
  %158 = fmul <4 x double> %61, %104
  %159 = fmul <4 x double> %83, %102
  %160 = fadd <4 x double> %151, %154
  %161 = fadd <4 x double> %155, %160
  %162 = fadd <4 x double> %156, %161
  %163 = fadd <4 x double> %157, %162
  %164 = fadd <4 x double> %158, %163
  %165 = fadd <4 x double> %159, %164
  %166 = and <4 x i64> %152, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %167 = bitcast <4 x i64> %166 to <4 x double>
  %168 = fsub <4 x double> %150, %167
  %169 = bitcast <4 x double> %145 to <4 x i64>
  %170 = and <4 x i64> %169, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %171 = bitcast <4 x i64> %170 to <4 x double>
  %172 = fsub <4 x double> %145, %171
  %173 = fmul <4 x double> %150, %145
  %174 = fmul <4 x double> %167, %171
  %175 = bitcast <4 x double> %173 to <4 x i64>
  %176 = xor <4 x i64> %175, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %177 = bitcast <4 x i64> %176 to <4 x double>
  %178 = fmul <4 x double> %168, %171
  %179 = fmul <4 x double> %172, %167
  %180 = fmul <4 x double> %168, %172
  %181 = fmul <4 x double> %165, %145
  %182 = fadd <4 x double> %174, %177
  %183 = fadd <4 x double> %178, %182
  %184 = fadd <4 x double> %179, %183
  %185 = fadd <4 x double> %180, %184
  %186 = fadd <4 x double> %181, %185
  %187 = fadd <4 x double> %61, %173
  %188 = fsub <4 x double> %61, %187
  %189 = fadd <4 x double> %173, %188
  %190 = fadd <4 x double> %83, %189
  %191 = fadd <4 x double> %190, %186
  %192 = bitcast <16 x i8> %39 to <4 x i32>
  %193 = sitofp <4 x i32> %192 to <4 x double>
  %194 = bitcast <4 x double> %193 to <4 x i64>
  %195 = and <4 x i64> %194, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %196 = bitcast <4 x i64> %195 to <4 x double>
  %197 = fsub <4 x double> %193, %196
  %198 = fmul <4 x double> %193, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %199 = fmul <4 x double> %196, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %200 = bitcast <4 x double> %198 to <4 x i64>
  %201 = xor <4 x i64> %200, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %202 = bitcast <4 x i64> %201 to <4 x double>
  %203 = fmul <4 x double> %196, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %204 = fmul <4 x double> %197, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %205 = fmul <4 x double> %197, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %206 = fmul <4 x double> %193, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %207 = fadd <4 x double> %199, %202
  %208 = fadd <4 x double> %203, %207
  %209 = fadd <4 x double> %204, %208
  %210 = fadd <4 x double> %205, %209
  %211 = fadd <4 x double> %206, %210
  %212 = fadd <4 x double> %198, %187
  %213 = fsub <4 x double> %198, %212
  %214 = fadd <4 x double> %187, %213
  %215 = fadd <4 x double> %211, %214
  %216 = fadd <4 x double> %215, %191
  %217 = fadd <4 x double> %212, %216
  %218 = bitcast <4 x double> %217 to <4 x i64>
  %219 = xor <4 x i64> %15, %218
  %220 = bitcast <4 x i64> %219 to <4 x double>
  %221 = and <4 x i64> %14, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %222 = bitcast <4 x i64> %221 to <4 x double>
  %223 = fcmp oeq <4 x double> %222, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %224 = fcmp oeq <4 x double> %8, zeroinitializer
  %225 = or <4 x i1> %223, %224
  %226 = sext <4 x i1> %225 to <4 x i64>
  %227 = or <4 x i64> %15, <i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352>
  %228 = bitcast <4 x i64> %227 to <4 x double>
  %229 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %228
  %230 = select <4 x i1> %223, <4 x double> %229, <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %231 = bitcast <4 x i64> %226 to <4 x double>
  %232 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %220, <4 x double> %230, <4 x double> %231) #6
  %233 = fcmp oeq <4 x double> %13, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %234 = sext <4 x i1> %233 to <4 x i64>
  %235 = or <4 x i64> %15, <i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856>
  %236 = bitcast <4 x i64> %235 to <4 x double>
  %237 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %236
  %238 = select <4 x i1> %223, <4 x double> %237, <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %239 = bitcast <4 x i64> %234 to <4 x double>
  %240 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %232, <4 x double> %238, <4 x double> %239) #6
  %241 = fcmp oeq <4 x double> %10, zeroinitializer
  %242 = sext <4 x i1> %241 to <4 x i64>
  %243 = select <4 x i1> %18, <4 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, <4 x double> zeroinitializer
  %244 = bitcast <4 x i64> %242 to <4 x double>
  %245 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %240, <4 x double> %243, <4 x double> %244) #6
  %246 = fcmp uno <4 x double> %10, %8
  %247 = bitcast <4 x double> %245 to <4 x i64>
  %248 = and <4 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %249 = xor <4 x i64> %248, %247
  %250 = bitcast <4 x i64> %249 to <4 x double>
  %251 = select <4 x i1> %246, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %250
  ret <4 x double> %251
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_asind4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i8 17) #6
  %6 = fmul <4 x double> %0, %0
  %7 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %8 = fmul <4 x double> %7, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %9 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %6, <4 x double> %5) #6
  %10 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %9) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> %4, <4 x double> %5) #6
  %12 = fmul <4 x double> %9, %9
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %9, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %16 = fadd <4 x double> %15, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %17 = fmul <4 x double> %9, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %18 = fadd <4 x double> %17, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %19 = fmul <4 x double> %12, %16
  %20 = fadd <4 x double> %18, %19
  %21 = fmul <4 x double> %9, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %22 = fadd <4 x double> %21, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %23 = fmul <4 x double> %9, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %24 = fadd <4 x double> %23, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %25 = fmul <4 x double> %12, %22
  %26 = fadd <4 x double> %24, %25
  %27 = fmul <4 x double> %9, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %28 = fadd <4 x double> %27, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %29 = fmul <4 x double> %9, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %30 = fadd <4 x double> %29, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %31 = fmul <4 x double> %12, %28
  %32 = fadd <4 x double> %30, %31
  %33 = fmul <4 x double> %13, %26
  %34 = fadd <4 x double> %32, %33
  %35 = fmul <4 x double> %14, %20
  %36 = fadd <4 x double> %35, %34
  %37 = fmul <4 x double> %9, %11
  %38 = fmul <4 x double> %37, %36
  %39 = fadd <4 x double> %11, %38
  %40 = fmul <4 x double> %39, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %41 = fadd <4 x double> %40, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %42 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %41, <4 x double> %39, <4 x double> %5) #6
  %43 = bitcast <4 x double> %42 to <4 x i64>
  %44 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %45 = xor <4 x i64> %44, %43
  %46 = bitcast <4 x i64> %45 to <4 x double>
  ret <4 x double> %46
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_asind4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i8 17) #6
  %6 = fmul <4 x double> %0, %0
  %7 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %8 = fmul <4 x double> %7, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %9 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %6, <4 x double> %5) #6
  %10 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %9) #6
  %11 = bitcast <4 x double> %10 to <4 x i64>
  %12 = and <4 x i64> %11, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = fsub <4 x double> %10, %13
  %15 = fmul <4 x double> %10, %10
  %16 = fmul <4 x double> %13, %13
  %17 = bitcast <4 x double> %15 to <4 x i64>
  %18 = xor <4 x i64> %17, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %19 = bitcast <4 x i64> %18 to <4 x double>
  %20 = fmul <4 x double> %14, %13
  %21 = fmul <4 x double> %14, %14
  %22 = fadd <4 x double> %16, %19
  %23 = fadd <4 x double> %20, %22
  %24 = fadd <4 x double> %20, %23
  %25 = fadd <4 x double> %21, %24
  %26 = fadd <4 x double> %9, %15
  %27 = fsub <4 x double> %26, %9
  %28 = fsub <4 x double> %26, %27
  %29 = fsub <4 x double> %9, %28
  %30 = fsub <4 x double> %15, %27
  %31 = fadd <4 x double> %30, %29
  %32 = fadd <4 x double> %31, %25
  %33 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %10
  %34 = bitcast <4 x double> %33 to <4 x i64>
  %35 = and <4 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fsub <4 x double> %33, %36
  %38 = fmul <4 x double> %13, %36
  %39 = fmul <4 x double> %37, %13
  %40 = fmul <4 x double> %14, %36
  %41 = fmul <4 x double> %14, %37
  %42 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %38
  %43 = fsub <4 x double> %42, %39
  %44 = fsub <4 x double> %43, %40
  %45 = fsub <4 x double> %44, %41
  %46 = fmul <4 x double> %33, %45
  %47 = bitcast <4 x double> %26 to <4 x i64>
  %48 = and <4 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <4 x i64> %48 to <4 x double>
  %50 = fsub <4 x double> %26, %49
  %51 = fmul <4 x double> %33, %26
  %52 = fmul <4 x double> %36, %49
  %53 = bitcast <4 x double> %51 to <4 x i64>
  %54 = xor <4 x i64> %53, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %55 = bitcast <4 x i64> %54 to <4 x double>
  %56 = fmul <4 x double> %50, %36
  %57 = fmul <4 x double> %37, %49
  %58 = fmul <4 x double> %37, %50
  %59 = fmul <4 x double> %26, %46
  %60 = fmul <4 x double> %33, %32
  %61 = fadd <4 x double> %52, %55
  %62 = fadd <4 x double> %56, %61
  %63 = fadd <4 x double> %57, %62
  %64 = fadd <4 x double> %58, %63
  %65 = fadd <4 x double> %64, %59
  %66 = fadd <4 x double> %60, %65
  %67 = fmul <4 x double> %51, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %68 = fmul <4 x double> %66, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %69 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %67, <4 x double> %4, <4 x double> %5) #6
  %70 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %68, <4 x double> zeroinitializer, <4 x double> %5) #6
  %71 = fcmp oeq <4 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %72 = sext <4 x i1> %71 to <4 x i64>
  %73 = bitcast <4 x i64> %72 to <4 x double>
  %74 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %69, <4 x double> zeroinitializer, <4 x double> %73) #6
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %70, <4 x double> zeroinitializer, <4 x double> %73) #6
  %76 = fmul <4 x double> %9, %9
  %77 = fmul <4 x double> %76, %76
  %78 = fmul <4 x double> %77, %77
  %79 = fmul <4 x double> %9, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %80 = fadd <4 x double> %79, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %81 = fmul <4 x double> %9, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %82 = fadd <4 x double> %81, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %83 = fmul <4 x double> %76, %80
  %84 = fadd <4 x double> %82, %83
  %85 = fmul <4 x double> %9, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %86 = fadd <4 x double> %85, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %87 = fmul <4 x double> %9, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %88 = fadd <4 x double> %87, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %89 = fmul <4 x double> %76, %86
  %90 = fadd <4 x double> %88, %89
  %91 = fmul <4 x double> %9, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %92 = fadd <4 x double> %91, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %93 = fmul <4 x double> %9, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %94 = fadd <4 x double> %93, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %95 = fmul <4 x double> %76, %92
  %96 = fadd <4 x double> %94, %95
  %97 = fmul <4 x double> %77, %90
  %98 = fadd <4 x double> %96, %97
  %99 = fmul <4 x double> %78, %84
  %100 = fadd <4 x double> %99, %98
  %101 = fmul <4 x double> %9, %74
  %102 = fmul <4 x double> %101, %100
  %103 = fsub <4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %74
  %104 = fsub <4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %103
  %105 = fsub <4 x double> %104, %74
  %106 = fadd <4 x double> %105, <double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07>
  %107 = fsub <4 x double> %106, %75
  %108 = fsub <4 x double> %103, %102
  %109 = fsub <4 x double> %103, %108
  %110 = fsub <4 x double> %109, %102
  %111 = fadd <4 x double> %107, %110
  %112 = fadd <4 x double> %74, %102
  %113 = fadd <4 x double> %108, %111
  %114 = fmul <4 x double> %113, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %115 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %114, <4 x double> %112, <4 x double> %5) #6
  %116 = bitcast <4 x double> %115 to <4 x i64>
  %117 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %118 = xor <4 x i64> %117, %116
  %119 = bitcast <4 x i64> %118 to <4 x double>
  ret <4 x double> %119
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_acosd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %0, %0
  %8 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %9 = fmul <4 x double> %8, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %7, <4 x double> %5) #6
  %11 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %10) #6
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %4, <4 x double> %5) #6
  %13 = fcmp oeq <4 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = sext <4 x i1> %13 to <4 x i64>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %12, <4 x double> zeroinitializer, <4 x double> %15) #6
  %17 = fmul <4 x double> %10, %10
  %18 = fmul <4 x double> %17, %17
  %19 = fmul <4 x double> %18, %18
  %20 = fmul <4 x double> %10, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %21 = fadd <4 x double> %20, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %22 = fmul <4 x double> %10, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %23 = fadd <4 x double> %22, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %24 = fmul <4 x double> %17, %21
  %25 = fadd <4 x double> %23, %24
  %26 = fmul <4 x double> %10, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %27 = fadd <4 x double> %26, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %28 = fmul <4 x double> %10, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %29 = fadd <4 x double> %28, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %30 = fmul <4 x double> %17, %27
  %31 = fadd <4 x double> %29, %30
  %32 = fmul <4 x double> %10, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %33 = fadd <4 x double> %32, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %34 = fmul <4 x double> %10, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %35 = fadd <4 x double> %34, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %36 = fmul <4 x double> %17, %33
  %37 = fadd <4 x double> %35, %36
  %38 = fmul <4 x double> %18, %31
  %39 = fadd <4 x double> %37, %38
  %40 = fmul <4 x double> %19, %25
  %41 = fadd <4 x double> %40, %39
  %42 = fmul <4 x double> %10, %16
  %43 = fmul <4 x double> %42, %41
  %44 = bitcast <4 x double> %16 to <4 x i64>
  %45 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %46 = xor <4 x i64> %45, %44
  %47 = bitcast <4 x i64> %46 to <4 x double>
  %48 = bitcast <4 x double> %43 to <4 x i64>
  %49 = xor <4 x i64> %45, %48
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fadd <4 x double> %47, %50
  %52 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %51
  %53 = fadd <4 x double> %16, %43
  %54 = fmul <4 x double> %53, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %55 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %54, <4 x double> %52, <4 x double> %5) #6
  %56 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %57 = bitcast <4 x double> %56 to <4 x i64>
  %58 = xor <4 x i64> %6, <i64 -1, i64 -1, i64 -1, i64 -1>
  %59 = and <4 x i64> %57, %58
  %60 = bitcast <4 x double> %55 to <4 x i64>
  %61 = xor <4 x i64> %60, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = bitcast <4 x i64> %61 to <4 x double>
  %63 = fadd <4 x double> %62, <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>
  %64 = bitcast <4 x i64> %59 to <4 x double>
  %65 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %55, <4 x double> %63, <4 x double> %64) #6
  ret <4 x double> %65
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_acosd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %0, %0
  %8 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %9 = fmul <4 x double> %8, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %7, <4 x double> %5) #6
  %11 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %10) #6
  %12 = bitcast <4 x double> %11 to <4 x i64>
  %13 = and <4 x i64> %12, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %14 = bitcast <4 x i64> %13 to <4 x double>
  %15 = fsub <4 x double> %11, %14
  %16 = fmul <4 x double> %11, %11
  %17 = fmul <4 x double> %14, %14
  %18 = bitcast <4 x double> %16 to <4 x i64>
  %19 = xor <4 x i64> %18, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = bitcast <4 x i64> %19 to <4 x double>
  %21 = fmul <4 x double> %15, %14
  %22 = fmul <4 x double> %15, %15
  %23 = fadd <4 x double> %17, %20
  %24 = fadd <4 x double> %21, %23
  %25 = fadd <4 x double> %21, %24
  %26 = fadd <4 x double> %22, %25
  %27 = fadd <4 x double> %10, %16
  %28 = fsub <4 x double> %27, %10
  %29 = fsub <4 x double> %27, %28
  %30 = fsub <4 x double> %10, %29
  %31 = fsub <4 x double> %16, %28
  %32 = fadd <4 x double> %31, %30
  %33 = fadd <4 x double> %32, %26
  %34 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %11
  %35 = bitcast <4 x double> %34 to <4 x i64>
  %36 = and <4 x i64> %35, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %37 = bitcast <4 x i64> %36 to <4 x double>
  %38 = fsub <4 x double> %34, %37
  %39 = fmul <4 x double> %14, %37
  %40 = fmul <4 x double> %38, %14
  %41 = fmul <4 x double> %15, %37
  %42 = fmul <4 x double> %15, %38
  %43 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <4 x double> %43, %40
  %45 = fsub <4 x double> %44, %41
  %46 = fsub <4 x double> %45, %42
  %47 = fmul <4 x double> %34, %46
  %48 = bitcast <4 x double> %27 to <4 x i64>
  %49 = and <4 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fsub <4 x double> %27, %50
  %52 = fmul <4 x double> %34, %27
  %53 = fmul <4 x double> %37, %50
  %54 = bitcast <4 x double> %52 to <4 x i64>
  %55 = xor <4 x i64> %54, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %56 = bitcast <4 x i64> %55 to <4 x double>
  %57 = fmul <4 x double> %51, %37
  %58 = fmul <4 x double> %38, %50
  %59 = fmul <4 x double> %38, %51
  %60 = fmul <4 x double> %27, %47
  %61 = fmul <4 x double> %34, %33
  %62 = fadd <4 x double> %53, %56
  %63 = fadd <4 x double> %57, %62
  %64 = fadd <4 x double> %58, %63
  %65 = fadd <4 x double> %59, %64
  %66 = fadd <4 x double> %65, %60
  %67 = fadd <4 x double> %61, %66
  %68 = fmul <4 x double> %52, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %69 = fmul <4 x double> %67, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %70 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %68, <4 x double> %4, <4 x double> %5) #6
  %71 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %69, <4 x double> zeroinitializer, <4 x double> %5) #6
  %72 = fcmp oeq <4 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %73 = sext <4 x i1> %72 to <4 x i64>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %70, <4 x double> zeroinitializer, <4 x double> %74) #6
  %76 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %71, <4 x double> zeroinitializer, <4 x double> %74) #6
  %77 = fmul <4 x double> %10, %10
  %78 = fmul <4 x double> %77, %77
  %79 = fmul <4 x double> %78, %78
  %80 = fmul <4 x double> %10, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %81 = fadd <4 x double> %80, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %82 = fmul <4 x double> %10, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %83 = fadd <4 x double> %82, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %84 = fmul <4 x double> %77, %81
  %85 = fadd <4 x double> %83, %84
  %86 = fmul <4 x double> %10, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %87 = fadd <4 x double> %86, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %88 = fmul <4 x double> %10, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %89 = fadd <4 x double> %88, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %90 = fmul <4 x double> %77, %87
  %91 = fadd <4 x double> %89, %90
  %92 = fmul <4 x double> %10, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %93 = fadd <4 x double> %92, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %94 = fmul <4 x double> %10, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %95 = fadd <4 x double> %94, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %96 = fmul <4 x double> %77, %93
  %97 = fadd <4 x double> %95, %96
  %98 = fmul <4 x double> %78, %91
  %99 = fadd <4 x double> %97, %98
  %100 = fmul <4 x double> %79, %85
  %101 = fadd <4 x double> %100, %99
  %102 = fmul <4 x double> %10, %75
  %103 = fmul <4 x double> %102, %101
  %104 = bitcast <4 x double> %75 to <4 x i64>
  %105 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %106 = xor <4 x i64> %105, %104
  %107 = bitcast <4 x i64> %106 to <4 x double>
  %108 = bitcast <4 x double> %103 to <4 x i64>
  %109 = xor <4 x i64> %105, %108
  %110 = bitcast <4 x i64> %109 to <4 x double>
  %111 = fadd <4 x double> %107, %110
  %112 = fsub <4 x double> %107, %111
  %113 = fadd <4 x double> %112, %110
  %114 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %111
  %115 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %114
  %116 = fsub <4 x double> %115, %111
  %117 = fadd <4 x double> %116, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %118 = fsub <4 x double> %117, %113
  %119 = fadd <4 x double> %75, %103
  %120 = fsub <4 x double> %75, %119
  %121 = fadd <4 x double> %103, %120
  %122 = fadd <4 x double> %76, %121
  %123 = fmul <4 x double> %119, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %124 = fmul <4 x double> %122, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %125 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %123, <4 x double> %114, <4 x double> %5) #6
  %126 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %124, <4 x double> %118, <4 x double> %5) #6
  %127 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %128 = bitcast <4 x double> %127 to <4 x i64>
  %129 = xor <4 x i64> %6, <i64 -1, i64 -1, i64 -1, i64 -1>
  %130 = and <4 x i64> %128, %129
  %131 = fsub <4 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, %125
  %132 = fsub <4 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, %131
  %133 = fsub <4 x double> %132, %125
  %134 = fadd <4 x double> %133, <double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07>
  %135 = fsub <4 x double> %134, %126
  %136 = bitcast <4 x i64> %130 to <4 x double>
  %137 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %125, <4 x double> %131, <4 x double> %136) #6
  %138 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %126, <4 x double> %135, <4 x double> %136) #6
  %139 = fadd <4 x double> %137, %138
  ret <4 x double> %139
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_atand4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> zeroinitializer) #6
  %6 = bitcast <4 x i32> %5 to <2 x i64>
  %7 = and <2 x i64> %6, <i64 -4294967298, i64 -4294967298>
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> zeroinitializer, i8 17) #6
  %9 = bitcast <4 x double> %8 to <4 x i64>
  %10 = and <4 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %11 = or <4 x i64> %10, <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %12 = bitcast <4 x i64> %11 to <4 x double>
  %13 = bitcast <4 x i64> %10 to <4 x double>
  %14 = bitcast <2 x i64> %7 to <4 x i32>
  %15 = add <4 x i32> %14, <i32 1, i32 1, i32 1, i32 1>
  %16 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %12, <4 x double> %4, i8 17) #6
  %17 = bitcast <4 x double> %16 to <4 x i64>
  %18 = and <4 x i64> %17, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %19 = bitcast <4 x i64> %18 to <4 x double>
  %20 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %19) #6
  %21 = bitcast <2 x i64> %7 to <16 x i8>
  %22 = bitcast <4 x i32> %15 to <16 x i8>
  %23 = bitcast <4 x i32> %20 to <16 x i8>
  %24 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %21, <16 x i8> %22, <16 x i8> %23) #6
  %25 = xor <4 x i64> %10, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %26 = xor <4 x i64> %10, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %27 = bitcast <4 x i64> %25 to <4 x double>
  %28 = bitcast <4 x i64> %26 to <4 x double>
  %29 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %27, <4 x double> %16) #6
  %30 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %28, <4 x double> %16) #6
  %31 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %12, <4 x double> %4, <4 x double> %16) #6
  %32 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %13, <4 x double> zeroinitializer, <4 x double> %16) #6
  %33 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %31
  %34 = bitcast <4 x double> %31 to <4 x i64>
  %35 = and <4 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fsub <4 x double> %31, %36
  %38 = bitcast <4 x double> %33 to <4 x i64>
  %39 = and <4 x i64> %38, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = fsub <4 x double> %33, %40
  %42 = bitcast <4 x double> %29 to <4 x i64>
  %43 = and <4 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %29, %44
  %46 = fmul <4 x double> %29, %33
  %47 = fmul <4 x double> %44, %40
  %48 = fsub <4 x double> %47, %46
  %49 = fmul <4 x double> %41, %44
  %50 = fmul <4 x double> %45, %40
  %51 = fmul <4 x double> %45, %41
  %52 = fmul <4 x double> %36, %40
  %53 = fmul <4 x double> %41, %36
  %54 = fmul <4 x double> %37, %40
  %55 = fmul <4 x double> %37, %41
  %56 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %52
  %57 = fsub <4 x double> %56, %53
  %58 = fsub <4 x double> %57, %54
  %59 = fsub <4 x double> %58, %55
  %60 = fmul <4 x double> %46, %59
  %61 = fadd <4 x double> %48, %49
  %62 = fadd <4 x double> %50, %61
  %63 = fadd <4 x double> %51, %62
  %64 = fadd <4 x double> %63, %60
  %65 = fmul <4 x double> %32, %46
  %66 = fsub <4 x double> %30, %65
  %67 = fmul <4 x double> %33, %66
  %68 = fadd <4 x double> %67, %64
  %69 = bitcast <4 x double> %46 to <4 x i64>
  %70 = and <4 x i64> %69, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %71 = bitcast <4 x i64> %70 to <4 x double>
  %72 = fsub <4 x double> %46, %71
  %73 = fmul <4 x double> %46, %46
  %74 = fmul <4 x double> %71, %71
  %75 = bitcast <4 x double> %73 to <4 x i64>
  %76 = xor <4 x i64> %75, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %77 = bitcast <4 x i64> %76 to <4 x double>
  %78 = fadd <4 x double> %71, %71
  %79 = fmul <4 x double> %78, %72
  %80 = fmul <4 x double> %72, %72
  %81 = fadd <4 x double> %68, %68
  %82 = fmul <4 x double> %46, %81
  %83 = fadd <4 x double> %74, %77
  %84 = fadd <4 x double> %83, %79
  %85 = fadd <4 x double> %80, %84
  %86 = fadd <4 x double> %85, %82
  %87 = fadd <4 x double> %73, %86
  %88 = fsub <4 x double> %73, %87
  %89 = fadd <4 x double> %86, %88
  %90 = fmul <4 x double> %87, %87
  %91 = fmul <4 x double> %90, %90
  %92 = fmul <4 x double> %91, %91
  %93 = fmul <4 x double> %87, <double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72>
  %94 = fadd <4 x double> %93, <double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE>
  %95 = fmul <4 x double> %87, <double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98>
  %96 = fadd <4 x double> %95, <double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE>
  %97 = fmul <4 x double> %90, %94
  %98 = fadd <4 x double> %96, %97
  %99 = fmul <4 x double> %87, <double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3>
  %100 = fadd <4 x double> %99, <double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5>
  %101 = fmul <4 x double> %87, <double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320>
  %102 = fadd <4 x double> %101, <double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7>
  %103 = fmul <4 x double> %90, %100
  %104 = fadd <4 x double> %102, %103
  %105 = fmul <4 x double> %91, %98
  %106 = fadd <4 x double> %104, %105
  %107 = fmul <4 x double> %87, <double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD>
  %108 = fadd <4 x double> %107, <double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577>
  %109 = fmul <4 x double> %87, <double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6>
  %110 = fadd <4 x double> %109, <double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E>
  %111 = fmul <4 x double> %90, %108
  %112 = fadd <4 x double> %110, %111
  %113 = fmul <4 x double> %87, <double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B>
  %114 = fadd <4 x double> %113, <double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6>
  %115 = fmul <4 x double> %87, <double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10>
  %116 = fadd <4 x double> %115, <double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC>
  %117 = fmul <4 x double> %90, %114
  %118 = fadd <4 x double> %116, %117
  %119 = fmul <4 x double> %91, %112
  %120 = fadd <4 x double> %118, %119
  %121 = fmul <4 x double> %92, %106
  %122 = fadd <4 x double> %120, %121
  %123 = fmul <4 x double> %87, %122
  %124 = fadd <4 x double> %123, <double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B>
  %125 = fmul <4 x double> %87, %124
  %126 = fadd <4 x double> %125, <double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7>
  %127 = fmul <4 x double> %87, %126
  %128 = fadd <4 x double> %127, <double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0>
  %129 = fmul <4 x double> %87, %128
  %130 = fadd <4 x double> %129, <double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A>
  %131 = bitcast <4 x double> %87 to <4 x i64>
  %132 = and <4 x i64> %131, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %133 = bitcast <4 x i64> %132 to <4 x double>
  %134 = fsub <4 x double> %87, %133
  %135 = fmul <4 x double> %46, %87
  %136 = fmul <4 x double> %71, %133
  %137 = bitcast <4 x double> %135 to <4 x i64>
  %138 = xor <4 x i64> %137, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %139 = bitcast <4 x i64> %138 to <4 x double>
  %140 = fmul <4 x double> %72, %133
  %141 = fmul <4 x double> %134, %71
  %142 = fmul <4 x double> %72, %134
  %143 = fmul <4 x double> %46, %89
  %144 = fmul <4 x double> %68, %87
  %145 = fadd <4 x double> %136, %139
  %146 = fadd <4 x double> %140, %145
  %147 = fadd <4 x double> %141, %146
  %148 = fadd <4 x double> %142, %147
  %149 = fadd <4 x double> %143, %148
  %150 = fadd <4 x double> %144, %149
  %151 = and <4 x i64> %137, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %152 = bitcast <4 x i64> %151 to <4 x double>
  %153 = fsub <4 x double> %135, %152
  %154 = bitcast <4 x double> %130 to <4 x i64>
  %155 = and <4 x i64> %154, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fsub <4 x double> %130, %156
  %158 = fmul <4 x double> %135, %130
  %159 = fmul <4 x double> %152, %156
  %160 = bitcast <4 x double> %158 to <4 x i64>
  %161 = xor <4 x i64> %160, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %162 = bitcast <4 x i64> %161 to <4 x double>
  %163 = fmul <4 x double> %153, %156
  %164 = fmul <4 x double> %157, %152
  %165 = fmul <4 x double> %153, %157
  %166 = fmul <4 x double> %150, %130
  %167 = fadd <4 x double> %159, %162
  %168 = fadd <4 x double> %163, %167
  %169 = fadd <4 x double> %164, %168
  %170 = fadd <4 x double> %165, %169
  %171 = fadd <4 x double> %166, %170
  %172 = fadd <4 x double> %46, %158
  %173 = fsub <4 x double> %46, %172
  %174 = fadd <4 x double> %158, %173
  %175 = fadd <4 x double> %68, %174
  %176 = fadd <4 x double> %175, %171
  %177 = bitcast <16 x i8> %24 to <4 x i32>
  %178 = sitofp <4 x i32> %177 to <4 x double>
  %179 = bitcast <4 x double> %178 to <4 x i64>
  %180 = and <4 x i64> %179, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %181 = bitcast <4 x i64> %180 to <4 x double>
  %182 = fsub <4 x double> %178, %181
  %183 = fmul <4 x double> %178, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %184 = fmul <4 x double> %181, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %185 = bitcast <4 x double> %183 to <4 x i64>
  %186 = xor <4 x i64> %185, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %187 = bitcast <4 x i64> %186 to <4 x double>
  %188 = fmul <4 x double> %181, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %189 = fmul <4 x double> %182, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %190 = fmul <4 x double> %182, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %191 = fmul <4 x double> %178, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %192 = fadd <4 x double> %184, %187
  %193 = fadd <4 x double> %188, %192
  %194 = fadd <4 x double> %189, %193
  %195 = fadd <4 x double> %190, %194
  %196 = fadd <4 x double> %191, %195
  %197 = fadd <4 x double> %183, %172
  %198 = fsub <4 x double> %183, %197
  %199 = fadd <4 x double> %172, %198
  %200 = fadd <4 x double> %196, %199
  %201 = fadd <4 x double> %200, %176
  %202 = fadd <4 x double> %197, %201
  %203 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %204 = sext <4 x i1> %203 to <4 x i64>
  %205 = bitcast <4 x i64> %204 to <4 x double>
  %206 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %202, <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, <4 x double> %205) #6
  %207 = bitcast <4 x double> %206 to <4 x i64>
  %208 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %209 = xor <4 x i64> %208, %207
  %210 = bitcast <4 x i64> %209 to <4 x double>
  ret <4 x double> %210
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_atand4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %4 = xor <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = fcmp oeq <4 x double> %5, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %7 = select <4 x i1> %6, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> zeroinitializer
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = bitcast <4 x i32> %8 to <2 x i64>
  %10 = and <2 x i64> %9, <i64 8589934594, i64 8589934594>
  %11 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %12 = bitcast <4 x i64> %11 to <4 x double>
  %13 = bitcast <2 x i64> %10 to <4 x i32>
  %14 = add <4 x i32> %13, <i32 1, i32 1, i32 1, i32 1>
  %15 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %12, i8 17) #6
  %16 = bitcast <4 x double> %15 to <4 x i64>
  %17 = and <4 x i64> %16, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %18) #6
  %20 = bitcast <2 x i64> %10 to <16 x i8>
  %21 = bitcast <4 x i32> %14 to <16 x i8>
  %22 = bitcast <4 x i32> %19 to <16 x i8>
  %23 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %20, <16 x i8> %21, <16 x i8> %22) #6
  %24 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %12
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %12, <4 x double> %24, <4 x double> %15) #6
  %26 = fmul <4 x double> %25, %25
  %27 = fmul <4 x double> %26, %26
  %28 = fmul <4 x double> %27, %27
  %29 = fmul <4 x double> %28, %28
  %30 = fmul <4 x double> %29, %29
  %31 = fmul <4 x double> %26, <double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF>
  %32 = fadd <4 x double> %31, <double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA>
  %33 = fmul <4 x double> %27, <double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F>
  %34 = fadd <4 x double> %33, %32
  %35 = fmul <4 x double> %26, <double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20>
  %36 = fadd <4 x double> %35, <double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56>
  %37 = fmul <4 x double> %26, <double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286>
  %38 = fadd <4 x double> %37, <double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC>
  %39 = fmul <4 x double> %27, %36
  %40 = fadd <4 x double> %38, %39
  %41 = fmul <4 x double> %26, <double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E>
  %42 = fadd <4 x double> %41, <double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638>
  %43 = fmul <4 x double> %26, <double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE>
  %44 = fadd <4 x double> %43, <double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA>
  %45 = fmul <4 x double> %27, %42
  %46 = fadd <4 x double> %44, %45
  %47 = fmul <4 x double> %28, %40
  %48 = fadd <4 x double> %46, %47
  %49 = fmul <4 x double> %26, <double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622>
  %50 = fadd <4 x double> %49, <double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0>
  %51 = fmul <4 x double> %26, <double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1>
  %52 = fadd <4 x double> %51, <double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8>
  %53 = fmul <4 x double> %27, %50
  %54 = fadd <4 x double> %52, %53
  %55 = fmul <4 x double> %26, <double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F>
  %56 = fadd <4 x double> %55, <double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB>
  %57 = fmul <4 x double> %26, <double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD>
  %58 = fadd <4 x double> %57, <double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5>
  %59 = fmul <4 x double> %27, %56
  %60 = fadd <4 x double> %58, %59
  %61 = fmul <4 x double> %28, %54
  %62 = fadd <4 x double> %60, %61
  %63 = fmul <4 x double> %29, %48
  %64 = fadd <4 x double> %62, %63
  %65 = fmul <4 x double> %34, %30
  %66 = fadd <4 x double> %65, %64
  %67 = fmul <4 x double> %26, %66
  %68 = fmul <4 x double> %25, %67
  %69 = fadd <4 x double> %25, %68
  %70 = bitcast <16 x i8> %23 to <4 x i32>
  %71 = and <4 x i32> %70, <i32 1, i32 1, i32 1, i32 1>
  %72 = icmp ne <4 x i32> %71, zeroinitializer
  %73 = sitofp <4 x i1> %72 to <4 x double>
  %74 = fcmp oeq <4 x double> %73, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %75 = sext <4 x i1> %74 to <4 x i64>
  %76 = fsub <4 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %69
  %77 = bitcast <4 x i64> %75 to <4 x double>
  %78 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %69, <4 x double> %76, <4 x double> %77) #6
  %79 = and <4 x i32> %70, <i32 2, i32 2, i32 2, i32 2>
  %80 = icmp ne <4 x i32> %79, zeroinitializer
  %81 = sitofp <4 x i1> %80 to <4 x double>
  %82 = fcmp oeq <4 x double> %81, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %83 = select <4 x i1> %82, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %84 = bitcast <4 x double> %78 to <4 x i64>
  %85 = xor <4 x i64> %83, %84
  %86 = bitcast <4 x i64> %85 to <4 x double>
  ret <4 x double> %86
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_logd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fdiv <4 x double> %49, %50
  %52 = fmul <4 x double> %51, %51
  %53 = fmul <4 x double> %52, %52
  %54 = fmul <4 x double> %53, %53
  %55 = fmul <4 x double> %51, %52
  %56 = fmul <4 x double> %52, <double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D>
  %57 = fadd <4 x double> %56, <double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F>
  %58 = fmul <4 x double> %53, <double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39>
  %59 = fadd <4 x double> %58, %57
  %60 = fmul <4 x double> %52, <double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419>
  %61 = fadd <4 x double> %60, <double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987>
  %62 = fmul <4 x double> %52, <double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E>
  %63 = fadd <4 x double> %62, <double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F>
  %64 = fmul <4 x double> %53, %61
  %65 = fadd <4 x double> %63, %64
  %66 = fmul <4 x double> %54, %59
  %67 = fadd <4 x double> %66, %65
  %68 = bitcast <16 x i8> %48 to <4 x i32>
  %69 = sitofp <4 x i32> %68 to <4 x double>
  %70 = fmul <4 x double> %69, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %71 = fmul <4 x double> %51, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %72 = fadd <4 x double> %70, %71
  %73 = fmul <4 x double> %55, %67
  %74 = fadd <4 x double> %72, %73
  %75 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %76 = sext <4 x i1> %75 to <4 x i64>
  %77 = bitcast <4 x i64> %76 to <4 x double>
  %78 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %74, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %77) #6
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %80 = fcmp uno <4 x double> %5, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %81) #6
  %83 = fcmp oeq <4 x double> %5, zeroinitializer
  %84 = sext <4 x i1> %83 to <4 x i64>
  %85 = bitcast <4 x i64> %84 to <4 x double>
  %86 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %82, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %85) #6
  ret <4 x double> %86
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_expd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %3 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %2, i32 8) #6
  %4 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %3) #6
  %5 = fmul <4 x double> %3, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %6 = fadd <4 x double> %5, %0
  %7 = fmul <4 x double> %3, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %8 = fadd <4 x double> %7, %6
  %9 = fmul <4 x double> %8, %8
  %10 = fmul <4 x double> %9, %9
  %11 = fmul <4 x double> %10, %10
  %12 = fmul <4 x double> %8, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %13 = fadd <4 x double> %12, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %14 = fmul <4 x double> %8, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %15 = fadd <4 x double> %14, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %16 = fmul <4 x double> %8, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %17 = fadd <4 x double> %16, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %18 = fmul <4 x double> %9, %15
  %19 = fadd <4 x double> %17, %18
  %20 = fmul <4 x double> %8, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %21 = fadd <4 x double> %20, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %22 = fmul <4 x double> %8, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %23 = fadd <4 x double> %22, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %24 = fmul <4 x double> %9, %21
  %25 = fadd <4 x double> %23, %24
  %26 = fmul <4 x double> %10, %19
  %27 = fadd <4 x double> %25, %26
  %28 = fmul <4 x double> %13, %11
  %29 = fadd <4 x double> %28, %27
  %30 = fmul <4 x double> %8, %29
  %31 = fadd <4 x double> %30, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %32 = fmul <4 x double> %9, %31
  %33 = fadd <4 x double> %8, %32
  %34 = fadd <4 x double> %33, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %35 = ashr <4 x i32> %4, <i32 1, i32 1, i32 1, i32 1>
  %36 = add nsw <4 x i32> %35, <i32 1023, i32 1023, i32 1023, i32 1023>
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %38 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %39 = and <4 x i32> %37, <i32 0, i32 -1, i32 0, i32 -1>
  %40 = shl <4 x i32> %39, <i32 20, i32 20, i32 20, i32 20>
  %41 = and <4 x i32> %38, <i32 0, i32 -1, i32 0, i32 -1>
  %42 = shl <4 x i32> %41, <i32 20, i32 20, i32 20, i32 20>
  %43 = bitcast <4 x i32> %40 to <2 x i64>
  %44 = bitcast <4 x i32> %42 to <2 x i64>
  %45 = shufflevector <2 x i64> %43, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %46 = shufflevector <2 x i64> %44, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %47 = shufflevector <4 x i64> %45, <4 x i64> %46, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %48 = bitcast <4 x i64> %47 to <4 x double>
  %49 = fmul <4 x double> %34, %48
  %50 = sub <4 x i32> %4, %35
  %51 = add <4 x i32> %50, <i32 1023, i32 1023, i32 1023, i32 1023>
  %52 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %53 = shufflevector <4 x i32> %51, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %54 = and <4 x i32> %52, <i32 0, i32 -1, i32 0, i32 -1>
  %55 = shl <4 x i32> %54, <i32 20, i32 20, i32 20, i32 20>
  %56 = and <4 x i32> %53, <i32 0, i32 -1, i32 0, i32 -1>
  %57 = shl <4 x i32> %56, <i32 20, i32 20, i32 20, i32 20>
  %58 = bitcast <4 x i32> %55 to <2 x i64>
  %59 = bitcast <4 x i32> %57 to <2 x i64>
  %60 = shufflevector <2 x i64> %58, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %61 = shufflevector <2 x i64> %59, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %62 = shufflevector <4 x i64> %60, <4 x i64> %61, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %63 = bitcast <4 x i64> %62 to <4 x double>
  %64 = fmul <4 x double> %49, %63
  %65 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i8 30) #6
  %66 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %64, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %65) #6
  %67 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %68 = bitcast <4 x double> %67 to <4 x i64>
  %69 = bitcast <4 x double> %66 to <4 x i64>
  %70 = xor <4 x i64> %68, <i64 -1, i64 -1, i64 -1, i64 -1>
  %71 = and <4 x i64> %70, %69
  %72 = bitcast <4 x i64> %71 to <4 x double>
  ret <4 x double> %72
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_logd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %101 = fadd <4 x double> %100, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %102 = fmul <4 x double> %98, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %105 = fadd <4 x double> %104, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %106 = fmul <4 x double> %97, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %107 = fadd <4 x double> %106, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %113 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %113, %116
  %118 = fmul <4 x double> %113, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %119 = fmul <4 x double> %116, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %116, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %124 = fmul <4 x double> %117, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %125 = fmul <4 x double> %117, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %126 = fmul <4 x double> %113, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %127 = fadd <4 x double> %119, %122
  %128 = fadd <4 x double> %123, %127
  %129 = fadd <4 x double> %124, %128
  %130 = fadd <4 x double> %125, %129
  %131 = fadd <4 x double> %126, %130
  %132 = fmul <4 x double> %74, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %133 = fmul <4 x double> %96, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %134 = fadd <4 x double> %118, %132
  %135 = fsub <4 x double> %118, %134
  %136 = fadd <4 x double> %132, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %137, %133
  %139 = fmul <4 x double> %74, %97
  %140 = fmul <4 x double> %139, %111
  %141 = fadd <4 x double> %134, %140
  %142 = fsub <4 x double> %134, %141
  %143 = fadd <4 x double> %140, %142
  %144 = fadd <4 x double> %143, %138
  %145 = fadd <4 x double> %141, %144
  %146 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %147 = sext <4 x i1> %146 to <4 x i64>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %148) #6
  %150 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %151 = fcmp uno <4 x double> %5, zeroinitializer
  %152 = select <4 x i1> %151, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %150
  %153 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %149, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %152) #6
  %154 = fcmp oeq <4 x double> %5, zeroinitializer
  %155 = sext <4 x i1> %154 to <4 x i64>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %153, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %156) #6
  ret <4 x double> %157
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_powd4_u10avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %1, i32 11) #6
  %4 = fcmp oeq <4 x double> %3, %1
  %5 = sext <4 x i1> %4 to <4 x i64>
  %6 = fmul <4 x double> %1, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 11) #6
  %8 = fcmp une <4 x double> %7, %6
  %9 = and <4 x i1> %8, %4
  %10 = sext <4 x i1> %9 to <4 x i64>
  %11 = bitcast <4 x double> %0 to <4 x i64>
  %12 = and <4 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %13, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %15 = bitcast <4 x double> %14 to <4 x i64>
  %16 = fmul <4 x double> %13, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %17 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %13, <4 x double> %16, <4 x double> %14) #6
  %18 = fmul <4 x double> %17, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = shufflevector <4 x i64> %19, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %21 = shufflevector <4 x i64> %19, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %22 = bitcast <2 x i64> %20 to <4 x i32>
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %24 = bitcast <4 x i32> %23 to <2 x i64>
  %25 = bitcast <2 x i64> %21 to <4 x i32>
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %27 = bitcast <4 x i32> %26 to <2 x i64>
  %28 = shufflevector <2 x i64> %27, <2 x i64> %24, <2 x i32> <i32 2, i32 1>
  %29 = bitcast <2 x i64> %28 to <4 x i32>
  %30 = lshr <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = and <4 x i32> %30, <i32 2047, i32 2047, i32 2047, i32 2047>
  %32 = add nsw <4 x i32> %31, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %33 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %31
  %34 = bitcast <4 x double> %17 to <4 x i64>
  %35 = shufflevector <4 x i64> %34, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %36 = shufflevector <4 x i64> %34, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %37 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %38 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %39 = and <4 x i32> %37, <i32 0, i32 -1, i32 0, i32 -1>
  %40 = shl <4 x i32> %39, <i32 20, i32 20, i32 20, i32 20>
  %41 = and <4 x i32> %38, <i32 0, i32 -1, i32 0, i32 -1>
  %42 = shl <4 x i32> %41, <i32 20, i32 20, i32 20, i32 20>
  %43 = bitcast <2 x i64> %35 to <4 x i32>
  %44 = add <4 x i32> %40, %43
  %45 = bitcast <2 x i64> %36 to <4 x i32>
  %46 = add <4 x i32> %42, %45
  %47 = bitcast <4 x i32> %44 to <2 x i64>
  %48 = bitcast <4 x i32> %46 to <2 x i64>
  %49 = shufflevector <2 x i64> %47, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %50 = shufflevector <2 x i64> %48, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %51 = shufflevector <4 x i64> %49, <4 x i64> %50, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %52 = bitcast <4 x i64> %51 to <4 x double>
  %53 = and <4 x i64> %15, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %54 = bitcast <4 x i64> %53 to <4 x double>
  %55 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %54) #6
  %56 = add nsw <4 x i32> %31, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %57 = bitcast <4 x i32> %32 to <16 x i8>
  %58 = bitcast <4 x i32> %56 to <16 x i8>
  %59 = bitcast <4 x i32> %55 to <16 x i8>
  %60 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %57, <16 x i8> %58, <16 x i8> %59) #6
  %61 = fadd <4 x double> %52, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %62 = fadd <4 x double> %61, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %63 = fsub <4 x double> %61, %62
  %64 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %63
  %65 = fsub <4 x double> %52, %62
  %66 = fadd <4 x double> %65, %64
  %67 = fadd <4 x double> %52, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %68 = fadd <4 x double> %67, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %69 = fsub <4 x double> %67, %68
  %70 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %69
  %71 = fsub <4 x double> %52, %68
  %72 = fadd <4 x double> %71, %70
  %73 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %67
  %74 = bitcast <4 x double> %67 to <4 x i64>
  %75 = and <4 x i64> %74, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %76 = bitcast <4 x i64> %75 to <4 x double>
  %77 = fsub <4 x double> %67, %76
  %78 = bitcast <4 x double> %73 to <4 x i64>
  %79 = and <4 x i64> %78, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fsub <4 x double> %73, %80
  %82 = bitcast <4 x double> %61 to <4 x i64>
  %83 = and <4 x i64> %82, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %84 = bitcast <4 x i64> %83 to <4 x double>
  %85 = fsub <4 x double> %61, %84
  %86 = fmul <4 x double> %61, %73
  %87 = fmul <4 x double> %84, %80
  %88 = fsub <4 x double> %87, %86
  %89 = fmul <4 x double> %81, %84
  %90 = fmul <4 x double> %85, %80
  %91 = fmul <4 x double> %85, %81
  %92 = fmul <4 x double> %76, %80
  %93 = fmul <4 x double> %81, %76
  %94 = fmul <4 x double> %77, %80
  %95 = fmul <4 x double> %77, %81
  %96 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %92
  %97 = fsub <4 x double> %96, %93
  %98 = fsub <4 x double> %97, %94
  %99 = fsub <4 x double> %98, %95
  %100 = fmul <4 x double> %86, %99
  %101 = fadd <4 x double> %88, %89
  %102 = fadd <4 x double> %90, %101
  %103 = fadd <4 x double> %91, %102
  %104 = fadd <4 x double> %103, %100
  %105 = fmul <4 x double> %86, %72
  %106 = fsub <4 x double> %66, %105
  %107 = fmul <4 x double> %73, %106
  %108 = fadd <4 x double> %107, %104
  %109 = bitcast <4 x double> %86 to <4 x i64>
  %110 = and <4 x i64> %109, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = fsub <4 x double> %86, %111
  %113 = fmul <4 x double> %86, %86
  %114 = fmul <4 x double> %111, %111
  %115 = bitcast <4 x double> %113 to <4 x i64>
  %116 = xor <4 x i64> %115, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %117 = bitcast <4 x i64> %116 to <4 x double>
  %118 = fadd <4 x double> %111, %111
  %119 = fmul <4 x double> %118, %112
  %120 = fmul <4 x double> %112, %112
  %121 = fadd <4 x double> %108, %108
  %122 = fmul <4 x double> %86, %121
  %123 = fadd <4 x double> %114, %117
  %124 = fadd <4 x double> %123, %119
  %125 = fadd <4 x double> %120, %124
  %126 = fadd <4 x double> %125, %122
  %127 = fmul <4 x double> %113, %113
  %128 = fmul <4 x double> %127, %127
  %129 = fmul <4 x double> %128, %128
  %130 = fmul <4 x double> %113, <double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11>
  %131 = fadd <4 x double> %130, <double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A>
  %132 = fmul <4 x double> %113, <double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C>
  %133 = fadd <4 x double> %132, <double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1>
  %134 = fmul <4 x double> %127, %131
  %135 = fadd <4 x double> %133, %134
  %136 = fmul <4 x double> %113, <double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1>
  %137 = fadd <4 x double> %136, <double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F>
  %138 = fmul <4 x double> %113, <double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200>
  %139 = fadd <4 x double> %138, <double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B>
  %140 = fmul <4 x double> %127, %137
  %141 = fadd <4 x double> %139, %140
  %142 = fmul <4 x double> %128, %135
  %143 = fadd <4 x double> %141, %142
  %144 = fmul <4 x double> %129, <double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3>
  %145 = fadd <4 x double> %144, %143
  %146 = bitcast <16 x i8> %60 to <4 x i32>
  %147 = sitofp <4 x i32> %146 to <4 x double>
  %148 = bitcast <4 x double> %147 to <4 x i64>
  %149 = and <4 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fsub <4 x double> %147, %150
  %152 = fmul <4 x double> %147, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %153 = fmul <4 x double> %150, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %154 = bitcast <4 x double> %152 to <4 x i64>
  %155 = xor <4 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fmul <4 x double> %150, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %158 = fmul <4 x double> %151, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %159 = fmul <4 x double> %151, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %160 = fmul <4 x double> %147, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %161 = fadd <4 x double> %153, %156
  %162 = fadd <4 x double> %157, %161
  %163 = fadd <4 x double> %158, %162
  %164 = fadd <4 x double> %159, %163
  %165 = fadd <4 x double> %160, %164
  %166 = fmul <4 x double> %86, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %167 = fmul <4 x double> %108, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %168 = fadd <4 x double> %152, %166
  %169 = fsub <4 x double> %152, %168
  %170 = fadd <4 x double> %166, %169
  %171 = fadd <4 x double> %165, %170
  %172 = fadd <4 x double> %171, %167
  %173 = and <4 x i64> %115, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %174 = bitcast <4 x i64> %173 to <4 x double>
  %175 = fsub <4 x double> %113, %174
  %176 = fmul <4 x double> %86, %113
  %177 = fmul <4 x double> %111, %174
  %178 = bitcast <4 x double> %176 to <4 x i64>
  %179 = xor <4 x i64> %178, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %180 = bitcast <4 x i64> %179 to <4 x double>
  %181 = fmul <4 x double> %175, %111
  %182 = fmul <4 x double> %112, %174
  %183 = fmul <4 x double> %112, %175
  %184 = fmul <4 x double> %113, %108
  %185 = fmul <4 x double> %86, %126
  %186 = fadd <4 x double> %177, %180
  %187 = fadd <4 x double> %181, %186
  %188 = fadd <4 x double> %182, %187
  %189 = fadd <4 x double> %183, %188
  %190 = fadd <4 x double> %189, %184
  %191 = fadd <4 x double> %190, %185
  %192 = and <4 x i64> %178, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %193 = bitcast <4 x i64> %192 to <4 x double>
  %194 = fsub <4 x double> %176, %193
  %195 = fmul <4 x double> %176, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %196 = fmul <4 x double> %193, <double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000>
  %197 = bitcast <4 x double> %195 to <4 x i64>
  %198 = xor <4 x i64> %197, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %199 = bitcast <4 x i64> %198 to <4 x double>
  %200 = fmul <4 x double> %194, <double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000>
  %201 = fmul <4 x double> %193, <double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000>
  %202 = fmul <4 x double> %194, <double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000>
  %203 = fmul <4 x double> %176, <double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000>
  %204 = fmul <4 x double> %191, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %205 = fadd <4 x double> %196, %199
  %206 = fadd <4 x double> %200, %205
  %207 = fadd <4 x double> %201, %206
  %208 = fadd <4 x double> %202, %207
  %209 = fadd <4 x double> %203, %208
  %210 = fadd <4 x double> %209, %204
  %211 = fadd <4 x double> %168, %195
  %212 = fsub <4 x double> %168, %211
  %213 = fadd <4 x double> %195, %212
  %214 = fadd <4 x double> %213, %172
  %215 = fadd <4 x double> %214, %210
  %216 = fmul <4 x double> %113, %176
  %217 = fmul <4 x double> %174, %193
  %218 = bitcast <4 x double> %216 to <4 x i64>
  %219 = xor <4 x i64> %218, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %220 = bitcast <4 x i64> %219 to <4 x double>
  %221 = fmul <4 x double> %175, %193
  %222 = fmul <4 x double> %194, %174
  %223 = fmul <4 x double> %175, %194
  %224 = fmul <4 x double> %113, %191
  %225 = fmul <4 x double> %176, %126
  %226 = fadd <4 x double> %217, %220
  %227 = fadd <4 x double> %221, %226
  %228 = fadd <4 x double> %222, %227
  %229 = fadd <4 x double> %223, %228
  %230 = fadd <4 x double> %229, %224
  %231 = fadd <4 x double> %225, %230
  %232 = and <4 x i64> %218, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %233 = bitcast <4 x i64> %232 to <4 x double>
  %234 = fsub <4 x double> %216, %233
  %235 = bitcast <4 x double> %145 to <4 x i64>
  %236 = and <4 x i64> %235, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %237 = bitcast <4 x i64> %236 to <4 x double>
  %238 = fsub <4 x double> %145, %237
  %239 = fmul <4 x double> %216, %145
  %240 = fmul <4 x double> %233, %237
  %241 = bitcast <4 x double> %239 to <4 x i64>
  %242 = xor <4 x i64> %241, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %243 = bitcast <4 x i64> %242 to <4 x double>
  %244 = fmul <4 x double> %234, %237
  %245 = fmul <4 x double> %238, %233
  %246 = fmul <4 x double> %234, %238
  %247 = fmul <4 x double> %145, %231
  %248 = fadd <4 x double> %240, %243
  %249 = fadd <4 x double> %244, %248
  %250 = fadd <4 x double> %245, %249
  %251 = fadd <4 x double> %246, %250
  %252 = fadd <4 x double> %251, %247
  %253 = fadd <4 x double> %211, %239
  %254 = fsub <4 x double> %211, %253
  %255 = fadd <4 x double> %239, %254
  %256 = fadd <4 x double> %255, %215
  %257 = fadd <4 x double> %256, %252
  %258 = bitcast <4 x double> %253 to <4 x i64>
  %259 = and <4 x i64> %258, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %260 = bitcast <4 x i64> %259 to <4 x double>
  %261 = fsub <4 x double> %253, %260
  %262 = bitcast <4 x double> %1 to <4 x i64>
  %263 = and <4 x i64> %262, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %264 = bitcast <4 x i64> %263 to <4 x double>
  %265 = fsub <4 x double> %1, %264
  %266 = fmul <4 x double> %253, %1
  %267 = fmul <4 x double> %264, %260
  %268 = bitcast <4 x double> %266 to <4 x i64>
  %269 = xor <4 x i64> %268, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %270 = bitcast <4 x i64> %269 to <4 x double>
  %271 = fmul <4 x double> %261, %264
  %272 = fmul <4 x double> %265, %260
  %273 = fmul <4 x double> %265, %261
  %274 = fmul <4 x double> %257, %1
  %275 = fadd <4 x double> %267, %270
  %276 = fadd <4 x double> %271, %275
  %277 = fadd <4 x double> %272, %276
  %278 = fadd <4 x double> %273, %277
  %279 = fadd <4 x double> %278, %274
  %280 = fadd <4 x double> %266, %279
  %281 = fmul <4 x double> %280, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %282 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %281, i32 8) #6
  %283 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %282) #6
  %284 = fmul <4 x double> %282, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %285 = fadd <4 x double> %284, %266
  %286 = fsub <4 x double> %285, %266
  %287 = fsub <4 x double> %285, %286
  %288 = fsub <4 x double> %266, %287
  %289 = fsub <4 x double> %284, %286
  %290 = fadd <4 x double> %289, %288
  %291 = fadd <4 x double> %290, %279
  %292 = fmul <4 x double> %282, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %293 = fadd <4 x double> %292, %285
  %294 = fsub <4 x double> %293, %285
  %295 = fsub <4 x double> %293, %294
  %296 = fsub <4 x double> %285, %295
  %297 = fsub <4 x double> %292, %294
  %298 = fadd <4 x double> %297, %296
  %299 = fadd <4 x double> %298, %291
  %300 = fadd <4 x double> %293, %299
  %301 = fsub <4 x double> %293, %300
  %302 = fadd <4 x double> %299, %301
  %303 = fmul <4 x double> %300, %300
  %304 = fmul <4 x double> %303, %303
  %305 = fmul <4 x double> %304, %304
  %306 = fmul <4 x double> %300, <double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9>
  %307 = fadd <4 x double> %306, <double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD>
  %308 = fmul <4 x double> %300, <double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E>
  %309 = fadd <4 x double> %308, <double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B>
  %310 = fmul <4 x double> %300, <double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D>
  %311 = fadd <4 x double> %310, <double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B>
  %312 = fmul <4 x double> %303, %309
  %313 = fadd <4 x double> %311, %312
  %314 = fmul <4 x double> %300, <double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68>
  %315 = fadd <4 x double> %314, <double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90>
  %316 = fmul <4 x double> %300, <double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558>
  %317 = fadd <4 x double> %316, <double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009>
  %318 = fmul <4 x double> %303, %315
  %319 = fadd <4 x double> %317, %318
  %320 = fmul <4 x double> %304, %313
  %321 = fadd <4 x double> %319, %320
  %322 = fmul <4 x double> %307, %305
  %323 = fadd <4 x double> %322, %321
  %324 = fadd <4 x double> %300, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %325 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %324
  %326 = fadd <4 x double> %300, %325
  %327 = fadd <4 x double> %302, %326
  %328 = bitcast <4 x double> %300 to <4 x i64>
  %329 = and <4 x i64> %328, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %330 = bitcast <4 x i64> %329 to <4 x double>
  %331 = fsub <4 x double> %300, %330
  %332 = fmul <4 x double> %330, %330
  %333 = bitcast <4 x double> %303 to <4 x i64>
  %334 = xor <4 x i64> %333, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %335 = bitcast <4 x i64> %334 to <4 x double>
  %336 = fadd <4 x double> %330, %330
  %337 = fmul <4 x double> %336, %331
  %338 = fmul <4 x double> %331, %331
  %339 = fadd <4 x double> %302, %302
  %340 = fmul <4 x double> %300, %339
  %341 = fadd <4 x double> %332, %335
  %342 = fadd <4 x double> %341, %337
  %343 = fadd <4 x double> %338, %342
  %344 = fadd <4 x double> %340, %343
  %345 = and <4 x i64> %333, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %346 = bitcast <4 x i64> %345 to <4 x double>
  %347 = fsub <4 x double> %303, %346
  %348 = bitcast <4 x double> %323 to <4 x i64>
  %349 = and <4 x i64> %348, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %350 = bitcast <4 x i64> %349 to <4 x double>
  %351 = fsub <4 x double> %323, %350
  %352 = fmul <4 x double> %303, %323
  %353 = fmul <4 x double> %346, %350
  %354 = bitcast <4 x double> %352 to <4 x i64>
  %355 = xor <4 x i64> %354, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %356 = bitcast <4 x i64> %355 to <4 x double>
  %357 = fmul <4 x double> %347, %350
  %358 = fmul <4 x double> %351, %346
  %359 = fmul <4 x double> %347, %351
  %360 = fmul <4 x double> %323, %344
  %361 = fadd <4 x double> %353, %356
  %362 = fadd <4 x double> %357, %361
  %363 = fadd <4 x double> %358, %362
  %364 = fadd <4 x double> %359, %363
  %365 = fadd <4 x double> %360, %364
  %366 = fadd <4 x double> %324, %352
  %367 = fsub <4 x double> %324, %366
  %368 = fadd <4 x double> %352, %367
  %369 = fadd <4 x double> %327, %368
  %370 = fadd <4 x double> %369, %365
  %371 = fadd <4 x double> %366, %370
  %372 = ashr <4 x i32> %283, <i32 1, i32 1, i32 1, i32 1>
  %373 = add nsw <4 x i32> %372, <i32 1023, i32 1023, i32 1023, i32 1023>
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %375 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %376 = and <4 x i32> %374, <i32 0, i32 -1, i32 0, i32 -1>
  %377 = shl <4 x i32> %376, <i32 20, i32 20, i32 20, i32 20>
  %378 = and <4 x i32> %375, <i32 0, i32 -1, i32 0, i32 -1>
  %379 = shl <4 x i32> %378, <i32 20, i32 20, i32 20, i32 20>
  %380 = bitcast <4 x i32> %377 to <2 x i64>
  %381 = bitcast <4 x i32> %379 to <2 x i64>
  %382 = shufflevector <2 x i64> %380, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %383 = shufflevector <2 x i64> %381, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %384 = shufflevector <4 x i64> %382, <4 x i64> %383, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %385 = bitcast <4 x i64> %384 to <4 x double>
  %386 = fmul <4 x double> %371, %385
  %387 = sub <4 x i32> %283, %372
  %388 = add <4 x i32> %387, <i32 1023, i32 1023, i32 1023, i32 1023>
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %390 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %391 = and <4 x i32> %389, <i32 0, i32 -1, i32 0, i32 -1>
  %392 = shl <4 x i32> %391, <i32 20, i32 20, i32 20, i32 20>
  %393 = and <4 x i32> %390, <i32 0, i32 -1, i32 0, i32 -1>
  %394 = shl <4 x i32> %393, <i32 20, i32 20, i32 20, i32 20>
  %395 = bitcast <4 x i32> %392 to <2 x i64>
  %396 = bitcast <4 x i32> %394 to <2 x i64>
  %397 = shufflevector <2 x i64> %395, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %398 = shufflevector <2 x i64> %396, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %399 = shufflevector <4 x i64> %397, <4 x i64> %398, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %400 = bitcast <4 x i64> %399 to <4 x double>
  %401 = fmul <4 x double> %386, %400
  %402 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %266, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %403 = bitcast <4 x double> %402 to <4 x i64>
  %404 = bitcast <4 x double> %401 to <4 x i64>
  %405 = xor <4 x i64> %403, <i64 -1, i64 -1, i64 -1, i64 -1>
  %406 = and <4 x i64> %404, %405
  %407 = bitcast <4 x i64> %406 to <4 x double>
  %408 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %266, <4 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i8 30) #6
  %409 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %407, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %408) #6
  %410 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 30) #6
  %411 = bitcast <4 x i64> %10 to <4 x double>
  %412 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> %411) #6
  %413 = bitcast <4 x i64> %5 to <4 x double>
  %414 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %412, <4 x double> %413) #6
  %415 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %414, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %410) #6
  %416 = fmul <4 x double> %409, %415
  %417 = fadd <4 x double> %13, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %418 = bitcast <4 x double> %417 to <4 x i64>
  %419 = and <4 x i64> %262, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %420 = xor <4 x i64> %419, %418
  %421 = bitcast <4 x i64> %420 to <4 x double>
  %422 = and <4 x i64> %262, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %423 = bitcast <4 x i64> %422 to <4 x double>
  %424 = fcmp oeq <4 x double> %423, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %425 = sext <4 x i1> %424 to <4 x i64>
  %426 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %421, <4 x double> zeroinitializer, i8 17) #6
  %427 = bitcast <4 x double> %426 to <4 x i64>
  %428 = fcmp oeq <4 x double> %421, zeroinitializer
  %429 = sext <4 x i1> %428 to <4 x i64>
  %430 = bitcast <4 x i64> %429 to <4 x double>
  %431 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %430) #6
  %432 = bitcast <4 x double> %431 to <4 x i64>
  %433 = xor <4 x i64> %427, <i64 -1, i64 -1, i64 -1, i64 -1>
  %434 = and <4 x i64> %432, %433
  %435 = bitcast <4 x i64> %434 to <4 x double>
  %436 = bitcast <4 x i64> %425 to <4 x double>
  %437 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %416, <4 x double> %435, <4 x double> %436) #6
  %438 = fcmp oeq <4 x double> %13, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %439 = fcmp oeq <4 x double> %0, zeroinitializer
  %440 = sext <4 x i1> %439 to <4 x i64>
  %441 = or <4 x i1> %438, %439
  %442 = sext <4 x i1> %441 to <4 x i64>
  %443 = and <4 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %444 = or <4 x i64> %443, <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %445 = bitcast <4 x i64> %444 to <4 x double>
  %446 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %445, <4 x double> %411) #6
  %447 = xor <4 x i64> %262, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %448 = bitcast <4 x i64> %447 to <4 x double>
  %449 = bitcast <4 x i64> %440 to <4 x double>
  %450 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %1, <4 x double> %448, <4 x double> %449) #6
  %451 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %450, <4 x double> zeroinitializer, i8 17) #6
  %452 = bitcast <4 x double> %451 to <4 x i64>
  %453 = and <4 x i64> %452, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %454 = xor <4 x i64> %453, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %455 = bitcast <4 x i64> %454 to <4 x double>
  %456 = fmul <4 x double> %446, %455
  %457 = bitcast <4 x i64> %442 to <4 x double>
  %458 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %437, <4 x double> %456, <4 x double> %457) #6
  %459 = fcmp uno <4 x double> %1, %0
  %460 = select <4 x i1> %459, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %458
  %461 = fcmp oeq <4 x double> %1, zeroinitializer
  %462 = fcmp oeq <4 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %463 = or <4 x i1> %461, %462
  %464 = sext <4 x i1> %463 to <4 x i64>
  %465 = bitcast <4 x i64> %464 to <4 x double>
  %466 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %460, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %465) #6
  ret <4 x double> %466
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sinhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fadd <4 x double> %4, zeroinitializer
  %6 = fmul <4 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 8) #6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = fmul <4 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <4 x double> %9, %4
  %11 = fsub <4 x double> %10, %4
  %12 = fsub <4 x double> %10, %11
  %13 = fsub <4 x double> %4, %12
  %14 = fsub <4 x double> %9, %11
  %15 = fadd <4 x double> %14, %13
  %16 = fadd <4 x double> %15, zeroinitializer
  %17 = fmul <4 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <4 x double> %17, %10
  %19 = fsub <4 x double> %18, %10
  %20 = fsub <4 x double> %18, %19
  %21 = fsub <4 x double> %10, %20
  %22 = fsub <4 x double> %17, %19
  %23 = fadd <4 x double> %22, %21
  %24 = fadd <4 x double> %23, %16
  %25 = bitcast <4 x double> %18 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %18, %27
  %29 = fmul <4 x double> %18, %18
  %30 = fmul <4 x double> %27, %27
  %31 = bitcast <4 x double> %29 to <4 x i64>
  %32 = xor <4 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = fadd <4 x double> %27, %27
  %35 = fmul <4 x double> %34, %28
  %36 = fmul <4 x double> %28, %28
  %37 = fadd <4 x double> %24, %24
  %38 = fmul <4 x double> %18, %37
  %39 = fadd <4 x double> %30, %33
  %40 = fadd <4 x double> %39, %35
  %41 = fadd <4 x double> %36, %40
  %42 = fadd <4 x double> %38, %41
  %43 = and <4 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %29, %44
  %46 = fmul <4 x double> %29, %29
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fadd <4 x double> %44, %44
  %52 = fmul <4 x double> %51, %45
  %53 = fmul <4 x double> %45, %45
  %54 = fadd <4 x double> %42, %42
  %55 = fmul <4 x double> %29, %54
  %56 = fadd <4 x double> %47, %50
  %57 = fadd <4 x double> %56, %52
  %58 = fadd <4 x double> %53, %57
  %59 = fadd <4 x double> %58, %55
  %60 = fmul <4 x double> %46, %46
  %61 = fmul <4 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <4 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <4 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <4 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <4 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <4 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <4 x double> %29, %64
  %68 = fadd <4 x double> %66, %67
  %69 = fmul <4 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <4 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <4 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <4 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <4 x double> %29, %70
  %74 = fadd <4 x double> %72, %73
  %75 = fmul <4 x double> %46, %68
  %76 = fadd <4 x double> %74, %75
  %77 = fmul <4 x double> %62, %60
  %78 = fadd <4 x double> %77, %76
  %79 = fmul <4 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <4 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <4 x double> %79 to <4 x i64>
  %82 = xor <4 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <4 x i64> %82 to <4 x double>
  %84 = fmul <4 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <4 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <4 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <4 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <4 x double> %80, %83
  %89 = fadd <4 x double> %84, %88
  %90 = fadd <4 x double> %85, %89
  %91 = fadd <4 x double> %86, %90
  %92 = fadd <4 x double> %87, %91
  %93 = fadd <4 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <4 x double> %79, %94
  %96 = fadd <4 x double> %95, %92
  %97 = bitcast <4 x double> %93 to <4 x i64>
  %98 = and <4 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <4 x i64> %98 to <4 x double>
  %100 = fsub <4 x double> %93, %99
  %101 = fmul <4 x double> %18, %93
  %102 = fmul <4 x double> %27, %99
  %103 = bitcast <4 x double> %101 to <4 x i64>
  %104 = xor <4 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fmul <4 x double> %100, %27
  %107 = fmul <4 x double> %28, %99
  %108 = fmul <4 x double> %28, %100
  %109 = fmul <4 x double> %93, %24
  %110 = fmul <4 x double> %18, %96
  %111 = fadd <4 x double> %102, %105
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %108, %113
  %115 = fadd <4 x double> %109, %114
  %116 = fadd <4 x double> %110, %115
  %117 = fadd <4 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <4 x double> %101, %118
  %120 = fadd <4 x double> %119, %116
  %121 = bitcast <4 x double> %117 to <4 x i64>
  %122 = and <4 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <4 x i64> %122 to <4 x double>
  %124 = fsub <4 x double> %117, %123
  %125 = fmul <4 x double> %18, %117
  %126 = fmul <4 x double> %27, %123
  %127 = bitcast <4 x double> %125 to <4 x i64>
  %128 = xor <4 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <4 x i64> %128 to <4 x double>
  %130 = fmul <4 x double> %124, %27
  %131 = fmul <4 x double> %28, %123
  %132 = fmul <4 x double> %28, %124
  %133 = fmul <4 x double> %117, %24
  %134 = fmul <4 x double> %18, %120
  %135 = fadd <4 x double> %126, %129
  %136 = fadd <4 x double> %130, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %132, %137
  %139 = fadd <4 x double> %133, %138
  %140 = fadd <4 x double> %139, %134
  %141 = fadd <4 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <4 x double> %125, %142
  %144 = fadd <4 x double> %143, %140
  %145 = and <4 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <4 x i64> %145 to <4 x double>
  %147 = fsub <4 x double> %46, %146
  %148 = bitcast <4 x double> %78 to <4 x i64>
  %149 = and <4 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fsub <4 x double> %78, %150
  %152 = fmul <4 x double> %46, %78
  %153 = fmul <4 x double> %146, %150
  %154 = bitcast <4 x double> %152 to <4 x i64>
  %155 = xor <4 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fmul <4 x double> %147, %150
  %158 = fmul <4 x double> %151, %146
  %159 = fmul <4 x double> %147, %151
  %160 = fmul <4 x double> %78, %59
  %161 = fadd <4 x double> %153, %156
  %162 = fadd <4 x double> %157, %161
  %163 = fadd <4 x double> %158, %162
  %164 = fadd <4 x double> %159, %163
  %165 = fadd <4 x double> %160, %164
  %166 = fadd <4 x double> %141, %152
  %167 = fsub <4 x double> %141, %166
  %168 = fadd <4 x double> %152, %167
  %169 = fadd <4 x double> %168, %144
  %170 = fadd <4 x double> %165, %169
  %171 = ashr <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <4 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %174 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %175 = and <4 x i32> %173, <i32 0, i32 -1, i32 0, i32 -1>
  %176 = shl <4 x i32> %175, <i32 20, i32 20, i32 20, i32 20>
  %177 = and <4 x i32> %174, <i32 0, i32 -1, i32 0, i32 -1>
  %178 = shl <4 x i32> %177, <i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <4 x i32> %176 to <2 x i64>
  %180 = bitcast <4 x i32> %178 to <2 x i64>
  %181 = shufflevector <2 x i64> %179, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %182 = shufflevector <2 x i64> %180, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %183 = shufflevector <4 x i64> %181, <4 x i64> %182, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %184 = bitcast <4 x i64> %183 to <4 x double>
  %185 = fmul <4 x double> %166, %184
  %186 = sub <4 x i32> %8, %171
  %187 = add <4 x i32> %186, <i32 1023, i32 1023, i32 1023, i32 1023>
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %189 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %190 = and <4 x i32> %188, <i32 0, i32 -1, i32 0, i32 -1>
  %191 = shl <4 x i32> %190, <i32 20, i32 20, i32 20, i32 20>
  %192 = and <4 x i32> %189, <i32 0, i32 -1, i32 0, i32 -1>
  %193 = shl <4 x i32> %192, <i32 20, i32 20, i32 20, i32 20>
  %194 = bitcast <4 x i32> %191 to <2 x i64>
  %195 = bitcast <4 x i32> %193 to <2 x i64>
  %196 = shufflevector <2 x i64> %194, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %197 = shufflevector <2 x i64> %195, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %198 = shufflevector <4 x i64> %196, <4 x i64> %197, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %199 = bitcast <4 x i64> %198 to <4 x double>
  %200 = fmul <4 x double> %185, %199
  %201 = fmul <4 x double> %170, %184
  %202 = fmul <4 x double> %201, %199
  %203 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %204 = bitcast <4 x double> %203 to <4 x i64>
  %205 = bitcast <4 x double> %200 to <4 x i64>
  %206 = xor <4 x i64> %204, <i64 -1, i64 -1, i64 -1, i64 -1>
  %207 = and <4 x i64> %205, %206
  %208 = bitcast <4 x double> %202 to <4 x i64>
  %209 = and <4 x i64> %208, %206
  %210 = bitcast <4 x i64> %207 to <4 x double>
  %211 = bitcast <4 x i64> %209 to <4 x double>
  %212 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %210
  %213 = and <4 x i64> %207, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %214 = bitcast <4 x i64> %213 to <4 x double>
  %215 = fsub <4 x double> %210, %214
  %216 = bitcast <4 x double> %212 to <4 x i64>
  %217 = and <4 x i64> %216, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %218 = bitcast <4 x i64> %217 to <4 x double>
  %219 = fsub <4 x double> %212, %218
  %220 = fmul <4 x double> %214, %218
  %221 = fmul <4 x double> %219, %214
  %222 = fmul <4 x double> %215, %218
  %223 = fmul <4 x double> %215, %219
  %224 = fmul <4 x double> %212, %211
  %225 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %220
  %226 = fsub <4 x double> %225, %221
  %227 = fsub <4 x double> %226, %222
  %228 = fsub <4 x double> %227, %223
  %229 = fsub <4 x double> %228, %224
  %230 = fmul <4 x double> %212, %229
  %231 = fsub <4 x double> %210, %212
  %232 = fsub <4 x double> %210, %231
  %233 = fsub <4 x double> %232, %212
  %234 = fadd <4 x double> %233, %211
  %235 = fsub <4 x double> %234, %230
  %236 = fadd <4 x double> %231, %235
  %237 = fmul <4 x double> %236, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %238 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02>, i8 30) #6
  %239 = fcmp uno <4 x double> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %238
  %241 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %237, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %240) #6
  %242 = bitcast <4 x double> %241 to <4 x i64>
  %243 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %244 = xor <4 x i64> %243, %242
  %245 = fcmp uno <4 x double> %0, zeroinitializer
  %246 = bitcast <4 x i64> %244 to <4 x double>
  %247 = select <4 x i1> %245, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %246
  ret <4 x double> %247
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_coshd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fadd <4 x double> %4, zeroinitializer
  %6 = fmul <4 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 8) #6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = fmul <4 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <4 x double> %9, %4
  %11 = fsub <4 x double> %10, %4
  %12 = fsub <4 x double> %10, %11
  %13 = fsub <4 x double> %4, %12
  %14 = fsub <4 x double> %9, %11
  %15 = fadd <4 x double> %14, %13
  %16 = fadd <4 x double> %15, zeroinitializer
  %17 = fmul <4 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <4 x double> %17, %10
  %19 = fsub <4 x double> %18, %10
  %20 = fsub <4 x double> %18, %19
  %21 = fsub <4 x double> %10, %20
  %22 = fsub <4 x double> %17, %19
  %23 = fadd <4 x double> %22, %21
  %24 = fadd <4 x double> %23, %16
  %25 = bitcast <4 x double> %18 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %18, %27
  %29 = fmul <4 x double> %18, %18
  %30 = fmul <4 x double> %27, %27
  %31 = bitcast <4 x double> %29 to <4 x i64>
  %32 = xor <4 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = fadd <4 x double> %27, %27
  %35 = fmul <4 x double> %34, %28
  %36 = fmul <4 x double> %28, %28
  %37 = fadd <4 x double> %24, %24
  %38 = fmul <4 x double> %18, %37
  %39 = fadd <4 x double> %30, %33
  %40 = fadd <4 x double> %39, %35
  %41 = fadd <4 x double> %36, %40
  %42 = fadd <4 x double> %38, %41
  %43 = and <4 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %29, %44
  %46 = fmul <4 x double> %29, %29
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fadd <4 x double> %44, %44
  %52 = fmul <4 x double> %51, %45
  %53 = fmul <4 x double> %45, %45
  %54 = fadd <4 x double> %42, %42
  %55 = fmul <4 x double> %29, %54
  %56 = fadd <4 x double> %47, %50
  %57 = fadd <4 x double> %56, %52
  %58 = fadd <4 x double> %53, %57
  %59 = fadd <4 x double> %58, %55
  %60 = fmul <4 x double> %46, %46
  %61 = fmul <4 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <4 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <4 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <4 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <4 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <4 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <4 x double> %29, %64
  %68 = fadd <4 x double> %66, %67
  %69 = fmul <4 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <4 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <4 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <4 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <4 x double> %29, %70
  %74 = fadd <4 x double> %72, %73
  %75 = fmul <4 x double> %46, %68
  %76 = fadd <4 x double> %74, %75
  %77 = fmul <4 x double> %62, %60
  %78 = fadd <4 x double> %77, %76
  %79 = fmul <4 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <4 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <4 x double> %79 to <4 x i64>
  %82 = xor <4 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <4 x i64> %82 to <4 x double>
  %84 = fmul <4 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <4 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <4 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <4 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <4 x double> %80, %83
  %89 = fadd <4 x double> %84, %88
  %90 = fadd <4 x double> %85, %89
  %91 = fadd <4 x double> %86, %90
  %92 = fadd <4 x double> %87, %91
  %93 = fadd <4 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <4 x double> %79, %94
  %96 = fadd <4 x double> %95, %92
  %97 = bitcast <4 x double> %93 to <4 x i64>
  %98 = and <4 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <4 x i64> %98 to <4 x double>
  %100 = fsub <4 x double> %93, %99
  %101 = fmul <4 x double> %18, %93
  %102 = fmul <4 x double> %27, %99
  %103 = bitcast <4 x double> %101 to <4 x i64>
  %104 = xor <4 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fmul <4 x double> %100, %27
  %107 = fmul <4 x double> %28, %99
  %108 = fmul <4 x double> %28, %100
  %109 = fmul <4 x double> %93, %24
  %110 = fmul <4 x double> %18, %96
  %111 = fadd <4 x double> %102, %105
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %108, %113
  %115 = fadd <4 x double> %109, %114
  %116 = fadd <4 x double> %110, %115
  %117 = fadd <4 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <4 x double> %101, %118
  %120 = fadd <4 x double> %119, %116
  %121 = bitcast <4 x double> %117 to <4 x i64>
  %122 = and <4 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <4 x i64> %122 to <4 x double>
  %124 = fsub <4 x double> %117, %123
  %125 = fmul <4 x double> %18, %117
  %126 = fmul <4 x double> %27, %123
  %127 = bitcast <4 x double> %125 to <4 x i64>
  %128 = xor <4 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <4 x i64> %128 to <4 x double>
  %130 = fmul <4 x double> %124, %27
  %131 = fmul <4 x double> %28, %123
  %132 = fmul <4 x double> %28, %124
  %133 = fmul <4 x double> %117, %24
  %134 = fmul <4 x double> %18, %120
  %135 = fadd <4 x double> %126, %129
  %136 = fadd <4 x double> %130, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %132, %137
  %139 = fadd <4 x double> %133, %138
  %140 = fadd <4 x double> %139, %134
  %141 = fadd <4 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <4 x double> %125, %142
  %144 = fadd <4 x double> %143, %140
  %145 = and <4 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <4 x i64> %145 to <4 x double>
  %147 = fsub <4 x double> %46, %146
  %148 = bitcast <4 x double> %78 to <4 x i64>
  %149 = and <4 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fsub <4 x double> %78, %150
  %152 = fmul <4 x double> %46, %78
  %153 = fmul <4 x double> %146, %150
  %154 = bitcast <4 x double> %152 to <4 x i64>
  %155 = xor <4 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fmul <4 x double> %147, %150
  %158 = fmul <4 x double> %151, %146
  %159 = fmul <4 x double> %147, %151
  %160 = fmul <4 x double> %78, %59
  %161 = fadd <4 x double> %153, %156
  %162 = fadd <4 x double> %157, %161
  %163 = fadd <4 x double> %158, %162
  %164 = fadd <4 x double> %159, %163
  %165 = fadd <4 x double> %160, %164
  %166 = fadd <4 x double> %141, %152
  %167 = fsub <4 x double> %141, %166
  %168 = fadd <4 x double> %152, %167
  %169 = fadd <4 x double> %168, %144
  %170 = fadd <4 x double> %165, %169
  %171 = ashr <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <4 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %174 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %175 = and <4 x i32> %173, <i32 0, i32 -1, i32 0, i32 -1>
  %176 = shl <4 x i32> %175, <i32 20, i32 20, i32 20, i32 20>
  %177 = and <4 x i32> %174, <i32 0, i32 -1, i32 0, i32 -1>
  %178 = shl <4 x i32> %177, <i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <4 x i32> %176 to <2 x i64>
  %180 = bitcast <4 x i32> %178 to <2 x i64>
  %181 = shufflevector <2 x i64> %179, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %182 = shufflevector <2 x i64> %180, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %183 = shufflevector <4 x i64> %181, <4 x i64> %182, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %184 = bitcast <4 x i64> %183 to <4 x double>
  %185 = fmul <4 x double> %166, %184
  %186 = sub <4 x i32> %8, %171
  %187 = add <4 x i32> %186, <i32 1023, i32 1023, i32 1023, i32 1023>
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %189 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %190 = and <4 x i32> %188, <i32 0, i32 -1, i32 0, i32 -1>
  %191 = shl <4 x i32> %190, <i32 20, i32 20, i32 20, i32 20>
  %192 = and <4 x i32> %189, <i32 0, i32 -1, i32 0, i32 -1>
  %193 = shl <4 x i32> %192, <i32 20, i32 20, i32 20, i32 20>
  %194 = bitcast <4 x i32> %191 to <2 x i64>
  %195 = bitcast <4 x i32> %193 to <2 x i64>
  %196 = shufflevector <2 x i64> %194, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %197 = shufflevector <2 x i64> %195, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %198 = shufflevector <4 x i64> %196, <4 x i64> %197, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %199 = bitcast <4 x i64> %198 to <4 x double>
  %200 = fmul <4 x double> %185, %199
  %201 = fmul <4 x double> %170, %184
  %202 = fmul <4 x double> %201, %199
  %203 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %204 = bitcast <4 x double> %203 to <4 x i64>
  %205 = bitcast <4 x double> %200 to <4 x i64>
  %206 = xor <4 x i64> %204, <i64 -1, i64 -1, i64 -1, i64 -1>
  %207 = and <4 x i64> %205, %206
  %208 = bitcast <4 x double> %202 to <4 x i64>
  %209 = and <4 x i64> %208, %206
  %210 = bitcast <4 x i64> %207 to <4 x double>
  %211 = bitcast <4 x i64> %209 to <4 x double>
  %212 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %210
  %213 = and <4 x i64> %207, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %214 = bitcast <4 x i64> %213 to <4 x double>
  %215 = fsub <4 x double> %210, %214
  %216 = bitcast <4 x double> %212 to <4 x i64>
  %217 = and <4 x i64> %216, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %218 = bitcast <4 x i64> %217 to <4 x double>
  %219 = fsub <4 x double> %212, %218
  %220 = fmul <4 x double> %214, %218
  %221 = fmul <4 x double> %219, %214
  %222 = fmul <4 x double> %215, %218
  %223 = fmul <4 x double> %215, %219
  %224 = fmul <4 x double> %212, %211
  %225 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %220
  %226 = fsub <4 x double> %225, %221
  %227 = fsub <4 x double> %226, %222
  %228 = fsub <4 x double> %227, %223
  %229 = fsub <4 x double> %228, %224
  %230 = fmul <4 x double> %212, %229
  %231 = fadd <4 x double> %212, %210
  %232 = fsub <4 x double> %210, %231
  %233 = fadd <4 x double> %212, %232
  %234 = fadd <4 x double> %233, %211
  %235 = fadd <4 x double> %234, %230
  %236 = fadd <4 x double> %231, %235
  %237 = fmul <4 x double> %236, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %238 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02>, i8 30) #6
  %239 = fcmp uno <4 x double> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %238
  %241 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %237, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %240) #6
  %242 = fcmp uno <4 x double> %0, zeroinitializer
  %243 = select <4 x i1> %242, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %241
  ret <4 x double> %243
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_tanhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fadd <4 x double> %4, zeroinitializer
  %6 = fmul <4 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 8) #6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = fmul <4 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <4 x double> %9, %4
  %11 = fsub <4 x double> %10, %4
  %12 = fsub <4 x double> %10, %11
  %13 = fsub <4 x double> %4, %12
  %14 = fsub <4 x double> %9, %11
  %15 = fadd <4 x double> %14, %13
  %16 = fadd <4 x double> %15, zeroinitializer
  %17 = fmul <4 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <4 x double> %17, %10
  %19 = fsub <4 x double> %18, %10
  %20 = fsub <4 x double> %18, %19
  %21 = fsub <4 x double> %10, %20
  %22 = fsub <4 x double> %17, %19
  %23 = fadd <4 x double> %22, %21
  %24 = fadd <4 x double> %23, %16
  %25 = bitcast <4 x double> %18 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %18, %27
  %29 = fmul <4 x double> %18, %18
  %30 = fmul <4 x double> %27, %27
  %31 = bitcast <4 x double> %29 to <4 x i64>
  %32 = xor <4 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = fadd <4 x double> %27, %27
  %35 = fmul <4 x double> %34, %28
  %36 = fmul <4 x double> %28, %28
  %37 = fadd <4 x double> %24, %24
  %38 = fmul <4 x double> %18, %37
  %39 = fadd <4 x double> %30, %33
  %40 = fadd <4 x double> %39, %35
  %41 = fadd <4 x double> %36, %40
  %42 = fadd <4 x double> %38, %41
  %43 = and <4 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %29, %44
  %46 = fmul <4 x double> %29, %29
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fadd <4 x double> %44, %44
  %52 = fmul <4 x double> %51, %45
  %53 = fmul <4 x double> %45, %45
  %54 = fadd <4 x double> %42, %42
  %55 = fmul <4 x double> %29, %54
  %56 = fadd <4 x double> %47, %50
  %57 = fadd <4 x double> %56, %52
  %58 = fadd <4 x double> %53, %57
  %59 = fadd <4 x double> %58, %55
  %60 = fmul <4 x double> %46, %46
  %61 = fmul <4 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <4 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <4 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <4 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <4 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <4 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <4 x double> %29, %64
  %68 = fadd <4 x double> %66, %67
  %69 = fmul <4 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <4 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <4 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <4 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <4 x double> %29, %70
  %74 = fadd <4 x double> %72, %73
  %75 = fmul <4 x double> %46, %68
  %76 = fadd <4 x double> %74, %75
  %77 = fmul <4 x double> %62, %60
  %78 = fadd <4 x double> %77, %76
  %79 = fmul <4 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <4 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <4 x double> %79 to <4 x i64>
  %82 = xor <4 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <4 x i64> %82 to <4 x double>
  %84 = fmul <4 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <4 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <4 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <4 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <4 x double> %80, %83
  %89 = fadd <4 x double> %84, %88
  %90 = fadd <4 x double> %85, %89
  %91 = fadd <4 x double> %86, %90
  %92 = fadd <4 x double> %87, %91
  %93 = fadd <4 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <4 x double> %79, %94
  %96 = fadd <4 x double> %95, %92
  %97 = bitcast <4 x double> %93 to <4 x i64>
  %98 = and <4 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <4 x i64> %98 to <4 x double>
  %100 = fsub <4 x double> %93, %99
  %101 = fmul <4 x double> %18, %93
  %102 = fmul <4 x double> %27, %99
  %103 = bitcast <4 x double> %101 to <4 x i64>
  %104 = xor <4 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fmul <4 x double> %100, %27
  %107 = fmul <4 x double> %28, %99
  %108 = fmul <4 x double> %28, %100
  %109 = fmul <4 x double> %93, %24
  %110 = fmul <4 x double> %18, %96
  %111 = fadd <4 x double> %102, %105
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %108, %113
  %115 = fadd <4 x double> %109, %114
  %116 = fadd <4 x double> %110, %115
  %117 = fadd <4 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <4 x double> %101, %118
  %120 = fadd <4 x double> %119, %116
  %121 = bitcast <4 x double> %117 to <4 x i64>
  %122 = and <4 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <4 x i64> %122 to <4 x double>
  %124 = fsub <4 x double> %117, %123
  %125 = fmul <4 x double> %18, %117
  %126 = fmul <4 x double> %27, %123
  %127 = bitcast <4 x double> %125 to <4 x i64>
  %128 = xor <4 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <4 x i64> %128 to <4 x double>
  %130 = fmul <4 x double> %124, %27
  %131 = fmul <4 x double> %28, %123
  %132 = fmul <4 x double> %28, %124
  %133 = fmul <4 x double> %117, %24
  %134 = fmul <4 x double> %18, %120
  %135 = fadd <4 x double> %126, %129
  %136 = fadd <4 x double> %130, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %132, %137
  %139 = fadd <4 x double> %133, %138
  %140 = fadd <4 x double> %139, %134
  %141 = fadd <4 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <4 x double> %125, %142
  %144 = fadd <4 x double> %143, %140
  %145 = and <4 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <4 x i64> %145 to <4 x double>
  %147 = fsub <4 x double> %46, %146
  %148 = bitcast <4 x double> %78 to <4 x i64>
  %149 = and <4 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fsub <4 x double> %78, %150
  %152 = fmul <4 x double> %46, %78
  %153 = fmul <4 x double> %146, %150
  %154 = bitcast <4 x double> %152 to <4 x i64>
  %155 = xor <4 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = fmul <4 x double> %147, %150
  %158 = fmul <4 x double> %151, %146
  %159 = fmul <4 x double> %147, %151
  %160 = fmul <4 x double> %78, %59
  %161 = fadd <4 x double> %153, %156
  %162 = fadd <4 x double> %157, %161
  %163 = fadd <4 x double> %158, %162
  %164 = fadd <4 x double> %159, %163
  %165 = fadd <4 x double> %160, %164
  %166 = fadd <4 x double> %141, %152
  %167 = fsub <4 x double> %141, %166
  %168 = fadd <4 x double> %152, %167
  %169 = fadd <4 x double> %168, %144
  %170 = fadd <4 x double> %165, %169
  %171 = ashr <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <4 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %174 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %175 = and <4 x i32> %173, <i32 0, i32 -1, i32 0, i32 -1>
  %176 = shl <4 x i32> %175, <i32 20, i32 20, i32 20, i32 20>
  %177 = and <4 x i32> %174, <i32 0, i32 -1, i32 0, i32 -1>
  %178 = shl <4 x i32> %177, <i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <4 x i32> %176 to <2 x i64>
  %180 = bitcast <4 x i32> %178 to <2 x i64>
  %181 = shufflevector <2 x i64> %179, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %182 = shufflevector <2 x i64> %180, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %183 = shufflevector <4 x i64> %181, <4 x i64> %182, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %184 = bitcast <4 x i64> %183 to <4 x double>
  %185 = fmul <4 x double> %166, %184
  %186 = sub <4 x i32> %8, %171
  %187 = add <4 x i32> %186, <i32 1023, i32 1023, i32 1023, i32 1023>
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %189 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %190 = and <4 x i32> %188, <i32 0, i32 -1, i32 0, i32 -1>
  %191 = shl <4 x i32> %190, <i32 20, i32 20, i32 20, i32 20>
  %192 = and <4 x i32> %189, <i32 0, i32 -1, i32 0, i32 -1>
  %193 = shl <4 x i32> %192, <i32 20, i32 20, i32 20, i32 20>
  %194 = bitcast <4 x i32> %191 to <2 x i64>
  %195 = bitcast <4 x i32> %193 to <2 x i64>
  %196 = shufflevector <2 x i64> %194, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %197 = shufflevector <2 x i64> %195, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %198 = shufflevector <4 x i64> %196, <4 x i64> %197, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %199 = bitcast <4 x i64> %198 to <4 x double>
  %200 = fmul <4 x double> %185, %199
  %201 = fmul <4 x double> %170, %184
  %202 = fmul <4 x double> %201, %199
  %203 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %204 = bitcast <4 x double> %203 to <4 x i64>
  %205 = bitcast <4 x double> %200 to <4 x i64>
  %206 = xor <4 x i64> %204, <i64 -1, i64 -1, i64 -1, i64 -1>
  %207 = and <4 x i64> %205, %206
  %208 = bitcast <4 x double> %202 to <4 x i64>
  %209 = and <4 x i64> %208, %206
  %210 = bitcast <4 x i64> %207 to <4 x double>
  %211 = bitcast <4 x i64> %209 to <4 x double>
  %212 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %210
  %213 = and <4 x i64> %207, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %214 = bitcast <4 x i64> %213 to <4 x double>
  %215 = fsub <4 x double> %210, %214
  %216 = bitcast <4 x double> %212 to <4 x i64>
  %217 = and <4 x i64> %216, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %218 = bitcast <4 x i64> %217 to <4 x double>
  %219 = fsub <4 x double> %212, %218
  %220 = fmul <4 x double> %214, %218
  %221 = fmul <4 x double> %219, %214
  %222 = fmul <4 x double> %215, %218
  %223 = fmul <4 x double> %215, %219
  %224 = fmul <4 x double> %212, %211
  %225 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %220
  %226 = fsub <4 x double> %225, %221
  %227 = fsub <4 x double> %226, %222
  %228 = fsub <4 x double> %227, %223
  %229 = fsub <4 x double> %228, %224
  %230 = fmul <4 x double> %212, %229
  %231 = xor <4 x i64> %216, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %232 = bitcast <4 x double> %230 to <4 x i64>
  %233 = xor <4 x i64> %232, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %234 = bitcast <4 x i64> %231 to <4 x double>
  %235 = bitcast <4 x i64> %233 to <4 x double>
  %236 = fadd <4 x double> %210, %234
  %237 = fsub <4 x double> %236, %210
  %238 = fsub <4 x double> %236, %237
  %239 = fsub <4 x double> %210, %238
  %240 = fsub <4 x double> %234, %237
  %241 = fadd <4 x double> %240, %239
  %242 = fadd <4 x double> %211, %235
  %243 = fadd <4 x double> %241, %242
  %244 = fadd <4 x double> %212, %210
  %245 = fsub <4 x double> %244, %210
  %246 = fsub <4 x double> %244, %245
  %247 = fsub <4 x double> %210, %246
  %248 = fsub <4 x double> %212, %245
  %249 = fadd <4 x double> %248, %247
  %250 = fadd <4 x double> %230, %211
  %251 = fadd <4 x double> %249, %250
  %252 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %244
  %253 = bitcast <4 x double> %244 to <4 x i64>
  %254 = and <4 x i64> %253, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %255 = bitcast <4 x i64> %254 to <4 x double>
  %256 = fsub <4 x double> %244, %255
  %257 = bitcast <4 x double> %252 to <4 x i64>
  %258 = and <4 x i64> %257, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %259 = bitcast <4 x i64> %258 to <4 x double>
  %260 = fsub <4 x double> %252, %259
  %261 = bitcast <4 x double> %236 to <4 x i64>
  %262 = and <4 x i64> %261, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %263 = bitcast <4 x i64> %262 to <4 x double>
  %264 = fsub <4 x double> %236, %263
  %265 = fmul <4 x double> %252, %236
  %266 = fmul <4 x double> %259, %263
  %267 = fsub <4 x double> %266, %265
  %268 = fmul <4 x double> %260, %263
  %269 = fmul <4 x double> %264, %259
  %270 = fmul <4 x double> %260, %264
  %271 = fmul <4 x double> %255, %259
  %272 = fmul <4 x double> %260, %255
  %273 = fmul <4 x double> %256, %259
  %274 = fmul <4 x double> %256, %260
  %275 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %271
  %276 = fsub <4 x double> %275, %272
  %277 = fsub <4 x double> %276, %273
  %278 = fsub <4 x double> %277, %274
  %279 = fmul <4 x double> %265, %278
  %280 = fadd <4 x double> %268, %267
  %281 = fadd <4 x double> %269, %280
  %282 = fadd <4 x double> %270, %281
  %283 = fadd <4 x double> %279, %282
  %284 = fmul <4 x double> %265, %251
  %285 = fsub <4 x double> %243, %284
  %286 = fmul <4 x double> %252, %285
  %287 = fadd <4 x double> %283, %286
  %288 = fadd <4 x double> %265, %287
  %289 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i8 30) #6
  %290 = fcmp uno <4 x double> %288, zeroinitializer
  %291 = select <4 x i1> %290, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %289
  %292 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %288, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %291) #6
  %293 = bitcast <4 x double> %292 to <4 x i64>
  %294 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %295 = xor <4 x i64> %294, %293
  %296 = fcmp uno <4 x double> %0, zeroinitializer
  %297 = bitcast <4 x i64> %295 to <4 x double>
  %298 = select <4 x i1> %296, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %297
  ret <4 x double> %298
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sinhd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %5, i32 8) #6
  %7 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %6) #6
  %8 = fmul <4 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <4 x double> %8, %4
  %10 = fmul <4 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <4 x double> %10, %9
  %12 = fmul <4 x double> %11, %11
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <4 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <4 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <4 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <4 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <4 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <4 x double> %12, %18
  %22 = fadd <4 x double> %20, %21
  %23 = fmul <4 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <4 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <4 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <4 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <4 x double> %12, %24
  %28 = fadd <4 x double> %26, %27
  %29 = fmul <4 x double> %13, %22
  %30 = fadd <4 x double> %28, %29
  %31 = fmul <4 x double> %16, %14
  %32 = fadd <4 x double> %31, %30
  %33 = fmul <4 x double> %11, %12
  %34 = fmul <4 x double> %33, %32
  %35 = fmul <4 x double> %12, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %36 = fadd <4 x double> %35, %34
  %37 = fadd <4 x double> %11, %36
  %38 = icmp eq <4 x i32> %7, zeroinitializer
  %39 = sitofp <4 x i1> %38 to <4 x double>
  %40 = fcmp oeq <4 x double> %39, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %41 = sext <4 x i1> %40 to <4 x i64>
  %42 = fadd <4 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %43 = ashr <4 x i32> %7, <i32 1, i32 1, i32 1, i32 1>
  %44 = add nsw <4 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023>
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %46 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %47 = and <4 x i32> %45, <i32 0, i32 -1, i32 0, i32 -1>
  %48 = shl <4 x i32> %47, <i32 20, i32 20, i32 20, i32 20>
  %49 = and <4 x i32> %46, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = bitcast <4 x i32> %48 to <2 x i64>
  %52 = bitcast <4 x i32> %50 to <2 x i64>
  %53 = shufflevector <2 x i64> %51, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %54 = shufflevector <2 x i64> %52, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %55 = shufflevector <4 x i64> %53, <4 x i64> %54, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %56 = bitcast <4 x i64> %55 to <4 x double>
  %57 = fmul <4 x double> %42, %56
  %58 = sub <4 x i32> %7, %43
  %59 = add <4 x i32> %58, <i32 1023, i32 1023, i32 1023, i32 1023>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %61 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %62 = and <4 x i32> %60, <i32 0, i32 -1, i32 0, i32 -1>
  %63 = shl <4 x i32> %62, <i32 20, i32 20, i32 20, i32 20>
  %64 = and <4 x i32> %61, <i32 0, i32 -1, i32 0, i32 -1>
  %65 = shl <4 x i32> %64, <i32 20, i32 20, i32 20, i32 20>
  %66 = bitcast <4 x i32> %63 to <2 x i64>
  %67 = bitcast <4 x i32> %65 to <2 x i64>
  %68 = shufflevector <2 x i64> %66, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %69 = shufflevector <2 x i64> %67, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %70 = shufflevector <4 x i64> %68, <4 x i64> %69, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %71 = bitcast <4 x i64> %70 to <4 x double>
  %72 = fmul <4 x double> %57, %71
  %73 = fadd <4 x double> %72, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %74 = bitcast <4 x i64> %41 to <4 x double>
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %73, <4 x double> %37, <4 x double> %74) #6
  %76 = fadd <4 x double> %75, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %77 = fadd <4 x double> %75, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %78 = fdiv <4 x double> %76, %77
  %79 = fmul <4 x double> %75, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %80 = fmul <4 x double> %79, %78
  %81 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i8 30) #6
  %82 = fcmp uno <4 x double> %80, zeroinitializer
  %83 = select <4 x i1> %82, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %81
  %84 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %80, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %83) #6
  %85 = bitcast <4 x double> %84 to <4 x i64>
  %86 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %87 = xor <4 x i64> %86, %85
  %88 = fcmp uno <4 x double> %0, zeroinitializer
  %89 = bitcast <4 x i64> %87 to <4 x double>
  %90 = select <4 x i1> %88, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %89
  ret <4 x double> %90
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_coshd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %5, i32 8) #6
  %7 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %6) #6
  %8 = fmul <4 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <4 x double> %8, %4
  %10 = fmul <4 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <4 x double> %10, %9
  %12 = fmul <4 x double> %11, %11
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <4 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <4 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <4 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <4 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <4 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <4 x double> %12, %18
  %22 = fadd <4 x double> %20, %21
  %23 = fmul <4 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <4 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <4 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <4 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <4 x double> %12, %24
  %28 = fadd <4 x double> %26, %27
  %29 = fmul <4 x double> %13, %22
  %30 = fadd <4 x double> %28, %29
  %31 = fmul <4 x double> %16, %14
  %32 = fadd <4 x double> %31, %30
  %33 = fmul <4 x double> %11, %32
  %34 = fadd <4 x double> %33, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %35 = fmul <4 x double> %12, %34
  %36 = fadd <4 x double> %11, %35
  %37 = fadd <4 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %38 = ashr <4 x i32> %7, <i32 1, i32 1, i32 1, i32 1>
  %39 = add nsw <4 x i32> %38, <i32 1023, i32 1023, i32 1023, i32 1023>
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %41 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %42 = and <4 x i32> %40, <i32 0, i32 -1, i32 0, i32 -1>
  %43 = shl <4 x i32> %42, <i32 20, i32 20, i32 20, i32 20>
  %44 = and <4 x i32> %41, <i32 0, i32 -1, i32 0, i32 -1>
  %45 = shl <4 x i32> %44, <i32 20, i32 20, i32 20, i32 20>
  %46 = bitcast <4 x i32> %43 to <2 x i64>
  %47 = bitcast <4 x i32> %45 to <2 x i64>
  %48 = shufflevector <2 x i64> %46, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %49 = shufflevector <2 x i64> %47, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %50 = shufflevector <4 x i64> %48, <4 x i64> %49, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %51 = bitcast <4 x i64> %50 to <4 x double>
  %52 = fmul <4 x double> %37, %51
  %53 = sub <4 x i32> %7, %38
  %54 = add <4 x i32> %53, <i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %56 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %57 = and <4 x i32> %55, <i32 0, i32 -1, i32 0, i32 -1>
  %58 = shl <4 x i32> %57, <i32 20, i32 20, i32 20, i32 20>
  %59 = and <4 x i32> %56, <i32 0, i32 -1, i32 0, i32 -1>
  %60 = shl <4 x i32> %59, <i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <4 x i32> %58 to <2 x i64>
  %62 = bitcast <4 x i32> %60 to <2 x i64>
  %63 = shufflevector <2 x i64> %61, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %64 = shufflevector <2 x i64> %62, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %65 = shufflevector <4 x i64> %63, <4 x i64> %64, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %66 = bitcast <4 x i64> %65 to <4 x double>
  %67 = fmul <4 x double> %52, %66
  %68 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i8 30) #6
  %69 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %67, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %68) #6
  %70 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %71 = bitcast <4 x double> %70 to <4 x i64>
  %72 = bitcast <4 x double> %69 to <4 x i64>
  %73 = xor <4 x i64> %71, <i64 -1, i64 -1, i64 -1, i64 -1>
  %74 = and <4 x i64> %73, %72
  %75 = bitcast <4 x i64> %74 to <4 x double>
  %76 = fdiv <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %75
  %77 = fmul <4 x double> %75, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %78 = fadd <4 x double> %77, %76
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i8 30) #6
  %80 = fcmp uno <4 x double> %78, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %81) #6
  %83 = fcmp uno <4 x double> %0, zeroinitializer
  %84 = select <4 x i1> %83, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %82
  ret <4 x double> %84
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_tanhd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %6 = fmul <4 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 8) #6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = fmul <4 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <4 x double> %5, %9
  %11 = fmul <4 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %12 = fadd <4 x double> %11, %10
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %14, %14
  %16 = fmul <4 x double> %12, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %17 = fadd <4 x double> %16, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %18 = fmul <4 x double> %12, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %19 = fadd <4 x double> %18, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %20 = fmul <4 x double> %12, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %21 = fadd <4 x double> %20, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %22 = fmul <4 x double> %13, %19
  %23 = fadd <4 x double> %21, %22
  %24 = fmul <4 x double> %12, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %25 = fadd <4 x double> %24, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %26 = fmul <4 x double> %12, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %27 = fadd <4 x double> %26, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %28 = fmul <4 x double> %13, %25
  %29 = fadd <4 x double> %27, %28
  %30 = fmul <4 x double> %14, %23
  %31 = fadd <4 x double> %29, %30
  %32 = fmul <4 x double> %17, %15
  %33 = fadd <4 x double> %32, %31
  %34 = fmul <4 x double> %12, %13
  %35 = fmul <4 x double> %34, %33
  %36 = fmul <4 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %37 = fadd <4 x double> %36, %35
  %38 = fadd <4 x double> %12, %37
  %39 = icmp eq <4 x i32> %8, zeroinitializer
  %40 = sitofp <4 x i1> %39 to <4 x double>
  %41 = fcmp oeq <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %42 = sext <4 x i1> %41 to <4 x i64>
  %43 = fadd <4 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %44 = ashr <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %45 = add nsw <4 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %47 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %48 = and <4 x i32> %46, <i32 0, i32 -1, i32 0, i32 -1>
  %49 = shl <4 x i32> %48, <i32 20, i32 20, i32 20, i32 20>
  %50 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %51 = shl <4 x i32> %50, <i32 20, i32 20, i32 20, i32 20>
  %52 = bitcast <4 x i32> %49 to <2 x i64>
  %53 = bitcast <4 x i32> %51 to <2 x i64>
  %54 = shufflevector <2 x i64> %52, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <4 x i64> %54, <4 x i64> %55, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %57 = bitcast <4 x i64> %56 to <4 x double>
  %58 = fmul <4 x double> %43, %57
  %59 = sub <4 x i32> %8, %44
  %60 = add <4 x i32> %59, <i32 1023, i32 1023, i32 1023, i32 1023>
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %62 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %63 = and <4 x i32> %61, <i32 0, i32 -1, i32 0, i32 -1>
  %64 = shl <4 x i32> %63, <i32 20, i32 20, i32 20, i32 20>
  %65 = and <4 x i32> %62, <i32 0, i32 -1, i32 0, i32 -1>
  %66 = shl <4 x i32> %65, <i32 20, i32 20, i32 20, i32 20>
  %67 = bitcast <4 x i32> %64 to <2 x i64>
  %68 = bitcast <4 x i32> %66 to <2 x i64>
  %69 = shufflevector <2 x i64> %67, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %70 = shufflevector <2 x i64> %68, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %71 = shufflevector <4 x i64> %69, <4 x i64> %70, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fmul <4 x double> %58, %72
  %74 = fadd <4 x double> %73, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %75 = bitcast <4 x i64> %42 to <4 x double>
  %76 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %74, <4 x double> %38, <4 x double> %75) #6
  %77 = fadd <4 x double> %76, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %78 = fdiv <4 x double> %76, %77
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i8 30) #6
  %80 = fcmp uno <4 x double> %78, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %81) #6
  %83 = bitcast <4 x double> %82 to <4 x i64>
  %84 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %85 = xor <4 x i64> %84, %83
  %86 = fcmp uno <4 x double> %0, zeroinitializer
  %87 = bitcast <4 x i64> %85 to <4 x double>
  %88 = select <4 x i1> %86, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %87
  ret <4 x double> %88
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_asinhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i8 30) #6
  %6 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %0
  %7 = and <4 x i64> %2, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = fsub <4 x double> %0, %8
  %10 = bitcast <4 x double> %6 to <4 x i64>
  %11 = and <4 x i64> %10, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %12 = bitcast <4 x i64> %11 to <4 x double>
  %13 = fsub <4 x double> %6, %12
  %14 = fmul <4 x double> %8, %12
  %15 = fmul <4 x double> %13, %8
  %16 = fmul <4 x double> %9, %12
  %17 = fmul <4 x double> %9, %13
  %18 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %19 = fsub <4 x double> %18, %15
  %20 = fsub <4 x double> %19, %16
  %21 = fsub <4 x double> %20, %17
  %22 = fmul <4 x double> %6, %21
  %23 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %6, <4 x double> %5) #6
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %22, <4 x double> %5) #6
  %25 = bitcast <4 x double> %23 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %23, %27
  %29 = fmul <4 x double> %23, %23
  %30 = fmul <4 x double> %27, %27
  %31 = bitcast <4 x double> %29 to <4 x i64>
  %32 = xor <4 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = fadd <4 x double> %27, %27
  %35 = fmul <4 x double> %34, %28
  %36 = fmul <4 x double> %28, %28
  %37 = fadd <4 x double> %24, %24
  %38 = fmul <4 x double> %23, %37
  %39 = fadd <4 x double> %30, %33
  %40 = fadd <4 x double> %39, %35
  %41 = fadd <4 x double> %36, %40
  %42 = fadd <4 x double> %38, %41
  %43 = fadd <4 x double> %29, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %44 = fsub <4 x double> %43, %29
  %45 = fsub <4 x double> %43, %44
  %46 = fsub <4 x double> %29, %45
  %47 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %44
  %48 = fadd <4 x double> %47, %46
  %49 = fadd <4 x double> %48, %42
  %50 = fadd <4 x double> %43, %49
  %51 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %50) #6
  %52 = bitcast <4 x double> %51 to <4 x i64>
  %53 = and <4 x i64> %52, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %54 = bitcast <4 x i64> %53 to <4 x double>
  %55 = fsub <4 x double> %51, %54
  %56 = fmul <4 x double> %51, %51
  %57 = fmul <4 x double> %54, %54
  %58 = bitcast <4 x double> %56 to <4 x i64>
  %59 = xor <4 x i64> %58, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %60 = bitcast <4 x i64> %59 to <4 x double>
  %61 = fmul <4 x double> %55, %54
  %62 = fmul <4 x double> %55, %55
  %63 = fadd <4 x double> %57, %60
  %64 = fadd <4 x double> %61, %63
  %65 = fadd <4 x double> %61, %64
  %66 = fadd <4 x double> %62, %65
  %67 = fadd <4 x double> %43, %56
  %68 = fsub <4 x double> %67, %43
  %69 = fsub <4 x double> %67, %68
  %70 = fsub <4 x double> %43, %69
  %71 = fsub <4 x double> %56, %68
  %72 = fadd <4 x double> %71, %70
  %73 = fadd <4 x double> %49, %66
  %74 = fadd <4 x double> %72, %73
  %75 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %51
  %76 = bitcast <4 x double> %75 to <4 x i64>
  %77 = and <4 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = fsub <4 x double> %75, %78
  %80 = fmul <4 x double> %54, %78
  %81 = fmul <4 x double> %79, %54
  %82 = fmul <4 x double> %55, %78
  %83 = fmul <4 x double> %55, %79
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %75, %87
  %89 = bitcast <4 x double> %67 to <4 x i64>
  %90 = and <4 x i64> %89, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %91 = bitcast <4 x i64> %90 to <4 x double>
  %92 = fsub <4 x double> %67, %91
  %93 = fmul <4 x double> %75, %67
  %94 = fmul <4 x double> %78, %91
  %95 = bitcast <4 x double> %93 to <4 x i64>
  %96 = xor <4 x i64> %95, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %97 = bitcast <4 x i64> %96 to <4 x double>
  %98 = fmul <4 x double> %92, %78
  %99 = fmul <4 x double> %79, %91
  %100 = fmul <4 x double> %79, %92
  %101 = fmul <4 x double> %67, %88
  %102 = fmul <4 x double> %75, %74
  %103 = fadd <4 x double> %94, %97
  %104 = fadd <4 x double> %98, %103
  %105 = fadd <4 x double> %99, %104
  %106 = fadd <4 x double> %100, %105
  %107 = fadd <4 x double> %106, %101
  %108 = fadd <4 x double> %102, %107
  %109 = fmul <4 x double> %93, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %110 = fmul <4 x double> %108, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %111 = bitcast <4 x double> %109 to <4 x i64>
  %112 = and <4 x i64> %111, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %113 = bitcast <4 x i64> %112 to <4 x double>
  %114 = fsub <4 x double> %109, %113
  %115 = and <4 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %4, %116
  %118 = fmul <4 x double> %109, %4
  %119 = fmul <4 x double> %116, %113
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %114, %116
  %124 = fmul <4 x double> %117, %113
  %125 = fmul <4 x double> %117, %114
  %126 = fmul <4 x double> %110, %4
  %127 = fadd <4 x double> %119, %122
  %128 = fadd <4 x double> %123, %127
  %129 = fadd <4 x double> %124, %128
  %130 = fadd <4 x double> %125, %129
  %131 = fadd <4 x double> %130, %126
  %132 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %109, <4 x double> %118, <4 x double> %5) #6
  %133 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %110, <4 x double> %131, <4 x double> %5) #6
  %134 = fadd <4 x double> %132, %0
  %135 = fsub <4 x double> %134, %132
  %136 = fsub <4 x double> %134, %135
  %137 = fsub <4 x double> %132, %136
  %138 = fsub <4 x double> %0, %135
  %139 = fadd <4 x double> %138, %137
  %140 = fadd <4 x double> %133, %139
  %141 = fadd <4 x double> %134, %140
  %142 = fsub <4 x double> %134, %141
  %143 = fadd <4 x double> %140, %142
  %144 = fmul <4 x double> %141, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %145 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %144, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %146 = bitcast <4 x double> %145 to <4 x i64>
  %147 = fmul <4 x double> %144, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %148 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %144, <4 x double> %147, <4 x double> %145) #6
  %149 = bitcast <4 x double> %148 to <4 x i64>
  %150 = shufflevector <4 x i64> %149, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %151 = shufflevector <4 x i64> %149, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %152 = bitcast <2 x i64> %150 to <4 x i32>
  %153 = shufflevector <4 x i32> %152, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = bitcast <2 x i64> %151 to <4 x i32>
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %157 = bitcast <4 x i32> %156 to <2 x i64>
  %158 = shufflevector <2 x i64> %157, <2 x i64> %154, <2 x i32> <i32 2, i32 1>
  %159 = bitcast <2 x i64> %158 to <4 x i32>
  %160 = lshr <4 x i32> %159, <i32 20, i32 20, i32 20, i32 20>
  %161 = and <4 x i64> %146, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %162 = bitcast <4 x i64> %161 to <4 x double>
  %163 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %162) #6
  %164 = bitcast <4 x i32> %163 to <16 x i8>
  %165 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %164) #6
  %166 = bitcast <16 x i8> %165 to <4 x i32>
  %167 = sub <4 x i32> %160, %166
  %168 = sub <4 x i32> zeroinitializer, %167
  %169 = ashr <4 x i32> %168, <i32 1, i32 1, i32 1, i32 1>
  %170 = add nsw <4 x i32> %169, <i32 1023, i32 1023, i32 1023, i32 1023>
  %171 = shufflevector <4 x i32> %170, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %172 = shufflevector <4 x i32> %170, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %173 = and <4 x i32> %171, <i32 0, i32 -1, i32 0, i32 -1>
  %174 = shl <4 x i32> %173, <i32 20, i32 20, i32 20, i32 20>
  %175 = and <4 x i32> %172, <i32 0, i32 -1, i32 0, i32 -1>
  %176 = shl <4 x i32> %175, <i32 20, i32 20, i32 20, i32 20>
  %177 = bitcast <4 x i32> %174 to <2 x i64>
  %178 = bitcast <4 x i32> %176 to <2 x i64>
  %179 = shufflevector <2 x i64> %177, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %180 = shufflevector <2 x i64> %178, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %181 = shufflevector <4 x i64> %179, <4 x i64> %180, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %182 = bitcast <4 x i64> %181 to <4 x double>
  %183 = fmul <4 x double> %141, %182
  %184 = sub <4 x i32> %168, %169
  %185 = add <4 x i32> %184, <i32 1023, i32 1023, i32 1023, i32 1023>
  %186 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %187 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %188 = and <4 x i32> %186, <i32 0, i32 -1, i32 0, i32 -1>
  %189 = shl <4 x i32> %188, <i32 20, i32 20, i32 20, i32 20>
  %190 = and <4 x i32> %187, <i32 0, i32 -1, i32 0, i32 -1>
  %191 = shl <4 x i32> %190, <i32 20, i32 20, i32 20, i32 20>
  %192 = bitcast <4 x i32> %189 to <2 x i64>
  %193 = bitcast <4 x i32> %191 to <2 x i64>
  %194 = shufflevector <2 x i64> %192, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %195 = shufflevector <2 x i64> %193, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %196 = shufflevector <4 x i64> %194, <4 x i64> %195, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %197 = bitcast <4 x i64> %196 to <4 x double>
  %198 = fmul <4 x double> %183, %197
  %199 = fmul <4 x double> %143, %182
  %200 = fmul <4 x double> %199, %197
  %201 = fadd <4 x double> %198, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %202 = fsub <4 x double> %201, %198
  %203 = fsub <4 x double> %201, %202
  %204 = fsub <4 x double> %198, %203
  %205 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %202
  %206 = fadd <4 x double> %205, %204
  %207 = fadd <4 x double> %200, %206
  %208 = fadd <4 x double> %198, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %209 = fsub <4 x double> %208, %198
  %210 = fsub <4 x double> %208, %209
  %211 = fsub <4 x double> %198, %210
  %212 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %209
  %213 = fadd <4 x double> %212, %211
  %214 = fadd <4 x double> %200, %213
  %215 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %208
  %216 = bitcast <4 x double> %208 to <4 x i64>
  %217 = and <4 x i64> %216, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %218 = bitcast <4 x i64> %217 to <4 x double>
  %219 = fsub <4 x double> %208, %218
  %220 = bitcast <4 x double> %215 to <4 x i64>
  %221 = and <4 x i64> %220, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %222 = bitcast <4 x i64> %221 to <4 x double>
  %223 = fsub <4 x double> %215, %222
  %224 = bitcast <4 x double> %201 to <4 x i64>
  %225 = and <4 x i64> %224, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %226 = bitcast <4 x i64> %225 to <4 x double>
  %227 = fsub <4 x double> %201, %226
  %228 = fmul <4 x double> %201, %215
  %229 = fmul <4 x double> %226, %222
  %230 = fsub <4 x double> %229, %228
  %231 = fmul <4 x double> %223, %226
  %232 = fmul <4 x double> %227, %222
  %233 = fmul <4 x double> %227, %223
  %234 = fmul <4 x double> %218, %222
  %235 = fmul <4 x double> %223, %218
  %236 = fmul <4 x double> %219, %222
  %237 = fmul <4 x double> %219, %223
  %238 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %234
  %239 = fsub <4 x double> %238, %235
  %240 = fsub <4 x double> %239, %236
  %241 = fsub <4 x double> %240, %237
  %242 = fmul <4 x double> %228, %241
  %243 = fadd <4 x double> %230, %231
  %244 = fadd <4 x double> %232, %243
  %245 = fadd <4 x double> %233, %244
  %246 = fadd <4 x double> %245, %242
  %247 = fmul <4 x double> %228, %214
  %248 = fsub <4 x double> %207, %247
  %249 = fmul <4 x double> %215, %248
  %250 = fadd <4 x double> %249, %246
  %251 = bitcast <4 x double> %228 to <4 x i64>
  %252 = and <4 x i64> %251, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %253 = bitcast <4 x i64> %252 to <4 x double>
  %254 = fsub <4 x double> %228, %253
  %255 = fmul <4 x double> %228, %228
  %256 = fmul <4 x double> %253, %253
  %257 = bitcast <4 x double> %255 to <4 x i64>
  %258 = xor <4 x i64> %257, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %259 = bitcast <4 x i64> %258 to <4 x double>
  %260 = fadd <4 x double> %253, %253
  %261 = fmul <4 x double> %260, %254
  %262 = fmul <4 x double> %254, %254
  %263 = fadd <4 x double> %250, %250
  %264 = fmul <4 x double> %228, %263
  %265 = fadd <4 x double> %256, %259
  %266 = fadd <4 x double> %265, %261
  %267 = fadd <4 x double> %262, %266
  %268 = fadd <4 x double> %267, %264
  %269 = fmul <4 x double> %255, %255
  %270 = fmul <4 x double> %269, %269
  %271 = fmul <4 x double> %255, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %272 = fadd <4 x double> %271, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %273 = fmul <4 x double> %269, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %274 = fadd <4 x double> %273, %272
  %275 = fmul <4 x double> %255, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %276 = fadd <4 x double> %275, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %277 = fmul <4 x double> %255, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %278 = fadd <4 x double> %277, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %279 = fmul <4 x double> %269, %276
  %280 = fadd <4 x double> %278, %279
  %281 = fmul <4 x double> %270, %274
  %282 = fadd <4 x double> %281, %280
  %283 = fmul <4 x double> %255, %282
  %284 = fadd <4 x double> %283, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %285 = sitofp <4 x i32> %167 to <4 x double>
  %286 = bitcast <4 x double> %285 to <4 x i64>
  %287 = and <4 x i64> %286, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %288 = bitcast <4 x i64> %287 to <4 x double>
  %289 = fsub <4 x double> %285, %288
  %290 = fmul <4 x double> %285, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %291 = fmul <4 x double> %288, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %292 = bitcast <4 x double> %290 to <4 x i64>
  %293 = xor <4 x i64> %292, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %294 = bitcast <4 x i64> %293 to <4 x double>
  %295 = fmul <4 x double> %288, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %296 = fmul <4 x double> %289, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %297 = fmul <4 x double> %289, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %298 = fmul <4 x double> %285, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %299 = fadd <4 x double> %291, %294
  %300 = fadd <4 x double> %295, %299
  %301 = fadd <4 x double> %296, %300
  %302 = fadd <4 x double> %297, %301
  %303 = fadd <4 x double> %298, %302
  %304 = fmul <4 x double> %228, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %305 = fmul <4 x double> %250, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %306 = fadd <4 x double> %290, %304
  %307 = fsub <4 x double> %290, %306
  %308 = fadd <4 x double> %304, %307
  %309 = fadd <4 x double> %303, %308
  %310 = fadd <4 x double> %309, %305
  %311 = and <4 x i64> %257, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %312 = bitcast <4 x i64> %311 to <4 x double>
  %313 = fsub <4 x double> %255, %312
  %314 = fmul <4 x double> %228, %255
  %315 = fmul <4 x double> %253, %312
  %316 = bitcast <4 x double> %314 to <4 x i64>
  %317 = xor <4 x i64> %316, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %318 = bitcast <4 x i64> %317 to <4 x double>
  %319 = fmul <4 x double> %313, %253
  %320 = fmul <4 x double> %254, %312
  %321 = fmul <4 x double> %254, %313
  %322 = fmul <4 x double> %255, %250
  %323 = fmul <4 x double> %228, %268
  %324 = fadd <4 x double> %315, %318
  %325 = fadd <4 x double> %319, %324
  %326 = fadd <4 x double> %320, %325
  %327 = fadd <4 x double> %321, %326
  %328 = fadd <4 x double> %327, %322
  %329 = fadd <4 x double> %328, %323
  %330 = and <4 x i64> %316, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %331 = bitcast <4 x i64> %330 to <4 x double>
  %332 = fsub <4 x double> %314, %331
  %333 = bitcast <4 x double> %284 to <4 x i64>
  %334 = and <4 x i64> %333, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %335 = bitcast <4 x i64> %334 to <4 x double>
  %336 = fsub <4 x double> %284, %335
  %337 = fmul <4 x double> %314, %284
  %338 = fmul <4 x double> %331, %335
  %339 = bitcast <4 x double> %337 to <4 x i64>
  %340 = xor <4 x i64> %339, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %341 = bitcast <4 x i64> %340 to <4 x double>
  %342 = fmul <4 x double> %332, %335
  %343 = fmul <4 x double> %336, %331
  %344 = fmul <4 x double> %332, %336
  %345 = fmul <4 x double> %284, %329
  %346 = fadd <4 x double> %338, %341
  %347 = fadd <4 x double> %342, %346
  %348 = fadd <4 x double> %343, %347
  %349 = fadd <4 x double> %344, %348
  %350 = fadd <4 x double> %345, %349
  %351 = fadd <4 x double> %306, %337
  %352 = fsub <4 x double> %306, %351
  %353 = fadd <4 x double> %337, %352
  %354 = fadd <4 x double> %353, %310
  %355 = fadd <4 x double> %354, %350
  %356 = fadd <4 x double> %351, %355
  %357 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF>, i8 30) #6
  %358 = fcmp uno <4 x double> %356, zeroinitializer
  %359 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %360 = or <4 x i64> %359, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %361 = bitcast <4 x i64> %360 to <4 x double>
  %362 = select <4 x i1> %358, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %357
  %363 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %356, <4 x double> %361, <4 x double> %362) #6
  %364 = fcmp uno <4 x double> %0, zeroinitializer
  %365 = select <4 x i1> %364, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %363
  %366 = xor <4 x i64> %2, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %367 = bitcast <4 x i64> %366 to <4 x double>
  %368 = fcmp oeq <4 x double> %367, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %369 = sext <4 x i1> %368 to <4 x i64>
  %370 = bitcast <4 x i64> %369 to <4 x double>
  %371 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %365, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %370) #6
  ret <4 x double> %371
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_acoshd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = fsub <4 x double> %2, %0
  %4 = fsub <4 x double> %2, %3
  %5 = fsub <4 x double> %0, %4
  %6 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %3
  %7 = fadd <4 x double> %6, %5
  %8 = fadd <4 x double> %2, %7
  %9 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %8) #6
  %10 = bitcast <4 x double> %9 to <4 x i64>
  %11 = and <4 x i64> %10, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %12 = bitcast <4 x i64> %11 to <4 x double>
  %13 = fsub <4 x double> %9, %12
  %14 = fmul <4 x double> %9, %9
  %15 = fmul <4 x double> %12, %12
  %16 = bitcast <4 x double> %14 to <4 x i64>
  %17 = xor <4 x i64> %16, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = fmul <4 x double> %13, %12
  %20 = fmul <4 x double> %13, %13
  %21 = fadd <4 x double> %15, %18
  %22 = fadd <4 x double> %19, %21
  %23 = fadd <4 x double> %19, %22
  %24 = fadd <4 x double> %20, %23
  %25 = fadd <4 x double> %2, %14
  %26 = fsub <4 x double> %25, %2
  %27 = fsub <4 x double> %25, %26
  %28 = fsub <4 x double> %2, %27
  %29 = fsub <4 x double> %14, %26
  %30 = fadd <4 x double> %29, %28
  %31 = fadd <4 x double> %7, %24
  %32 = fadd <4 x double> %30, %31
  %33 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %9
  %34 = bitcast <4 x double> %33 to <4 x i64>
  %35 = and <4 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fsub <4 x double> %33, %36
  %38 = fmul <4 x double> %12, %36
  %39 = fmul <4 x double> %37, %12
  %40 = fmul <4 x double> %13, %36
  %41 = fmul <4 x double> %13, %37
  %42 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %38
  %43 = fsub <4 x double> %42, %39
  %44 = fsub <4 x double> %43, %40
  %45 = fsub <4 x double> %44, %41
  %46 = fmul <4 x double> %33, %45
  %47 = bitcast <4 x double> %25 to <4 x i64>
  %48 = and <4 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <4 x i64> %48 to <4 x double>
  %50 = fsub <4 x double> %25, %49
  %51 = fmul <4 x double> %33, %25
  %52 = fmul <4 x double> %36, %49
  %53 = bitcast <4 x double> %51 to <4 x i64>
  %54 = xor <4 x i64> %53, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %55 = bitcast <4 x i64> %54 to <4 x double>
  %56 = fmul <4 x double> %50, %36
  %57 = fmul <4 x double> %37, %49
  %58 = fmul <4 x double> %37, %50
  %59 = fmul <4 x double> %25, %46
  %60 = fmul <4 x double> %33, %32
  %61 = fadd <4 x double> %52, %55
  %62 = fadd <4 x double> %56, %61
  %63 = fadd <4 x double> %57, %62
  %64 = fadd <4 x double> %58, %63
  %65 = fadd <4 x double> %64, %59
  %66 = fadd <4 x double> %60, %65
  %67 = fmul <4 x double> %51, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %68 = fmul <4 x double> %66, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %69 = fadd <4 x double> %0, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %70 = fsub <4 x double> %69, %0
  %71 = fsub <4 x double> %69, %70
  %72 = fsub <4 x double> %0, %71
  %73 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %70
  %74 = fadd <4 x double> %73, %72
  %75 = fadd <4 x double> %69, %74
  %76 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %75) #6
  %77 = bitcast <4 x double> %76 to <4 x i64>
  %78 = and <4 x i64> %77, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %79 = bitcast <4 x i64> %78 to <4 x double>
  %80 = fsub <4 x double> %76, %79
  %81 = fmul <4 x double> %76, %76
  %82 = fmul <4 x double> %79, %79
  %83 = bitcast <4 x double> %81 to <4 x i64>
  %84 = xor <4 x i64> %83, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %85 = bitcast <4 x i64> %84 to <4 x double>
  %86 = fmul <4 x double> %80, %79
  %87 = fmul <4 x double> %80, %80
  %88 = fadd <4 x double> %82, %85
  %89 = fadd <4 x double> %86, %88
  %90 = fadd <4 x double> %86, %89
  %91 = fadd <4 x double> %87, %90
  %92 = fadd <4 x double> %69, %81
  %93 = fsub <4 x double> %92, %69
  %94 = fsub <4 x double> %92, %93
  %95 = fsub <4 x double> %69, %94
  %96 = fsub <4 x double> %81, %93
  %97 = fadd <4 x double> %96, %95
  %98 = fadd <4 x double> %74, %91
  %99 = fadd <4 x double> %97, %98
  %100 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %76
  %101 = bitcast <4 x double> %100 to <4 x i64>
  %102 = and <4 x i64> %101, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %103 = bitcast <4 x i64> %102 to <4 x double>
  %104 = fsub <4 x double> %100, %103
  %105 = fmul <4 x double> %79, %103
  %106 = fmul <4 x double> %104, %79
  %107 = fmul <4 x double> %80, %103
  %108 = fmul <4 x double> %80, %104
  %109 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %105
  %110 = fsub <4 x double> %109, %106
  %111 = fsub <4 x double> %110, %107
  %112 = fsub <4 x double> %111, %108
  %113 = fmul <4 x double> %100, %112
  %114 = bitcast <4 x double> %92 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %92, %116
  %118 = fmul <4 x double> %100, %92
  %119 = fmul <4 x double> %103, %116
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %117, %103
  %124 = fmul <4 x double> %104, %116
  %125 = fmul <4 x double> %104, %117
  %126 = fmul <4 x double> %92, %113
  %127 = fmul <4 x double> %100, %99
  %128 = fadd <4 x double> %119, %122
  %129 = fadd <4 x double> %123, %128
  %130 = fadd <4 x double> %124, %129
  %131 = fadd <4 x double> %125, %130
  %132 = fadd <4 x double> %131, %126
  %133 = fadd <4 x double> %127, %132
  %134 = fmul <4 x double> %118, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %135 = fmul <4 x double> %133, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %136 = bitcast <4 x double> %67 to <4 x i64>
  %137 = and <4 x i64> %136, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %138 = bitcast <4 x i64> %137 to <4 x double>
  %139 = fsub <4 x double> %67, %138
  %140 = bitcast <4 x double> %134 to <4 x i64>
  %141 = and <4 x i64> %140, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %142 = bitcast <4 x i64> %141 to <4 x double>
  %143 = fsub <4 x double> %134, %142
  %144 = fmul <4 x double> %67, %134
  %145 = fmul <4 x double> %138, %142
  %146 = bitcast <4 x double> %144 to <4 x i64>
  %147 = xor <4 x i64> %146, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = fmul <4 x double> %139, %142
  %150 = fmul <4 x double> %143, %138
  %151 = fmul <4 x double> %139, %143
  %152 = fmul <4 x double> %67, %135
  %153 = fmul <4 x double> %134, %68
  %154 = fadd <4 x double> %145, %148
  %155 = fadd <4 x double> %149, %154
  %156 = fadd <4 x double> %150, %155
  %157 = fadd <4 x double> %151, %156
  %158 = fadd <4 x double> %157, %152
  %159 = fadd <4 x double> %153, %158
  %160 = fadd <4 x double> %144, %0
  %161 = fsub <4 x double> %160, %144
  %162 = fsub <4 x double> %160, %161
  %163 = fsub <4 x double> %144, %162
  %164 = fsub <4 x double> %0, %161
  %165 = fadd <4 x double> %164, %163
  %166 = fadd <4 x double> %165, %159
  %167 = fmul <4 x double> %160, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %168 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %167, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %169 = bitcast <4 x double> %168 to <4 x i64>
  %170 = fmul <4 x double> %167, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %171 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %167, <4 x double> %170, <4 x double> %168) #6
  %172 = bitcast <4 x double> %171 to <4 x i64>
  %173 = shufflevector <4 x i64> %172, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %174 = shufflevector <4 x i64> %172, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %175 = bitcast <2 x i64> %173 to <4 x i32>
  %176 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = bitcast <2 x i64> %174 to <4 x i32>
  %179 = shufflevector <4 x i32> %178, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %180 = bitcast <4 x i32> %179 to <2 x i64>
  %181 = shufflevector <2 x i64> %180, <2 x i64> %177, <2 x i32> <i32 2, i32 1>
  %182 = bitcast <2 x i64> %181 to <4 x i32>
  %183 = lshr <4 x i32> %182, <i32 20, i32 20, i32 20, i32 20>
  %184 = and <4 x i64> %169, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %185 = bitcast <4 x i64> %184 to <4 x double>
  %186 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %185) #6
  %187 = bitcast <4 x i32> %186 to <16 x i8>
  %188 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %187) #6
  %189 = bitcast <16 x i8> %188 to <4 x i32>
  %190 = sub <4 x i32> %183, %189
  %191 = sub <4 x i32> zeroinitializer, %190
  %192 = ashr <4 x i32> %191, <i32 1, i32 1, i32 1, i32 1>
  %193 = add nsw <4 x i32> %192, <i32 1023, i32 1023, i32 1023, i32 1023>
  %194 = shufflevector <4 x i32> %193, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %195 = shufflevector <4 x i32> %193, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %196 = and <4 x i32> %194, <i32 0, i32 -1, i32 0, i32 -1>
  %197 = shl <4 x i32> %196, <i32 20, i32 20, i32 20, i32 20>
  %198 = and <4 x i32> %195, <i32 0, i32 -1, i32 0, i32 -1>
  %199 = shl <4 x i32> %198, <i32 20, i32 20, i32 20, i32 20>
  %200 = bitcast <4 x i32> %197 to <2 x i64>
  %201 = bitcast <4 x i32> %199 to <2 x i64>
  %202 = shufflevector <2 x i64> %200, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %203 = shufflevector <2 x i64> %201, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %204 = shufflevector <4 x i64> %202, <4 x i64> %203, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %205 = bitcast <4 x i64> %204 to <4 x double>
  %206 = fmul <4 x double> %160, %205
  %207 = sub <4 x i32> %191, %192
  %208 = add <4 x i32> %207, <i32 1023, i32 1023, i32 1023, i32 1023>
  %209 = shufflevector <4 x i32> %208, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %210 = shufflevector <4 x i32> %208, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %211 = and <4 x i32> %209, <i32 0, i32 -1, i32 0, i32 -1>
  %212 = shl <4 x i32> %211, <i32 20, i32 20, i32 20, i32 20>
  %213 = and <4 x i32> %210, <i32 0, i32 -1, i32 0, i32 -1>
  %214 = shl <4 x i32> %213, <i32 20, i32 20, i32 20, i32 20>
  %215 = bitcast <4 x i32> %212 to <2 x i64>
  %216 = bitcast <4 x i32> %214 to <2 x i64>
  %217 = shufflevector <2 x i64> %215, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %218 = shufflevector <2 x i64> %216, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %219 = shufflevector <4 x i64> %217, <4 x i64> %218, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %220 = bitcast <4 x i64> %219 to <4 x double>
  %221 = fmul <4 x double> %206, %220
  %222 = fmul <4 x double> %166, %205
  %223 = fmul <4 x double> %222, %220
  %224 = fadd <4 x double> %221, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %225 = fsub <4 x double> %224, %221
  %226 = fsub <4 x double> %224, %225
  %227 = fsub <4 x double> %221, %226
  %228 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %225
  %229 = fadd <4 x double> %228, %227
  %230 = fadd <4 x double> %223, %229
  %231 = fadd <4 x double> %221, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %232 = fsub <4 x double> %231, %221
  %233 = fsub <4 x double> %231, %232
  %234 = fsub <4 x double> %221, %233
  %235 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %232
  %236 = fadd <4 x double> %235, %234
  %237 = fadd <4 x double> %223, %236
  %238 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %231
  %239 = bitcast <4 x double> %231 to <4 x i64>
  %240 = and <4 x i64> %239, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %241 = bitcast <4 x i64> %240 to <4 x double>
  %242 = fsub <4 x double> %231, %241
  %243 = bitcast <4 x double> %238 to <4 x i64>
  %244 = and <4 x i64> %243, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %245 = bitcast <4 x i64> %244 to <4 x double>
  %246 = fsub <4 x double> %238, %245
  %247 = bitcast <4 x double> %224 to <4 x i64>
  %248 = and <4 x i64> %247, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %249 = bitcast <4 x i64> %248 to <4 x double>
  %250 = fsub <4 x double> %224, %249
  %251 = fmul <4 x double> %224, %238
  %252 = fmul <4 x double> %249, %245
  %253 = fsub <4 x double> %252, %251
  %254 = fmul <4 x double> %246, %249
  %255 = fmul <4 x double> %250, %245
  %256 = fmul <4 x double> %250, %246
  %257 = fmul <4 x double> %241, %245
  %258 = fmul <4 x double> %246, %241
  %259 = fmul <4 x double> %242, %245
  %260 = fmul <4 x double> %242, %246
  %261 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %257
  %262 = fsub <4 x double> %261, %258
  %263 = fsub <4 x double> %262, %259
  %264 = fsub <4 x double> %263, %260
  %265 = fmul <4 x double> %251, %264
  %266 = fadd <4 x double> %253, %254
  %267 = fadd <4 x double> %255, %266
  %268 = fadd <4 x double> %256, %267
  %269 = fadd <4 x double> %268, %265
  %270 = fmul <4 x double> %251, %237
  %271 = fsub <4 x double> %230, %270
  %272 = fmul <4 x double> %238, %271
  %273 = fadd <4 x double> %272, %269
  %274 = bitcast <4 x double> %251 to <4 x i64>
  %275 = and <4 x i64> %274, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %276 = bitcast <4 x i64> %275 to <4 x double>
  %277 = fsub <4 x double> %251, %276
  %278 = fmul <4 x double> %251, %251
  %279 = fmul <4 x double> %276, %276
  %280 = bitcast <4 x double> %278 to <4 x i64>
  %281 = xor <4 x i64> %280, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %282 = bitcast <4 x i64> %281 to <4 x double>
  %283 = fadd <4 x double> %276, %276
  %284 = fmul <4 x double> %283, %277
  %285 = fmul <4 x double> %277, %277
  %286 = fadd <4 x double> %273, %273
  %287 = fmul <4 x double> %251, %286
  %288 = fadd <4 x double> %279, %282
  %289 = fadd <4 x double> %288, %284
  %290 = fadd <4 x double> %285, %289
  %291 = fadd <4 x double> %290, %287
  %292 = fmul <4 x double> %278, %278
  %293 = fmul <4 x double> %292, %292
  %294 = fmul <4 x double> %278, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %295 = fadd <4 x double> %294, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %296 = fmul <4 x double> %292, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %297 = fadd <4 x double> %296, %295
  %298 = fmul <4 x double> %278, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %299 = fadd <4 x double> %298, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %300 = fmul <4 x double> %278, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %301 = fadd <4 x double> %300, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %302 = fmul <4 x double> %292, %299
  %303 = fadd <4 x double> %301, %302
  %304 = fmul <4 x double> %293, %297
  %305 = fadd <4 x double> %304, %303
  %306 = fmul <4 x double> %278, %305
  %307 = fadd <4 x double> %306, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %308 = sitofp <4 x i32> %190 to <4 x double>
  %309 = bitcast <4 x double> %308 to <4 x i64>
  %310 = and <4 x i64> %309, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %311 = bitcast <4 x i64> %310 to <4 x double>
  %312 = fsub <4 x double> %308, %311
  %313 = fmul <4 x double> %308, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %314 = fmul <4 x double> %311, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %315 = bitcast <4 x double> %313 to <4 x i64>
  %316 = xor <4 x i64> %315, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %317 = bitcast <4 x i64> %316 to <4 x double>
  %318 = fmul <4 x double> %311, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %319 = fmul <4 x double> %312, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %320 = fmul <4 x double> %312, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %321 = fmul <4 x double> %308, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %322 = fadd <4 x double> %314, %317
  %323 = fadd <4 x double> %318, %322
  %324 = fadd <4 x double> %319, %323
  %325 = fadd <4 x double> %320, %324
  %326 = fadd <4 x double> %321, %325
  %327 = fmul <4 x double> %251, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %328 = fmul <4 x double> %273, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %329 = fadd <4 x double> %313, %327
  %330 = fsub <4 x double> %313, %329
  %331 = fadd <4 x double> %327, %330
  %332 = fadd <4 x double> %326, %331
  %333 = fadd <4 x double> %332, %328
  %334 = and <4 x i64> %280, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %335 = bitcast <4 x i64> %334 to <4 x double>
  %336 = fsub <4 x double> %278, %335
  %337 = fmul <4 x double> %251, %278
  %338 = fmul <4 x double> %276, %335
  %339 = bitcast <4 x double> %337 to <4 x i64>
  %340 = xor <4 x i64> %339, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %341 = bitcast <4 x i64> %340 to <4 x double>
  %342 = fmul <4 x double> %336, %276
  %343 = fmul <4 x double> %277, %335
  %344 = fmul <4 x double> %277, %336
  %345 = fmul <4 x double> %278, %273
  %346 = fmul <4 x double> %251, %291
  %347 = fadd <4 x double> %338, %341
  %348 = fadd <4 x double> %342, %347
  %349 = fadd <4 x double> %343, %348
  %350 = fadd <4 x double> %344, %349
  %351 = fadd <4 x double> %350, %345
  %352 = fadd <4 x double> %351, %346
  %353 = and <4 x i64> %339, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %354 = bitcast <4 x i64> %353 to <4 x double>
  %355 = fsub <4 x double> %337, %354
  %356 = bitcast <4 x double> %307 to <4 x i64>
  %357 = and <4 x i64> %356, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %358 = bitcast <4 x i64> %357 to <4 x double>
  %359 = fsub <4 x double> %307, %358
  %360 = fmul <4 x double> %337, %307
  %361 = fmul <4 x double> %354, %358
  %362 = bitcast <4 x double> %360 to <4 x i64>
  %363 = xor <4 x i64> %362, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %364 = bitcast <4 x i64> %363 to <4 x double>
  %365 = fmul <4 x double> %355, %358
  %366 = fmul <4 x double> %359, %354
  %367 = fmul <4 x double> %355, %359
  %368 = fmul <4 x double> %307, %352
  %369 = fadd <4 x double> %361, %364
  %370 = fadd <4 x double> %365, %369
  %371 = fadd <4 x double> %366, %370
  %372 = fadd <4 x double> %367, %371
  %373 = fadd <4 x double> %368, %372
  %374 = fadd <4 x double> %329, %360
  %375 = fsub <4 x double> %329, %374
  %376 = fadd <4 x double> %360, %375
  %377 = fadd <4 x double> %376, %333
  %378 = fadd <4 x double> %377, %373
  %379 = fadd <4 x double> %374, %378
  %380 = bitcast <4 x double> %0 to <4 x i64>
  %381 = and <4 x i64> %380, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %382 = bitcast <4 x i64> %381 to <4 x double>
  %383 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %382, <4 x double> <double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF>, i8 30) #6
  %384 = fcmp uno <4 x double> %379, zeroinitializer
  %385 = select <4 x i1> %384, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %383
  %386 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %379, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %385) #6
  %387 = fcmp une <4 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %388 = bitcast <4 x double> %386 to <4 x i64>
  %389 = select <4 x i1> %387, <4 x i64> %388, <4 x i64> zeroinitializer
  %390 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i8 17) #6
  %391 = bitcast <4 x double> %390 to <4 x i64>
  %392 = or <4 x i64> %389, %391
  %393 = fcmp uno <4 x double> %0, zeroinitializer
  %394 = bitcast <4 x i64> %392 to <4 x double>
  %395 = select <4 x i1> %393, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %394
  ret <4 x double> %395
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_atanhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fadd <4 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %6 = fadd <4 x double> %5, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %7 = fsub <4 x double> %5, %6
  %8 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %7
  %9 = fsub <4 x double> %4, %6
  %10 = fadd <4 x double> %9, %8
  %11 = or <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %12 = bitcast <4 x i64> %11 to <4 x double>
  %13 = fadd <4 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = fadd <4 x double> %13, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %15 = fsub <4 x double> %13, %14
  %16 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %15
  %17 = fsub <4 x double> %12, %14
  %18 = fadd <4 x double> %17, %16
  %19 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %20 = bitcast <4 x double> %13 to <4 x i64>
  %21 = and <4 x i64> %20, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = fsub <4 x double> %13, %22
  %24 = bitcast <4 x double> %19 to <4 x i64>
  %25 = and <4 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <4 x i64> %25 to <4 x double>
  %27 = fsub <4 x double> %19, %26
  %28 = bitcast <4 x double> %5 to <4 x i64>
  %29 = and <4 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <4 x i64> %29 to <4 x double>
  %31 = fsub <4 x double> %5, %30
  %32 = fmul <4 x double> %5, %19
  %33 = fmul <4 x double> %30, %26
  %34 = fsub <4 x double> %33, %32
  %35 = fmul <4 x double> %27, %30
  %36 = fmul <4 x double> %31, %26
  %37 = fmul <4 x double> %31, %27
  %38 = fmul <4 x double> %22, %26
  %39 = fmul <4 x double> %27, %22
  %40 = fmul <4 x double> %23, %26
  %41 = fmul <4 x double> %23, %27
  %42 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %38
  %43 = fsub <4 x double> %42, %39
  %44 = fsub <4 x double> %43, %40
  %45 = fsub <4 x double> %44, %41
  %46 = fmul <4 x double> %32, %45
  %47 = fadd <4 x double> %34, %35
  %48 = fadd <4 x double> %36, %47
  %49 = fadd <4 x double> %37, %48
  %50 = fadd <4 x double> %49, %46
  %51 = fmul <4 x double> %32, %18
  %52 = fsub <4 x double> %10, %51
  %53 = fmul <4 x double> %19, %52
  %54 = fadd <4 x double> %53, %50
  %55 = fmul <4 x double> %32, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %56 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %55, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %57 = bitcast <4 x double> %56 to <4 x i64>
  %58 = fmul <4 x double> %55, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %59 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %55, <4 x double> %58, <4 x double> %56) #6
  %60 = bitcast <4 x double> %59 to <4 x i64>
  %61 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %62 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %63 = bitcast <2 x i64> %61 to <4 x i32>
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %65 = bitcast <4 x i32> %64 to <2 x i64>
  %66 = bitcast <2 x i64> %62 to <4 x i32>
  %67 = shufflevector <4 x i32> %66, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %68 = bitcast <4 x i32> %67 to <2 x i64>
  %69 = shufflevector <2 x i64> %68, <2 x i64> %65, <2 x i32> <i32 2, i32 1>
  %70 = bitcast <2 x i64> %69 to <4 x i32>
  %71 = lshr <4 x i32> %70, <i32 20, i32 20, i32 20, i32 20>
  %72 = and <4 x i64> %57, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %73 = bitcast <4 x i64> %72 to <4 x double>
  %74 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %73) #6
  %75 = bitcast <4 x i32> %74 to <16 x i8>
  %76 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %75) #6
  %77 = bitcast <16 x i8> %76 to <4 x i32>
  %78 = sub <4 x i32> %71, %77
  %79 = sub <4 x i32> zeroinitializer, %78
  %80 = ashr <4 x i32> %79, <i32 1, i32 1, i32 1, i32 1>
  %81 = add nsw <4 x i32> %80, <i32 1023, i32 1023, i32 1023, i32 1023>
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %83 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %84 = and <4 x i32> %82, <i32 0, i32 -1, i32 0, i32 -1>
  %85 = shl <4 x i32> %84, <i32 20, i32 20, i32 20, i32 20>
  %86 = and <4 x i32> %83, <i32 0, i32 -1, i32 0, i32 -1>
  %87 = shl <4 x i32> %86, <i32 20, i32 20, i32 20, i32 20>
  %88 = bitcast <4 x i32> %85 to <2 x i64>
  %89 = bitcast <4 x i32> %87 to <2 x i64>
  %90 = shufflevector <2 x i64> %88, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %92 = shufflevector <4 x i64> %90, <4 x i64> %91, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %93 = bitcast <4 x i64> %92 to <4 x double>
  %94 = fmul <4 x double> %32, %93
  %95 = sub <4 x i32> %79, %80
  %96 = add <4 x i32> %95, <i32 1023, i32 1023, i32 1023, i32 1023>
  %97 = shufflevector <4 x i32> %96, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %98 = shufflevector <4 x i32> %96, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %99 = and <4 x i32> %97, <i32 0, i32 -1, i32 0, i32 -1>
  %100 = shl <4 x i32> %99, <i32 20, i32 20, i32 20, i32 20>
  %101 = and <4 x i32> %98, <i32 0, i32 -1, i32 0, i32 -1>
  %102 = shl <4 x i32> %101, <i32 20, i32 20, i32 20, i32 20>
  %103 = bitcast <4 x i32> %100 to <2 x i64>
  %104 = bitcast <4 x i32> %102 to <2 x i64>
  %105 = shufflevector <2 x i64> %103, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %106 = shufflevector <2 x i64> %104, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %107 = shufflevector <4 x i64> %105, <4 x i64> %106, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %108 = bitcast <4 x i64> %107 to <4 x double>
  %109 = fmul <4 x double> %94, %108
  %110 = fmul <4 x double> %54, %93
  %111 = fmul <4 x double> %110, %108
  %112 = fadd <4 x double> %109, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %113 = fsub <4 x double> %112, %109
  %114 = fsub <4 x double> %112, %113
  %115 = fsub <4 x double> %109, %114
  %116 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %113
  %117 = fadd <4 x double> %116, %115
  %118 = fadd <4 x double> %111, %117
  %119 = fadd <4 x double> %109, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %120 = fsub <4 x double> %119, %109
  %121 = fsub <4 x double> %119, %120
  %122 = fsub <4 x double> %109, %121
  %123 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %120
  %124 = fadd <4 x double> %123, %122
  %125 = fadd <4 x double> %111, %124
  %126 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %119
  %127 = bitcast <4 x double> %119 to <4 x i64>
  %128 = and <4 x i64> %127, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %129 = bitcast <4 x i64> %128 to <4 x double>
  %130 = fsub <4 x double> %119, %129
  %131 = bitcast <4 x double> %126 to <4 x i64>
  %132 = and <4 x i64> %131, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %133 = bitcast <4 x i64> %132 to <4 x double>
  %134 = fsub <4 x double> %126, %133
  %135 = bitcast <4 x double> %112 to <4 x i64>
  %136 = and <4 x i64> %135, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %137 = bitcast <4 x i64> %136 to <4 x double>
  %138 = fsub <4 x double> %112, %137
  %139 = fmul <4 x double> %112, %126
  %140 = fmul <4 x double> %137, %133
  %141 = fsub <4 x double> %140, %139
  %142 = fmul <4 x double> %134, %137
  %143 = fmul <4 x double> %138, %133
  %144 = fmul <4 x double> %138, %134
  %145 = fmul <4 x double> %129, %133
  %146 = fmul <4 x double> %134, %129
  %147 = fmul <4 x double> %130, %133
  %148 = fmul <4 x double> %130, %134
  %149 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %145
  %150 = fsub <4 x double> %149, %146
  %151 = fsub <4 x double> %150, %147
  %152 = fsub <4 x double> %151, %148
  %153 = fmul <4 x double> %139, %152
  %154 = fadd <4 x double> %141, %142
  %155 = fadd <4 x double> %143, %154
  %156 = fadd <4 x double> %144, %155
  %157 = fadd <4 x double> %156, %153
  %158 = fmul <4 x double> %139, %125
  %159 = fsub <4 x double> %118, %158
  %160 = fmul <4 x double> %126, %159
  %161 = fadd <4 x double> %160, %157
  %162 = bitcast <4 x double> %139 to <4 x i64>
  %163 = and <4 x i64> %162, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %164 = bitcast <4 x i64> %163 to <4 x double>
  %165 = fsub <4 x double> %139, %164
  %166 = fmul <4 x double> %139, %139
  %167 = fmul <4 x double> %164, %164
  %168 = bitcast <4 x double> %166 to <4 x i64>
  %169 = xor <4 x i64> %168, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %170 = bitcast <4 x i64> %169 to <4 x double>
  %171 = fadd <4 x double> %164, %164
  %172 = fmul <4 x double> %171, %165
  %173 = fmul <4 x double> %165, %165
  %174 = fadd <4 x double> %161, %161
  %175 = fmul <4 x double> %139, %174
  %176 = fadd <4 x double> %167, %170
  %177 = fadd <4 x double> %176, %172
  %178 = fadd <4 x double> %173, %177
  %179 = fadd <4 x double> %178, %175
  %180 = fmul <4 x double> %166, %166
  %181 = fmul <4 x double> %180, %180
  %182 = fmul <4 x double> %166, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %183 = fadd <4 x double> %182, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %184 = fmul <4 x double> %180, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %185 = fadd <4 x double> %184, %183
  %186 = fmul <4 x double> %166, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %187 = fadd <4 x double> %186, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %188 = fmul <4 x double> %166, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %189 = fadd <4 x double> %188, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %190 = fmul <4 x double> %180, %187
  %191 = fadd <4 x double> %189, %190
  %192 = fmul <4 x double> %181, %185
  %193 = fadd <4 x double> %192, %191
  %194 = fmul <4 x double> %166, %193
  %195 = fadd <4 x double> %194, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %196 = sitofp <4 x i32> %78 to <4 x double>
  %197 = bitcast <4 x double> %196 to <4 x i64>
  %198 = and <4 x i64> %197, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %199 = bitcast <4 x i64> %198 to <4 x double>
  %200 = fsub <4 x double> %196, %199
  %201 = fmul <4 x double> %196, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %202 = fmul <4 x double> %199, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %203 = bitcast <4 x double> %201 to <4 x i64>
  %204 = xor <4 x i64> %203, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %205 = bitcast <4 x i64> %204 to <4 x double>
  %206 = fmul <4 x double> %199, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %207 = fmul <4 x double> %200, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %208 = fmul <4 x double> %200, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %209 = fmul <4 x double> %196, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %210 = fadd <4 x double> %202, %205
  %211 = fadd <4 x double> %206, %210
  %212 = fadd <4 x double> %207, %211
  %213 = fadd <4 x double> %208, %212
  %214 = fadd <4 x double> %209, %213
  %215 = fmul <4 x double> %139, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %216 = fmul <4 x double> %161, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %217 = fadd <4 x double> %201, %215
  %218 = fsub <4 x double> %201, %217
  %219 = fadd <4 x double> %215, %218
  %220 = fadd <4 x double> %214, %219
  %221 = fadd <4 x double> %220, %216
  %222 = and <4 x i64> %168, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %223 = bitcast <4 x i64> %222 to <4 x double>
  %224 = fsub <4 x double> %166, %223
  %225 = fmul <4 x double> %139, %166
  %226 = fmul <4 x double> %164, %223
  %227 = bitcast <4 x double> %225 to <4 x i64>
  %228 = xor <4 x i64> %227, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %229 = bitcast <4 x i64> %228 to <4 x double>
  %230 = fmul <4 x double> %224, %164
  %231 = fmul <4 x double> %165, %223
  %232 = fmul <4 x double> %165, %224
  %233 = fmul <4 x double> %166, %161
  %234 = fmul <4 x double> %139, %179
  %235 = fadd <4 x double> %226, %229
  %236 = fadd <4 x double> %230, %235
  %237 = fadd <4 x double> %231, %236
  %238 = fadd <4 x double> %232, %237
  %239 = fadd <4 x double> %238, %233
  %240 = fadd <4 x double> %239, %234
  %241 = and <4 x i64> %227, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %242 = bitcast <4 x i64> %241 to <4 x double>
  %243 = fsub <4 x double> %225, %242
  %244 = bitcast <4 x double> %195 to <4 x i64>
  %245 = and <4 x i64> %244, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %246 = bitcast <4 x i64> %245 to <4 x double>
  %247 = fsub <4 x double> %195, %246
  %248 = fmul <4 x double> %225, %195
  %249 = fmul <4 x double> %242, %246
  %250 = bitcast <4 x double> %248 to <4 x i64>
  %251 = xor <4 x i64> %250, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %252 = bitcast <4 x i64> %251 to <4 x double>
  %253 = fmul <4 x double> %243, %246
  %254 = fmul <4 x double> %247, %242
  %255 = fmul <4 x double> %243, %247
  %256 = fmul <4 x double> %195, %240
  %257 = fadd <4 x double> %249, %252
  %258 = fadd <4 x double> %253, %257
  %259 = fadd <4 x double> %254, %258
  %260 = fadd <4 x double> %255, %259
  %261 = fadd <4 x double> %256, %260
  %262 = fadd <4 x double> %217, %248
  %263 = fsub <4 x double> %217, %262
  %264 = fadd <4 x double> %248, %263
  %265 = fadd <4 x double> %264, %221
  %266 = fadd <4 x double> %265, %261
  %267 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i8 30) #6
  %268 = bitcast <4 x double> %267 to <4 x i64>
  %269 = fcmp oeq <4 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %270 = sext <4 x i1> %269 to <4 x i64>
  %271 = fadd <4 x double> %262, %266
  %272 = fmul <4 x double> %271, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %273 = bitcast <4 x i64> %270 to <4 x double>
  %274 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %272, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %273) #6
  %275 = bitcast <4 x double> %274 to <4 x i64>
  %276 = or <4 x i64> %275, %268
  %277 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %278 = xor <4 x i64> %276, %277
  %279 = bitcast <4 x i64> %278 to <4 x double>
  %280 = fcmp oeq <4 x double> %4, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %281 = fcmp uno <4 x double> %279, zeroinitializer
  %282 = fcmp uno <4 x double> %0, zeroinitializer
  %283 = or <4 x i1> %280, %282
  %284 = or <4 x i1> %283, %281
  %285 = select <4 x i1> %284, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %279
  ret <4 x double> %285
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cbrtd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %4, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %8 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %7, <4 x double> %5) #6
  %9 = bitcast <4 x double> %8 to <4 x i64>
  %10 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %11 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %12 = bitcast <2 x i64> %10 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = bitcast <2 x i64> %11 to <4 x i32>
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %17, <2 x i64> %14, <2 x i32> <i32 2, i32 1>
  %19 = bitcast <2 x i64> %18 to <4 x i32>
  %20 = lshr <4 x i32> %19, <i32 20, i32 20, i32 20, i32 20>
  %21 = and <4 x i64> %6, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %22) #6
  %24 = bitcast <4 x i32> %23 to <16 x i8>
  %25 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %24) #6
  %26 = bitcast <16 x i8> %25 to <4 x i32>
  %27 = sub <4 x i32> %20, %26
  %28 = add <4 x i32> %27, <i32 1, i32 1, i32 1, i32 1>
  %29 = xor <4 x i32> %27, <i32 -1, i32 -1, i32 -1, i32 -1>
  %30 = ashr <4 x i32> %29, <i32 1, i32 1, i32 1, i32 1>
  %31 = add nsw <4 x i32> %30, <i32 1023, i32 1023, i32 1023, i32 1023>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %33 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %34 = and <4 x i32> %32, <i32 0, i32 -1, i32 0, i32 -1>
  %35 = shl <4 x i32> %34, <i32 20, i32 20, i32 20, i32 20>
  %36 = and <4 x i32> %33, <i32 0, i32 -1, i32 0, i32 -1>
  %37 = shl <4 x i32> %36, <i32 20, i32 20, i32 20, i32 20>
  %38 = bitcast <4 x i32> %35 to <2 x i64>
  %39 = bitcast <4 x i32> %37 to <2 x i64>
  %40 = shufflevector <2 x i64> %38, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %41 = shufflevector <2 x i64> %39, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %42 = shufflevector <4 x i64> %40, <4 x i64> %41, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %43 = bitcast <4 x i64> %42 to <4 x double>
  %44 = fmul <4 x double> %43, %0
  %45 = sub <4 x i32> %29, %30
  %46 = add <4 x i32> %45, <i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %48 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %49 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = and <4 x i32> %48, <i32 0, i32 -1, i32 0, i32 -1>
  %52 = shl <4 x i32> %51, <i32 20, i32 20, i32 20, i32 20>
  %53 = bitcast <4 x i32> %50 to <2 x i64>
  %54 = bitcast <4 x i32> %52 to <2 x i64>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <2 x i64> %54, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %57 = shufflevector <4 x i64> %55, <4 x i64> %56, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %44, %58
  %60 = sitofp <4 x i32> %28 to <4 x double>
  %61 = fadd <4 x double> %60, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %62 = fmul <4 x double> %61, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %63 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %62) #6
  %64 = sitofp <4 x i32> %63 to <4 x double>
  %65 = fmul <4 x double> %64, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %66 = fsub <4 x double> %61, %65
  %67 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %66) #6
  %68 = icmp eq <4 x i32> %67, <i32 1, i32 1, i32 1, i32 1>
  %69 = sitofp <4 x i1> %68 to <4 x double>
  %70 = fcmp oeq <4 x double> %69, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %71 = sext <4 x i1> %70 to <4 x i64>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B>, <4 x double> %72) #6
  %74 = icmp eq <4 x i32> %67, <i32 2, i32 2, i32 2, i32 2>
  %75 = sitofp <4 x i1> %74 to <4 x double>
  %76 = fcmp oeq <4 x double> %75, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %77 = sext <4 x i1> %76 to <4 x i64>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %73, <4 x double> <double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D>, <4 x double> %78) #6
  %80 = add <4 x i32> %63, <i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %81 = ashr <4 x i32> %80, <i32 1, i32 1, i32 1, i32 1>
  %82 = add nsw <4 x i32> %81, <i32 1023, i32 1023, i32 1023, i32 1023>
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %84 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %85 = and <4 x i32> %83, <i32 0, i32 -1, i32 0, i32 -1>
  %86 = shl <4 x i32> %85, <i32 20, i32 20, i32 20, i32 20>
  %87 = and <4 x i32> %84, <i32 0, i32 -1, i32 0, i32 -1>
  %88 = shl <4 x i32> %87, <i32 20, i32 20, i32 20, i32 20>
  %89 = bitcast <4 x i32> %86 to <2 x i64>
  %90 = bitcast <4 x i32> %88 to <2 x i64>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %92 = shufflevector <2 x i64> %90, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %93 = shufflevector <4 x i64> %91, <4 x i64> %92, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %94 = bitcast <4 x i64> %93 to <4 x double>
  %95 = fmul <4 x double> %79, %94
  %96 = sub <4 x i32> %80, %81
  %97 = add <4 x i32> %96, <i32 1023, i32 1023, i32 1023, i32 1023>
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %99 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %100 = and <4 x i32> %98, <i32 0, i32 -1, i32 0, i32 -1>
  %101 = shl <4 x i32> %100, <i32 20, i32 20, i32 20, i32 20>
  %102 = and <4 x i32> %99, <i32 0, i32 -1, i32 0, i32 -1>
  %103 = shl <4 x i32> %102, <i32 20, i32 20, i32 20, i32 20>
  %104 = bitcast <4 x i32> %101 to <2 x i64>
  %105 = bitcast <4 x i32> %103 to <2 x i64>
  %106 = shufflevector <2 x i64> %104, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %107 = shufflevector <2 x i64> %105, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %108 = shufflevector <4 x i64> %106, <4 x i64> %107, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %109 = bitcast <4 x i64> %108 to <4 x double>
  %110 = fmul <4 x double> %95, %109
  %111 = bitcast <4 x double> %110 to <4 x i64>
  %112 = bitcast <4 x double> %59 to <4 x i64>
  %113 = and <4 x i64> %112, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %114 = xor <4 x i64> %113, %111
  %115 = bitcast <4 x i64> %114 to <4 x double>
  %116 = and <4 x i64> %112, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %117 = bitcast <4 x i64> %116 to <4 x double>
  %118 = fmul <4 x double> %117, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %119 = fadd <4 x double> %118, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %120 = fmul <4 x double> %119, %117
  %121 = fadd <4 x double> %120, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %122 = fmul <4 x double> %121, %117
  %123 = fadd <4 x double> %122, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %124 = fmul <4 x double> %123, %117
  %125 = fadd <4 x double> %124, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %126 = fmul <4 x double> %125, %117
  %127 = fadd <4 x double> %126, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %128 = fmul <4 x double> %127, %127
  %129 = fmul <4 x double> %128, %128
  %130 = fmul <4 x double> %129, %117
  %131 = fsub <4 x double> %130, %127
  %132 = fmul <4 x double> %131, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %133 = fsub <4 x double> %127, %132
  %134 = fmul <4 x double> %133, %117
  %135 = fmul <4 x double> %133, %134
  %136 = fmul <4 x double> %135, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %137 = fmul <4 x double> %133, %135
  %138 = fadd <4 x double> %137, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %139 = fmul <4 x double> %136, %138
  %140 = fsub <4 x double> %135, %139
  %141 = fmul <4 x double> %140, %115
  ret <4 x double> %141
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cbrtd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %4, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %8 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %7, <4 x double> %5) #6
  %9 = bitcast <4 x double> %8 to <4 x i64>
  %10 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %11 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %12 = bitcast <2 x i64> %10 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = bitcast <2 x i64> %11 to <4 x i32>
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %17, <2 x i64> %14, <2 x i32> <i32 2, i32 1>
  %19 = bitcast <2 x i64> %18 to <4 x i32>
  %20 = lshr <4 x i32> %19, <i32 20, i32 20, i32 20, i32 20>
  %21 = and <4 x i64> %6, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %22) #6
  %24 = bitcast <4 x i32> %23 to <16 x i8>
  %25 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %24) #6
  %26 = bitcast <16 x i8> %25 to <4 x i32>
  %27 = sub <4 x i32> %20, %26
  %28 = add <4 x i32> %27, <i32 1, i32 1, i32 1, i32 1>
  %29 = xor <4 x i32> %27, <i32 -1, i32 -1, i32 -1, i32 -1>
  %30 = ashr <4 x i32> %29, <i32 1, i32 1, i32 1, i32 1>
  %31 = add nsw <4 x i32> %30, <i32 1023, i32 1023, i32 1023, i32 1023>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %33 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %34 = and <4 x i32> %32, <i32 0, i32 -1, i32 0, i32 -1>
  %35 = shl <4 x i32> %34, <i32 20, i32 20, i32 20, i32 20>
  %36 = and <4 x i32> %33, <i32 0, i32 -1, i32 0, i32 -1>
  %37 = shl <4 x i32> %36, <i32 20, i32 20, i32 20, i32 20>
  %38 = bitcast <4 x i32> %35 to <2 x i64>
  %39 = bitcast <4 x i32> %37 to <2 x i64>
  %40 = shufflevector <2 x i64> %38, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %41 = shufflevector <2 x i64> %39, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %42 = shufflevector <4 x i64> %40, <4 x i64> %41, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %43 = bitcast <4 x i64> %42 to <4 x double>
  %44 = fmul <4 x double> %43, %0
  %45 = sub <4 x i32> %29, %30
  %46 = add <4 x i32> %45, <i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %48 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %49 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = and <4 x i32> %48, <i32 0, i32 -1, i32 0, i32 -1>
  %52 = shl <4 x i32> %51, <i32 20, i32 20, i32 20, i32 20>
  %53 = bitcast <4 x i32> %50 to <2 x i64>
  %54 = bitcast <4 x i32> %52 to <2 x i64>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <2 x i64> %54, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %57 = shufflevector <4 x i64> %55, <4 x i64> %56, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %44, %58
  %60 = sitofp <4 x i32> %28 to <4 x double>
  %61 = fadd <4 x double> %60, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %62 = fmul <4 x double> %61, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %63 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %62) #6
  %64 = sitofp <4 x i32> %63 to <4 x double>
  %65 = fmul <4 x double> %64, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %66 = fsub <4 x double> %61, %65
  %67 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %66) #6
  %68 = icmp eq <4 x i32> %67, <i32 1, i32 1, i32 1, i32 1>
  %69 = sitofp <4 x i1> %68 to <4 x double>
  %70 = fcmp oeq <4 x double> %69, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %71 = sext <4 x i1> %70 to <4 x i64>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B>, <4 x double> %72) #6
  %74 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> <double 0xBC7DDC22548EA41E, double 0xBC7DDC22548EA41E, double 0xBC7DDC22548EA41E, double 0xBC7DDC22548EA41E>, <4 x double> %72) #6
  %75 = icmp eq <4 x i32> %67, <i32 2, i32 2, i32 2, i32 2>
  %76 = sitofp <4 x i1> %75 to <4 x double>
  %77 = fcmp oeq <4 x double> %76, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %78 = sext <4 x i1> %77 to <4 x i64>
  %79 = bitcast <4 x i64> %78 to <4 x double>
  %80 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %73, <4 x double> <double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D>, <4 x double> %79) #6
  %81 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %74, <4 x double> <double 0xBC9F53E999952F09, double 0xBC9F53E999952F09, double 0xBC9F53E999952F09, double 0xBC9F53E999952F09>, <4 x double> %79) #6
  %82 = bitcast <4 x double> %80 to <4 x i64>
  %83 = bitcast <4 x double> %59 to <4 x i64>
  %84 = and <4 x i64> %83, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %85 = xor <4 x i64> %84, %82
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = bitcast <4 x double> %81 to <4 x i64>
  %88 = xor <4 x i64> %84, %87
  %89 = bitcast <4 x i64> %88 to <4 x double>
  %90 = and <4 x i64> %83, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %91 = bitcast <4 x i64> %90 to <4 x double>
  %92 = fmul <4 x double> %91, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %93 = fadd <4 x double> %92, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %94 = fmul <4 x double> %93, %91
  %95 = fadd <4 x double> %94, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %96 = fmul <4 x double> %95, %91
  %97 = fadd <4 x double> %96, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %98 = fmul <4 x double> %97, %91
  %99 = fadd <4 x double> %98, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %100 = fmul <4 x double> %99, %91
  %101 = fadd <4 x double> %100, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %102 = fmul <4 x double> %101, %101
  %103 = fmul <4 x double> %102, %102
  %104 = fmul <4 x double> %103, %91
  %105 = fsub <4 x double> %104, %101
  %106 = fmul <4 x double> %105, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %107 = fsub <4 x double> %101, %106
  %108 = bitcast <4 x double> %107 to <4 x i64>
  %109 = and <4 x i64> %108, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %110 = bitcast <4 x i64> %109 to <4 x double>
  %111 = fsub <4 x double> %107, %110
  %112 = fmul <4 x double> %107, %107
  %113 = fmul <4 x double> %110, %110
  %114 = bitcast <4 x double> %112 to <4 x i64>
  %115 = xor <4 x i64> %114, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fmul <4 x double> %111, %110
  %118 = fmul <4 x double> %111, %111
  %119 = fadd <4 x double> %113, %116
  %120 = fadd <4 x double> %117, %119
  %121 = fadd <4 x double> %117, %120
  %122 = fadd <4 x double> %118, %121
  %123 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %124 = bitcast <4 x i64> %123 to <4 x double>
  %125 = fsub <4 x double> %112, %124
  %126 = fmul <4 x double> %112, %112
  %127 = fmul <4 x double> %124, %124
  %128 = bitcast <4 x double> %126 to <4 x i64>
  %129 = xor <4 x i64> %128, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %130 = bitcast <4 x i64> %129 to <4 x double>
  %131 = fmul <4 x double> %125, %124
  %132 = fmul <4 x double> %125, %125
  %133 = fmul <4 x double> %112, %122
  %134 = fadd <4 x double> %127, %130
  %135 = fadd <4 x double> %131, %134
  %136 = fadd <4 x double> %131, %135
  %137 = fadd <4 x double> %132, %136
  %138 = fadd <4 x double> %133, %137
  %139 = fadd <4 x double> %133, %138
  %140 = and <4 x i64> %128, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %141 = bitcast <4 x i64> %140 to <4 x double>
  %142 = fsub <4 x double> %126, %141
  %143 = and <4 x i64> %83, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = fsub <4 x double> %91, %144
  %146 = fmul <4 x double> %126, %91
  %147 = fmul <4 x double> %144, %141
  %148 = bitcast <4 x double> %146 to <4 x i64>
  %149 = xor <4 x i64> %148, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fmul <4 x double> %142, %144
  %152 = fmul <4 x double> %145, %141
  %153 = fmul <4 x double> %145, %142
  %154 = fmul <4 x double> %139, %91
  %155 = fadd <4 x double> %147, %150
  %156 = fadd <4 x double> %151, %155
  %157 = fadd <4 x double> %152, %156
  %158 = fadd <4 x double> %153, %157
  %159 = fadd <4 x double> %158, %154
  %160 = xor <4 x i64> %108, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %161 = bitcast <4 x i64> %160 to <4 x double>
  %162 = fadd <4 x double> %146, %161
  %163 = fsub <4 x double> %162, %146
  %164 = fsub <4 x double> %162, %163
  %165 = fsub <4 x double> %146, %164
  %166 = fsub <4 x double> %161, %163
  %167 = fadd <4 x double> %166, %165
  %168 = fadd <4 x double> %167, %159
  %169 = fadd <4 x double> %162, %168
  %170 = fmul <4 x double> %169, <double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555>
  %171 = fmul <4 x double> %107, %170
  %172 = fadd <4 x double> %112, %171
  %173 = fsub <4 x double> %172, %112
  %174 = fsub <4 x double> %172, %173
  %175 = fsub <4 x double> %112, %174
  %176 = fsub <4 x double> %171, %173
  %177 = fadd <4 x double> %176, %175
  %178 = fadd <4 x double> %122, %177
  %179 = bitcast <4 x double> %172 to <4 x i64>
  %180 = and <4 x i64> %179, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %181 = bitcast <4 x i64> %180 to <4 x double>
  %182 = fsub <4 x double> %172, %181
  %183 = fmul <4 x double> %172, %91
  %184 = fmul <4 x double> %144, %181
  %185 = bitcast <4 x double> %183 to <4 x i64>
  %186 = xor <4 x i64> %185, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %187 = bitcast <4 x i64> %186 to <4 x double>
  %188 = fmul <4 x double> %182, %144
  %189 = fmul <4 x double> %145, %181
  %190 = fmul <4 x double> %145, %182
  %191 = fmul <4 x double> %178, %91
  %192 = fadd <4 x double> %184, %187
  %193 = fadd <4 x double> %188, %192
  %194 = fadd <4 x double> %189, %193
  %195 = fadd <4 x double> %190, %194
  %196 = fadd <4 x double> %191, %195
  %197 = and <4 x i64> %185, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %198 = bitcast <4 x i64> %197 to <4 x double>
  %199 = fsub <4 x double> %183, %198
  %200 = and <4 x i64> %85, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %201 = bitcast <4 x i64> %200 to <4 x double>
  %202 = fsub <4 x double> %86, %201
  %203 = fmul <4 x double> %183, %86
  %204 = fmul <4 x double> %201, %198
  %205 = bitcast <4 x double> %203 to <4 x i64>
  %206 = xor <4 x i64> %205, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %207 = bitcast <4 x i64> %206 to <4 x double>
  %208 = fmul <4 x double> %199, %201
  %209 = fmul <4 x double> %202, %198
  %210 = fmul <4 x double> %202, %199
  %211 = fmul <4 x double> %183, %89
  %212 = fmul <4 x double> %196, %86
  %213 = fadd <4 x double> %204, %207
  %214 = fadd <4 x double> %208, %213
  %215 = fadd <4 x double> %209, %214
  %216 = fadd <4 x double> %210, %215
  %217 = fadd <4 x double> %211, %216
  %218 = fadd <4 x double> %212, %217
  %219 = fadd <4 x double> %203, %218
  %220 = add <4 x i32> %63, <i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %221 = ashr <4 x i32> %220, <i32 1, i32 1, i32 1, i32 1>
  %222 = add nsw <4 x i32> %221, <i32 1023, i32 1023, i32 1023, i32 1023>
  %223 = shufflevector <4 x i32> %222, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %224 = shufflevector <4 x i32> %222, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %225 = and <4 x i32> %223, <i32 0, i32 -1, i32 0, i32 -1>
  %226 = shl <4 x i32> %225, <i32 20, i32 20, i32 20, i32 20>
  %227 = and <4 x i32> %224, <i32 0, i32 -1, i32 0, i32 -1>
  %228 = shl <4 x i32> %227, <i32 20, i32 20, i32 20, i32 20>
  %229 = bitcast <4 x i32> %226 to <2 x i64>
  %230 = bitcast <4 x i32> %228 to <2 x i64>
  %231 = shufflevector <2 x i64> %229, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %232 = shufflevector <2 x i64> %230, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %233 = shufflevector <4 x i64> %231, <4 x i64> %232, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %234 = bitcast <4 x i64> %233 to <4 x double>
  %235 = fmul <4 x double> %219, %234
  %236 = sub <4 x i32> %220, %221
  %237 = add <4 x i32> %236, <i32 1023, i32 1023, i32 1023, i32 1023>
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %239 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %240 = and <4 x i32> %238, <i32 0, i32 -1, i32 0, i32 -1>
  %241 = shl <4 x i32> %240, <i32 20, i32 20, i32 20, i32 20>
  %242 = and <4 x i32> %239, <i32 0, i32 -1, i32 0, i32 -1>
  %243 = shl <4 x i32> %242, <i32 20, i32 20, i32 20, i32 20>
  %244 = bitcast <4 x i32> %241 to <2 x i64>
  %245 = bitcast <4 x i32> %243 to <2 x i64>
  %246 = shufflevector <2 x i64> %244, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %247 = shufflevector <2 x i64> %245, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %248 = shufflevector <4 x i64> %246, <4 x i64> %247, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %249 = bitcast <4 x i64> %248 to <4 x double>
  %250 = fmul <4 x double> %235, %249
  %251 = fcmp oeq <4 x double> %91, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %252 = sext <4 x i1> %251 to <4 x i64>
  %253 = and <4 x i64> %85, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %254 = or <4 x i64> %253, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %255 = bitcast <4 x i64> %254 to <4 x double>
  %256 = bitcast <4 x i64> %252 to <4 x double>
  %257 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %250, <4 x double> %255, <4 x double> %256) #6
  %258 = fcmp oeq <4 x double> %91, zeroinitializer
  %259 = sext <4 x i1> %258 to <4 x i64>
  %260 = bitcast <4 x i64> %253 to <4 x double>
  %261 = bitcast <4 x i64> %259 to <4 x double>
  %262 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %257, <4 x double> %260, <4 x double> %261) #6
  ret <4 x double> %262
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_exp2d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 8) #6
  %3 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %2) #6
  %4 = fsub <4 x double> %0, %2
  %5 = fmul <4 x double> %4, %4
  %6 = fmul <4 x double> %5, %5
  %7 = fmul <4 x double> %6, %6
  %8 = fmul <4 x double> %4, <double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150>
  %9 = fadd <4 x double> %8, <double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17>
  %10 = fmul <4 x double> %4, <double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979>
  %11 = fadd <4 x double> %10, <double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81>
  %12 = fmul <4 x double> %4, <double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80>
  %13 = fadd <4 x double> %12, <double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC>
  %14 = fmul <4 x double> %5, %11
  %15 = fadd <4 x double> %13, %14
  %16 = fmul <4 x double> %4, <double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960>
  %17 = fadd <4 x double> %16, <double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0>
  %18 = fmul <4 x double> %4, <double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F>
  %19 = fadd <4 x double> %18, <double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1>
  %20 = fmul <4 x double> %5, %17
  %21 = fadd <4 x double> %19, %20
  %22 = fmul <4 x double> %6, %15
  %23 = fadd <4 x double> %21, %22
  %24 = fmul <4 x double> %9, %7
  %25 = fadd <4 x double> %24, %23
  %26 = fmul <4 x double> %4, %25
  %27 = fadd <4 x double> %26, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %28 = bitcast <4 x double> %27 to <4 x i64>
  %29 = and <4 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <4 x i64> %29 to <4 x double>
  %31 = fsub <4 x double> %27, %30
  %32 = bitcast <4 x double> %4 to <4 x i64>
  %33 = and <4 x i64> %32, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %34 = bitcast <4 x i64> %33 to <4 x double>
  %35 = fsub <4 x double> %4, %34
  %36 = fmul <4 x double> %4, %27
  %37 = fmul <4 x double> %34, %30
  %38 = bitcast <4 x double> %36 to <4 x i64>
  %39 = xor <4 x i64> %38, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = fmul <4 x double> %31, %34
  %42 = fmul <4 x double> %35, %30
  %43 = fmul <4 x double> %35, %31
  %44 = fadd <4 x double> %37, %40
  %45 = fadd <4 x double> %41, %44
  %46 = fadd <4 x double> %42, %45
  %47 = fadd <4 x double> %43, %46
  %48 = fadd <4 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %49 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %48
  %50 = fadd <4 x double> %36, %49
  %51 = fadd <4 x double> %50, %47
  %52 = fadd <4 x double> %48, %51
  %53 = ashr <4 x i32> %3, <i32 1, i32 1, i32 1, i32 1>
  %54 = add nsw <4 x i32> %53, <i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %56 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %57 = and <4 x i32> %55, <i32 0, i32 -1, i32 0, i32 -1>
  %58 = shl <4 x i32> %57, <i32 20, i32 20, i32 20, i32 20>
  %59 = and <4 x i32> %56, <i32 0, i32 -1, i32 0, i32 -1>
  %60 = shl <4 x i32> %59, <i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <4 x i32> %58 to <2 x i64>
  %62 = bitcast <4 x i32> %60 to <2 x i64>
  %63 = shufflevector <2 x i64> %61, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %64 = shufflevector <2 x i64> %62, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %65 = shufflevector <4 x i64> %63, <4 x i64> %64, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %66 = bitcast <4 x i64> %65 to <4 x double>
  %67 = fmul <4 x double> %52, %66
  %68 = sub <4 x i32> %3, %53
  %69 = add <4 x i32> %68, <i32 1023, i32 1023, i32 1023, i32 1023>
  %70 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %71 = shufflevector <4 x i32> %69, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %72 = and <4 x i32> %70, <i32 0, i32 -1, i32 0, i32 -1>
  %73 = shl <4 x i32> %72, <i32 20, i32 20, i32 20, i32 20>
  %74 = and <4 x i32> %71, <i32 0, i32 -1, i32 0, i32 -1>
  %75 = shl <4 x i32> %74, <i32 20, i32 20, i32 20, i32 20>
  %76 = bitcast <4 x i32> %73 to <2 x i64>
  %77 = bitcast <4 x i32> %75 to <2 x i64>
  %78 = shufflevector <2 x i64> %76, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %79 = shufflevector <2 x i64> %77, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %80 = shufflevector <4 x i64> %78, <4 x i64> %79, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %81 = bitcast <4 x i64> %80 to <4 x double>
  %82 = fmul <4 x double> %67, %81
  %83 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, i8 29) #6
  %84 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %82, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %83) #6
  %85 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03>, i8 17) #6
  %86 = bitcast <4 x double> %85 to <4 x i64>
  %87 = bitcast <4 x double> %84 to <4 x i64>
  %88 = xor <4 x i64> %86, <i64 -1, i64 -1, i64 -1, i64 -1>
  %89 = and <4 x i64> %88, %87
  %90 = bitcast <4 x i64> %89 to <4 x double>
  ret <4 x double> %90
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_exp2d4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 8) #6
  %3 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %2) #6
  %4 = fsub <4 x double> %0, %2
  %5 = fmul <4 x double> %4, %4
  %6 = fmul <4 x double> %5, %5
  %7 = fmul <4 x double> %6, %6
  %8 = fmul <4 x double> %4, <double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150>
  %9 = fadd <4 x double> %8, <double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17>
  %10 = fmul <4 x double> %4, <double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979>
  %11 = fadd <4 x double> %10, <double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81>
  %12 = fmul <4 x double> %4, <double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80>
  %13 = fadd <4 x double> %12, <double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC>
  %14 = fmul <4 x double> %5, %11
  %15 = fadd <4 x double> %13, %14
  %16 = fmul <4 x double> %4, <double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960>
  %17 = fadd <4 x double> %16, <double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0>
  %18 = fmul <4 x double> %4, <double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F>
  %19 = fadd <4 x double> %18, <double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1>
  %20 = fmul <4 x double> %5, %17
  %21 = fadd <4 x double> %19, %20
  %22 = fmul <4 x double> %6, %15
  %23 = fadd <4 x double> %21, %22
  %24 = fmul <4 x double> %9, %7
  %25 = fadd <4 x double> %24, %23
  %26 = fmul <4 x double> %4, %25
  %27 = fadd <4 x double> %26, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %28 = fmul <4 x double> %4, %27
  %29 = fadd <4 x double> %28, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %30 = ashr <4 x i32> %3, <i32 1, i32 1, i32 1, i32 1>
  %31 = add nsw <4 x i32> %30, <i32 1023, i32 1023, i32 1023, i32 1023>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %33 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %34 = and <4 x i32> %32, <i32 0, i32 -1, i32 0, i32 -1>
  %35 = shl <4 x i32> %34, <i32 20, i32 20, i32 20, i32 20>
  %36 = and <4 x i32> %33, <i32 0, i32 -1, i32 0, i32 -1>
  %37 = shl <4 x i32> %36, <i32 20, i32 20, i32 20, i32 20>
  %38 = bitcast <4 x i32> %35 to <2 x i64>
  %39 = bitcast <4 x i32> %37 to <2 x i64>
  %40 = shufflevector <2 x i64> %38, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %41 = shufflevector <2 x i64> %39, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %42 = shufflevector <4 x i64> %40, <4 x i64> %41, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %43 = bitcast <4 x i64> %42 to <4 x double>
  %44 = fmul <4 x double> %29, %43
  %45 = sub <4 x i32> %3, %30
  %46 = add <4 x i32> %45, <i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %48 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %49 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = and <4 x i32> %48, <i32 0, i32 -1, i32 0, i32 -1>
  %52 = shl <4 x i32> %51, <i32 20, i32 20, i32 20, i32 20>
  %53 = bitcast <4 x i32> %50 to <2 x i64>
  %54 = bitcast <4 x i32> %52 to <2 x i64>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <2 x i64> %54, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %57 = shufflevector <4 x i64> %55, <4 x i64> %56, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %44, %58
  %60 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, i8 29) #6
  %61 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %59, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %60) #6
  %62 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03>, i8 17) #6
  %63 = bitcast <4 x double> %62 to <4 x i64>
  %64 = bitcast <4 x double> %61 to <4 x i64>
  %65 = xor <4 x i64> %63, <i64 -1, i64 -1, i64 -1, i64 -1>
  %66 = and <4 x i64> %65, %64
  %67 = bitcast <4 x i64> %66 to <4 x double>
  ret <4 x double> %67
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_exp10d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371>
  %3 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %2, i32 8) #6
  %4 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %3) #6
  %5 = fmul <4 x double> %3, <double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000>
  %6 = fadd <4 x double> %5, %0
  %7 = fmul <4 x double> %3, <double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B>
  %8 = fadd <4 x double> %7, %6
  %9 = fmul <4 x double> %8, <double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F>
  %10 = fadd <4 x double> %9, <double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A>
  %11 = fmul <4 x double> %8, %10
  %12 = fadd <4 x double> %11, <double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706>
  %13 = fmul <4 x double> %8, %12
  %14 = fadd <4 x double> %13, <double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154>
  %15 = fmul <4 x double> %8, %14
  %16 = fadd <4 x double> %15, <double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37>
  %17 = fmul <4 x double> %8, %16
  %18 = fadd <4 x double> %17, <double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E>
  %19 = fmul <4 x double> %8, %18
  %20 = fadd <4 x double> %19, <double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2>
  %21 = fmul <4 x double> %8, %20
  %22 = fadd <4 x double> %21, <double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B>
  %23 = fmul <4 x double> %8, %22
  %24 = fadd <4 x double> %23, <double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43>
  %25 = fmul <4 x double> %8, %24
  %26 = fadd <4 x double> %25, <double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78>
  %27 = fmul <4 x double> %8, %26
  %28 = fadd <4 x double> %27, <double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516>
  %29 = bitcast <4 x double> %28 to <4 x i64>
  %30 = and <4 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <4 x i64> %30 to <4 x double>
  %32 = fsub <4 x double> %28, %31
  %33 = bitcast <4 x double> %8 to <4 x i64>
  %34 = and <4 x i64> %33, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %35 = bitcast <4 x i64> %34 to <4 x double>
  %36 = fsub <4 x double> %8, %35
  %37 = fmul <4 x double> %8, %28
  %38 = fmul <4 x double> %35, %31
  %39 = bitcast <4 x double> %37 to <4 x i64>
  %40 = xor <4 x i64> %39, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %41 = bitcast <4 x i64> %40 to <4 x double>
  %42 = fmul <4 x double> %32, %35
  %43 = fmul <4 x double> %36, %31
  %44 = fmul <4 x double> %36, %32
  %45 = fadd <4 x double> %38, %41
  %46 = fadd <4 x double> %42, %45
  %47 = fadd <4 x double> %43, %46
  %48 = fadd <4 x double> %44, %47
  %49 = fadd <4 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %50 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %49
  %51 = fadd <4 x double> %37, %50
  %52 = fadd <4 x double> %51, %48
  %53 = fadd <4 x double> %49, %52
  %54 = ashr <4 x i32> %4, <i32 1, i32 1, i32 1, i32 1>
  %55 = add nsw <4 x i32> %54, <i32 1023, i32 1023, i32 1023, i32 1023>
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %57 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %58 = and <4 x i32> %56, <i32 0, i32 -1, i32 0, i32 -1>
  %59 = shl <4 x i32> %58, <i32 20, i32 20, i32 20, i32 20>
  %60 = and <4 x i32> %57, <i32 0, i32 -1, i32 0, i32 -1>
  %61 = shl <4 x i32> %60, <i32 20, i32 20, i32 20, i32 20>
  %62 = bitcast <4 x i32> %59 to <2 x i64>
  %63 = bitcast <4 x i32> %61 to <2 x i64>
  %64 = shufflevector <2 x i64> %62, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %65 = shufflevector <2 x i64> %63, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %66 = shufflevector <4 x i64> %64, <4 x i64> %65, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fmul <4 x double> %53, %67
  %69 = sub <4 x i32> %4, %54
  %70 = add <4 x i32> %69, <i32 1023, i32 1023, i32 1023, i32 1023>
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %72 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %73 = and <4 x i32> %71, <i32 0, i32 -1, i32 0, i32 -1>
  %74 = shl <4 x i32> %73, <i32 20, i32 20, i32 20, i32 20>
  %75 = and <4 x i32> %72, <i32 0, i32 -1, i32 0, i32 -1>
  %76 = shl <4 x i32> %75, <i32 20, i32 20, i32 20, i32 20>
  %77 = bitcast <4 x i32> %74 to <2 x i64>
  %78 = bitcast <4 x i32> %76 to <2 x i64>
  %79 = shufflevector <2 x i64> %77, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %80 = shufflevector <2 x i64> %78, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %81 = shufflevector <4 x i64> %79, <4 x i64> %80, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %82 = bitcast <4 x i64> %81 to <4 x double>
  %83 = fmul <4 x double> %68, %82
  %84 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE>, i8 30) #6
  %85 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %83, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %84) #6
  %86 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02>, i8 17) #6
  %87 = bitcast <4 x double> %86 to <4 x i64>
  %88 = bitcast <4 x double> %85 to <4 x i64>
  %89 = xor <4 x i64> %87, <i64 -1, i64 -1, i64 -1, i64 -1>
  %90 = and <4 x i64> %89, %88
  %91 = bitcast <4 x i64> %90 to <4 x double>
  ret <4 x double> %91
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_exp10d4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371>
  %3 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %2, i32 8) #6
  %4 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %3) #6
  %5 = fmul <4 x double> %3, <double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000>
  %6 = fadd <4 x double> %5, %0
  %7 = fmul <4 x double> %3, <double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B>
  %8 = fadd <4 x double> %7, %6
  %9 = fmul <4 x double> %8, %8
  %10 = fmul <4 x double> %9, %9
  %11 = fmul <4 x double> %10, %10
  %12 = fmul <4 x double> %8, <double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A>
  %13 = fadd <4 x double> %12, <double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706>
  %14 = fmul <4 x double> %9, <double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F>
  %15 = fadd <4 x double> %14, %13
  %16 = fmul <4 x double> %8, <double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154>
  %17 = fadd <4 x double> %16, <double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37>
  %18 = fmul <4 x double> %8, <double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E>
  %19 = fadd <4 x double> %18, <double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2>
  %20 = fmul <4 x double> %9, %17
  %21 = fadd <4 x double> %19, %20
  %22 = fmul <4 x double> %8, <double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B>
  %23 = fadd <4 x double> %22, <double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43>
  %24 = fmul <4 x double> %8, <double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78>
  %25 = fadd <4 x double> %24, <double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516>
  %26 = fmul <4 x double> %9, %23
  %27 = fadd <4 x double> %25, %26
  %28 = fmul <4 x double> %10, %21
  %29 = fadd <4 x double> %27, %28
  %30 = fmul <4 x double> %11, %15
  %31 = fadd <4 x double> %30, %29
  %32 = fmul <4 x double> %8, %31
  %33 = fadd <4 x double> %32, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %34 = ashr <4 x i32> %4, <i32 1, i32 1, i32 1, i32 1>
  %35 = add nsw <4 x i32> %34, <i32 1023, i32 1023, i32 1023, i32 1023>
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %37 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %38 = and <4 x i32> %36, <i32 0, i32 -1, i32 0, i32 -1>
  %39 = shl <4 x i32> %38, <i32 20, i32 20, i32 20, i32 20>
  %40 = and <4 x i32> %37, <i32 0, i32 -1, i32 0, i32 -1>
  %41 = shl <4 x i32> %40, <i32 20, i32 20, i32 20, i32 20>
  %42 = bitcast <4 x i32> %39 to <2 x i64>
  %43 = bitcast <4 x i32> %41 to <2 x i64>
  %44 = shufflevector <2 x i64> %42, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %45 = shufflevector <2 x i64> %43, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %46 = shufflevector <4 x i64> %44, <4 x i64> %45, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %47 = bitcast <4 x i64> %46 to <4 x double>
  %48 = fmul <4 x double> %33, %47
  %49 = sub <4 x i32> %4, %34
  %50 = add <4 x i32> %49, <i32 1023, i32 1023, i32 1023, i32 1023>
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %52 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %53 = and <4 x i32> %51, <i32 0, i32 -1, i32 0, i32 -1>
  %54 = shl <4 x i32> %53, <i32 20, i32 20, i32 20, i32 20>
  %55 = and <4 x i32> %52, <i32 0, i32 -1, i32 0, i32 -1>
  %56 = shl <4 x i32> %55, <i32 20, i32 20, i32 20, i32 20>
  %57 = bitcast <4 x i32> %54 to <2 x i64>
  %58 = bitcast <4 x i32> %56 to <2 x i64>
  %59 = shufflevector <2 x i64> %57, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %60 = shufflevector <2 x i64> %58, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %61 = shufflevector <4 x i64> %59, <4 x i64> %60, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %62 = bitcast <4 x i64> %61 to <4 x double>
  %63 = fmul <4 x double> %48, %62
  %64 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE>, i8 30) #6
  %65 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %63, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %64) #6
  %66 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02>, i8 17) #6
  %67 = bitcast <4 x double> %66 to <4 x i64>
  %68 = bitcast <4 x double> %65 to <4 x i64>
  %69 = xor <4 x i64> %67, <i64 -1, i64 -1, i64 -1, i64 -1>
  %70 = and <4 x i64> %69, %68
  %71 = bitcast <4 x i64> %70 to <4 x double>
  ret <4 x double> %71
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_expm1d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, zeroinitializer
  %3 = fmul <4 x double> %2, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %4 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %3, i32 8) #6
  %5 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %4) #6
  %6 = fmul <4 x double> %4, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %7 = fadd <4 x double> %6, %0
  %8 = fsub <4 x double> %7, %0
  %9 = fsub <4 x double> %7, %8
  %10 = fsub <4 x double> %0, %9
  %11 = fsub <4 x double> %6, %8
  %12 = fadd <4 x double> %11, %10
  %13 = fadd <4 x double> %12, zeroinitializer
  %14 = fmul <4 x double> %4, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %15 = fadd <4 x double> %14, %7
  %16 = fsub <4 x double> %15, %7
  %17 = fsub <4 x double> %15, %16
  %18 = fsub <4 x double> %7, %17
  %19 = fsub <4 x double> %14, %16
  %20 = fadd <4 x double> %19, %18
  %21 = fadd <4 x double> %20, %13
  %22 = bitcast <4 x double> %15 to <4 x i64>
  %23 = and <4 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %24 = bitcast <4 x i64> %23 to <4 x double>
  %25 = fsub <4 x double> %15, %24
  %26 = fmul <4 x double> %15, %15
  %27 = fmul <4 x double> %24, %24
  %28 = bitcast <4 x double> %26 to <4 x i64>
  %29 = xor <4 x i64> %28, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %30 = bitcast <4 x i64> %29 to <4 x double>
  %31 = fadd <4 x double> %24, %24
  %32 = fmul <4 x double> %31, %25
  %33 = fmul <4 x double> %25, %25
  %34 = fadd <4 x double> %21, %21
  %35 = fmul <4 x double> %15, %34
  %36 = fadd <4 x double> %27, %30
  %37 = fadd <4 x double> %36, %32
  %38 = fadd <4 x double> %33, %37
  %39 = fadd <4 x double> %35, %38
  %40 = and <4 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %41 = bitcast <4 x i64> %40 to <4 x double>
  %42 = fsub <4 x double> %26, %41
  %43 = fmul <4 x double> %26, %26
  %44 = fmul <4 x double> %41, %41
  %45 = bitcast <4 x double> %43 to <4 x i64>
  %46 = xor <4 x i64> %45, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %47 = bitcast <4 x i64> %46 to <4 x double>
  %48 = fadd <4 x double> %41, %41
  %49 = fmul <4 x double> %48, %42
  %50 = fmul <4 x double> %42, %42
  %51 = fadd <4 x double> %39, %39
  %52 = fmul <4 x double> %26, %51
  %53 = fadd <4 x double> %44, %47
  %54 = fadd <4 x double> %53, %49
  %55 = fadd <4 x double> %50, %54
  %56 = fadd <4 x double> %55, %52
  %57 = fmul <4 x double> %43, %43
  %58 = fmul <4 x double> %15, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %59 = fadd <4 x double> %58, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %60 = fmul <4 x double> %15, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %61 = fadd <4 x double> %60, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %62 = fmul <4 x double> %15, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %63 = fadd <4 x double> %62, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %64 = fmul <4 x double> %26, %61
  %65 = fadd <4 x double> %63, %64
  %66 = fmul <4 x double> %15, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %67 = fadd <4 x double> %66, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %68 = fmul <4 x double> %15, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %69 = fadd <4 x double> %68, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %70 = fmul <4 x double> %26, %67
  %71 = fadd <4 x double> %69, %70
  %72 = fmul <4 x double> %43, %65
  %73 = fadd <4 x double> %71, %72
  %74 = fmul <4 x double> %59, %57
  %75 = fadd <4 x double> %74, %73
  %76 = fmul <4 x double> %15, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %77 = fmul <4 x double> %24, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %78 = bitcast <4 x double> %76 to <4 x i64>
  %79 = xor <4 x i64> %78, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fmul <4 x double> %25, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %82 = fmul <4 x double> %24, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %83 = fmul <4 x double> %25, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %84 = fmul <4 x double> %21, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %85 = fadd <4 x double> %77, %80
  %86 = fadd <4 x double> %81, %85
  %87 = fadd <4 x double> %82, %86
  %88 = fadd <4 x double> %83, %87
  %89 = fadd <4 x double> %84, %88
  %90 = fadd <4 x double> %76, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %91 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %90
  %92 = fadd <4 x double> %76, %91
  %93 = fadd <4 x double> %92, %89
  %94 = bitcast <4 x double> %90 to <4 x i64>
  %95 = and <4 x i64> %94, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %96 = bitcast <4 x i64> %95 to <4 x double>
  %97 = fsub <4 x double> %90, %96
  %98 = fmul <4 x double> %15, %90
  %99 = fmul <4 x double> %24, %96
  %100 = bitcast <4 x double> %98 to <4 x i64>
  %101 = xor <4 x i64> %100, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = fmul <4 x double> %97, %24
  %104 = fmul <4 x double> %25, %96
  %105 = fmul <4 x double> %25, %97
  %106 = fmul <4 x double> %90, %21
  %107 = fmul <4 x double> %15, %93
  %108 = fadd <4 x double> %99, %102
  %109 = fadd <4 x double> %103, %108
  %110 = fadd <4 x double> %104, %109
  %111 = fadd <4 x double> %105, %110
  %112 = fadd <4 x double> %106, %111
  %113 = fadd <4 x double> %107, %112
  %114 = fadd <4 x double> %98, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %115 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %114
  %116 = fadd <4 x double> %98, %115
  %117 = fadd <4 x double> %116, %113
  %118 = bitcast <4 x double> %114 to <4 x i64>
  %119 = and <4 x i64> %118, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %120 = bitcast <4 x i64> %119 to <4 x double>
  %121 = fsub <4 x double> %114, %120
  %122 = fmul <4 x double> %15, %114
  %123 = fmul <4 x double> %24, %120
  %124 = bitcast <4 x double> %122 to <4 x i64>
  %125 = xor <4 x i64> %124, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %126 = bitcast <4 x i64> %125 to <4 x double>
  %127 = fmul <4 x double> %121, %24
  %128 = fmul <4 x double> %25, %120
  %129 = fmul <4 x double> %25, %121
  %130 = fmul <4 x double> %114, %21
  %131 = fmul <4 x double> %15, %117
  %132 = fadd <4 x double> %123, %126
  %133 = fadd <4 x double> %127, %132
  %134 = fadd <4 x double> %128, %133
  %135 = fadd <4 x double> %129, %134
  %136 = fadd <4 x double> %130, %135
  %137 = fadd <4 x double> %136, %131
  %138 = fadd <4 x double> %122, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %139 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %138
  %140 = fadd <4 x double> %122, %139
  %141 = fadd <4 x double> %140, %137
  %142 = and <4 x i64> %45, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %143 = bitcast <4 x i64> %142 to <4 x double>
  %144 = fsub <4 x double> %43, %143
  %145 = bitcast <4 x double> %75 to <4 x i64>
  %146 = and <4 x i64> %145, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %147 = bitcast <4 x i64> %146 to <4 x double>
  %148 = fsub <4 x double> %75, %147
  %149 = fmul <4 x double> %43, %75
  %150 = fmul <4 x double> %143, %147
  %151 = bitcast <4 x double> %149 to <4 x i64>
  %152 = xor <4 x i64> %151, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %153 = bitcast <4 x i64> %152 to <4 x double>
  %154 = fmul <4 x double> %144, %147
  %155 = fmul <4 x double> %148, %143
  %156 = fmul <4 x double> %144, %148
  %157 = fmul <4 x double> %75, %56
  %158 = fadd <4 x double> %150, %153
  %159 = fadd <4 x double> %154, %158
  %160 = fadd <4 x double> %155, %159
  %161 = fadd <4 x double> %156, %160
  %162 = fadd <4 x double> %157, %161
  %163 = fadd <4 x double> %138, %149
  %164 = fsub <4 x double> %138, %163
  %165 = fadd <4 x double> %149, %164
  %166 = fadd <4 x double> %165, %141
  %167 = fadd <4 x double> %162, %166
  %168 = ashr <4 x i32> %5, <i32 1, i32 1, i32 1, i32 1>
  %169 = add nsw <4 x i32> %168, <i32 1023, i32 1023, i32 1023, i32 1023>
  %170 = shufflevector <4 x i32> %169, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %171 = shufflevector <4 x i32> %169, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %172 = and <4 x i32> %170, <i32 0, i32 -1, i32 0, i32 -1>
  %173 = shl <4 x i32> %172, <i32 20, i32 20, i32 20, i32 20>
  %174 = and <4 x i32> %171, <i32 0, i32 -1, i32 0, i32 -1>
  %175 = shl <4 x i32> %174, <i32 20, i32 20, i32 20, i32 20>
  %176 = bitcast <4 x i32> %173 to <2 x i64>
  %177 = bitcast <4 x i32> %175 to <2 x i64>
  %178 = shufflevector <2 x i64> %176, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %179 = shufflevector <2 x i64> %177, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %180 = shufflevector <4 x i64> %178, <4 x i64> %179, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %181 = bitcast <4 x i64> %180 to <4 x double>
  %182 = fmul <4 x double> %163, %181
  %183 = sub <4 x i32> %5, %168
  %184 = add <4 x i32> %183, <i32 1023, i32 1023, i32 1023, i32 1023>
  %185 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %186 = shufflevector <4 x i32> %184, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %187 = and <4 x i32> %185, <i32 0, i32 -1, i32 0, i32 -1>
  %188 = shl <4 x i32> %187, <i32 20, i32 20, i32 20, i32 20>
  %189 = and <4 x i32> %186, <i32 0, i32 -1, i32 0, i32 -1>
  %190 = shl <4 x i32> %189, <i32 20, i32 20, i32 20, i32 20>
  %191 = bitcast <4 x i32> %188 to <2 x i64>
  %192 = bitcast <4 x i32> %190 to <2 x i64>
  %193 = shufflevector <2 x i64> %191, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %194 = shufflevector <2 x i64> %192, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %195 = shufflevector <4 x i64> %193, <4 x i64> %194, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %196 = bitcast <4 x i64> %195 to <4 x double>
  %197 = fmul <4 x double> %182, %196
  %198 = fmul <4 x double> %167, %181
  %199 = fmul <4 x double> %198, %196
  %200 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %201 = bitcast <4 x double> %200 to <4 x i64>
  %202 = bitcast <4 x double> %197 to <4 x i64>
  %203 = xor <4 x i64> %201, <i64 -1, i64 -1, i64 -1, i64 -1>
  %204 = and <4 x i64> %202, %203
  %205 = bitcast <4 x double> %199 to <4 x i64>
  %206 = and <4 x i64> %205, %203
  %207 = bitcast <4 x i64> %204 to <4 x double>
  %208 = bitcast <4 x i64> %206 to <4 x double>
  %209 = fadd <4 x double> %207, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %210 = fsub <4 x double> %209, %207
  %211 = fsub <4 x double> %209, %210
  %212 = fsub <4 x double> %207, %211
  %213 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %210
  %214 = fadd <4 x double> %213, %212
  %215 = fadd <4 x double> %214, %208
  %216 = fadd <4 x double> %209, %215
  %217 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF>, i8 30) #6
  %218 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %216, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %217) #6
  %219 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA>, i8 17) #6
  %220 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %218, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> %219) #6
  %221 = bitcast <4 x double> %0 to <4 x i64>
  %222 = xor <4 x i64> %221, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %223 = bitcast <4 x i64> %222 to <4 x double>
  %224 = fcmp oeq <4 x double> %223, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %225 = sext <4 x i1> %224 to <4 x i64>
  %226 = bitcast <4 x i64> %225 to <4 x double>
  %227 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %220, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %226) #6
  ret <4 x double> %227
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_log10d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192>
  %101 = fadd <4 x double> %100, <double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48>
  %102 = fmul <4 x double> %98, <double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74>
  %105 = fadd <4 x double> %104, <double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821>
  %106 = fmul <4 x double> %97, <double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88>
  %107 = fadd <4 x double> %106, <double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %113 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %113, %116
  %118 = fmul <4 x double> %113, <double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF>
  %119 = fmul <4 x double> %116, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %116, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %124 = fmul <4 x double> %117, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %125 = fmul <4 x double> %117, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %126 = fmul <4 x double> %113, <double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21>
  %127 = fadd <4 x double> %119, %122
  %128 = fadd <4 x double> %123, %127
  %129 = fadd <4 x double> %124, %128
  %130 = fadd <4 x double> %125, %129
  %131 = fadd <4 x double> %126, %130
  %132 = bitcast <4 x double> %74 to <4 x i64>
  %133 = and <4 x i64> %132, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %134 = bitcast <4 x i64> %133 to <4 x double>
  %135 = fsub <4 x double> %74, %134
  %136 = fmul <4 x double> %74, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %137 = fmul <4 x double> %134, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %138 = bitcast <4 x double> %136 to <4 x i64>
  %139 = xor <4 x i64> %138, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = fmul <4 x double> %135, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %142 = fmul <4 x double> %134, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %143 = fmul <4 x double> %135, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %144 = fmul <4 x double> %74, <double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F>
  %145 = fmul <4 x double> %96, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %146 = fadd <4 x double> %137, %140
  %147 = fadd <4 x double> %141, %146
  %148 = fadd <4 x double> %142, %147
  %149 = fadd <4 x double> %143, %148
  %150 = fadd <4 x double> %144, %149
  %151 = fadd <4 x double> %150, %145
  %152 = fadd <4 x double> %118, %136
  %153 = fsub <4 x double> %118, %152
  %154 = fadd <4 x double> %136, %153
  %155 = fadd <4 x double> %131, %154
  %156 = fadd <4 x double> %155, %151
  %157 = fmul <4 x double> %74, %97
  %158 = fmul <4 x double> %157, %111
  %159 = fadd <4 x double> %152, %158
  %160 = fsub <4 x double> %152, %159
  %161 = fadd <4 x double> %158, %160
  %162 = fadd <4 x double> %161, %156
  %163 = fadd <4 x double> %159, %162
  %164 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %165 = sext <4 x i1> %164 to <4 x i64>
  %166 = bitcast <4 x i64> %165 to <4 x double>
  %167 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %163, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %166) #6
  %168 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %169 = fcmp uno <4 x double> %5, zeroinitializer
  %170 = select <4 x i1> %169, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %168
  %171 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %167, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %170) #6
  %172 = fcmp oeq <4 x double> %5, zeroinitializer
  %173 = sext <4 x i1> %172 to <4 x i64>
  %174 = bitcast <4 x i64> %173 to <4 x double>
  %175 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %171, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %174) #6
  ret <4 x double> %175
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_log2d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %101 = fadd <4 x double> %100, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %102 = fmul <4 x double> %98, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %105 = fadd <4 x double> %104, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %106 = fmul <4 x double> %97, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %107 = fadd <4 x double> %106, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %74 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %74, %116
  %118 = fmul <4 x double> %74, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %119 = fmul <4 x double> %116, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %117, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %124 = fmul <4 x double> %116, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %125 = fmul <4 x double> %117, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %126 = fmul <4 x double> %74, <double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1>
  %127 = fmul <4 x double> %96, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %128 = fadd <4 x double> %119, %122
  %129 = fadd <4 x double> %123, %128
  %130 = fadd <4 x double> %124, %129
  %131 = fadd <4 x double> %125, %130
  %132 = fadd <4 x double> %126, %131
  %133 = fadd <4 x double> %132, %127
  %134 = fadd <4 x double> %118, %113
  %135 = fsub <4 x double> %134, %113
  %136 = fsub <4 x double> %134, %135
  %137 = fsub <4 x double> %113, %136
  %138 = fsub <4 x double> %118, %135
  %139 = fadd <4 x double> %138, %137
  %140 = fadd <4 x double> %139, %133
  %141 = fmul <4 x double> %74, %97
  %142 = fmul <4 x double> %141, %111
  %143 = fadd <4 x double> %134, %142
  %144 = fsub <4 x double> %143, %134
  %145 = fsub <4 x double> %143, %144
  %146 = fsub <4 x double> %134, %145
  %147 = fsub <4 x double> %142, %144
  %148 = fadd <4 x double> %147, %146
  %149 = fadd <4 x double> %148, %140
  %150 = fadd <4 x double> %143, %149
  %151 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %152 = sext <4 x i1> %151 to <4 x i64>
  %153 = bitcast <4 x i64> %152 to <4 x double>
  %154 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %150, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %153) #6
  %155 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %156 = fcmp uno <4 x double> %5, zeroinitializer
  %157 = select <4 x i1> %156, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %155
  %158 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %154, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %157) #6
  %159 = fcmp oeq <4 x double> %5, zeroinitializer
  %160 = sext <4 x i1> %159 to <4 x i64>
  %161 = bitcast <4 x i64> %160 to <4 x double>
  %162 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %158, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %161) #6
  ret <4 x double> %162
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_log2d4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fdiv <4 x double> %49, %50
  %52 = fmul <4 x double> %51, %51
  %53 = fmul <4 x double> %52, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %54 = fadd <4 x double> %53, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %55 = fmul <4 x double> %52, %54
  %56 = fadd <4 x double> %55, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %57 = fmul <4 x double> %52, %56
  %58 = fadd <4 x double> %57, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %59 = fmul <4 x double> %52, %58
  %60 = fadd <4 x double> %59, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %61 = fmul <4 x double> %52, %60
  %62 = fadd <4 x double> %61, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %63 = fmul <4 x double> %52, %62
  %64 = fadd <4 x double> %63, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %65 = bitcast <16 x i8> %48 to <4 x i32>
  %66 = sitofp <4 x i32> %65 to <4 x double>
  %67 = bitcast <4 x double> %51 to <4 x i64>
  %68 = and <4 x i64> %67, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %69 = bitcast <4 x i64> %68 to <4 x double>
  %70 = fsub <4 x double> %51, %69
  %71 = fmul <4 x double> %51, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %72 = fmul <4 x double> %69, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %73 = bitcast <4 x double> %71 to <4 x i64>
  %74 = xor <4 x i64> %73, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %75 = bitcast <4 x i64> %74 to <4 x double>
  %76 = fmul <4 x double> %70, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %77 = fmul <4 x double> %69, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %78 = fmul <4 x double> %70, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %79 = fadd <4 x double> %72, %75
  %80 = fadd <4 x double> %76, %79
  %81 = fadd <4 x double> %77, %80
  %82 = fadd <4 x double> %78, %81
  %83 = fadd <4 x double> %71, %66
  %84 = fsub <4 x double> %66, %83
  %85 = fadd <4 x double> %71, %84
  %86 = fadd <4 x double> %85, %82
  %87 = fmul <4 x double> %51, %52
  %88 = fadd <4 x double> %83, %86
  %89 = fmul <4 x double> %87, %64
  %90 = fadd <4 x double> %88, %89
  %91 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %92 = sext <4 x i1> %91 to <4 x i64>
  %93 = bitcast <4 x i64> %92 to <4 x double>
  %94 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %90, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %93) #6
  %95 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %96 = fcmp uno <4 x double> %5, zeroinitializer
  %97 = select <4 x i1> %96, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %95
  %98 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %94, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %97) #6
  %99 = fcmp oeq <4 x double> %5, zeroinitializer
  %100 = sext <4 x i1> %99 to <4 x i64>
  %101 = bitcast <4 x i64> %100 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %98, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %101) #6
  ret <4 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_log1pd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %2, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %4 = bitcast <4 x double> %3 to <4 x i64>
  %5 = fmul <4 x double> %2, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %5, <4 x double> %3) #6
  %7 = fmul <4 x double> %6, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %10 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %11 = bitcast <2 x i64> %9 to <4 x i32>
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = bitcast <2 x i64> %10 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %16, <2 x i64> %13, <2 x i32> <i32 2, i32 1>
  %18 = bitcast <2 x i64> %17 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 20, i32 20, i32 20, i32 20>
  %20 = and <4 x i32> %19, <i32 2047, i32 2047, i32 2047, i32 2047>
  %21 = add nsw <4 x i32> %20, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %22 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %20
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %24 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %25 = and <4 x i32> %23, <i32 0, i32 -1, i32 0, i32 -1>
  %26 = shl <4 x i32> %25, <i32 20, i32 20, i32 20, i32 20>
  %27 = and <4 x i32> %24, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = add <4 x i32> %26, <i32 0, i32 1072693248, i32 0, i32 1072693248>
  %30 = add <4 x i32> %28, <i32 0, i32 1072693248, i32 0, i32 1072693248>
  %31 = bitcast <4 x i32> %29 to <2 x i64>
  %32 = bitcast <4 x i32> %30 to <2 x i64>
  %33 = shufflevector <2 x i64> %31, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %34 = shufflevector <2 x i64> %32, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %35 = shufflevector <4 x i64> %33, <4 x i64> %34, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fadd <4 x double> %36, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %38 = fmul <4 x double> %36, %0
  %39 = fadd <4 x double> %38, %37
  %40 = and <4 x i64> %4, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %41 = bitcast <4 x i64> %40 to <4 x double>
  %42 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %41) #6
  %43 = add nsw <4 x i32> %20, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %44 = bitcast <4 x i32> %21 to <16 x i8>
  %45 = bitcast <4 x i32> %43 to <16 x i8>
  %46 = bitcast <4 x i32> %42 to <16 x i8>
  %47 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %44, <16 x i8> %45, <16 x i8> %46) #6
  %48 = bitcast <16 x i8> %47 to <4 x i32>
  %49 = sitofp <4 x i32> %48 to <4 x double>
  %50 = bitcast <4 x double> %49 to <4 x i64>
  %51 = and <4 x i64> %50, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %52 = bitcast <4 x i64> %51 to <4 x double>
  %53 = fsub <4 x double> %49, %52
  %54 = fmul <4 x double> %49, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %55 = fmul <4 x double> %52, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %56 = bitcast <4 x double> %54 to <4 x i64>
  %57 = xor <4 x i64> %56, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %52, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %60 = fmul <4 x double> %53, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %61 = fmul <4 x double> %53, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %62 = fmul <4 x double> %49, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %63 = fadd <4 x double> %55, %58
  %64 = fadd <4 x double> %59, %63
  %65 = fadd <4 x double> %60, %64
  %66 = fadd <4 x double> %61, %65
  %67 = fadd <4 x double> %62, %66
  %68 = fadd <4 x double> %39, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %69 = fsub <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %68
  %70 = fadd <4 x double> %39, %69
  %71 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %68
  %72 = bitcast <4 x double> %68 to <4 x i64>
  %73 = and <4 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = fsub <4 x double> %68, %74
  %76 = bitcast <4 x double> %71 to <4 x i64>
  %77 = and <4 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = fsub <4 x double> %71, %78
  %80 = bitcast <4 x double> %39 to <4 x i64>
  %81 = and <4 x i64> %80, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %82 = bitcast <4 x i64> %81 to <4 x double>
  %83 = fsub <4 x double> %39, %82
  %84 = fmul <4 x double> %39, %71
  %85 = fmul <4 x double> %82, %78
  %86 = fsub <4 x double> %85, %84
  %87 = fmul <4 x double> %79, %82
  %88 = fmul <4 x double> %83, %78
  %89 = fmul <4 x double> %83, %79
  %90 = fmul <4 x double> %74, %78
  %91 = fmul <4 x double> %79, %74
  %92 = fmul <4 x double> %75, %78
  %93 = fmul <4 x double> %75, %79
  %94 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %90
  %95 = fsub <4 x double> %94, %91
  %96 = fsub <4 x double> %95, %92
  %97 = fsub <4 x double> %96, %93
  %98 = fmul <4 x double> %84, %97
  %99 = fadd <4 x double> %86, %87
  %100 = fadd <4 x double> %88, %99
  %101 = fadd <4 x double> %89, %100
  %102 = fadd <4 x double> %101, %98
  %103 = fmul <4 x double> %84, %70
  %104 = fsub <4 x double> zeroinitializer, %103
  %105 = fmul <4 x double> %71, %104
  %106 = fadd <4 x double> %105, %102
  %107 = fmul <4 x double> %84, %84
  %108 = fmul <4 x double> %107, %107
  %109 = fmul <4 x double> %108, %108
  %110 = fmul <4 x double> %107, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %111 = fadd <4 x double> %110, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %112 = fmul <4 x double> %108, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %113 = fadd <4 x double> %112, %111
  %114 = fmul <4 x double> %107, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %115 = fadd <4 x double> %114, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %116 = fmul <4 x double> %107, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %117 = fadd <4 x double> %116, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %118 = fmul <4 x double> %108, %115
  %119 = fadd <4 x double> %117, %118
  %120 = fmul <4 x double> %109, %113
  %121 = fadd <4 x double> %120, %119
  %122 = fmul <4 x double> %84, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %123 = fmul <4 x double> %106, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %124 = fadd <4 x double> %54, %122
  %125 = fsub <4 x double> %54, %124
  %126 = fadd <4 x double> %122, %125
  %127 = fadd <4 x double> %67, %126
  %128 = fadd <4 x double> %127, %123
  %129 = fmul <4 x double> %84, %107
  %130 = fmul <4 x double> %129, %121
  %131 = fadd <4 x double> %124, %130
  %132 = fsub <4 x double> %124, %131
  %133 = fadd <4 x double> %130, %132
  %134 = fadd <4 x double> %133, %128
  %135 = fadd <4 x double> %131, %134
  %136 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433>, i8 30) #6
  %137 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %135, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %136) #6
  %138 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i8 17) #6
  %139 = fcmp uno <4 x double> %0, zeroinitializer
  %140 = select <4 x i1> %139, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %138
  %141 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %137, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %140) #6
  %142 = fcmp oeq <4 x double> %0, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %143 = sext <4 x i1> %142 to <4 x i64>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %141, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %144) #6
  %146 = bitcast <4 x double> %0 to <4 x i64>
  %147 = xor <4 x i64> %146, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = fcmp oeq <4 x double> %148, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %150 = sext <4 x i1> %149 to <4 x i64>
  %151 = bitcast <4 x i64> %150 to <4 x double>
  %152 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %151) #6
  ret <4 x double> %152
}

; Function Attrs: norecurse nounwind readnone uwtable
define <4 x double> @Sleef_fabsd4_avx(<4 x double>) local_unnamed_addr #3 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  ret <4 x double> %4
}

; Function Attrs: norecurse nounwind readnone uwtable
define <4 x double> @Sleef_copysignd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #3 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x double> %1 to <4 x i64>
  %6 = and <4 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = or <4 x i64> %6, %4
  %8 = bitcast <4 x i64> %7 to <4 x double>
  ret <4 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_fmaxd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp uno <4 x double> %1, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %0, <4 x double> %1) #6
  %6 = bitcast <4 x i64> %4 to <4 x double>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %0, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_fmind4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp uno <4 x double> %1, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %0, <4 x double> %1) #6
  %6 = bitcast <4 x i64> %4 to <4 x double>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %0, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_fdimd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fsub <4 x double> %0, %1
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> zeroinitializer, i8 17) #6
  %5 = fcmp oeq <4 x double> %0, %1
  %6 = select <4 x i1> %5, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %4
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> zeroinitializer, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_truncd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 11) #6
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_floord4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = sitofp <4 x i32> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <4 x double> %0, %5
  %7 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %6) #6
  %8 = sitofp <4 x i32> %7 to <4 x double>
  %9 = fsub <4 x double> %6, %8
  %10 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %9, <4 x double> zeroinitializer, i8 17) #6
  %11 = fadd <4 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %11, <4 x double> %10) #6
  %13 = bitcast <4 x double> %0 to <4 x i64>
  %14 = and <4 x i64> %13, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %15, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %18 = fsub <4 x double> %0, %12
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = and <4 x i64> %19, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %21 = and <4 x i64> %13, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %22 = or <4 x i64> %20, %21
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = select <4 x i1> %16, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %17
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> %0, <4 x double> %24) #6
  ret <4 x double> %25
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_ceild4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = sitofp <4 x i32> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <4 x double> %0, %5
  %7 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %6) #6
  %8 = sitofp <4 x i32> %7 to <4 x double>
  %9 = fsub <4 x double> %6, %8
  %10 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %9, <4 x double> zeroinitializer, i8 18) #6
  %11 = fadd <4 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %9, <4 x double> %10) #6
  %13 = bitcast <4 x double> %0 to <4 x i64>
  %14 = and <4 x i64> %13, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %15, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %18 = fsub <4 x double> %0, %12
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = and <4 x i64> %19, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %21 = and <4 x i64> %13, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %22 = or <4 x i64> %20, %21
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = select <4 x i1> %16, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %17
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> %0, <4 x double> %24) #6
  ret <4 x double> %25
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_roundd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %3 = fmul <4 x double> %2, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = sitofp <4 x i32> %4 to <4 x double>
  %6 = fmul <4 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <4 x double> %2, %6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %7) #6
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %7, %9
  %11 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %2, <4 x double> zeroinitializer, i8 18) #6
  %12 = fcmp oeq <4 x double> %10, zeroinitializer
  %13 = fadd <4 x double> %2, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %14 = select <4 x i1> %12, <4 x double> %11, <4 x double> zeroinitializer
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %13, <4 x double> %14) #6
  %16 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %10, <4 x double> zeroinitializer, i8 17) #6
  %17 = fadd <4 x double> %10, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> %17, <4 x double> %16) #6
  %19 = fcmp oeq <4 x double> %0, <double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF>
  %20 = sext <4 x i1> %19 to <4 x i64>
  %21 = bitcast <4 x i64> %20 to <4 x double>
  %22 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> zeroinitializer, <4 x double> %21) #6
  %23 = bitcast <4 x double> %0 to <4 x i64>
  %24 = and <4 x i64> %23, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %25 = bitcast <4 x i64> %24 to <4 x double>
  %26 = fcmp oeq <4 x double> %25, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %27 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %25, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %28 = fsub <4 x double> %22, %18
  %29 = bitcast <4 x double> %28 to <4 x i64>
  %30 = and <4 x i64> %29, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %31 = and <4 x i64> %23, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %32 = or <4 x i64> %30, %31
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = select <4 x i1> %26, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %27
  %35 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %33, <4 x double> %0, <4 x double> %34) #6
  ret <4 x double> %35
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_rintd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 8) #6
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_nextafterd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp oeq <4 x double> %0, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = bitcast <4 x double> %1 to <4 x i64>
  %6 = and <4 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = bitcast <4 x i64> %6 to <4 x double>
  %8 = bitcast <4 x i64> %4 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %7, <4 x double> %8) #6
  %10 = bitcast <4 x double> %9 to <4 x i64>
  %11 = shufflevector <4 x i64> %10, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %12 = shufflevector <4 x i64> %10, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %13 = and <4 x i64> %10, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %14 = xor <4 x i64> %13, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %17 = sext <4 x i1> %16 to <4 x i64>
  %18 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %1, <4 x double> %9, i8 29) #6
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = xor <4 x i64> %17, %19
  %21 = bitcast <2 x i64> %11 to <4 x i32>
  %22 = xor <4 x i32> %21, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %23 = add <4 x i32> %22, <i32 1, i32 0, i32 1, i32 0>
  %24 = bitcast <2 x i64> %12 to <4 x i32>
  %25 = xor <4 x i32> %24, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %26 = add <4 x i32> %25, <i32 1, i32 0, i32 1, i32 0>
  %27 = icmp eq <4 x i32> %23, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = sext <4 x i1> %27 to <4 x i32>
  %29 = icmp eq <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = sext <4 x i1> %29 to <4 x i32>
  %31 = bitcast <4 x i32> %28 to <2 x i64>
  %32 = bitcast <4 x i32> %30 to <2 x i64>
  %33 = and <2 x i64> %31, <i64 1, i64 1>
  %34 = and <2 x i64> %32, <i64 1, i64 1>
  %35 = shufflevector <2 x i64> %33, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %36 = shufflevector <2 x i64> %34, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %37 = shufflevector <4 x i64> %35, <4 x i64> %36, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %38 = bitcast <4 x i64> %37 to <8 x float>
  %39 = shufflevector <8 x float> %38, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %40 = bitcast <8 x float> %39 to <4 x i64>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %42 = shufflevector <4 x i64> %40, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %43 = bitcast <2 x i64> %41 to <4 x i32>
  %44 = add <4 x i32> %23, %43
  %45 = bitcast <2 x i64> %42 to <4 x i32>
  %46 = add <4 x i32> %26, %45
  %47 = bitcast <4 x i32> %44 to <2 x i64>
  %48 = bitcast <4 x i32> %46 to <2 x i64>
  %49 = shufflevector <2 x i64> %47, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %50 = shufflevector <2 x i64> %48, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %51 = shufflevector <4 x i64> %49, <4 x i64> %50, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %52 = bitcast <4 x i64> %51 to <4 x double>
  %53 = bitcast <4 x i64> %20 to <4 x double>
  %54 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %52, <4 x double> %53) #6
  %55 = bitcast <4 x double> %54 to <4 x i64>
  %56 = shufflevector <4 x i64> %55, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %57 = shufflevector <4 x i64> %55, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %58 = fcmp une <4 x double> %9, %1
  %59 = sext <4 x i1> %58 to <4 x i64>
  %60 = and <4 x i64> %59, <i64 1, i64 1, i64 1, i64 1>
  %61 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %62 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %63 = bitcast <2 x i64> %56 to <4 x i32>
  %64 = bitcast <2 x i64> %61 to <4 x i32>
  %65 = sub <4 x i32> %63, %64
  %66 = bitcast <2 x i64> %57 to <4 x i32>
  %67 = bitcast <2 x i64> %62 to <4 x i32>
  %68 = sub <4 x i32> %66, %67
  %69 = bitcast <4 x i32> %65 to <2 x i64>
  %70 = bitcast <4 x i32> %68 to <2 x i64>
  %71 = icmp eq <4 x i32> %65, <i32 -1, i32 0, i32 -1, i32 0>
  %72 = sext <4 x i1> %71 to <4 x i32>
  %73 = icmp eq <4 x i32> %68, <i32 -1, i32 0, i32 -1, i32 0>
  %74 = sext <4 x i1> %73 to <4 x i32>
  %75 = bitcast <4 x i32> %72 to <2 x i64>
  %76 = bitcast <4 x i32> %74 to <2 x i64>
  %77 = and <2 x i64> %75, <i64 4294967295, i64 4294967295>
  %78 = and <2 x i64> %76, <i64 4294967295, i64 4294967295>
  %79 = shufflevector <2 x i64> %77, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %80 = shufflevector <2 x i64> %78, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %81 = shufflevector <4 x i64> %79, <4 x i64> %80, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %82 = bitcast <4 x i64> %81 to <8 x float>
  %83 = shufflevector <8 x float> %82, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %84 = bitcast <8 x float> %83 to <4 x i64>
  %85 = shufflevector <4 x i64> %84, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %86 = shufflevector <4 x i64> %84, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %87 = bitcast <2 x i64> %85 to <4 x i32>
  %88 = add <4 x i32> %65, %87
  %89 = bitcast <2 x i64> %86 to <4 x i32>
  %90 = add <4 x i32> %68, %89
  %91 = bitcast <4 x i32> %88 to <2 x i64>
  %92 = bitcast <4 x i32> %90 to <2 x i64>
  %93 = shufflevector <2 x i64> %91, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %94 = shufflevector <2 x i64> %92, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %95 = shufflevector <4 x i64> %93, <4 x i64> %94, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %96 = bitcast <4 x i64> %95 to <4 x double>
  %97 = shufflevector <2 x i64> %69, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %98 = shufflevector <2 x i64> %70, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %99 = shufflevector <4 x i64> %97, <4 x i64> %98, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %100 = bitcast <4 x i64> %99 to <4 x double>
  %101 = bitcast <4 x i64> %59 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> %96, <4 x double> %101) #6
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = shufflevector <4 x i64> %103, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %105 = shufflevector <4 x i64> %103, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %106 = bitcast <2 x i64> %104 to <4 x i32>
  %107 = xor <4 x i32> %106, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %108 = add <4 x i32> %107, <i32 1, i32 0, i32 1, i32 0>
  %109 = bitcast <2 x i64> %105 to <4 x i32>
  %110 = xor <4 x i32> %109, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %111 = add <4 x i32> %110, <i32 1, i32 0, i32 1, i32 0>
  %112 = icmp eq <4 x i32> %108, <i32 0, i32 -1, i32 0, i32 -1>
  %113 = sext <4 x i1> %112 to <4 x i32>
  %114 = icmp eq <4 x i32> %111, <i32 0, i32 -1, i32 0, i32 -1>
  %115 = sext <4 x i1> %114 to <4 x i32>
  %116 = bitcast <4 x i32> %113 to <2 x i64>
  %117 = bitcast <4 x i32> %115 to <2 x i64>
  %118 = and <2 x i64> %116, <i64 1, i64 1>
  %119 = and <2 x i64> %117, <i64 1, i64 1>
  %120 = shufflevector <2 x i64> %118, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %121 = shufflevector <2 x i64> %119, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %122 = shufflevector <4 x i64> %120, <4 x i64> %121, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %123 = bitcast <4 x i64> %122 to <8 x float>
  %124 = shufflevector <8 x float> %123, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %125 = bitcast <8 x float> %124 to <4 x i64>
  %126 = shufflevector <4 x i64> %125, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %127 = shufflevector <4 x i64> %125, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %128 = bitcast <2 x i64> %126 to <4 x i32>
  %129 = add <4 x i32> %108, %128
  %130 = bitcast <2 x i64> %127 to <4 x i32>
  %131 = add <4 x i32> %111, %130
  %132 = bitcast <4 x i32> %129 to <2 x i64>
  %133 = bitcast <4 x i32> %131 to <2 x i64>
  %134 = shufflevector <2 x i64> %132, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %135 = shufflevector <2 x i64> %133, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %136 = shufflevector <4 x i64> %134, <4 x i64> %135, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %137 = bitcast <4 x i64> %136 to <4 x double>
  %138 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %102, <4 x double> %137, <4 x double> %53) #6
  %139 = fcmp oeq <4 x double> %138, zeroinitializer
  %140 = fcmp une <4 x double> %9, zeroinitializer
  %141 = and <4 x i1> %139, %140
  %142 = sext <4 x i1> %141 to <4 x i64>
  %143 = bitcast <4 x i64> %13 to <4 x double>
  %144 = bitcast <4 x i64> %142 to <4 x double>
  %145 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %138, <4 x double> %143, <4 x double> %144) #6
  %146 = fcmp oeq <4 x double> %9, zeroinitializer
  %147 = fcmp oeq <4 x double> %1, zeroinitializer
  %148 = and <4 x i1> %146, %147
  %149 = sext <4 x i1> %148 to <4 x i64>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> %1, <4 x double> %150) #6
  %152 = fcmp uno <4 x double> %9, %1
  %153 = sext <4 x i1> %152 to <4 x i64>
  %154 = bitcast <4 x i64> %153 to <4 x double>
  %155 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %151, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %154) #6
  ret <4 x double> %155
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_frfrexpd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %6 = fmul <4 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %6, <4 x double> %5) #6
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = and <4 x i64> %8, <i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313>
  %10 = or <4 x i64> %9, <i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912>
  %11 = bitcast <4 x i64> %10 to <4 x double>
  %12 = and <4 x i64> %8, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = fcmp oeq <4 x double> %13, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %15 = sext <4 x i1> %14 to <4 x i64>
  %16 = and <4 x i64> %8, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %17 = or <4 x i64> %16, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = bitcast <4 x i64> %15 to <4 x double>
  %20 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %18, <4 x double> %19) #6
  %21 = fcmp oeq <4 x double> %7, zeroinitializer
  %22 = sext <4 x i1> %21 to <4 x i64>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %20, <4 x double> %7, <4 x double> %23) #6
  ret <4 x double> %24
}

; Function Attrs: nounwind readnone uwtable
define <2 x i64> @Sleef_expfrexpd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %6 = fmul <4 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %6, <4 x double> %5) #6
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %10 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %11 = bitcast <2 x i64> %9 to <4 x i32>
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = bitcast <2 x i64> %10 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %16, <2 x i64> %13, <2 x i32> <i32 2, i32 1>
  %18 = bitcast <2 x i64> %17 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 20, i32 20, i32 20, i32 20>
  %20 = and <4 x i32> %19, <i32 2047, i32 2047, i32 2047, i32 2047>
  %21 = add nsw <4 x i32> %20, <i32 -1022, i32 -1022, i32 -1022, i32 -1022>
  %22 = fcmp ueq <4 x double> %7, zeroinitializer
  %23 = and <4 x i64> %8, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %24 = bitcast <4 x i64> %23 to <4 x double>
  %25 = fcmp oeq <4 x double> %24, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %26 = or <4 x i1> %25, %22
  %27 = sext <4 x i1> %26 to <4 x i64>
  %28 = shufflevector <4 x i64> %27, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %29 = bitcast <4 x i32> %21 to <16 x i8>
  %30 = bitcast <2 x i64> %28 to <16 x i8>
  %31 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %29, <16 x i8> zeroinitializer, <16 x i8> %30) #6
  %32 = bitcast <16 x i8> %31 to <2 x i64>
  ret <2 x i64> %32
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_fmad4_avx(<4 x double>, <4 x double>, <4 x double>) local_unnamed_addr #0 {
  %4 = fmul <4 x double> %0, %1
  %5 = fadd <4 x double> %4, %2
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300>, i8 17) #6
  %10 = fmul <4 x double> %0, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %1, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %1, <4 x double> %12, <4 x double> %9) #6
  %14 = fmul <4 x double> %2, <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %14, <4 x double> %9) #6
  %16 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>, <4 x double> %9) #6
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300>, i8 30) #6
  %18 = fmul <4 x double> %11, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %18, <4 x double> %17) #6
  %20 = fmul <4 x double> %13, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %21 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %13, <4 x double> %20, <4 x double> %17) #6
  %22 = fmul <4 x double> %15, <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>
  %23 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> %22, <4 x double> %17) #6
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %16, <4 x double> <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>, <4 x double> %17) #6
  %25 = bitcast <4 x double> %19 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %19, %27
  %29 = bitcast <4 x double> %21 to <4 x i64>
  %30 = and <4 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <4 x i64> %30 to <4 x double>
  %32 = fsub <4 x double> %21, %31
  %33 = fmul <4 x double> %19, %21
  %34 = fmul <4 x double> %27, %31
  %35 = bitcast <4 x double> %33 to <4 x i64>
  %36 = xor <4 x i64> %35, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %37 = bitcast <4 x i64> %36 to <4 x double>
  %38 = fmul <4 x double> %28, %31
  %39 = fmul <4 x double> %32, %27
  %40 = fmul <4 x double> %28, %32
  %41 = fadd <4 x double> %34, %37
  %42 = fadd <4 x double> %38, %41
  %43 = fadd <4 x double> %39, %42
  %44 = fadd <4 x double> %40, %43
  %45 = fadd <4 x double> %33, %23
  %46 = fsub <4 x double> %45, %33
  %47 = fsub <4 x double> %45, %46
  %48 = fsub <4 x double> %33, %47
  %49 = fsub <4 x double> %23, %46
  %50 = fadd <4 x double> %49, %48
  %51 = fadd <4 x double> %50, %44
  %52 = fcmp oeq <4 x double> %19, zeroinitializer
  %53 = fcmp oeq <4 x double> %21, zeroinitializer
  %54 = or <4 x i1> %53, %52
  %55 = sext <4 x i1> %54 to <4 x i64>
  %56 = fadd <4 x double> %45, %51
  %57 = bitcast <4 x i64> %55 to <4 x double>
  %58 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %56, <4 x double> %23, <4 x double> %57) #6
  %59 = bitcast <4 x double> %23 to <4 x i64>
  %60 = and <4 x i64> %59, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %61 = bitcast <4 x i64> %60 to <4 x double>
  %62 = fcmp oeq <4 x double> %61, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %63 = and <4 x i64> %25, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fcmp une <4 x double> %64, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %66 = and <4 x i64> %29, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fcmp une <4 x double> %67, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %69 = fcmp ord <4 x double> %21, %19
  %70 = and <4 x i1> %69, %65
  %71 = and <4 x i1> %70, %68
  %72 = and <4 x i1> %71, %62
  %73 = sext <4 x i1> %72 to <4 x i64>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %23, <4 x double> %74) #6
  %76 = bitcast <4 x double> %75 to <4 x i64>
  %77 = and <4 x i64> %76, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = fcmp oeq <4 x double> %78, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %80 = fcmp uno <4 x double> %75, zeroinitializer
  %81 = or <4 x i1> %79, %80
  %82 = sext <4 x i1> %81 to <4 x i64>
  %83 = fmul <4 x double> %24, %58
  %84 = bitcast <4 x i64> %82 to <4 x double>
  %85 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %83, <4 x double> %75, <4 x double> %84) #6
  ret <4 x double> %85
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sqrtd4_u05avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %3 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %2) #6
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i8 17) #6
  %5 = fmul <4 x double> %3, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> %5, <4 x double> %4) #6
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <4 x double> %4) #6
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %6, <4 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i8 30) #6
  %9 = fmul <4 x double> %6, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %6, <4 x double> %9, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %7, <4 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <4 x double> %8) #6
  %12 = fadd <4 x double> %10, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %13 = bitcast <4 x double> %12 to <4 x i64>
  %14 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %15 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = lshr <4 x i32> %16, <i32 1, i32 1, i32 1, i32 1>
  %18 = bitcast <2 x i64> %15 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 1, i32 1, i32 1, i32 1>
  %20 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %21 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %19
  %22 = bitcast <4 x i32> %20 to <2 x i64>
  %23 = bitcast <4 x i32> %21 to <2 x i64>
  %24 = shufflevector <2 x i64> %22, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %25 = shufflevector <2 x i64> %23, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %26 = shufflevector <4 x i64> %24, <4 x i64> %25, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fmul <4 x double> %10, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %29 = fmul <4 x double> %28, %27
  %30 = fmul <4 x double> %29, %27
  %31 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <4 x double> %31, %27
  %33 = fmul <4 x double> %28, %32
  %34 = fmul <4 x double> %32, %33
  %35 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %34
  %36 = fmul <4 x double> %32, %35
  %37 = fmul <4 x double> %28, %36
  %38 = fmul <4 x double> %36, %37
  %39 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %38
  %40 = fmul <4 x double> %36, %39
  %41 = fmul <4 x double> %10, %40
  %42 = bitcast <4 x double> %41 to <4 x i64>
  %43 = and <4 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %41, %44
  %46 = fmul <4 x double> %41, %41
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fmul <4 x double> %45, %44
  %52 = fmul <4 x double> %45, %45
  %53 = fadd <4 x double> %47, %50
  %54 = fadd <4 x double> %51, %53
  %55 = fadd <4 x double> %51, %54
  %56 = fadd <4 x double> %52, %55
  %57 = fadd <4 x double> %10, %46
  %58 = fsub <4 x double> %57, %10
  %59 = fsub <4 x double> %57, %58
  %60 = fsub <4 x double> %10, %59
  %61 = fsub <4 x double> %46, %58
  %62 = fadd <4 x double> %61, %60
  %63 = fadd <4 x double> %62, %56
  %64 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %41
  %65 = bitcast <4 x double> %64 to <4 x i64>
  %66 = and <4 x i64> %65, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fsub <4 x double> %64, %67
  %69 = fmul <4 x double> %44, %67
  %70 = fmul <4 x double> %68, %44
  %71 = fmul <4 x double> %45, %67
  %72 = fmul <4 x double> %45, %68
  %73 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %69
  %74 = fsub <4 x double> %73, %70
  %75 = fsub <4 x double> %74, %71
  %76 = fsub <4 x double> %75, %72
  %77 = fmul <4 x double> %64, %76
  %78 = bitcast <4 x double> %57 to <4 x i64>
  %79 = and <4 x i64> %78, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fsub <4 x double> %57, %80
  %82 = fmul <4 x double> %64, %57
  %83 = fmul <4 x double> %67, %80
  %84 = bitcast <4 x double> %82 to <4 x i64>
  %85 = xor <4 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fmul <4 x double> %81, %67
  %88 = fmul <4 x double> %68, %80
  %89 = fmul <4 x double> %68, %81
  %90 = fmul <4 x double> %57, %77
  %91 = fmul <4 x double> %64, %63
  %92 = fadd <4 x double> %83, %86
  %93 = fadd <4 x double> %87, %92
  %94 = fadd <4 x double> %88, %93
  %95 = fadd <4 x double> %89, %94
  %96 = fadd <4 x double> %95, %90
  %97 = fadd <4 x double> %91, %96
  %98 = fadd <4 x double> %82, %97
  %99 = fmul <4 x double> %11, %98
  %100 = fcmp oeq <4 x double> %10, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %101 = sext <4 x i1> %100 to <4 x i64>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %99, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %102) #6
  %104 = fcmp oeq <4 x double> %10, zeroinitializer
  %105 = sext <4 x i1> %104 to <4 x i64>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %103, <4 x double> %10, <4 x double> %106) #6
  ret <4 x double> %107
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sqrtd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %0) #6
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_sqrtd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %3 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %2) #6
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i8 17) #6
  %5 = fmul <4 x double> %3, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> %5, <4 x double> %4) #6
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <4 x double> %4) #6
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %6, <4 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i8 30) #6
  %9 = fmul <4 x double> %6, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %6, <4 x double> %9, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %7, <4 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <4 x double> %8) #6
  %12 = fadd <4 x double> %10, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %13 = bitcast <4 x double> %12 to <4 x i64>
  %14 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %15 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = lshr <4 x i32> %16, <i32 1, i32 1, i32 1, i32 1>
  %18 = bitcast <2 x i64> %15 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 1, i32 1, i32 1, i32 1>
  %20 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %21 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %19
  %22 = bitcast <4 x i32> %20 to <2 x i64>
  %23 = bitcast <4 x i32> %21 to <2 x i64>
  %24 = shufflevector <2 x i64> %22, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %25 = shufflevector <2 x i64> %23, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %26 = shufflevector <4 x i64> %24, <4 x i64> %25, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fmul <4 x double> %10, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %29 = fmul <4 x double> %28, %27
  %30 = fmul <4 x double> %29, %27
  %31 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <4 x double> %31, %27
  %33 = fmul <4 x double> %28, %32
  %34 = fmul <4 x double> %32, %33
  %35 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %34
  %36 = fmul <4 x double> %32, %35
  %37 = fmul <4 x double> %28, %36
  %38 = fmul <4 x double> %36, %37
  %39 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %38
  %40 = fmul <4 x double> %36, %39
  %41 = fmul <4 x double> %10, %40
  %42 = bitcast <4 x double> %41 to <4 x i64>
  %43 = and <4 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %41, %44
  %46 = fmul <4 x double> %41, %41
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fmul <4 x double> %45, %44
  %52 = fmul <4 x double> %45, %45
  %53 = fadd <4 x double> %47, %50
  %54 = fadd <4 x double> %51, %53
  %55 = fadd <4 x double> %51, %54
  %56 = fadd <4 x double> %52, %55
  %57 = fadd <4 x double> %10, %46
  %58 = fsub <4 x double> %57, %10
  %59 = fsub <4 x double> %57, %58
  %60 = fsub <4 x double> %10, %59
  %61 = fsub <4 x double> %46, %58
  %62 = fadd <4 x double> %61, %60
  %63 = fadd <4 x double> %62, %56
  %64 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %41
  %65 = bitcast <4 x double> %64 to <4 x i64>
  %66 = and <4 x i64> %65, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fsub <4 x double> %64, %67
  %69 = fmul <4 x double> %44, %67
  %70 = fmul <4 x double> %68, %44
  %71 = fmul <4 x double> %45, %67
  %72 = fmul <4 x double> %45, %68
  %73 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %69
  %74 = fsub <4 x double> %73, %70
  %75 = fsub <4 x double> %74, %71
  %76 = fsub <4 x double> %75, %72
  %77 = fmul <4 x double> %64, %76
  %78 = bitcast <4 x double> %57 to <4 x i64>
  %79 = and <4 x i64> %78, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fsub <4 x double> %57, %80
  %82 = fmul <4 x double> %64, %57
  %83 = fmul <4 x double> %67, %80
  %84 = bitcast <4 x double> %82 to <4 x i64>
  %85 = xor <4 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fmul <4 x double> %81, %67
  %88 = fmul <4 x double> %68, %80
  %89 = fmul <4 x double> %68, %81
  %90 = fmul <4 x double> %57, %77
  %91 = fmul <4 x double> %64, %63
  %92 = fadd <4 x double> %83, %86
  %93 = fadd <4 x double> %87, %92
  %94 = fadd <4 x double> %88, %93
  %95 = fadd <4 x double> %89, %94
  %96 = fadd <4 x double> %95, %90
  %97 = fadd <4 x double> %91, %96
  %98 = fadd <4 x double> %82, %97
  %99 = fmul <4 x double> %11, %98
  %100 = fcmp oeq <4 x double> %10, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %101 = sext <4 x i1> %100 to <4 x i64>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %99, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %102) #6
  %104 = fcmp oeq <4 x double> %10, zeroinitializer
  %105 = sext <4 x i1> %104 to <4 x i64>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %103, <4 x double> %10, <4 x double> %106) #6
  ret <4 x double> %107
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_hypotd4_u05avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %5, <4 x double> %8) #6
  %10 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %5, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %10, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %12 = fmul <4 x double> %9, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %12, <4 x double> %11) #6
  %14 = fmul <4 x double> %10, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> %14, <4 x double> %11) #6
  %16 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %15
  %17 = bitcast <4 x double> %15 to <4 x i64>
  %18 = and <4 x i64> %17, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %19 = bitcast <4 x i64> %18 to <4 x double>
  %20 = fsub <4 x double> %15, %19
  %21 = bitcast <4 x double> %16 to <4 x i64>
  %22 = and <4 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = fsub <4 x double> %16, %23
  %25 = bitcast <4 x double> %13 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %13, %27
  %29 = fmul <4 x double> %13, %16
  %30 = fmul <4 x double> %27, %23
  %31 = fsub <4 x double> %30, %29
  %32 = fmul <4 x double> %24, %27
  %33 = fmul <4 x double> %28, %23
  %34 = fmul <4 x double> %28, %24
  %35 = fmul <4 x double> %19, %23
  %36 = fmul <4 x double> %24, %19
  %37 = fmul <4 x double> %20, %23
  %38 = fmul <4 x double> %20, %24
  %39 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %35
  %40 = fsub <4 x double> %39, %36
  %41 = fsub <4 x double> %40, %37
  %42 = fsub <4 x double> %41, %38
  %43 = fmul <4 x double> %29, %42
  %44 = fadd <4 x double> %31, %32
  %45 = fadd <4 x double> %33, %44
  %46 = fadd <4 x double> %34, %45
  %47 = fadd <4 x double> %46, %43
  %48 = fmul <4 x double> %29, zeroinitializer
  %49 = fsub <4 x double> zeroinitializer, %48
  %50 = fmul <4 x double> %16, %49
  %51 = fadd <4 x double> %50, %47
  %52 = bitcast <4 x double> %29 to <4 x i64>
  %53 = and <4 x i64> %52, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %54 = bitcast <4 x i64> %53 to <4 x double>
  %55 = fsub <4 x double> %29, %54
  %56 = fmul <4 x double> %29, %29
  %57 = fmul <4 x double> %54, %54
  %58 = bitcast <4 x double> %56 to <4 x i64>
  %59 = xor <4 x i64> %58, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %60 = bitcast <4 x i64> %59 to <4 x double>
  %61 = fadd <4 x double> %54, %54
  %62 = fmul <4 x double> %61, %55
  %63 = fmul <4 x double> %55, %55
  %64 = fadd <4 x double> %51, %51
  %65 = fmul <4 x double> %29, %64
  %66 = fadd <4 x double> %57, %60
  %67 = fadd <4 x double> %66, %62
  %68 = fadd <4 x double> %63, %67
  %69 = fadd <4 x double> %68, %65
  %70 = fadd <4 x double> %56, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %71 = fsub <4 x double> %70, %56
  %72 = fsub <4 x double> %70, %71
  %73 = fsub <4 x double> %56, %72
  %74 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %71
  %75 = fadd <4 x double> %74, %73
  %76 = fadd <4 x double> %75, %69
  %77 = fadd <4 x double> %70, %76
  %78 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %77) #6
  %79 = bitcast <4 x double> %78 to <4 x i64>
  %80 = and <4 x i64> %79, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %81 = bitcast <4 x i64> %80 to <4 x double>
  %82 = fsub <4 x double> %78, %81
  %83 = fmul <4 x double> %78, %78
  %84 = fmul <4 x double> %81, %81
  %85 = bitcast <4 x double> %83 to <4 x i64>
  %86 = xor <4 x i64> %85, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %87 = bitcast <4 x i64> %86 to <4 x double>
  %88 = fmul <4 x double> %82, %81
  %89 = fmul <4 x double> %82, %82
  %90 = fadd <4 x double> %84, %87
  %91 = fadd <4 x double> %88, %90
  %92 = fadd <4 x double> %88, %91
  %93 = fadd <4 x double> %89, %92
  %94 = fadd <4 x double> %83, %70
  %95 = fsub <4 x double> %94, %70
  %96 = fsub <4 x double> %94, %95
  %97 = fsub <4 x double> %70, %96
  %98 = fsub <4 x double> %83, %95
  %99 = fadd <4 x double> %98, %97
  %100 = fadd <4 x double> %93, %76
  %101 = fadd <4 x double> %99, %100
  %102 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %78
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = and <4 x i64> %103, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fsub <4 x double> %102, %105
  %107 = fmul <4 x double> %81, %105
  %108 = fmul <4 x double> %106, %81
  %109 = fmul <4 x double> %82, %105
  %110 = fmul <4 x double> %82, %106
  %111 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %107
  %112 = fsub <4 x double> %111, %108
  %113 = fsub <4 x double> %112, %109
  %114 = fsub <4 x double> %113, %110
  %115 = fmul <4 x double> %102, %114
  %116 = bitcast <4 x double> %94 to <4 x i64>
  %117 = and <4 x i64> %116, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %118 = bitcast <4 x i64> %117 to <4 x double>
  %119 = fsub <4 x double> %94, %118
  %120 = fmul <4 x double> %102, %94
  %121 = fmul <4 x double> %105, %118
  %122 = bitcast <4 x double> %120 to <4 x i64>
  %123 = xor <4 x i64> %122, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %124 = bitcast <4 x i64> %123 to <4 x double>
  %125 = fmul <4 x double> %119, %105
  %126 = fmul <4 x double> %106, %118
  %127 = fmul <4 x double> %106, %119
  %128 = fmul <4 x double> %94, %115
  %129 = fmul <4 x double> %102, %101
  %130 = fadd <4 x double> %121, %124
  %131 = fadd <4 x double> %125, %130
  %132 = fadd <4 x double> %126, %131
  %133 = fadd <4 x double> %127, %132
  %134 = fadd <4 x double> %128, %133
  %135 = fadd <4 x double> %134, %129
  %136 = fmul <4 x double> %120, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %137 = fmul <4 x double> %135, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %138 = bitcast <4 x double> %136 to <4 x i64>
  %139 = and <4 x i64> %138, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = fsub <4 x double> %136, %140
  %142 = bitcast <4 x double> %10 to <4 x i64>
  %143 = and <4 x i64> %142, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = fsub <4 x double> %10, %144
  %146 = fmul <4 x double> %10, %136
  %147 = fmul <4 x double> %144, %140
  %148 = bitcast <4 x double> %146 to <4 x i64>
  %149 = xor <4 x i64> %148, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fmul <4 x double> %141, %144
  %152 = fmul <4 x double> %145, %140
  %153 = fmul <4 x double> %145, %141
  %154 = fmul <4 x double> %10, %137
  %155 = fadd <4 x double> %147, %150
  %156 = fadd <4 x double> %151, %155
  %157 = fadd <4 x double> %152, %156
  %158 = fadd <4 x double> %153, %157
  %159 = fadd <4 x double> %158, %154
  %160 = fadd <4 x double> %146, %159
  %161 = fcmp uno <4 x double> %160, zeroinitializer
  %162 = sext <4 x i1> %161 to <4 x i64>
  %163 = bitcast <4 x i64> %162 to <4 x double>
  %164 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %160, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %163) #6
  %165 = fcmp oeq <4 x double> %9, zeroinitializer
  %166 = sext <4 x i1> %165 to <4 x i64>
  %167 = bitcast <4 x i64> %166 to <4 x double>
  %168 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %164, <4 x double> %10, <4 x double> %167) #6
  %169 = fcmp uno <4 x double> %8, %5
  %170 = sext <4 x i1> %169 to <4 x i64>
  %171 = bitcast <4 x i64> %170 to <4 x double>
  %172 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %168, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %171) #6
  %173 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %174 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %175 = or <4 x i1> %174, %173
  %176 = sext <4 x i1> %175 to <4 x i64>
  %177 = bitcast <4 x i64> %176 to <4 x double>
  %178 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %172, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %177) #6
  ret <4 x double> %178
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_hypotd4_u35avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %5, <4 x double> %8) #6
  %10 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %5, <4 x double> %8) #6
  %11 = fdiv <4 x double> %9, %10
  %12 = fmul <4 x double> %11, %11
  %13 = fadd <4 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %13) #6
  %15 = fmul <4 x double> %10, %14
  %16 = fcmp oeq <4 x double> %9, zeroinitializer
  %17 = sext <4 x i1> %16 to <4 x i64>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> %10, <4 x double> %18) #6
  %20 = fcmp uno <4 x double> %8, %5
  %21 = sext <4 x i1> %20 to <4 x i64>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %19, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %22) #6
  %24 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %25 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %26 = or <4 x i1> %25, %24
  %27 = sext <4 x i1> %26 to <4 x i64>
  %28 = bitcast <4 x i64> %27 to <4 x double>
  %29 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %28) #6
  ret <4 x double> %29
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_fmodd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %10 = fmul <4 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %12, <4 x double> %9) #6
  %14 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %15 = bitcast <4 x double> %14 to <4 x i64>
  %16 = add <4 x i64> %15, <i64 -1, i64 -1, i64 -1, i64 -1>
  %17 = bitcast <4 x i64> %16 to <4 x double>
  %18 = fcmp oeq <4 x double> %14, zeroinitializer
  %19 = sext <4 x i1> %18 to <4 x i64>
  %20 = bitcast <4 x i64> %19 to <4 x double>
  %21 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %17, <4 x double> zeroinitializer, <4 x double> %20) #6
  %22 = fmul <4 x double> %13, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %23 = fadd <4 x double> %13, %13
  %24 = bitcast <4 x double> %13 to <4 x i64>
  %25 = xor <4 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = bitcast <4 x i64> %25 to <4 x double>
  %27 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <4 x i64> %27 to <4 x double>
  %29 = fsub <4 x double> %26, %28
  br label %30

; <label>:30:                                     ; preds = %30, %2
  %31 = phi i32 [ 0, %2 ], [ %92, %30 ]
  %32 = phi <4 x double> [ zeroinitializer, %2 ], [ %84, %30 ]
  %33 = phi <4 x double> [ %11, %2 ], [ %82, %30 ]
  %34 = bitcast <4 x double> %33 to <4 x i64>
  %35 = add <4 x i64> %34, <i64 -1, i64 -1, i64 -1, i64 -1>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fcmp oeq <4 x double> %33, zeroinitializer
  %38 = sext <4 x i1> %37 to <4 x i64>
  %39 = bitcast <4 x i64> %38 to <4 x double>
  %40 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %36, <4 x double> zeroinitializer, <4 x double> %39) #6
  %41 = fmul <4 x double> %21, %40
  %42 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %41, i32 11) #6
  %43 = bitcast <4 x double> %42 to <4 x i64>
  %44 = and <4 x i64> %43, <i64 -2, i64 -2, i64 -2, i64 -2>
  %45 = bitcast <4 x i64> %44 to <4 x double>
  %46 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %22, <4 x double> %33, i8 30) #6
  %47 = bitcast <4 x double> %46 to <4 x i64>
  %48 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %33, <4 x double> %13, i8 29) #6
  %49 = bitcast <4 x double> %48 to <4 x i64>
  %50 = and <4 x i64> %49, %47
  %51 = bitcast <4 x i64> %50 to <4 x double>
  %52 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %45, <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, <4 x double> %51) #6
  %53 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %23, <4 x double> %33, i8 30) #6
  %54 = bitcast <4 x double> %53 to <4 x i64>
  %55 = and <4 x i64> %54, %49
  %56 = bitcast <4 x i64> %55 to <4 x double>
  %57 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %52, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %56) #6
  %58 = bitcast <4 x double> %57 to <4 x i64>
  %59 = and <4 x i64> %58, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %60 = bitcast <4 x i64> %59 to <4 x double>
  %61 = fsub <4 x double> %57, %60
  %62 = fmul <4 x double> %57, %26
  %63 = fmul <4 x double> %28, %60
  %64 = bitcast <4 x double> %62 to <4 x i64>
  %65 = xor <4 x i64> %64, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %66 = bitcast <4 x i64> %65 to <4 x double>
  %67 = fmul <4 x double> %61, %28
  %68 = fmul <4 x double> %29, %60
  %69 = fmul <4 x double> %29, %61
  %70 = fadd <4 x double> %63, %66
  %71 = fadd <4 x double> %67, %70
  %72 = fadd <4 x double> %68, %71
  %73 = fadd <4 x double> %69, %72
  %74 = fadd <4 x double> %33, %62
  %75 = fsub <4 x double> %74, %33
  %76 = fsub <4 x double> %74, %75
  %77 = fsub <4 x double> %33, %76
  %78 = fsub <4 x double> %62, %75
  %79 = fadd <4 x double> %78, %77
  %80 = fadd <4 x double> %32, %73
  %81 = fadd <4 x double> %79, %80
  %82 = fadd <4 x double> %74, %81
  %83 = fsub <4 x double> %74, %82
  %84 = fadd <4 x double> %81, %83
  %85 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %82, <4 x double> %13, i8 17) #6
  %86 = bitcast <4 x double> %85 to <4 x i64>
  %87 = shufflevector <4 x i64> %86, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %88 = shufflevector <4 x i64> %86, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %89 = and <2 x i64> %88, %87
  %90 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %89, <2 x i64> <i64 -1, i64 -1>) #6
  %91 = icmp eq i32 %90, 0
  %92 = add nuw nsw i32 %31, 1
  %93 = icmp ult i32 %92, 21
  %94 = and i1 %91, %93
  br i1 %94, label %30, label %95

; <label>:95:                                     ; preds = %30
  %96 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <4 x double> %9) #6
  %97 = fmul <4 x double> %96, %82
  %98 = fadd <4 x double> %82, %84
  %99 = fcmp oeq <4 x double> %98, %13
  %100 = sext <4 x i1> %99 to <4 x i64>
  %101 = bitcast <4 x i64> %100 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %97, <4 x double> zeroinitializer, <4 x double> %101) #6
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = and <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = xor <4 x i64> %104, %103
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %11, <4 x double> %13, i8 17) #6
  %108 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %106, <4 x double> %0, <4 x double> %107) #6
  %109 = fcmp oeq <4 x double> %13, zeroinitializer
  %110 = sext <4 x i1> %109 to <4 x i64>
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %108, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %111) #6
  ret <4 x double> %112
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_remainderd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000>, i8 17) #6
  %10 = fmul <4 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %12, <4 x double> %9) #6
  %14 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <4 x double> %9) #6
  %15 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %16 = fmul <4 x double> %13, <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>
  %17 = fmul <4 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %18 = bitcast <4 x double> %13 to <4 x i64>
  %19 = xor <4 x i64> %18, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = bitcast <4 x i64> %19 to <4 x double>
  %21 = and <4 x i64> %19, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = fsub <4 x double> %20, %22
  br label %24

; <label>:24:                                     ; preds = %2, %54
  %25 = phi i32 [ 0, %2 ], [ %99, %54 ]
  %26 = phi <4 x i64> [ zeroinitializer, %2 ], [ %71, %54 ]
  %27 = phi <4 x double> [ zeroinitializer, %2 ], [ %98, %54 ]
  %28 = phi <4 x double> [ %11, %2 ], [ %96, %54 ]
  %29 = fmul <4 x double> %15, %28
  %30 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %29, i32 8) #6
  %31 = bitcast <4 x double> %30 to <4 x i64>
  %32 = and <4 x i64> %31, <i64 -2, i64 -2, i64 -2, i64 -2>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = bitcast <4 x double> %28 to <4 x i64>
  %35 = and <4 x i64> %34, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %36, <4 x double> %16, i8 17) #6
  %38 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %33, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %37) #6
  %39 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %36, <4 x double> %17, i8 17) #6
  %40 = bitcast <4 x double> %39 to <4 x i64>
  %41 = fcmp oeq <4 x double> %17, %36
  %42 = xor <4 x i64> %26, <i64 -1, i64 -1, i64 -1, i64 -1>
  %43 = select <4 x i1> %41, <4 x i64> %42, <4 x i64> zeroinitializer
  %44 = or <4 x i64> %43, %40
  %45 = bitcast <4 x i64> %44 to <4 x double>
  %46 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %38, <4 x double> zeroinitializer, <4 x double> %45) #6
  %47 = fcmp oeq <4 x double> %46, zeroinitializer
  %48 = sext <4 x i1> %47 to <4 x i64>
  %49 = shufflevector <4 x i64> %48, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %50 = shufflevector <4 x i64> %48, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %51 = and <2 x i64> %50, %49
  %52 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %51, <2 x i64> <i64 -1, i64 -1>) #6
  %53 = icmp eq i32 %52, 0
  br i1 %53, label %54, label %101

; <label>:54:                                     ; preds = %24
  %55 = fmul <4 x double> %46, %20
  %56 = bitcast <4 x double> %55 to <4 x i64>
  %57 = and <4 x i64> %56, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fcmp oeq <4 x double> %58, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %60 = sext <4 x i1> %59 to <4 x i64>
  %61 = and <4 x i64> %34, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = xor <4 x i64> %61, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %63 = bitcast <4 x i64> %62 to <4 x double>
  %64 = fadd <4 x double> %46, %63
  %65 = bitcast <4 x i64> %60 to <4 x double>
  %66 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %46, <4 x double> %64, <4 x double> %65) #6
  %67 = fmul <4 x double> %66, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %68 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %67, i32 11) #6
  %69 = fcmp une <4 x double> %68, %67
  %70 = sext <4 x i1> %69 to <4 x i64>
  %71 = xor <4 x i64> %26, %70
  %72 = bitcast <4 x double> %66 to <4 x i64>
  %73 = and <4 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = fsub <4 x double> %66, %74
  %76 = fmul <4 x double> %66, %20
  %77 = fmul <4 x double> %22, %74
  %78 = bitcast <4 x double> %76 to <4 x i64>
  %79 = xor <4 x i64> %78, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fmul <4 x double> %75, %22
  %82 = fmul <4 x double> %23, %74
  %83 = fmul <4 x double> %23, %75
  %84 = fadd <4 x double> %77, %80
  %85 = fadd <4 x double> %81, %84
  %86 = fadd <4 x double> %82, %85
  %87 = fadd <4 x double> %83, %86
  %88 = fadd <4 x double> %28, %76
  %89 = fsub <4 x double> %88, %28
  %90 = fsub <4 x double> %88, %89
  %91 = fsub <4 x double> %28, %90
  %92 = fsub <4 x double> %76, %89
  %93 = fadd <4 x double> %92, %91
  %94 = fadd <4 x double> %27, %87
  %95 = fadd <4 x double> %93, %94
  %96 = fadd <4 x double> %88, %95
  %97 = fsub <4 x double> %88, %96
  %98 = fadd <4 x double> %95, %97
  %99 = add nuw nsw i32 %25, 1
  %100 = icmp ult i32 %99, 21
  br i1 %100, label %24, label %101

; <label>:101:                                    ; preds = %24, %54
  %102 = phi <4 x double> [ %28, %24 ], [ %96, %54 ]
  %103 = fmul <4 x double> %14, %102
  %104 = bitcast <4 x double> %103 to <4 x i64>
  %105 = and <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %106 = xor <4 x i64> %105, %104
  %107 = bitcast <4 x i64> %106 to <4 x double>
  %108 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %109 = sext <4 x i1> %108 to <4 x i64>
  %110 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %111 = sext <4 x i1> %110 to <4 x i64>
  %112 = bitcast <4 x i64> %111 to <4 x double>
  %113 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %112) #6
  %114 = bitcast <4 x i64> %109 to <4 x double>
  %115 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %107, <4 x double> %113, <4 x double> %114) #6
  %116 = fcmp oeq <4 x double> %13, zeroinitializer
  %117 = sext <4 x i1> %116 to <4 x i64>
  %118 = bitcast <4 x i64> %117 to <4 x double>
  %119 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %115, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %118) #6
  ret <4 x double> %119
}

; Function Attrs: nounwind uwtable
define <4 x double> @Sleef_tgammad4_u10avx(<4 x double>) local_unnamed_addr #2 {
  %2 = alloca %struct.dd2, align 32
  %3 = bitcast %struct.dd2* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %3) #6
  call fastcc void @gammak(%struct.dd2* noalias nonnull %2, <4 x double> %0)
  %4 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 0
  %5 = load <4 x double>, <4 x double>* %4, align 32
  %6 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 1
  %7 = load <4 x double>, <4 x double>* %6, align 32
  %8 = fadd <4 x double> %5, %7
  %9 = fmul <4 x double> %8, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %10 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %9, i32 8) #6
  %11 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %10) #6
  %12 = fmul <4 x double> %10, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %13 = fadd <4 x double> %5, %12
  %14 = fsub <4 x double> %13, %5
  %15 = fsub <4 x double> %13, %14
  %16 = fsub <4 x double> %5, %15
  %17 = fsub <4 x double> %12, %14
  %18 = fadd <4 x double> %17, %16
  %19 = fadd <4 x double> %7, %18
  %20 = fmul <4 x double> %10, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %21 = fadd <4 x double> %20, %13
  %22 = fsub <4 x double> %21, %13
  %23 = fsub <4 x double> %21, %22
  %24 = fsub <4 x double> %13, %23
  %25 = fsub <4 x double> %20, %22
  %26 = fadd <4 x double> %25, %24
  %27 = fadd <4 x double> %26, %19
  %28 = bitcast <4 x double> %21 to <4 x i64>
  %29 = and <4 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <4 x i64> %29 to <4 x double>
  %31 = fsub <4 x double> %21, %30
  %32 = fmul <4 x double> %21, %21
  %33 = fmul <4 x double> %30, %30
  %34 = bitcast <4 x double> %32 to <4 x i64>
  %35 = xor <4 x i64> %34, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fadd <4 x double> %30, %30
  %38 = fmul <4 x double> %37, %31
  %39 = fmul <4 x double> %31, %31
  %40 = fadd <4 x double> %27, %27
  %41 = fmul <4 x double> %21, %40
  %42 = fadd <4 x double> %33, %36
  %43 = fadd <4 x double> %42, %38
  %44 = fadd <4 x double> %39, %43
  %45 = fadd <4 x double> %41, %44
  %46 = and <4 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %47 = bitcast <4 x i64> %46 to <4 x double>
  %48 = fsub <4 x double> %32, %47
  %49 = fmul <4 x double> %32, %32
  %50 = fmul <4 x double> %47, %47
  %51 = bitcast <4 x double> %49 to <4 x i64>
  %52 = xor <4 x i64> %51, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %53 = bitcast <4 x i64> %52 to <4 x double>
  %54 = fadd <4 x double> %47, %47
  %55 = fmul <4 x double> %54, %48
  %56 = fmul <4 x double> %48, %48
  %57 = fadd <4 x double> %45, %45
  %58 = fmul <4 x double> %32, %57
  %59 = fadd <4 x double> %50, %53
  %60 = fadd <4 x double> %59, %55
  %61 = fadd <4 x double> %56, %60
  %62 = fadd <4 x double> %61, %58
  %63 = fmul <4 x double> %49, %49
  %64 = fmul <4 x double> %21, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %65 = fadd <4 x double> %64, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %66 = fmul <4 x double> %21, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %67 = fadd <4 x double> %66, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %68 = fmul <4 x double> %21, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %69 = fadd <4 x double> %68, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %70 = fmul <4 x double> %32, %67
  %71 = fadd <4 x double> %69, %70
  %72 = fmul <4 x double> %21, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %73 = fadd <4 x double> %72, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %74 = fmul <4 x double> %21, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %75 = fadd <4 x double> %74, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %76 = fmul <4 x double> %32, %73
  %77 = fadd <4 x double> %75, %76
  %78 = fmul <4 x double> %49, %71
  %79 = fadd <4 x double> %77, %78
  %80 = fmul <4 x double> %65, %63
  %81 = fadd <4 x double> %80, %79
  %82 = fmul <4 x double> %21, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %83 = fmul <4 x double> %30, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %84 = bitcast <4 x double> %82 to <4 x i64>
  %85 = xor <4 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fmul <4 x double> %31, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %88 = fmul <4 x double> %30, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %89 = fmul <4 x double> %31, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %90 = fmul <4 x double> %27, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %91 = fadd <4 x double> %83, %86
  %92 = fadd <4 x double> %87, %91
  %93 = fadd <4 x double> %88, %92
  %94 = fadd <4 x double> %89, %93
  %95 = fadd <4 x double> %90, %94
  %96 = fadd <4 x double> %82, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %97 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %96
  %98 = fadd <4 x double> %82, %97
  %99 = fadd <4 x double> %98, %95
  %100 = bitcast <4 x double> %96 to <4 x i64>
  %101 = and <4 x i64> %100, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = fsub <4 x double> %96, %102
  %104 = fmul <4 x double> %21, %96
  %105 = fmul <4 x double> %30, %102
  %106 = bitcast <4 x double> %104 to <4 x i64>
  %107 = xor <4 x i64> %106, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %108 = bitcast <4 x i64> %107 to <4 x double>
  %109 = fmul <4 x double> %103, %30
  %110 = fmul <4 x double> %31, %102
  %111 = fmul <4 x double> %31, %103
  %112 = fmul <4 x double> %96, %27
  %113 = fmul <4 x double> %21, %99
  %114 = fadd <4 x double> %105, %108
  %115 = fadd <4 x double> %109, %114
  %116 = fadd <4 x double> %110, %115
  %117 = fadd <4 x double> %111, %116
  %118 = fadd <4 x double> %112, %117
  %119 = fadd <4 x double> %113, %118
  %120 = fadd <4 x double> %104, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %121 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %120
  %122 = fadd <4 x double> %104, %121
  %123 = fadd <4 x double> %122, %119
  %124 = bitcast <4 x double> %120 to <4 x i64>
  %125 = and <4 x i64> %124, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %126 = bitcast <4 x i64> %125 to <4 x double>
  %127 = fsub <4 x double> %120, %126
  %128 = fmul <4 x double> %21, %120
  %129 = fmul <4 x double> %30, %126
  %130 = bitcast <4 x double> %128 to <4 x i64>
  %131 = xor <4 x i64> %130, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %132 = bitcast <4 x i64> %131 to <4 x double>
  %133 = fmul <4 x double> %127, %30
  %134 = fmul <4 x double> %31, %126
  %135 = fmul <4 x double> %31, %127
  %136 = fmul <4 x double> %120, %27
  %137 = fmul <4 x double> %21, %123
  %138 = fadd <4 x double> %129, %132
  %139 = fadd <4 x double> %133, %138
  %140 = fadd <4 x double> %134, %139
  %141 = fadd <4 x double> %135, %140
  %142 = fadd <4 x double> %136, %141
  %143 = fadd <4 x double> %142, %137
  %144 = fadd <4 x double> %128, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %145 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %144
  %146 = fadd <4 x double> %128, %145
  %147 = fadd <4 x double> %146, %143
  %148 = and <4 x i64> %51, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <4 x i64> %148 to <4 x double>
  %150 = fsub <4 x double> %49, %149
  %151 = bitcast <4 x double> %81 to <4 x i64>
  %152 = and <4 x i64> %151, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %153 = bitcast <4 x i64> %152 to <4 x double>
  %154 = fsub <4 x double> %81, %153
  %155 = fmul <4 x double> %49, %81
  %156 = fmul <4 x double> %149, %153
  %157 = bitcast <4 x double> %155 to <4 x i64>
  %158 = xor <4 x i64> %157, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %159 = bitcast <4 x i64> %158 to <4 x double>
  %160 = fmul <4 x double> %150, %153
  %161 = fmul <4 x double> %154, %149
  %162 = fmul <4 x double> %150, %154
  %163 = fmul <4 x double> %81, %62
  %164 = fadd <4 x double> %156, %159
  %165 = fadd <4 x double> %160, %164
  %166 = fadd <4 x double> %161, %165
  %167 = fadd <4 x double> %162, %166
  %168 = fadd <4 x double> %163, %167
  %169 = fadd <4 x double> %144, %155
  %170 = fsub <4 x double> %144, %169
  %171 = fadd <4 x double> %155, %170
  %172 = fadd <4 x double> %171, %147
  %173 = fadd <4 x double> %168, %172
  %174 = ashr <4 x i32> %11, <i32 1, i32 1, i32 1, i32 1>
  %175 = add nsw <4 x i32> %174, <i32 1023, i32 1023, i32 1023, i32 1023>
  %176 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %177 = shufflevector <4 x i32> %175, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %178 = and <4 x i32> %176, <i32 0, i32 -1, i32 0, i32 -1>
  %179 = shl <4 x i32> %178, <i32 20, i32 20, i32 20, i32 20>
  %180 = and <4 x i32> %177, <i32 0, i32 -1, i32 0, i32 -1>
  %181 = shl <4 x i32> %180, <i32 20, i32 20, i32 20, i32 20>
  %182 = bitcast <4 x i32> %179 to <2 x i64>
  %183 = bitcast <4 x i32> %181 to <2 x i64>
  %184 = shufflevector <2 x i64> %182, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %185 = shufflevector <2 x i64> %183, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %186 = shufflevector <4 x i64> %184, <4 x i64> %185, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %187 = bitcast <4 x i64> %186 to <4 x double>
  %188 = fmul <4 x double> %169, %187
  %189 = sub <4 x i32> %11, %174
  %190 = add <4 x i32> %189, <i32 1023, i32 1023, i32 1023, i32 1023>
  %191 = shufflevector <4 x i32> %190, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %192 = shufflevector <4 x i32> %190, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %193 = and <4 x i32> %191, <i32 0, i32 -1, i32 0, i32 -1>
  %194 = shl <4 x i32> %193, <i32 20, i32 20, i32 20, i32 20>
  %195 = and <4 x i32> %192, <i32 0, i32 -1, i32 0, i32 -1>
  %196 = shl <4 x i32> %195, <i32 20, i32 20, i32 20, i32 20>
  %197 = bitcast <4 x i32> %194 to <2 x i64>
  %198 = bitcast <4 x i32> %196 to <2 x i64>
  %199 = shufflevector <2 x i64> %197, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %200 = shufflevector <2 x i64> %198, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %201 = shufflevector <4 x i64> %199, <4 x i64> %200, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %202 = bitcast <4 x i64> %201 to <4 x double>
  %203 = fmul <4 x double> %188, %202
  %204 = fmul <4 x double> %173, %187
  %205 = fmul <4 x double> %204, %202
  %206 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %207 = bitcast <4 x double> %206 to <4 x i64>
  %208 = bitcast <4 x double> %203 to <4 x i64>
  %209 = xor <4 x i64> %207, <i64 -1, i64 -1, i64 -1, i64 -1>
  %210 = and <4 x i64> %208, %209
  %211 = bitcast <4 x double> %205 to <4 x i64>
  %212 = and <4 x i64> %211, %209
  %213 = bitcast <4 x i64> %210 to <4 x double>
  %214 = bitcast <4 x i64> %212 to <4 x double>
  %215 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 0
  %216 = load <4 x double>, <4 x double>* %215, align 32
  %217 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 1
  %218 = load <4 x double>, <4 x double>* %217, align 32
  %219 = and <4 x i64> %210, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %220 = bitcast <4 x i64> %219 to <4 x double>
  %221 = fsub <4 x double> %213, %220
  %222 = bitcast <4 x double> %216 to <4 x i64>
  %223 = and <4 x i64> %222, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %224 = bitcast <4 x i64> %223 to <4 x double>
  %225 = fsub <4 x double> %216, %224
  %226 = fmul <4 x double> %216, %213
  %227 = fmul <4 x double> %224, %220
  %228 = bitcast <4 x double> %226 to <4 x i64>
  %229 = xor <4 x i64> %228, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %230 = bitcast <4 x i64> %229 to <4 x double>
  %231 = fmul <4 x double> %221, %224
  %232 = fmul <4 x double> %225, %220
  %233 = fmul <4 x double> %225, %221
  %234 = fmul <4 x double> %218, %213
  %235 = fmul <4 x double> %216, %214
  %236 = fadd <4 x double> %227, %230
  %237 = fadd <4 x double> %231, %236
  %238 = fadd <4 x double> %232, %237
  %239 = fadd <4 x double> %233, %238
  %240 = fadd <4 x double> %234, %239
  %241 = fadd <4 x double> %240, %235
  %242 = fadd <4 x double> %226, %241
  %243 = fcmp oeq <4 x double> %0, <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>
  %244 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %245 = bitcast <4 x double> %244 to <4 x i64>
  %246 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 11) #6
  %247 = fcmp oeq <4 x double> %246, %0
  %248 = select <4 x i1> %247, <4 x i64> %245, <4 x i64> zeroinitializer
  %249 = select <4 x i1> %243, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, <4 x i64> %248
  %250 = bitcast <4 x double> %0 to <4 x i64>
  %251 = and <4 x i64> %250, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %252 = bitcast <4 x i64> %251 to <4 x double>
  %253 = fcmp une <4 x double> %252, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %254 = fcmp ord <4 x double> %0, zeroinitializer
  %255 = and <4 x i1> %253, %254
  %256 = fcmp uno <4 x double> %242, zeroinitializer
  %257 = and <4 x i1> %256, %255
  %258 = select <4 x i1> %257, <4 x i64> %245, <4 x i64> zeroinitializer
  %259 = or <4 x i64> %258, %249
  %260 = bitcast <4 x i64> %259 to <4 x double>
  %261 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %242, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %260) #6
  %262 = fcmp oeq <4 x double> %0, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %263 = or <4 x i1> %255, %262
  %264 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000>, i8 29) #6
  %265 = bitcast <4 x double> %264 to <4 x i64>
  %266 = select <4 x i1> %263, <4 x i64> %265, <4 x i64> zeroinitializer
  %267 = fcmp oeq <4 x double> %0, zeroinitializer
  %268 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02>, i8 30) #6
  %269 = bitcast <4 x double> %268 to <4 x i64>
  %270 = fcmp uno <4 x double> %261, zeroinitializer
  %271 = or <4 x i1> %270, %267
  %272 = select <4 x i1> %271, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, <4 x i64> %269
  %273 = and <4 x i64> %272, %266
  %274 = and <4 x i64> %250, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %275 = or <4 x i64> %274, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %276 = bitcast <4 x i64> %275 to <4 x double>
  %277 = bitcast <4 x i64> %273 to <4 x double>
  %278 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %261, <4 x double> %276, <4 x double> %277) #6
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %3) #6
  ret <4 x double> %278
}

; Function Attrs: nounwind uwtable
define internal fastcc void @gammak(%struct.dd2* noalias nocapture, <4 x double>) unnamed_addr #2 {
  %3 = bitcast <4 x double> %1 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> <double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306>, i8 17) #6
  %7 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %1, <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i8 17) #6
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = xor <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %10 = bitcast <4 x i64> %9 to <4 x double>
  %11 = fadd <4 x double> %10, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %12 = fadd <4 x double> %11, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %13 = fsub <4 x double> %11, %12
  %14 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %15 = fsub <4 x double> %10, %12
  %16 = fadd <4 x double> %15, %14
  %17 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %1, <4 x double> %11, <4 x double> %7) #6
  %18 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %16, <4 x double> %7) #6
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %17, <4 x double> zeroinitializer, <4 x double> %6) #6
  %20 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %18, <4 x double> zeroinitializer, <4 x double> %6) #6
  %21 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> %19, i8 18) #6
  %22 = bitcast <4 x double> %21 to <4 x i64>
  %23 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %19, <4 x double> <double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00>, i8 18) #6
  %24 = bitcast <4 x double> %23 to <4 x i64>
  %25 = and <4 x i64> %24, %22
  %26 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> <double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00>, <4 x double> %19, i8 18) #6
  %27 = bitcast <4 x double> %26 to <4 x i64>
  %28 = fadd <4 x double> %19, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %29 = fsub <4 x double> %28, %19
  %30 = fsub <4 x double> %28, %29
  %31 = fsub <4 x double> %19, %30
  %32 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %29
  %33 = fadd <4 x double> %32, %31
  %34 = fadd <4 x double> %20, %33
  %35 = bitcast <4 x double> %28 to <4 x i64>
  %36 = and <4 x i64> %35, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %37 = bitcast <4 x i64> %36 to <4 x double>
  %38 = fsub <4 x double> %28, %37
  %39 = bitcast <4 x double> %19 to <4 x i64>
  %40 = and <4 x i64> %39, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %41 = bitcast <4 x i64> %40 to <4 x double>
  %42 = fsub <4 x double> %19, %41
  %43 = fmul <4 x double> %19, %28
  %44 = fmul <4 x double> %41, %37
  %45 = bitcast <4 x double> %43 to <4 x i64>
  %46 = xor <4 x i64> %45, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %47 = bitcast <4 x i64> %46 to <4 x double>
  %48 = fmul <4 x double> %38, %41
  %49 = fmul <4 x double> %42, %37
  %50 = fmul <4 x double> %42, %38
  %51 = fmul <4 x double> %28, %20
  %52 = fmul <4 x double> %19, %34
  %53 = fadd <4 x double> %44, %47
  %54 = fadd <4 x double> %48, %53
  %55 = fadd <4 x double> %49, %54
  %56 = fadd <4 x double> %50, %55
  %57 = fadd <4 x double> %51, %56
  %58 = fadd <4 x double> %52, %57
  %59 = fadd <4 x double> %43, %58
  %60 = fsub <4 x double> %43, %59
  %61 = fadd <4 x double> %58, %60
  %62 = fadd <4 x double> %19, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %63 = fsub <4 x double> %62, %19
  %64 = fsub <4 x double> %62, %63
  %65 = fsub <4 x double> %19, %64
  %66 = fsub <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %63
  %67 = fadd <4 x double> %66, %65
  %68 = fadd <4 x double> %20, %67
  %69 = bitcast <4 x double> %62 to <4 x i64>
  %70 = and <4 x i64> %69, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %71 = bitcast <4 x i64> %70 to <4 x double>
  %72 = fsub <4 x double> %62, %71
  %73 = bitcast <4 x double> %59 to <4 x i64>
  %74 = and <4 x i64> %73, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %75 = bitcast <4 x i64> %74 to <4 x double>
  %76 = fsub <4 x double> %59, %75
  %77 = fmul <4 x double> %62, %59
  %78 = fmul <4 x double> %71, %75
  %79 = bitcast <4 x double> %77 to <4 x i64>
  %80 = xor <4 x i64> %79, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %81 = bitcast <4 x i64> %80 to <4 x double>
  %82 = fmul <4 x double> %72, %75
  %83 = fmul <4 x double> %76, %71
  %84 = fmul <4 x double> %72, %76
  %85 = fmul <4 x double> %62, %61
  %86 = fmul <4 x double> %68, %59
  %87 = fadd <4 x double> %78, %81
  %88 = fadd <4 x double> %82, %87
  %89 = fadd <4 x double> %83, %88
  %90 = fadd <4 x double> %84, %89
  %91 = fadd <4 x double> %85, %90
  %92 = fadd <4 x double> %86, %91
  %93 = fadd <4 x double> %77, %92
  %94 = fsub <4 x double> %77, %93
  %95 = fadd <4 x double> %92, %94
  %96 = fadd <4 x double> %19, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %97 = fsub <4 x double> %96, %19
  %98 = fsub <4 x double> %96, %97
  %99 = fsub <4 x double> %19, %98
  %100 = fsub <4 x double> <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>, %97
  %101 = fadd <4 x double> %100, %99
  %102 = fadd <4 x double> %20, %101
  %103 = bitcast <4 x double> %96 to <4 x i64>
  %104 = and <4 x i64> %103, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fsub <4 x double> %96, %105
  %107 = bitcast <4 x double> %93 to <4 x i64>
  %108 = and <4 x i64> %107, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %109 = bitcast <4 x i64> %108 to <4 x double>
  %110 = fsub <4 x double> %93, %109
  %111 = fmul <4 x double> %96, %93
  %112 = fmul <4 x double> %105, %109
  %113 = bitcast <4 x double> %111 to <4 x i64>
  %114 = xor <4 x i64> %113, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %115 = bitcast <4 x i64> %114 to <4 x double>
  %116 = fmul <4 x double> %106, %109
  %117 = fmul <4 x double> %110, %105
  %118 = fmul <4 x double> %106, %110
  %119 = fmul <4 x double> %96, %95
  %120 = fmul <4 x double> %102, %93
  %121 = fadd <4 x double> %112, %115
  %122 = fadd <4 x double> %116, %121
  %123 = fadd <4 x double> %117, %122
  %124 = fadd <4 x double> %118, %123
  %125 = fadd <4 x double> %119, %124
  %126 = fadd <4 x double> %120, %125
  %127 = fadd <4 x double> %111, %126
  %128 = fsub <4 x double> %111, %127
  %129 = fadd <4 x double> %126, %128
  %130 = fadd <4 x double> %19, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %131 = fsub <4 x double> %130, %19
  %132 = fsub <4 x double> %130, %131
  %133 = fsub <4 x double> %19, %132
  %134 = fsub <4 x double> <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>, %131
  %135 = fadd <4 x double> %134, %133
  %136 = fadd <4 x double> %20, %135
  %137 = bitcast <4 x double> %130 to <4 x i64>
  %138 = and <4 x i64> %137, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %139 = bitcast <4 x i64> %138 to <4 x double>
  %140 = fsub <4 x double> %130, %139
  %141 = bitcast <4 x double> %127 to <4 x i64>
  %142 = and <4 x i64> %141, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %143 = bitcast <4 x i64> %142 to <4 x double>
  %144 = fsub <4 x double> %127, %143
  %145 = fmul <4 x double> %130, %127
  %146 = fmul <4 x double> %139, %143
  %147 = bitcast <4 x double> %145 to <4 x i64>
  %148 = xor <4 x i64> %147, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %149 = bitcast <4 x i64> %148 to <4 x double>
  %150 = fmul <4 x double> %140, %143
  %151 = fmul <4 x double> %144, %139
  %152 = fmul <4 x double> %140, %144
  %153 = fmul <4 x double> %130, %129
  %154 = fmul <4 x double> %136, %127
  %155 = fadd <4 x double> %146, %149
  %156 = fadd <4 x double> %150, %155
  %157 = fadd <4 x double> %151, %156
  %158 = fadd <4 x double> %152, %157
  %159 = fadd <4 x double> %153, %158
  %160 = fadd <4 x double> %154, %159
  %161 = fadd <4 x double> %145, %160
  %162 = fsub <4 x double> %145, %161
  %163 = fadd <4 x double> %160, %162
  %164 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %19, <4 x double> <double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00>, i8 18) #6
  %165 = bitcast <4 x double> %164 to <4 x i64>
  %166 = and <4 x i64> %165, %27
  %167 = bitcast <4 x i64> %166 to <4 x double>
  %168 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %161, <4 x double> %167) #6
  %169 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %163, <4 x double> %167) #6
  %170 = fadd <4 x double> %19, <double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00>
  %171 = fsub <4 x double> %170, %19
  %172 = fsub <4 x double> %170, %171
  %173 = fsub <4 x double> %19, %172
  %174 = fsub <4 x double> <double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00>, %171
  %175 = fadd <4 x double> %174, %173
  %176 = fadd <4 x double> %20, %175
  %177 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %19, <4 x double> %170, <4 x double> %167) #6
  %178 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %20, <4 x double> %176, <4 x double> %167) #6
  %179 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %177
  %180 = bitcast <4 x i64> %25 to <4 x double>
  %181 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <4 x double> %180) #6
  %182 = fadd <4 x double> %177, %181
  %183 = fsub <4 x double> %182, %177
  %184 = fsub <4 x double> %182, %183
  %185 = fsub <4 x double> %177, %184
  %186 = fsub <4 x double> %181, %183
  %187 = fadd <4 x double> %186, %185
  %188 = fadd <4 x double> %178, %187
  %189 = fadd <4 x double> %182, %188
  %190 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %189, <4 x double> %179, <4 x double> %26) #6
  %191 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E72FDC6CB0D558F, double 0x3E72FDC6CB0D558F, double 0x3E72FDC6CB0D558F, double 0x3E72FDC6CB0D558F>, <4 x double> <double 0x403D7AAABC7A3EA1, double 0x403D7AAABC7A3EA1, double 0x403D7AAABC7A3EA1, double 0x403D7AAABC7A3EA1>, <4 x double> %180) #6
  %192 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %191, <4 x double> <double 0xC06399A52C414C0D, double 0xC06399A52C414C0D, double 0xC06399A52C414C0D, double 0xC06399A52C414C0D>, <4 x double> %26) #6
  %193 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E9AE7D44E1AB8F6, double 0x3E9AE7D44E1AB8F6, double 0x3E9AE7D44E1AB8F6, double 0x3E9AE7D44E1AB8F6>, <4 x double> <double 0x406004ABC79048B9, double 0x406004ABC79048B9, double 0x406004ABC79048B9, double 0x406004ABC79048B9>, <4 x double> %180) #6
  %194 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %193, <4 x double> <double 0x3FF1EED0A9756022, double 0x3FF1EED0A9756022, double 0x3FF1EED0A9756022, double 0x3FF1EED0A9756022>, <4 x double> %26) #6
  %195 = fmul <4 x double> %190, %192
  %196 = fadd <4 x double> %195, %194
  %197 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EB1734224875A66, double 0x3EB1734224875A66, double 0x3EB1734224875A66, double 0x3EB1734224875A66>, <4 x double> <double 0x40705C120870277A, double 0x40705C120870277A, double 0x40705C120870277A, double 0x40705C120870277A>, <4 x double> %180) #6
  %198 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %197, <4 x double> <double 0x402ACBC4BFE43E00, double 0x402ACBC4BFE43E00, double 0x402ACBC4BFE43E00, double 0x402ACBC4BFE43E00>, <4 x double> %26) #6
  %199 = fmul <4 x double> %190, %196
  %200 = fadd <4 x double> %199, %198
  %201 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EB94E4F6E12FEE0, double 0x3EB94E4F6E12FEE0, double 0x3EB94E4F6E12FEE0, double 0x3EB94E4F6E12FEE0>, <4 x double> <double 0x40748B3C8FCAD7FF, double 0x40748B3C8FCAD7FF, double 0x40748B3C8FCAD7FF, double 0x40748B3C8FCAD7FF>, <4 x double> %180) #6
  %202 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %201, <4 x double> <double 0xBFBDD5FA0E771B94, double 0xBFBDD5FA0E771B94, double 0xBFBDD5FA0E771B94, double 0xBFBDD5FA0E771B94>, <4 x double> %26) #6
  %203 = fmul <4 x double> %190, %200
  %204 = fadd <4 x double> %203, %202
  %205 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EB59C884A045AF0, double 0x3EB59C884A045AF0, double 0x3EB59C884A045AF0, double 0x3EB59C884A045AF0>, <4 x double> <double 0x40719D088C23DF05, double 0x40719D088C23DF05, double 0x40719D088C23DF05, double 0x40719D088C23DF05>, <4 x double> %180) #6
  %206 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %205, <4 x double> <double 0xBFF644D13921C967, double 0xBFF644D13921C967, double 0xBFF644D13921C967, double 0xBFF644D13921C967>, <4 x double> %26) #6
  %207 = fmul <4 x double> %190, %204
  %208 = fadd <4 x double> %207, %206
  %209 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E9FD66B0AC39DFF, double 0x3E9FD66B0AC39DFF, double 0x3E9FD66B0AC39DFF, double 0x3E9FD66B0AC39DFF>, <4 x double> <double 0x40659BBECDBF523B, double 0x40659BBECDBF523B, double 0x40659BBECDBF523B, double 0x40659BBECDBF523B>, <4 x double> %180) #6
  %210 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %209, <4 x double> <double 0x3F8ED5BD48E4F389, double 0x3F8ED5BD48E4F389, double 0x3F8ED5BD48E4F389, double 0x3F8ED5BD48E4F389>, <4 x double> %26) #6
  %211 = fmul <4 x double> %190, %208
  %212 = fadd <4 x double> %211, %210
  %213 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE71986F7AC19AC9, double 0xBE71986F7AC19AC9, double 0xBE71986F7AC19AC9, double 0xBE71986F7AC19AC9>, <4 x double> <double 0x40535F30DE19A3FA, double 0x40535F30DE19A3FA, double 0x40535F30DE19A3FA, double 0x40535F30DE19A3FA>, <4 x double> %180) #6
  %214 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %213, <4 x double> <double 0x3FC6FB2BA98C8BC4, double 0x3FC6FB2BA98C8BC4, double 0x3FC6FB2BA98C8BC4, double 0x3FC6FB2BA98C8BC4>, <4 x double> %26) #6
  %215 = fmul <4 x double> %190, %212
  %216 = fadd <4 x double> %215, %214
  %217 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE956718120CF4B7, double 0xBE956718120CF4B7, double 0xBE956718120CF4B7, double 0xBE956718120CF4B7>, <4 x double> <double 0x403920E9BAC7B07E, double 0x403920E9BAC7B07E, double 0x403920E9BAC7B07E, double 0x403920E9BAC7B07E>, <4 x double> %180) #6
  %218 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %217, <4 x double> <double 0xBF645497F334CD1D, double 0xBF645497F334CD1D, double 0xBF645497F334CD1D, double 0xBF645497F334CD1D>, <4 x double> %26) #6
  %219 = fmul <4 x double> %190, %216
  %220 = fadd <4 x double> %219, %218
  %221 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E823D16D999C674, double 0x3E823D16D999C674, double 0x3E823D16D999C674, double 0x3E823D16D999C674>, <4 x double> <double 0x40171131F32ACF74, double 0x40171131F32ACF74, double 0x40171131F32ACF74, double 0x40171131F32ACF74>, <4 x double> %180) #6
  %222 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %221, <4 x double> <double 0xBF9E3C8E8BED86BB, double 0xBF9E3C8E8BED86BB, double 0xBF9E3C8E8BED86BB, double 0xBF9E3C8E8BED86BB>, <4 x double> %26) #6
  %223 = fmul <4 x double> %190, %220
  %224 = fadd <4 x double> %223, %222
  %225 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE9D26D12E073976, double 0xBE9D26D12E073976, double 0xBE9D26D12E073976, double 0xBE9D26D12E073976>, <4 x double> <double 0x3FE743CF466BEB1B, double 0x3FE743CF466BEB1B, double 0x3FE743CF466BEB1B, double 0x3FE743CF466BEB1B>, <4 x double> %180) #6
  %226 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %225, <4 x double> <double 0x3F41B33B019B3E6F, double 0x3F41B33B019B3E6F, double 0x3F41B33B019B3E6F, double 0x3F41B33B019B3E6F>, <4 x double> %26) #6
  %227 = fmul <4 x double> %190, %224
  %228 = fadd <4 x double> %227, %226
  %229 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EB050C384661C46, double 0x3EB050C384661C46, double 0x3EB050C384661C46, double 0x3EB050C384661C46>, <4 x double> <double 0x3FB57EDE06D746AF, double 0x3FB57EDE06D746AF, double 0x3FB57EDE06D746AF, double 0x3FB57EDE06D746AF>, <4 x double> %180) #6
  %230 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %229, <4 x double> <double 0x3F7A3A699F4A401B, double 0x3F7A3A699F4A401B, double 0x3F7A3A699F4A401B, double 0x3F7A3A699F4A401B>, <4 x double> %26) #6
  %231 = fmul <4 x double> %190, %228
  %232 = fadd <4 x double> %231, %230
  %233 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBEC1162DF3C28D5A, double 0xBEC1162DF3C28D5A, double 0xBEC1162DF3C28D5A, double 0xBEC1162DF3C28D5A>, <4 x double> <double 0xBFB50586EF5B83AC, double 0xBFB50586EF5B83AC, double 0xBFB50586EF5B83AC, double 0xBFB50586EF5B83AC>, <4 x double> %180) #6
  %234 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %233, <4 x double> <double 0xBF254D241144693F, double 0xBF254D241144693F, double 0xBF254D241144693F, double 0xBF254D241144693F>, <4 x double> %26) #6
  %235 = fmul <4 x double> %190, %232
  %236 = fadd <4 x double> %235, %234
  %237 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3ED257DCE81F6BB4, double 0x3ED257DCE81F6BB4, double 0x3ED257DCE81F6BB4, double 0x3ED257DCE81F6BB4>, <4 x double> <double 0x3FB17B57DDB9E32F, double 0x3FB17B57DDB9E32F, double 0x3FB17B57DDB9E32F, double 0x3FB17B57DDB9E32F>, <4 x double> %180) #6
  %238 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %237, <4 x double> <double 0xBF5F5DBCAF756CDE, double 0xBF5F5DBCAF756CDE, double 0xBF5F5DBCAF756CDE, double 0xBF5F5DBCAF756CDE>, <4 x double> %26) #6
  %239 = fmul <4 x double> %190, %236
  %240 = fadd <4 x double> %239, %238
  %241 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBEE3CC0905ECA8BE, double 0xBEE3CC0905ECA8BE, double 0xBEE3CC0905ECA8BE, double 0xBEE3CC0905ECA8BE>, <4 x double> <double 0xBFB3BE73A742EECE, double 0xBFB3BE73A742EECE, double 0xBFB3BE73A742EECE, double 0xBFB3BE73A742EECE>, <4 x double> %180) #6
  %242 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %241, <4 x double> <double 0x3F12E31F9B7913EA, double 0x3F12E31F9B7913EA, double 0x3F12E31F9B7913EA, double 0x3F12E31F9B7913EA>, <4 x double> %26) #6
  %243 = fmul <4 x double> %190, %240
  %244 = fadd <4 x double> %243, %242
  %245 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EF580E0E2726AC9, double 0x3EF580E0E2726AC9, double 0x3EF580E0E2726AC9, double 0x3EF580E0E2726AC9>, <4 x double> <double 0x3FB5580F0BB1F8CA, double 0x3FB5580F0BB1F8CA, double 0x3FB5580F0BB1F8CA, double 0x3FB5580F0BB1F8CA>, <4 x double> %180) #6
  %246 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %245, <4 x double> <double 0x3F4B8239C670E690, double 0x3F4B8239C670E690, double 0x3F4B8239C670E690, double 0x3F4B8239C670E690>, <4 x double> %26) #6
  %247 = fmul <4 x double> %190, %244
  %248 = fadd <4 x double> %247, %246
  %249 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF078DE48A7816D9, double 0xBF078DE48A7816D9, double 0xBF078DE48A7816D9, double 0xBF078DE48A7816D9>, <4 x double> <double 0xBFB74879E96382CA, double 0xBFB74879E96382CA, double 0xBFB74879E96382CA, double 0xBFB74879E96382CA>, <4 x double> %180) #6
  %250 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %249, <4 x double> <double 0xBF0B1D75D3346711, double 0xBF0B1D75D3346711, double 0xBF0B1D75D3346711, double 0xBF0B1D75D3346711>, <4 x double> %26) #6
  %251 = fmul <4 x double> %190, %248
  %252 = fadd <4 x double> %251, %250
  %253 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F1A127B0D3DBB7D, double 0x3F1A127B0D3DBB7D, double 0x3F1A127B0D3DBB7D, double 0x3F1A127B0D3DBB7D>, <4 x double> <double 0x3FB9A0212305C3B9, double 0x3FB9A0212305C3B9, double 0x3FB9A0212305C3B9, double 0x3FB9A0212305C3B9>, <4 x double> %180) #6
  %254 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %253, <4 x double> <double 0xBF436773BDB97B48, double 0xBF436773BDB97B48, double 0xBF436773BDB97B48, double 0xBF436773BDB97B48>, <4 x double> %26) #6
  %255 = fmul <4 x double> %190, %252
  %256 = fadd <4 x double> %255, %254
  %257 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF2D3FD4CA9D6B1F, double 0xBF2D3FD4CA9D6B1F, double 0xBF2D3FD4CA9D6B1F, double 0xBF2D3FD4CA9D6B1F>, <4 x double> <double 0xBFBC80675DF4ED19, double 0xBFBC80675DF4ED19, double 0xBFBC80675DF4ED19, double 0xBFBC80675DF4ED19>, <4 x double> %180) #6
  %258 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %257, <4 x double> <double 0x3F1247604839C038, double 0x3F1247604839C038, double 0x3F1247604839C038, double 0x3F1247604839C038>, <4 x double> %26) #6
  %259 = fmul <4 x double> %190, %256
  %260 = fadd <4 x double> %259, %258
  %261 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F40B36AF85EF785, double 0x3F40B36AF85EF785, double 0x3F40B36AF85EF785, double 0x3F40B36AF85EF785>, <4 x double> <double 0x3FC010B3663D08D8, double 0x3FC010B3663D08D8, double 0x3FC010B3663D08D8, double 0x3FC010B3663D08D8>, <4 x double> %180) #6
  %262 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %261, <4 x double> <double 0x3F49B0FF6874F2C4, double 0x3F49B0FF6874F2C4, double 0x3F49B0FF6874F2C4, double 0x3F49B0FF6874F2C4>, <4 x double> %26) #6
  %263 = fmul <4 x double> %190, %260
  %264 = fadd <4 x double> %263, %262
  %265 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF538AC5C2BD10CA, double 0xBF538AC5C2BD10CA, double 0xBF538AC5C2BD10CA, double 0xBF538AC5C2BD10CA>, <4 x double> <double 0xBFC2703A1DD72363, double 0xBFC2703A1DD72363, double 0xBFC2703A1DD72363, double 0xBFC2703A1DD72363>, <4 x double> %180) #6
  %266 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %265, <4 x double> <double 0xBF2E13CE465FA859, double 0xBF2E13CE465FA859, double 0xBF2E13CE465FA859, double 0xBF2E13CE465FA859>, <4 x double> %26) #6
  %267 = fmul <4 x double> %190, %264
  %268 = fadd <4 x double> %267, %266
  %269 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F67ADD6EADB7260, double 0x3F67ADD6EADB7260, double 0x3F67ADD6EADB7260, double 0x3F67ADD6EADB7260>, <4 x double> <double 0x3FC5B40CB1047E2E, double 0x3FC5B40CB1047E2E, double 0x3FC5B40CB1047E2E, double 0x3FC5B40CB1047E2E>, <4 x double> %180) #6
  %270 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %269, <4 x double> <double 0xBF65F7268EDAB4C8, double 0xBF65F7268EDAB4C8, double 0xBF65F7268EDAB4C8, double 0xBF65F7268EDAB4C8>, <4 x double> %26) #6
  %271 = fmul <4 x double> %190, %268
  %272 = fadd <4 x double> %271, %270
  %273 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF7E404FC218F817, double 0xBF7E404FC218F817, double 0xBF7E404FC218F817, double 0xBF7E404FC218F817>, <4 x double> <double 0xBFCA8B9C17AA3C08, double 0xBFCA8B9C17AA3C08, double 0xBFCA8B9C17AA3C08, double 0xBFCA8B9C17AA3C08>, <4 x double> %180) #6
  %274 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %273, <4 x double> <double 0x3F6C71C71C71C71C, double 0x3F6C71C71C71C71C, double 0x3F6C71C71C71C71C, double 0x3F6C71C71C71C71C>, <4 x double> %26) #6
  %275 = fmul <4 x double> %190, %272
  %276 = fadd <4 x double> %275, %274
  %277 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F951322AC7D8485, double 0x3F951322AC7D8485, double 0x3F951322AC7D8485, double 0x3F951322AC7D8485>, <4 x double> <double 0x3FD151322AC7D813, double 0x3FD151322AC7D813, double 0x3FD151322AC7D813, double 0x3FD151322AC7D813>, <4 x double> %180) #6
  %278 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %277, <4 x double> <double 0x3FB5555555555555, double 0x3FB5555555555555, double 0x3FB5555555555555, double 0x3FB5555555555555>, <4 x double> %26) #6
  %279 = fmul <4 x double> %190, %276
  %280 = fadd <4 x double> %279, %278
  %281 = fadd <4 x double> %177, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %282 = fsub <4 x double> %281, %177
  %283 = fsub <4 x double> %281, %282
  %284 = fsub <4 x double> %177, %283
  %285 = fsub <4 x double> <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>, %282
  %286 = fadd <4 x double> %285, %284
  %287 = fadd <4 x double> %178, %286
  %288 = fmul <4 x double> %177, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %289 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %288, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %290 = bitcast <4 x double> %289 to <4 x i64>
  %291 = fmul <4 x double> %288, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %292 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %288, <4 x double> %291, <4 x double> %289) #6
  %293 = bitcast <4 x double> %292 to <4 x i64>
  %294 = shufflevector <4 x i64> %293, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %295 = shufflevector <4 x i64> %293, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %296 = bitcast <2 x i64> %294 to <4 x i32>
  %297 = shufflevector <4 x i32> %296, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %298 = bitcast <4 x i32> %297 to <2 x i64>
  %299 = bitcast <2 x i64> %295 to <4 x i32>
  %300 = shufflevector <4 x i32> %299, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %301 = bitcast <4 x i32> %300 to <2 x i64>
  %302 = shufflevector <2 x i64> %301, <2 x i64> %298, <2 x i32> <i32 2, i32 1>
  %303 = bitcast <2 x i64> %302 to <4 x i32>
  %304 = lshr <4 x i32> %303, <i32 20, i32 20, i32 20, i32 20>
  %305 = and <4 x i64> %290, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %306 = bitcast <4 x i64> %305 to <4 x double>
  %307 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %306) #6
  %308 = bitcast <4 x i32> %307 to <16 x i8>
  %309 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %308) #6
  %310 = bitcast <16 x i8> %309 to <4 x i32>
  %311 = sub <4 x i32> %304, %310
  %312 = sub <4 x i32> zeroinitializer, %311
  %313 = ashr <4 x i32> %312, <i32 1, i32 1, i32 1, i32 1>
  %314 = add nsw <4 x i32> %313, <i32 1023, i32 1023, i32 1023, i32 1023>
  %315 = shufflevector <4 x i32> %314, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %316 = shufflevector <4 x i32> %314, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %317 = and <4 x i32> %315, <i32 0, i32 -1, i32 0, i32 -1>
  %318 = shl <4 x i32> %317, <i32 20, i32 20, i32 20, i32 20>
  %319 = and <4 x i32> %316, <i32 0, i32 -1, i32 0, i32 -1>
  %320 = shl <4 x i32> %319, <i32 20, i32 20, i32 20, i32 20>
  %321 = bitcast <4 x i32> %318 to <2 x i64>
  %322 = bitcast <4 x i32> %320 to <2 x i64>
  %323 = shufflevector <2 x i64> %321, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %324 = shufflevector <2 x i64> %322, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %325 = shufflevector <4 x i64> %323, <4 x i64> %324, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %326 = bitcast <4 x i64> %325 to <4 x double>
  %327 = fmul <4 x double> %177, %326
  %328 = sub <4 x i32> %312, %313
  %329 = add <4 x i32> %328, <i32 1023, i32 1023, i32 1023, i32 1023>
  %330 = shufflevector <4 x i32> %329, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %331 = shufflevector <4 x i32> %329, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %332 = and <4 x i32> %330, <i32 0, i32 -1, i32 0, i32 -1>
  %333 = shl <4 x i32> %332, <i32 20, i32 20, i32 20, i32 20>
  %334 = and <4 x i32> %331, <i32 0, i32 -1, i32 0, i32 -1>
  %335 = shl <4 x i32> %334, <i32 20, i32 20, i32 20, i32 20>
  %336 = bitcast <4 x i32> %333 to <2 x i64>
  %337 = bitcast <4 x i32> %335 to <2 x i64>
  %338 = shufflevector <2 x i64> %336, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %339 = shufflevector <2 x i64> %337, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %340 = shufflevector <4 x i64> %338, <4 x i64> %339, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %341 = bitcast <4 x i64> %340 to <4 x double>
  %342 = fmul <4 x double> %327, %341
  %343 = fmul <4 x double> %178, %326
  %344 = fmul <4 x double> %343, %341
  %345 = fadd <4 x double> %342, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %346 = fsub <4 x double> %345, %342
  %347 = fsub <4 x double> %345, %346
  %348 = fsub <4 x double> %342, %347
  %349 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %346
  %350 = fadd <4 x double> %349, %348
  %351 = fadd <4 x double> %344, %350
  %352 = fadd <4 x double> %342, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %353 = fsub <4 x double> %352, %342
  %354 = fsub <4 x double> %352, %353
  %355 = fsub <4 x double> %342, %354
  %356 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %353
  %357 = fadd <4 x double> %356, %355
  %358 = fadd <4 x double> %344, %357
  %359 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %352
  %360 = bitcast <4 x double> %352 to <4 x i64>
  %361 = and <4 x i64> %360, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %362 = bitcast <4 x i64> %361 to <4 x double>
  %363 = fsub <4 x double> %352, %362
  %364 = bitcast <4 x double> %359 to <4 x i64>
  %365 = and <4 x i64> %364, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %366 = bitcast <4 x i64> %365 to <4 x double>
  %367 = fsub <4 x double> %359, %366
  %368 = bitcast <4 x double> %345 to <4 x i64>
  %369 = and <4 x i64> %368, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %370 = bitcast <4 x i64> %369 to <4 x double>
  %371 = fsub <4 x double> %345, %370
  %372 = fmul <4 x double> %345, %359
  %373 = fmul <4 x double> %370, %366
  %374 = fsub <4 x double> %373, %372
  %375 = fmul <4 x double> %367, %370
  %376 = fmul <4 x double> %371, %366
  %377 = fmul <4 x double> %371, %367
  %378 = fmul <4 x double> %362, %366
  %379 = fmul <4 x double> %367, %362
  %380 = fmul <4 x double> %363, %366
  %381 = fmul <4 x double> %363, %367
  %382 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %378
  %383 = fsub <4 x double> %382, %379
  %384 = fsub <4 x double> %383, %380
  %385 = fsub <4 x double> %384, %381
  %386 = fmul <4 x double> %372, %385
  %387 = fadd <4 x double> %374, %375
  %388 = fadd <4 x double> %376, %387
  %389 = fadd <4 x double> %377, %388
  %390 = fadd <4 x double> %389, %386
  %391 = fmul <4 x double> %372, %358
  %392 = fsub <4 x double> %351, %391
  %393 = fmul <4 x double> %359, %392
  %394 = fadd <4 x double> %393, %390
  %395 = bitcast <4 x double> %372 to <4 x i64>
  %396 = and <4 x i64> %395, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %397 = bitcast <4 x i64> %396 to <4 x double>
  %398 = fsub <4 x double> %372, %397
  %399 = fmul <4 x double> %372, %372
  %400 = fmul <4 x double> %397, %397
  %401 = bitcast <4 x double> %399 to <4 x i64>
  %402 = xor <4 x i64> %401, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %403 = bitcast <4 x i64> %402 to <4 x double>
  %404 = fadd <4 x double> %397, %397
  %405 = fmul <4 x double> %404, %398
  %406 = fmul <4 x double> %398, %398
  %407 = fadd <4 x double> %394, %394
  %408 = fmul <4 x double> %372, %407
  %409 = fadd <4 x double> %400, %403
  %410 = fadd <4 x double> %409, %405
  %411 = fadd <4 x double> %406, %410
  %412 = fadd <4 x double> %411, %408
  %413 = fmul <4 x double> %399, %399
  %414 = fmul <4 x double> %413, %413
  %415 = fmul <4 x double> %399, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %416 = fadd <4 x double> %415, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %417 = fmul <4 x double> %413, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %418 = fadd <4 x double> %417, %416
  %419 = fmul <4 x double> %399, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %420 = fadd <4 x double> %419, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %421 = fmul <4 x double> %399, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %422 = fadd <4 x double> %421, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %423 = fmul <4 x double> %413, %420
  %424 = fadd <4 x double> %422, %423
  %425 = fmul <4 x double> %414, %418
  %426 = fadd <4 x double> %425, %424
  %427 = fmul <4 x double> %399, %426
  %428 = fadd <4 x double> %427, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %429 = sitofp <4 x i32> %311 to <4 x double>
  %430 = bitcast <4 x double> %429 to <4 x i64>
  %431 = and <4 x i64> %430, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %432 = bitcast <4 x i64> %431 to <4 x double>
  %433 = fsub <4 x double> %429, %432
  %434 = fmul <4 x double> %429, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %435 = fmul <4 x double> %432, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %436 = bitcast <4 x double> %434 to <4 x i64>
  %437 = xor <4 x i64> %436, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %438 = bitcast <4 x i64> %437 to <4 x double>
  %439 = fmul <4 x double> %432, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %440 = fmul <4 x double> %433, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %441 = fmul <4 x double> %433, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %442 = fmul <4 x double> %429, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %443 = fadd <4 x double> %435, %438
  %444 = fadd <4 x double> %439, %443
  %445 = fadd <4 x double> %440, %444
  %446 = fadd <4 x double> %441, %445
  %447 = fadd <4 x double> %442, %446
  %448 = fmul <4 x double> %372, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %449 = fmul <4 x double> %394, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %450 = fadd <4 x double> %434, %448
  %451 = fsub <4 x double> %434, %450
  %452 = fadd <4 x double> %448, %451
  %453 = fadd <4 x double> %447, %452
  %454 = fadd <4 x double> %453, %449
  %455 = and <4 x i64> %401, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %456 = bitcast <4 x i64> %455 to <4 x double>
  %457 = fsub <4 x double> %399, %456
  %458 = fmul <4 x double> %372, %399
  %459 = fmul <4 x double> %397, %456
  %460 = bitcast <4 x double> %458 to <4 x i64>
  %461 = xor <4 x i64> %460, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %462 = bitcast <4 x i64> %461 to <4 x double>
  %463 = fmul <4 x double> %457, %397
  %464 = fmul <4 x double> %398, %456
  %465 = fmul <4 x double> %398, %457
  %466 = fmul <4 x double> %399, %394
  %467 = fmul <4 x double> %372, %412
  %468 = fadd <4 x double> %459, %462
  %469 = fadd <4 x double> %463, %468
  %470 = fadd <4 x double> %464, %469
  %471 = fadd <4 x double> %465, %470
  %472 = fadd <4 x double> %471, %466
  %473 = fadd <4 x double> %472, %467
  %474 = and <4 x i64> %460, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %475 = bitcast <4 x i64> %474 to <4 x double>
  %476 = fsub <4 x double> %458, %475
  %477 = bitcast <4 x double> %428 to <4 x i64>
  %478 = and <4 x i64> %477, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %479 = bitcast <4 x i64> %478 to <4 x double>
  %480 = fsub <4 x double> %428, %479
  %481 = fmul <4 x double> %458, %428
  %482 = fmul <4 x double> %475, %479
  %483 = bitcast <4 x double> %481 to <4 x i64>
  %484 = xor <4 x i64> %483, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %485 = bitcast <4 x i64> %484 to <4 x double>
  %486 = fmul <4 x double> %476, %479
  %487 = fmul <4 x double> %480, %475
  %488 = fmul <4 x double> %476, %480
  %489 = fmul <4 x double> %428, %473
  %490 = fadd <4 x double> %482, %485
  %491 = fadd <4 x double> %486, %490
  %492 = fadd <4 x double> %487, %491
  %493 = fadd <4 x double> %488, %492
  %494 = fadd <4 x double> %489, %493
  %495 = fadd <4 x double> %450, %481
  %496 = fsub <4 x double> %450, %495
  %497 = fadd <4 x double> %481, %496
  %498 = fadd <4 x double> %497, %454
  %499 = fadd <4 x double> %498, %494
  %500 = bitcast <4 x double> %281 to <4 x i64>
  %501 = and <4 x i64> %500, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %502 = bitcast <4 x i64> %501 to <4 x double>
  %503 = fsub <4 x double> %281, %502
  %504 = bitcast <4 x double> %495 to <4 x i64>
  %505 = and <4 x i64> %504, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %506 = bitcast <4 x i64> %505 to <4 x double>
  %507 = fsub <4 x double> %495, %506
  %508 = fmul <4 x double> %281, %495
  %509 = fmul <4 x double> %502, %506
  %510 = bitcast <4 x double> %508 to <4 x i64>
  %511 = xor <4 x i64> %510, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %512 = bitcast <4 x i64> %511 to <4 x double>
  %513 = fmul <4 x double> %503, %506
  %514 = fmul <4 x double> %507, %502
  %515 = fmul <4 x double> %503, %507
  %516 = fmul <4 x double> %281, %499
  %517 = fmul <4 x double> %287, %495
  %518 = fadd <4 x double> %509, %512
  %519 = fadd <4 x double> %513, %518
  %520 = fadd <4 x double> %514, %519
  %521 = fadd <4 x double> %515, %520
  %522 = fadd <4 x double> %521, %516
  %523 = fadd <4 x double> %517, %522
  %524 = bitcast <4 x double> %177 to <4 x i64>
  %525 = xor <4 x i64> %524, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %526 = bitcast <4 x double> %178 to <4 x i64>
  %527 = xor <4 x i64> %526, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %528 = bitcast <4 x i64> %525 to <4 x double>
  %529 = bitcast <4 x i64> %527 to <4 x double>
  %530 = fadd <4 x double> %508, %528
  %531 = fsub <4 x double> %530, %508
  %532 = fsub <4 x double> %530, %531
  %533 = fsub <4 x double> %508, %532
  %534 = fsub <4 x double> %528, %531
  %535 = fadd <4 x double> %534, %533
  %536 = fadd <4 x double> %523, %529
  %537 = fadd <4 x double> %535, %536
  %538 = fadd <4 x double> %530, <double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5>
  %539 = fsub <4 x double> %538, %530
  %540 = fsub <4 x double> %538, %539
  %541 = fsub <4 x double> %530, %540
  %542 = fsub <4 x double> <double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5>, %539
  %543 = fadd <4 x double> %542, %541
  %544 = fadd <4 x double> %537, <double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF>
  %545 = fadd <4 x double> %543, %544
  %546 = bitcast <4 x double> %280 to <4 x i64>
  %547 = and <4 x i64> %546, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %548 = bitcast <4 x i64> %547 to <4 x double>
  %549 = fsub <4 x double> %280, %548
  %550 = bitcast <4 x double> %190 to <4 x i64>
  %551 = and <4 x i64> %550, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %552 = bitcast <4 x i64> %551 to <4 x double>
  %553 = fsub <4 x double> %190, %552
  %554 = fmul <4 x double> %190, %280
  %555 = fmul <4 x double> %552, %548
  %556 = bitcast <4 x double> %554 to <4 x i64>
  %557 = xor <4 x i64> %556, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %558 = bitcast <4 x i64> %557 to <4 x double>
  %559 = fmul <4 x double> %549, %552
  %560 = fmul <4 x double> %553, %548
  %561 = fmul <4 x double> %553, %549
  %562 = fadd <4 x double> %555, %558
  %563 = fadd <4 x double> %559, %562
  %564 = fadd <4 x double> %560, %563
  %565 = fadd <4 x double> %561, %564
  %566 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607>, <4 x double> <double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8>, <4 x double> %180) #6
  %567 = fadd <4 x double> %554, %566
  %568 = fsub <4 x double> %567, %554
  %569 = fsub <4 x double> %567, %568
  %570 = fsub <4 x double> %554, %569
  %571 = fsub <4 x double> %566, %568
  %572 = fadd <4 x double> %571, %570
  %573 = fadd <4 x double> %565, %572
  %574 = bitcast <4 x double> %567 to <4 x i64>
  %575 = and <4 x i64> %574, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %576 = bitcast <4 x i64> %575 to <4 x double>
  %577 = fsub <4 x double> %567, %576
  %578 = fmul <4 x double> %190, %567
  %579 = fmul <4 x double> %552, %576
  %580 = bitcast <4 x double> %578 to <4 x i64>
  %581 = xor <4 x i64> %580, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %582 = bitcast <4 x i64> %581 to <4 x double>
  %583 = fmul <4 x double> %577, %552
  %584 = fmul <4 x double> %553, %576
  %585 = fmul <4 x double> %553, %577
  %586 = fmul <4 x double> %190, %573
  %587 = fadd <4 x double> %579, %582
  %588 = fadd <4 x double> %583, %587
  %589 = fadd <4 x double> %584, %588
  %590 = fadd <4 x double> %585, %589
  %591 = fadd <4 x double> %586, %590
  %592 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6>, <4 x double> <double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3>, <4 x double> %180) #6
  %593 = fadd <4 x double> %592, %578
  %594 = fsub <4 x double> %593, %578
  %595 = fsub <4 x double> %593, %594
  %596 = fsub <4 x double> %578, %595
  %597 = fsub <4 x double> %592, %594
  %598 = fadd <4 x double> %597, %596
  %599 = fadd <4 x double> %598, %591
  %600 = bitcast <4 x double> %593 to <4 x i64>
  %601 = and <4 x i64> %600, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %602 = bitcast <4 x i64> %601 to <4 x double>
  %603 = fsub <4 x double> %593, %602
  %604 = fmul <4 x double> %190, %593
  %605 = fmul <4 x double> %552, %602
  %606 = bitcast <4 x double> %604 to <4 x i64>
  %607 = xor <4 x i64> %606, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %608 = bitcast <4 x i64> %607 to <4 x double>
  %609 = fmul <4 x double> %603, %552
  %610 = fmul <4 x double> %553, %602
  %611 = fmul <4 x double> %553, %603
  %612 = fmul <4 x double> %190, %599
  %613 = fadd <4 x double> %605, %608
  %614 = fadd <4 x double> %609, %613
  %615 = fadd <4 x double> %610, %614
  %616 = fadd <4 x double> %611, %615
  %617 = fadd <4 x double> %616, %612
  %618 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE>, <4 x double> <double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619>, <4 x double> %180) #6
  %619 = fadd <4 x double> %618, %604
  %620 = fsub <4 x double> %619, %604
  %621 = fsub <4 x double> %619, %620
  %622 = fsub <4 x double> %604, %621
  %623 = fsub <4 x double> %618, %620
  %624 = fadd <4 x double> %623, %622
  %625 = fadd <4 x double> %624, %617
  %626 = bitcast <4 x double> %619 to <4 x i64>
  %627 = and <4 x i64> %626, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %628 = bitcast <4 x i64> %627 to <4 x double>
  %629 = fsub <4 x double> %619, %628
  %630 = fmul <4 x double> %190, %619
  %631 = fmul <4 x double> %552, %628
  %632 = bitcast <4 x double> %630 to <4 x i64>
  %633 = xor <4 x i64> %632, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %634 = bitcast <4 x i64> %633 to <4 x double>
  %635 = fmul <4 x double> %629, %552
  %636 = fmul <4 x double> %553, %628
  %637 = fmul <4 x double> %553, %629
  %638 = fmul <4 x double> %190, %625
  %639 = fadd <4 x double> %631, %634
  %640 = fadd <4 x double> %635, %639
  %641 = fadd <4 x double> %636, %640
  %642 = fadd <4 x double> %637, %641
  %643 = fadd <4 x double> %642, %638
  %644 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %630, <4 x double> %538, <4 x double> %26) #6
  %645 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %643, <4 x double> %545, <4 x double> %26) #6
  %646 = fadd <4 x double> %554, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %647 = fsub <4 x double> %646, %554
  %648 = fsub <4 x double> %646, %647
  %649 = fsub <4 x double> %554, %648
  %650 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %647
  %651 = fadd <4 x double> %650, %649
  %652 = fadd <4 x double> %651, %565
  %653 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %646, <4 x double> %26) #6
  %654 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %652, <4 x double> %26) #6
  %655 = bitcast <4 x double> %644 to <4 x i64>
  %656 = xor <4 x i64> %655, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %657 = bitcast <4 x double> %645 to <4 x i64>
  %658 = xor <4 x i64> %657, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %659 = bitcast <4 x i64> %656 to <4 x double>
  %660 = bitcast <4 x i64> %658 to <4 x double>
  %661 = fadd <4 x double> %659, <double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD>
  %662 = fadd <4 x double> %661, <double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD>
  %663 = fsub <4 x double> %661, %662
  %664 = fsub <4 x double> <double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD>, %663
  %665 = fsub <4 x double> %659, %662
  %666 = fadd <4 x double> %665, %664
  %667 = fadd <4 x double> %660, <double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088>
  %668 = fadd <4 x double> %667, %666
  %669 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %644, <4 x double> %661, <4 x double> %7) #6
  %670 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %645, <4 x double> %668, <4 x double> %7) #6
  %671 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %669, <4 x double> <double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650>, <4 x double> %6) #6
  %672 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %670, <4 x double> <double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E>, <4 x double> %6) #6
  %673 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %653, <4 x double> %168, <4 x double> %7) #6
  %674 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %654, <4 x double> %169, <4 x double> %7) #6
  %675 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %673, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %6) #6
  %676 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %674, <4 x double> zeroinitializer, <4 x double> %6) #6
  %677 = xor <4 x i64> %8, <i64 -1, i64 -1, i64 -1, i64 -1>
  %678 = shufflevector <4 x i64> %677, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %679 = shufflevector <4 x i64> %677, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %680 = and <2 x i64> %679, %678
  %681 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %680, <2 x i64> <i64 -1, i64 -1>) #6
  %682 = icmp eq i32 %681, 0
  br i1 %682, label %683, label %846

; <label>:683:                                    ; preds = %2
  %684 = fmul <4 x double> %1, <double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000>
  %685 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %684) #6
  %686 = sitofp <4 x i32> %685 to <4 x double>
  %687 = fmul <4 x double> %686, <double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000>
  %688 = fsub <4 x double> %1, %687
  %689 = fmul <4 x double> %688, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %690 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %689) #6
  %691 = lshr <4 x i32> %690, <i32 31, i32 31, i32 31, i32 31>
  %692 = xor <4 x i32> %691, <i32 1, i32 1, i32 1, i32 1>
  %693 = add <4 x i32> %692, %690
  %694 = and <4 x i32> %693, <i32 2, i32 2, i32 2, i32 2>
  %695 = icmp ne <4 x i32> %694, zeroinitializer
  %696 = sitofp <4 x i1> %695 to <4 x double>
  %697 = fcmp oeq <4 x double> %696, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %698 = sext <4 x i1> %697 to <4 x i64>
  %699 = and <4 x i32> %693, <i32 -2, i32 -2, i32 -2, i32 -2>
  %700 = sitofp <4 x i32> %699 to <4 x double>
  %701 = fsub <4 x double> %689, %700
  %702 = fmul <4 x double> %701, %701
  %703 = bitcast <4 x double> %701 to <4 x i64>
  %704 = and <4 x i64> %703, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %705 = bitcast <4 x i64> %704 to <4 x double>
  %706 = fsub <4 x double> %701, %705
  %707 = fmul <4 x double> %705, %705
  %708 = bitcast <4 x double> %702 to <4 x i64>
  %709 = xor <4 x i64> %708, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %710 = bitcast <4 x i64> %709 to <4 x double>
  %711 = fmul <4 x double> %706, %705
  %712 = fmul <4 x double> %706, %706
  %713 = fadd <4 x double> %707, %710
  %714 = fadd <4 x double> %711, %713
  %715 = fadd <4 x double> %711, %714
  %716 = fadd <4 x double> %712, %715
  %717 = bitcast <4 x i64> %698 to <4 x double>
  %718 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>, <4 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <4 x double> %717) #6
  %719 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>, <4 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <4 x double> %717) #6
  %720 = fmul <4 x double> %718, %702
  %721 = fadd <4 x double> %719, %720
  %722 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>, <4 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <4 x double> %717) #6
  %723 = fmul <4 x double> %702, %721
  %724 = fadd <4 x double> %722, %723
  %725 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>, <4 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <4 x double> %717) #6
  %726 = fmul <4 x double> %702, %724
  %727 = fadd <4 x double> %725, %726
  %728 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>, <4 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <4 x double> %717) #6
  %729 = fmul <4 x double> %702, %727
  %730 = fadd <4 x double> %728, %729
  %731 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>, <4 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <4 x double> %717) #6
  %732 = fmul <4 x double> %702, %730
  %733 = fadd <4 x double> %731, %732
  %734 = fmul <4 x double> %702, %733
  %735 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>, <4 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <4 x double> %717) #6
  %736 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>, <4 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <4 x double> %717) #6
  %737 = fadd <4 x double> %735, %734
  %738 = fsub <4 x double> %737, %734
  %739 = fsub <4 x double> %737, %738
  %740 = fsub <4 x double> %734, %739
  %741 = fsub <4 x double> %735, %738
  %742 = fadd <4 x double> %741, %740
  %743 = fadd <4 x double> %736, %742
  %744 = and <4 x i64> %708, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %745 = bitcast <4 x i64> %744 to <4 x double>
  %746 = fsub <4 x double> %702, %745
  %747 = bitcast <4 x double> %737 to <4 x i64>
  %748 = and <4 x i64> %747, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %749 = bitcast <4 x i64> %748 to <4 x double>
  %750 = fsub <4 x double> %737, %749
  %751 = fmul <4 x double> %702, %737
  %752 = fmul <4 x double> %745, %749
  %753 = bitcast <4 x double> %751 to <4 x i64>
  %754 = xor <4 x i64> %753, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %755 = bitcast <4 x i64> %754 to <4 x double>
  %756 = fmul <4 x double> %746, %749
  %757 = fmul <4 x double> %750, %745
  %758 = fmul <4 x double> %746, %750
  %759 = fmul <4 x double> %702, %743
  %760 = fmul <4 x double> %716, %737
  %761 = fadd <4 x double> %752, %755
  %762 = fadd <4 x double> %756, %761
  %763 = fadd <4 x double> %757, %762
  %764 = fadd <4 x double> %758, %763
  %765 = fadd <4 x double> %759, %764
  %766 = fadd <4 x double> %760, %765
  %767 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, <4 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <4 x double> %717) #6
  %768 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>, <4 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <4 x double> %717) #6
  %769 = fadd <4 x double> %767, %751
  %770 = fsub <4 x double> %769, %751
  %771 = fsub <4 x double> %769, %770
  %772 = fsub <4 x double> %751, %771
  %773 = fsub <4 x double> %767, %770
  %774 = fadd <4 x double> %773, %772
  %775 = fadd <4 x double> %768, %766
  %776 = fadd <4 x double> %774, %775
  %777 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %701, <4 x double> %702, <4 x double> %717) #6
  %778 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %716, <4 x double> %717) #6
  %779 = bitcast <4 x double> %769 to <4 x i64>
  %780 = and <4 x i64> %779, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %781 = bitcast <4 x i64> %780 to <4 x double>
  %782 = fsub <4 x double> %769, %781
  %783 = bitcast <4 x double> %777 to <4 x i64>
  %784 = and <4 x i64> %783, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %785 = bitcast <4 x i64> %784 to <4 x double>
  %786 = fsub <4 x double> %777, %785
  %787 = fmul <4 x double> %777, %769
  %788 = fmul <4 x double> %785, %781
  %789 = bitcast <4 x double> %787 to <4 x i64>
  %790 = xor <4 x i64> %789, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %791 = bitcast <4 x i64> %790 to <4 x double>
  %792 = fmul <4 x double> %782, %785
  %793 = fmul <4 x double> %786, %781
  %794 = fmul <4 x double> %786, %782
  %795 = fmul <4 x double> %778, %769
  %796 = fmul <4 x double> %777, %776
  %797 = fadd <4 x double> %788, %791
  %798 = fadd <4 x double> %792, %797
  %799 = fadd <4 x double> %793, %798
  %800 = fadd <4 x double> %794, %799
  %801 = fadd <4 x double> %795, %800
  %802 = fadd <4 x double> %801, %796
  %803 = fadd <4 x double> %787, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %804 = fsub <4 x double> %803, %787
  %805 = fsub <4 x double> %803, %804
  %806 = fsub <4 x double> %787, %805
  %807 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %804
  %808 = fadd <4 x double> %807, %806
  %809 = fadd <4 x double> %808, %802
  %810 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %787, <4 x double> %803, <4 x double> %717) #6
  %811 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %802, <4 x double> %809, <4 x double> %717) #6
  %812 = and <4 x i32> %693, <i32 4, i32 4, i32 4, i32 4>
  %813 = icmp ne <4 x i32> %812, zeroinitializer
  %814 = sitofp <4 x i1> %813 to <4 x double>
  %815 = fcmp oeq <4 x double> %814, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %816 = select <4 x i1> %815, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %817 = bitcast <4 x double> %810 to <4 x i64>
  %818 = xor <4 x i64> %816, %817
  %819 = bitcast <4 x double> %811 to <4 x i64>
  %820 = xor <4 x i64> %816, %819
  %821 = bitcast <4 x i64> %818 to <4 x double>
  %822 = bitcast <4 x i64> %820 to <4 x double>
  %823 = bitcast <4 x double> %653 to <4 x i64>
  %824 = and <4 x i64> %823, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %825 = bitcast <4 x i64> %824 to <4 x double>
  %826 = fsub <4 x double> %653, %825
  %827 = and <4 x i64> %818, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %828 = bitcast <4 x i64> %827 to <4 x double>
  %829 = fsub <4 x double> %821, %828
  %830 = fmul <4 x double> %653, %821
  %831 = fmul <4 x double> %825, %828
  %832 = bitcast <4 x double> %830 to <4 x i64>
  %833 = xor <4 x i64> %832, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %834 = bitcast <4 x i64> %833 to <4 x double>
  %835 = fmul <4 x double> %826, %828
  %836 = fmul <4 x double> %829, %825
  %837 = fmul <4 x double> %826, %829
  %838 = fmul <4 x double> %653, %822
  %839 = fmul <4 x double> %654, %821
  %840 = fadd <4 x double> %831, %834
  %841 = fadd <4 x double> %835, %840
  %842 = fadd <4 x double> %836, %841
  %843 = fadd <4 x double> %837, %842
  %844 = fadd <4 x double> %838, %843
  %845 = fadd <4 x double> %839, %844
  br label %846

; <label>:846:                                    ; preds = %2, %683
  %847 = phi <4 x double> [ %830, %683 ], [ %177, %2 ]
  %848 = phi <4 x double> [ %845, %683 ], [ %178, %2 ]
  %849 = fmul <4 x double> %1, <double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000>
  %850 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %168, <4 x double> %847, <4 x double> %7) #6
  %851 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %169, <4 x double> %848, <4 x double> %7) #6
  %852 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %850, <4 x double> %849, <4 x double> %6) #6
  %853 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %851, <4 x double> zeroinitializer, <4 x double> %6) #6
  %854 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %852
  %855 = bitcast <4 x double> %852 to <4 x i64>
  %856 = and <4 x i64> %855, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %857 = bitcast <4 x i64> %856 to <4 x double>
  %858 = fsub <4 x double> %852, %857
  %859 = bitcast <4 x double> %854 to <4 x i64>
  %860 = and <4 x i64> %859, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %861 = bitcast <4 x i64> %860 to <4 x double>
  %862 = fsub <4 x double> %854, %861
  %863 = bitcast <4 x double> %675 to <4 x i64>
  %864 = and <4 x i64> %863, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %865 = bitcast <4 x i64> %864 to <4 x double>
  %866 = fsub <4 x double> %675, %865
  %867 = fmul <4 x double> %675, %854
  %868 = fmul <4 x double> %865, %861
  %869 = fsub <4 x double> %868, %867
  %870 = fmul <4 x double> %862, %865
  %871 = fmul <4 x double> %866, %861
  %872 = fmul <4 x double> %866, %862
  %873 = fmul <4 x double> %857, %861
  %874 = fmul <4 x double> %862, %857
  %875 = fmul <4 x double> %858, %861
  %876 = fmul <4 x double> %858, %862
  %877 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %873
  %878 = fsub <4 x double> %877, %874
  %879 = fsub <4 x double> %878, %875
  %880 = fsub <4 x double> %879, %876
  %881 = fmul <4 x double> %867, %880
  %882 = fadd <4 x double> %869, %870
  %883 = fadd <4 x double> %871, %882
  %884 = fadd <4 x double> %872, %883
  %885 = fadd <4 x double> %884, %881
  %886 = fmul <4 x double> %853, %867
  %887 = fsub <4 x double> %676, %886
  %888 = fmul <4 x double> %854, %887
  %889 = fadd <4 x double> %888, %885
  %890 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 0, i32 0
  store <4 x double> %671, <4 x double>* %890, align 32
  %891 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 0, i32 1
  store <4 x double> %672, <4 x double>* %891, align 32
  %892 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 1, i32 0
  store <4 x double> %867, <4 x double>* %892, align 32
  %893 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 1, i32 1
  store <4 x double> %889, <4 x double>* %893, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define <4 x double> @Sleef_lgammad4_u10avx(<4 x double>) local_unnamed_addr #2 {
  %2 = alloca %struct.dd2, align 32
  %3 = bitcast %struct.dd2* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %3) #6
  call fastcc void @gammak(%struct.dd2* noalias nonnull %2, <4 x double> %0)
  %4 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1
  %5 = bitcast %struct.vdouble2* %4 to <4 x i64>*
  %6 = load <4 x i64>, <4 x i64>* %5, align 32
  %7 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 1
  %8 = bitcast <4 x double>* %7 to <4 x i64>*
  %9 = load <4 x i64>, <4 x i64>* %8, align 32
  %10 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %11 = and <4 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %12 = xor <4 x i64> %11, %9
  %13 = bitcast <4 x i64> %10 to <4 x double>
  %14 = bitcast <4 x i64> %12 to <4 x double>
  %15 = fmul <4 x double> %13, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %16 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %15, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %17 = bitcast <4 x double> %16 to <4 x i64>
  %18 = fmul <4 x double> %15, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> %18, <4 x double> %16) #6
  %20 = bitcast <4 x double> %19 to <4 x i64>
  %21 = shufflevector <4 x i64> %20, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %22 = shufflevector <4 x i64> %20, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %23 = bitcast <2 x i64> %21 to <4 x i32>
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %25 = bitcast <4 x i32> %24 to <2 x i64>
  %26 = bitcast <2 x i64> %22 to <4 x i32>
  %27 = shufflevector <4 x i32> %26, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %28 = bitcast <4 x i32> %27 to <2 x i64>
  %29 = shufflevector <2 x i64> %28, <2 x i64> %25, <2 x i32> <i32 2, i32 1>
  %30 = bitcast <2 x i64> %29 to <4 x i32>
  %31 = lshr <4 x i32> %30, <i32 20, i32 20, i32 20, i32 20>
  %32 = and <4 x i64> %17, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %33) #6
  %35 = bitcast <4 x i32> %34 to <16 x i8>
  %36 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %35) #6
  %37 = bitcast <16 x i8> %36 to <4 x i32>
  %38 = sub <4 x i32> %31, %37
  %39 = sub <4 x i32> zeroinitializer, %38
  %40 = ashr <4 x i32> %39, <i32 1, i32 1, i32 1, i32 1>
  %41 = add nsw <4 x i32> %40, <i32 1023, i32 1023, i32 1023, i32 1023>
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %43 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %44 = and <4 x i32> %42, <i32 0, i32 -1, i32 0, i32 -1>
  %45 = shl <4 x i32> %44, <i32 20, i32 20, i32 20, i32 20>
  %46 = and <4 x i32> %43, <i32 0, i32 -1, i32 0, i32 -1>
  %47 = shl <4 x i32> %46, <i32 20, i32 20, i32 20, i32 20>
  %48 = bitcast <4 x i32> %45 to <2 x i64>
  %49 = bitcast <4 x i32> %47 to <2 x i64>
  %50 = shufflevector <2 x i64> %48, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %51 = shufflevector <2 x i64> %49, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %52 = shufflevector <4 x i64> %50, <4 x i64> %51, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %53 = bitcast <4 x i64> %52 to <4 x double>
  %54 = fmul <4 x double> %13, %53
  %55 = sub <4 x i32> %39, %40
  %56 = add <4 x i32> %55, <i32 1023, i32 1023, i32 1023, i32 1023>
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %58 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %59 = and <4 x i32> %57, <i32 0, i32 -1, i32 0, i32 -1>
  %60 = shl <4 x i32> %59, <i32 20, i32 20, i32 20, i32 20>
  %61 = and <4 x i32> %58, <i32 0, i32 -1, i32 0, i32 -1>
  %62 = shl <4 x i32> %61, <i32 20, i32 20, i32 20, i32 20>
  %63 = bitcast <4 x i32> %60 to <2 x i64>
  %64 = bitcast <4 x i32> %62 to <2 x i64>
  %65 = shufflevector <2 x i64> %63, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %66 = shufflevector <2 x i64> %64, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %67 = shufflevector <4 x i64> %65, <4 x i64> %66, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fmul <4 x double> %54, %68
  %70 = fmul <4 x double> %14, %53
  %71 = fmul <4 x double> %70, %68
  %72 = fadd <4 x double> %69, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %73 = fsub <4 x double> %72, %69
  %74 = fsub <4 x double> %72, %73
  %75 = fsub <4 x double> %69, %74
  %76 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %73
  %77 = fadd <4 x double> %76, %75
  %78 = fadd <4 x double> %71, %77
  %79 = fadd <4 x double> %69, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %80 = fsub <4 x double> %79, %69
  %81 = fsub <4 x double> %79, %80
  %82 = fsub <4 x double> %69, %81
  %83 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %84 = fadd <4 x double> %83, %82
  %85 = fadd <4 x double> %71, %84
  %86 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %79
  %87 = bitcast <4 x double> %79 to <4 x i64>
  %88 = and <4 x i64> %87, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %89 = bitcast <4 x i64> %88 to <4 x double>
  %90 = fsub <4 x double> %79, %89
  %91 = bitcast <4 x double> %86 to <4 x i64>
  %92 = and <4 x i64> %91, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %93 = bitcast <4 x i64> %92 to <4 x double>
  %94 = fsub <4 x double> %86, %93
  %95 = bitcast <4 x double> %72 to <4 x i64>
  %96 = and <4 x i64> %95, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %97 = bitcast <4 x i64> %96 to <4 x double>
  %98 = fsub <4 x double> %72, %97
  %99 = fmul <4 x double> %72, %86
  %100 = fmul <4 x double> %97, %93
  %101 = fsub <4 x double> %100, %99
  %102 = fmul <4 x double> %94, %97
  %103 = fmul <4 x double> %98, %93
  %104 = fmul <4 x double> %98, %94
  %105 = fmul <4 x double> %89, %93
  %106 = fmul <4 x double> %94, %89
  %107 = fmul <4 x double> %90, %93
  %108 = fmul <4 x double> %90, %94
  %109 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %105
  %110 = fsub <4 x double> %109, %106
  %111 = fsub <4 x double> %110, %107
  %112 = fsub <4 x double> %111, %108
  %113 = fmul <4 x double> %99, %112
  %114 = fadd <4 x double> %101, %102
  %115 = fadd <4 x double> %103, %114
  %116 = fadd <4 x double> %104, %115
  %117 = fadd <4 x double> %116, %113
  %118 = fmul <4 x double> %99, %85
  %119 = fsub <4 x double> %78, %118
  %120 = fmul <4 x double> %86, %119
  %121 = fadd <4 x double> %120, %117
  %122 = bitcast <4 x double> %99 to <4 x i64>
  %123 = and <4 x i64> %122, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %124 = bitcast <4 x i64> %123 to <4 x double>
  %125 = fsub <4 x double> %99, %124
  %126 = fmul <4 x double> %99, %99
  %127 = fmul <4 x double> %124, %124
  %128 = bitcast <4 x double> %126 to <4 x i64>
  %129 = xor <4 x i64> %128, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %130 = bitcast <4 x i64> %129 to <4 x double>
  %131 = fadd <4 x double> %124, %124
  %132 = fmul <4 x double> %131, %125
  %133 = fmul <4 x double> %125, %125
  %134 = fadd <4 x double> %121, %121
  %135 = fmul <4 x double> %99, %134
  %136 = fadd <4 x double> %127, %130
  %137 = fadd <4 x double> %136, %132
  %138 = fadd <4 x double> %133, %137
  %139 = fadd <4 x double> %138, %135
  %140 = fmul <4 x double> %126, %126
  %141 = fmul <4 x double> %140, %140
  %142 = fmul <4 x double> %126, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %143 = fadd <4 x double> %142, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %144 = fmul <4 x double> %140, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %145 = fadd <4 x double> %144, %143
  %146 = fmul <4 x double> %126, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %147 = fadd <4 x double> %146, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %148 = fmul <4 x double> %126, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %149 = fadd <4 x double> %148, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %150 = fmul <4 x double> %140, %147
  %151 = fadd <4 x double> %149, %150
  %152 = fmul <4 x double> %141, %145
  %153 = fadd <4 x double> %152, %151
  %154 = fmul <4 x double> %126, %153
  %155 = fadd <4 x double> %154, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %156 = sitofp <4 x i32> %38 to <4 x double>
  %157 = bitcast <4 x double> %156 to <4 x i64>
  %158 = and <4 x i64> %157, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %159 = bitcast <4 x i64> %158 to <4 x double>
  %160 = fsub <4 x double> %156, %159
  %161 = fmul <4 x double> %156, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %162 = fmul <4 x double> %159, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %163 = bitcast <4 x double> %161 to <4 x i64>
  %164 = xor <4 x i64> %163, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %165 = bitcast <4 x i64> %164 to <4 x double>
  %166 = fmul <4 x double> %159, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %167 = fmul <4 x double> %160, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %168 = fmul <4 x double> %160, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %169 = fmul <4 x double> %156, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %170 = fadd <4 x double> %162, %165
  %171 = fadd <4 x double> %166, %170
  %172 = fadd <4 x double> %167, %171
  %173 = fadd <4 x double> %168, %172
  %174 = fadd <4 x double> %169, %173
  %175 = fmul <4 x double> %99, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %176 = fmul <4 x double> %121, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %177 = fadd <4 x double> %161, %175
  %178 = fsub <4 x double> %161, %177
  %179 = fadd <4 x double> %175, %178
  %180 = fadd <4 x double> %174, %179
  %181 = fadd <4 x double> %180, %176
  %182 = and <4 x i64> %128, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %183 = bitcast <4 x i64> %182 to <4 x double>
  %184 = fsub <4 x double> %126, %183
  %185 = fmul <4 x double> %99, %126
  %186 = fmul <4 x double> %124, %183
  %187 = bitcast <4 x double> %185 to <4 x i64>
  %188 = xor <4 x i64> %187, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %189 = bitcast <4 x i64> %188 to <4 x double>
  %190 = fmul <4 x double> %184, %124
  %191 = fmul <4 x double> %125, %183
  %192 = fmul <4 x double> %125, %184
  %193 = fmul <4 x double> %126, %121
  %194 = fmul <4 x double> %99, %139
  %195 = fadd <4 x double> %186, %189
  %196 = fadd <4 x double> %190, %195
  %197 = fadd <4 x double> %191, %196
  %198 = fadd <4 x double> %192, %197
  %199 = fadd <4 x double> %198, %193
  %200 = fadd <4 x double> %199, %194
  %201 = and <4 x i64> %187, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %202 = bitcast <4 x i64> %201 to <4 x double>
  %203 = fsub <4 x double> %185, %202
  %204 = bitcast <4 x double> %155 to <4 x i64>
  %205 = and <4 x i64> %204, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %206 = bitcast <4 x i64> %205 to <4 x double>
  %207 = fsub <4 x double> %155, %206
  %208 = fmul <4 x double> %185, %155
  %209 = fmul <4 x double> %202, %206
  %210 = bitcast <4 x double> %208 to <4 x i64>
  %211 = xor <4 x i64> %210, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %212 = bitcast <4 x i64> %211 to <4 x double>
  %213 = fmul <4 x double> %203, %206
  %214 = fmul <4 x double> %207, %202
  %215 = fmul <4 x double> %203, %207
  %216 = fmul <4 x double> %155, %200
  %217 = fadd <4 x double> %209, %212
  %218 = fadd <4 x double> %213, %217
  %219 = fadd <4 x double> %214, %218
  %220 = fadd <4 x double> %215, %219
  %221 = fadd <4 x double> %216, %220
  %222 = fadd <4 x double> %177, %208
  %223 = fsub <4 x double> %177, %222
  %224 = fadd <4 x double> %208, %223
  %225 = fadd <4 x double> %224, %181
  %226 = fadd <4 x double> %225, %221
  %227 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 0
  %228 = load <4 x double>, <4 x double>* %227, align 32
  %229 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 1
  %230 = load <4 x double>, <4 x double>* %229, align 32
  %231 = fadd <4 x double> %228, %222
  %232 = fsub <4 x double> %231, %228
  %233 = fsub <4 x double> %231, %232
  %234 = fsub <4 x double> %228, %233
  %235 = fsub <4 x double> %222, %232
  %236 = fadd <4 x double> %235, %234
  %237 = fadd <4 x double> %230, %226
  %238 = fadd <4 x double> %236, %237
  %239 = fadd <4 x double> %231, %238
  %240 = bitcast <4 x double> %0 to <4 x i64>
  %241 = and <4 x i64> %240, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %242 = bitcast <4 x i64> %241 to <4 x double>
  %243 = fcmp oeq <4 x double> %242, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %244 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 18) #6
  %245 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 11) #6
  %246 = fcmp oeq <4 x double> %245, %0
  %247 = fcmp une <4 x double> %242, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %248 = fcmp ord <4 x double> %0, zeroinitializer
  %249 = and <4 x i1> %247, %248
  %250 = fcmp uno <4 x double> %239, zeroinitializer
  %251 = and <4 x i1> %249, %250
  %252 = or <4 x i1> %251, %243
  %253 = select <4 x i1> %246, <4 x double> %244, <4 x double> zeroinitializer
  %254 = select <4 x i1> %252, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %253
  %255 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %239, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %254) #6
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %3) #6
  ret <4 x double> %255
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_erfd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i8 17) #6
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00>, i8 17) #6
  %7 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00>, i8 17) #6
  %8 = fmul <4 x double> %4, %4
  %9 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %8, <4 x double> %5) #6
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBC5AF69FE192740F, double 0xBC5AF69FE192740F, double 0xBC5AF69FE192740F, double 0xBC5AF69FE192740F>, <4 x double> <double 0x3D1FDFABBDFC43F1, double 0x3D1FDFABBDFC43F1, double 0x3D1FDFABBDFC43F1, double 0x3D1FDFABBDFC43F1>, <4 x double> %6) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> <double 0x3BC00EFEFABE989B, double 0x3BC00EFEFABE989B, double 0x3BC00EFEFABE989B, double 0x3BC00EFEFABE989B>, <4 x double> %5) #6
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3CC5E4C21B562709, double 0x3CC5E4C21B562709, double 0x3CC5E4C21B562709, double 0x3CC5E4C21B562709>, <4 x double> <double 0xBD7A8E25B9CCCB64, double 0xBD7A8E25B9CCCB64, double 0xBD7A8E25B9CCCB64, double 0xBD7A8E25B9CCCB64>, <4 x double> %6) #6
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %12, <4 x double> <double 0xBC0FE6EC06B043F5, double 0xBC0FE6EC06B043F5, double 0xBC0FE6EC06B043F5, double 0xBC0FE6EC06B043F5>, <4 x double> %5) #6
  %14 = fmul <4 x double> %9, %11
  %15 = fadd <4 x double> %14, %13
  %16 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBD20EE4A859274F9, double 0xBD20EE4A859274F9, double 0xBD20EE4A859274F9, double 0xBD20EE4A859274F9>, <4 x double> <double 0x3DC50B3AE48C7164, double 0x3DC50B3AE48C7164, double 0x3DC50B3AE48C7164, double 0x3DC50B3AE48C7164>, <4 x double> %6) #6
  %17 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %16, <4 x double> <double 0x3C55A7F67BDE0C17, double 0x3C55A7F67BDE0C17, double 0x3C55A7F67BDE0C17, double 0x3C55A7F67BDE0C17>, <4 x double> %5) #6
  %18 = fmul <4 x double> %9, %15
  %19 = fadd <4 x double> %18, %17
  %20 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3D7095F3964F9BBA, double 0x3D7095F3964F9BBA, double 0x3D7095F3964F9BBA, double 0x3D7095F3964F9BBA>, <4 x double> <double 0xBE0518912B895660, double 0xBE0518912B895660, double 0xBE0518912B895660, double 0xBE0518912B895660>, <4 x double> %6) #6
  %21 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %20, <4 x double> <double 0xBC9A15164BF4F36C, double 0xBC9A15164BF4F36C, double 0xBC9A15164BF4F36C, double 0xBC9A15164BF4F36C>, <4 x double> %5) #6
  %22 = fmul <4 x double> %9, %19
  %23 = fadd <4 x double> %22, %21
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBDB7174964833400, double 0xBDB7174964833400, double 0xBDB7174964833400, double 0xBDB7174964833400>, <4 x double> <double 0x3E3E0083E7FD4B05, double 0x3E3E0083E7FD4B05, double 0x3E3E0083E7FD4B05, double 0x3E3E0083E7FD4B05>, <4 x double> %6) #6
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %24, <4 x double> <double 0x3CDD6F95068FEEA8, double 0x3CDD6F95068FEEA8, double 0x3CDD6F95068FEEA8, double 0x3CDD6F95068FEEA8>, <4 x double> %5) #6
  %26 = fmul <4 x double> %9, %23
  %27 = fadd <4 x double> %26, %25
  %28 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3DF84A341FC35F63, double 0x3DF84A341FC35F63, double 0x3DF84A341FC35F63, double 0x3DF84A341FC35F63>, <4 x double> <double 0xBE70131398DAE973, double 0xBE70131398DAE973, double 0xBE70131398DAE973, double 0xBE70131398DAE973>, <4 x double> %6) #6
  %29 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %28, <4 x double> <double 0xBD1F56D9FF51275A, double 0xBD1F56D9FF51275A, double 0xBD1F56D9FF51275A, double 0xBD1F56D9FF51275A>, <4 x double> %5) #6
  %30 = fmul <4 x double> %9, %27
  %31 = fadd <4 x double> %30, %29
  %32 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE34092FAEC3CB81, double 0xBE34092FAEC3CB81, double 0xBE34092FAEC3CB81, double 0xBE34092FAEC3CB81>, <4 x double> <double 0x3E9AE1C4F259778D, double 0x3E9AE1C4F259778D, double 0x3E9AE1C4F259778D, double 0x3E9AE1C4F259778D>, <4 x double> %6) #6
  %33 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %32, <4 x double> <double 0x3D5F6839841402FB, double 0x3D5F6839841402FB, double 0x3D5F6839841402FB, double 0x3D5F6839841402FB>, <4 x double> %5) #6
  %34 = fmul <4 x double> %9, %31
  %35 = fadd <4 x double> %34, %33
  %36 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E6A8ABD2DF8AA98, double 0x3E6A8ABD2DF8AA98, double 0x3E6A8ABD2DF8AA98, double 0x3E6A8ABD2DF8AA98>, <4 x double> <double 0xBEC1E2D7E8039AC0, double 0xBEC1E2D7E8039AC0, double 0xBEC1E2D7E8039AC0, double 0xBEC1E2D7E8039AC0>, <4 x double> %6) #6
  %37 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %36, <4 x double> <double 0xBD9D8453B9E7FD7B, double 0xBD9D8453B9E7FD7B, double 0xBD9D8453B9E7FD7B, double 0xBD9D8453B9E7FD7B>, <4 x double> %5) #6
  %38 = fmul <4 x double> %9, %35
  %39 = fadd <4 x double> %38, %37
  %40 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBE9CA9DF1E6D3F55, double 0xBE9CA9DF1E6D3F55, double 0xBE9CA9DF1E6D3F55, double 0xBE9CA9DF1E6D3F55>, <4 x double> <double 0x3EE3117A5DB988BA, double 0x3EE3117A5DB988BA, double 0x3EE3117A5DB988BA, double 0x3EE3117A5DB988BA>, <4 x double> %6) #6
  %41 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %40, <4 x double> <double 0x3DD9E6AD5DAB7034, double 0x3DD9E6AD5DAB7034, double 0x3DD9E6AD5DAB7034, double 0x3DD9E6AD5DAB7034>, <4 x double> %5) #6
  %42 = fmul <4 x double> %9, %39
  %43 = fadd <4 x double> %42, %41
  %44 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EC9739C586B056B, double 0x3EC9739C586B056B, double 0x3EC9739C586B056B, double 0x3EC9739C586B056B>, <4 x double> <double 0xBF0024D0F7EE3723, double 0xBF0024D0F7EE3723, double 0xBF0024D0F7EE3723, double 0xBF0024D0F7EE3723>, <4 x double> %6) #6
  %45 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %44, <4 x double> <double 0xBE151D7181C08B9D, double 0xBE151D7181C08B9D, double 0xBE151D7181C08B9D, double 0xBE151D7181C08B9D>, <4 x double> %5) #6
  %46 = fmul <4 x double> %9, %43
  %47 = fadd <4 x double> %46, %45
  %48 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBEF2A034D3F36A50, double 0xBEF2A034D3F36A50, double 0xBEF2A034D3F36A50, double 0xBEF2A034D3F36A50>, <4 x double> <double 0x3F14E58666D1B46F, double 0x3F14E58666D1B46F, double 0x3F14E58666D1B46F, double 0x3F14E58666D1B46F>, <4 x double> %6) #6
  %49 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %48, <4 x double> <double 0x3E4FCC5720620921, double 0x3E4FCC5720620921, double 0x3E4FCC5720620921, double 0x3E4FCC5720620921>, <4 x double> %5) #6
  %50 = fmul <4 x double> %9, %47
  %51 = fadd <4 x double> %50, %49
  %52 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F1658BA21A7397E, double 0x3F1658BA21A7397E, double 0x3F1658BA21A7397E, double 0x3F1658BA21A7397E>, <4 x double> <double 0xBF2230DCD58EAD99, double 0xBF2230DCD58EAD99, double 0xBF2230DCD58EAD99, double 0xBF2230DCD58EAD99>, <4 x double> %6) #6
  %53 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %52, <4 x double> <double 0xBE85F742EC43E5C7, double 0xBE85F742EC43E5C7, double 0xBE85F742EC43E5C7, double 0xBE85F742EC43E5C7>, <4 x double> %5) #6
  %54 = fmul <4 x double> %9, %51
  %55 = fadd <4 x double> %54, %53
  %56 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF3590AE9D03C290, double 0xBF3590AE9D03C290, double 0xBF3590AE9D03C290, double 0xBF3590AE9D03C290>, <4 x double> <double 0x3F10F5BA38B6A6E5, double 0x3F10F5BA38B6A6E5, double 0x3F10F5BA38B6A6E5, double 0x3F10F5BA38B6A6E5>, <4 x double> %6) #6
  %57 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %56, <4 x double> <double 0x3EBB9E6C9DC6519C, double 0x3EBB9E6C9DC6519C, double 0x3EBB9E6C9DC6519C, double 0x3EBB9E6C9DC6519C>, <4 x double> %5) #6
  %58 = fmul <4 x double> %9, %55
  %59 = fadd <4 x double> %58, %57
  %60 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F4FC6679B56D25A, double 0x3F4FC6679B56D25A, double 0x3F4FC6679B56D25A, double 0x3F4FC6679B56D25A>, <4 x double> <double 0x3F405F7D6748381E, double 0x3F405F7D6748381E, double 0x3F405F7D6748381E, double 0x3F405F7D6748381E>, <4 x double> %6) #6
  %61 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %60, <4 x double> <double 0xBEEF4D25C3E0C2EA, double 0xBEEF4D25C3E0C2EA, double 0xBEEF4D25C3E0C2EA, double 0xBEEF4D25C3E0C2EA>, <4 x double> %5) #6
  %62 = fmul <4 x double> %9, %59
  %63 = fadd <4 x double> %62, %61
  %64 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF5DB24AB8ACFC8B, double 0xBF5DB24AB8ACFC8B, double 0xBF5DB24AB8ACFC8B, double 0xBF5DB24AB8ACFC8B>, <4 x double> <double 0xBF5A9686E5DE05F7, double 0xBF5A9686E5DE05F7, double 0xBF5A9686E5DE05F7, double 0xBF5A9686E5DE05F7>, <4 x double> %6) #6
  %65 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %64, <4 x double> <double 0x3F1F9A326F9B89B8, double 0x3F1F9A326F9B89B8, double 0x3F1F9A326F9B89B8, double 0x3F1F9A326F9B89B8>, <4 x double> %5) #6
  %66 = fmul <4 x double> %9, %63
  %67 = fadd <4 x double> %66, %65
  %68 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBF3EF7EC1133F0A8, double 0xBF3EF7EC1133F0A8, double 0xBF3EF7EC1133F0A8, double 0xBF3EF7EC1133F0A8>, <4 x double> <double 0x3F252C1DCB0324BA, double 0x3F252C1DCB0324BA, double 0x3F252C1DCB0324BA, double 0x3F252C1DCB0324BA>, <4 x double> %6) #6
  %69 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %68, <4 x double> <double 0xBF4C02DB40040B84, double 0xBF4C02DB40040B84, double 0xBF4C02DB40040B84, double 0xBF4C02DB40040B84>, <4 x double> %5) #6
  %70 = fmul <4 x double> %9, %67
  %71 = fadd <4 x double> %70, %69
  %72 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F9567A2F00CE3E5, double 0x3F9567A2F00CE3E5, double 0x3F9567A2F00CE3E5, double 0x3F9567A2F00CE3E5>, <4 x double> <double 0x3F939CBECA106F66, double 0x3F939CBECA106F66, double 0x3F939CBECA106F66, double 0x3F939CBECA106F66>, <4 x double> %6) #6
  %73 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %72, <4 x double> <double 0x3F7565BCD0E6A540, double 0x3F7565BCD0E6A540, double 0x3F7565BCD0E6A540, double 0x3F7565BCD0E6A540>, <4 x double> %5) #6
  %74 = fmul <4 x double> %9, %71
  %75 = fadd <4 x double> %74, %73
  %76 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFBAEEA974D564EF, double 0xBFBAEEA974D564EF, double 0xBFBAEEA974D564EF, double 0xBFBAEEA974D564EF>, <4 x double> <double 0xBFBA4FE8F5D2A23C, double 0xBFBA4FE8F5D2A23C, double 0xBFBA4FE8F5D2A23C, double 0xBFBA4FE8F5D2A23C>, <4 x double> %6) #6
  %77 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %76, <4 x double> <double 0xBF9B82CE31288B52, double 0xBF9B82CE31288B52, double 0xBF9B82CE31288B52, double 0xBF9B82CE31288B52>, <4 x double> %5) #6
  %78 = fmul <4 x double> %9, %75
  %79 = fadd <4 x double> %78, %77
  %80 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFE44E1CB940DA9C, double 0xBFE44E1CB940DA9C, double 0xBFE44E1CB940DA9C, double 0xBFE44E1CB940DA9C>, <4 x double> <double 0xBFE45F2B34C61AC0, double 0xBFE45F2B34C61AC0, double 0xBFE45F2B34C61AC0, double 0xBFE45F2B34C61AC0>, <4 x double> %6) #6
  %81 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %80, <4 x double> <double 0x3FBCE2F21A042BE3, double 0x3FBCE2F21A042BE3, double 0x3FBCE2F21A042BE3, double 0x3FBCE2F21A042BE3>, <4 x double> %5) #6
  %82 = fmul <4 x double> %9, %79
  %83 = fadd <4 x double> %82, %81
  %84 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFF21232BFB32B5A, double 0xBFF21232BFB32B5A, double 0xBFF21232BFB32B5A, double 0xBFF21232BFB32B5A>, <4 x double> <double 0xBFF20DD7C1F4F99A, double 0xBFF20DD7C1F4F99A, double 0xBFF20DD7C1F4F99A, double 0xBFF20DD7C1F4F99A>, <4 x double> %6) #6
  %85 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %84, <4 x double> <double 0xBFD812746B0379E7, double 0xBFD812746B0379E7, double 0xBFD812746B0379E7, double 0xBFD812746B0379E7>, <4 x double> %5) #6
  %86 = fmul <4 x double> %9, %83
  %87 = fadd <4 x double> %86, %85
  %88 = bitcast <4 x double> %87 to <4 x i64>
  %89 = and <4 x i64> %88, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %90 = bitcast <4 x i64> %89 to <4 x double>
  %91 = fsub <4 x double> %87, %90
  %92 = bitcast <4 x double> %9 to <4 x i64>
  %93 = and <4 x i64> %92, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %94 = bitcast <4 x i64> %93 to <4 x double>
  %95 = fsub <4 x double> %9, %94
  %96 = fmul <4 x double> %9, %87
  %97 = fmul <4 x double> %94, %90
  %98 = bitcast <4 x double> %96 to <4 x i64>
  %99 = xor <4 x i64> %98, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %100 = bitcast <4 x i64> %99 to <4 x double>
  %101 = fmul <4 x double> %91, %94
  %102 = fmul <4 x double> %95, %90
  %103 = fmul <4 x double> %95, %91
  %104 = fadd <4 x double> %97, %100
  %105 = fadd <4 x double> %101, %104
  %106 = fadd <4 x double> %102, %105
  %107 = fadd <4 x double> %103, %106
  %108 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F305C1A38102E9A, double 0x3F305C1A38102E9A, double 0x3F305C1A38102E9A, double 0x3F305C1A38102E9A>, <4 x double> <double 0x3E6250219DD8BAD1, double 0x3E6250219DD8BAD1, double 0x3E6250219DD8BAD1, double 0x3E6250219DD8BAD1>, <4 x double> %6) #6
  %109 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %108, <4 x double> <double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D>, <4 x double> %5) #6
  %110 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBBB9AC0AFE024E87, double 0xBBB9AC0AFE024E87, double 0xBBB9AC0AFE024E87, double 0xBBB9AC0AFE024E87>, <4 x double> <double 0xBB080EE9AD757828, double 0xBB080EE9AD757828, double 0xBB080EE9AD757828, double 0xBB080EE9AD757828>, <4 x double> %6) #6
  %111 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %110, <4 x double> <double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D>, <4 x double> %5) #6
  %112 = fadd <4 x double> %96, %109
  %113 = fsub <4 x double> %112, %96
  %114 = fsub <4 x double> %112, %113
  %115 = fsub <4 x double> %96, %114
  %116 = fsub <4 x double> %109, %113
  %117 = fadd <4 x double> %116, %115
  %118 = fadd <4 x double> %111, %107
  %119 = fadd <4 x double> %117, %118
  %120 = bitcast <4 x double> %112 to <4 x i64>
  %121 = and <4 x i64> %120, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fsub <4 x double> %112, %122
  %124 = and <4 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %125 = bitcast <4 x i64> %124 to <4 x double>
  %126 = fsub <4 x double> %4, %125
  %127 = fmul <4 x double> %112, %4
  %128 = fmul <4 x double> %125, %122
  %129 = bitcast <4 x double> %127 to <4 x i64>
  %130 = xor <4 x i64> %129, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %131 = bitcast <4 x i64> %130 to <4 x double>
  %132 = fmul <4 x double> %123, %125
  %133 = fmul <4 x double> %126, %122
  %134 = fmul <4 x double> %126, %123
  %135 = fmul <4 x double> %119, %4
  %136 = fadd <4 x double> %128, %131
  %137 = fadd <4 x double> %132, %136
  %138 = fadd <4 x double> %133, %137
  %139 = fadd <4 x double> %134, %138
  %140 = fadd <4 x double> %139, %135
  %141 = fadd <4 x double> %112, %119
  %142 = fmul <4 x double> %141, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %143 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %142, i32 8) #6
  %144 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %143) #6
  %145 = fmul <4 x double> %143, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %146 = fadd <4 x double> %112, %145
  %147 = fsub <4 x double> %146, %112
  %148 = fsub <4 x double> %146, %147
  %149 = fsub <4 x double> %112, %148
  %150 = fsub <4 x double> %145, %147
  %151 = fadd <4 x double> %150, %149
  %152 = fadd <4 x double> %151, %119
  %153 = fmul <4 x double> %143, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %154 = fadd <4 x double> %153, %146
  %155 = fsub <4 x double> %154, %146
  %156 = fsub <4 x double> %154, %155
  %157 = fsub <4 x double> %146, %156
  %158 = fsub <4 x double> %153, %155
  %159 = fadd <4 x double> %158, %157
  %160 = fadd <4 x double> %159, %152
  %161 = bitcast <4 x double> %154 to <4 x i64>
  %162 = and <4 x i64> %161, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %163 = bitcast <4 x i64> %162 to <4 x double>
  %164 = fsub <4 x double> %154, %163
  %165 = fmul <4 x double> %154, %154
  %166 = fmul <4 x double> %163, %163
  %167 = bitcast <4 x double> %165 to <4 x i64>
  %168 = xor <4 x i64> %167, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %169 = bitcast <4 x i64> %168 to <4 x double>
  %170 = fadd <4 x double> %163, %163
  %171 = fmul <4 x double> %170, %164
  %172 = fmul <4 x double> %164, %164
  %173 = fadd <4 x double> %160, %160
  %174 = fmul <4 x double> %154, %173
  %175 = fadd <4 x double> %166, %169
  %176 = fadd <4 x double> %175, %171
  %177 = fadd <4 x double> %172, %176
  %178 = fadd <4 x double> %174, %177
  %179 = and <4 x i64> %167, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %180 = bitcast <4 x i64> %179 to <4 x double>
  %181 = fsub <4 x double> %165, %180
  %182 = fmul <4 x double> %165, %165
  %183 = fmul <4 x double> %180, %180
  %184 = bitcast <4 x double> %182 to <4 x i64>
  %185 = xor <4 x i64> %184, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %186 = bitcast <4 x i64> %185 to <4 x double>
  %187 = fadd <4 x double> %180, %180
  %188 = fmul <4 x double> %187, %181
  %189 = fmul <4 x double> %181, %181
  %190 = fadd <4 x double> %178, %178
  %191 = fmul <4 x double> %165, %190
  %192 = fadd <4 x double> %183, %186
  %193 = fadd <4 x double> %192, %188
  %194 = fadd <4 x double> %189, %193
  %195 = fadd <4 x double> %194, %191
  %196 = fmul <4 x double> %182, %182
  %197 = fmul <4 x double> %154, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %198 = fadd <4 x double> %197, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %199 = fmul <4 x double> %154, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %200 = fadd <4 x double> %199, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %201 = fmul <4 x double> %154, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %202 = fadd <4 x double> %201, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %203 = fmul <4 x double> %165, %200
  %204 = fadd <4 x double> %202, %203
  %205 = fmul <4 x double> %154, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %206 = fadd <4 x double> %205, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %207 = fmul <4 x double> %154, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %208 = fadd <4 x double> %207, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %209 = fmul <4 x double> %165, %206
  %210 = fadd <4 x double> %208, %209
  %211 = fmul <4 x double> %182, %204
  %212 = fadd <4 x double> %210, %211
  %213 = fmul <4 x double> %198, %196
  %214 = fadd <4 x double> %213, %212
  %215 = fmul <4 x double> %154, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %216 = fmul <4 x double> %163, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %217 = bitcast <4 x double> %215 to <4 x i64>
  %218 = xor <4 x i64> %217, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %219 = bitcast <4 x i64> %218 to <4 x double>
  %220 = fmul <4 x double> %164, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %221 = fmul <4 x double> %163, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %222 = fmul <4 x double> %164, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %223 = fmul <4 x double> %160, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %224 = fadd <4 x double> %216, %219
  %225 = fadd <4 x double> %220, %224
  %226 = fadd <4 x double> %221, %225
  %227 = fadd <4 x double> %222, %226
  %228 = fadd <4 x double> %223, %227
  %229 = fadd <4 x double> %215, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %230 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %229
  %231 = fadd <4 x double> %215, %230
  %232 = fadd <4 x double> %231, %228
  %233 = bitcast <4 x double> %229 to <4 x i64>
  %234 = and <4 x i64> %233, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %235 = bitcast <4 x i64> %234 to <4 x double>
  %236 = fsub <4 x double> %229, %235
  %237 = fmul <4 x double> %154, %229
  %238 = fmul <4 x double> %163, %235
  %239 = bitcast <4 x double> %237 to <4 x i64>
  %240 = xor <4 x i64> %239, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %241 = bitcast <4 x i64> %240 to <4 x double>
  %242 = fmul <4 x double> %236, %163
  %243 = fmul <4 x double> %164, %235
  %244 = fmul <4 x double> %164, %236
  %245 = fmul <4 x double> %229, %160
  %246 = fmul <4 x double> %154, %232
  %247 = fadd <4 x double> %238, %241
  %248 = fadd <4 x double> %242, %247
  %249 = fadd <4 x double> %243, %248
  %250 = fadd <4 x double> %244, %249
  %251 = fadd <4 x double> %245, %250
  %252 = fadd <4 x double> %246, %251
  %253 = fadd <4 x double> %237, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %254 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %253
  %255 = fadd <4 x double> %237, %254
  %256 = fadd <4 x double> %255, %252
  %257 = bitcast <4 x double> %253 to <4 x i64>
  %258 = and <4 x i64> %257, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %259 = bitcast <4 x i64> %258 to <4 x double>
  %260 = fsub <4 x double> %253, %259
  %261 = fmul <4 x double> %154, %253
  %262 = fmul <4 x double> %163, %259
  %263 = bitcast <4 x double> %261 to <4 x i64>
  %264 = xor <4 x i64> %263, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %265 = bitcast <4 x i64> %264 to <4 x double>
  %266 = fmul <4 x double> %260, %163
  %267 = fmul <4 x double> %164, %259
  %268 = fmul <4 x double> %164, %260
  %269 = fmul <4 x double> %253, %160
  %270 = fmul <4 x double> %154, %256
  %271 = fadd <4 x double> %262, %265
  %272 = fadd <4 x double> %266, %271
  %273 = fadd <4 x double> %267, %272
  %274 = fadd <4 x double> %268, %273
  %275 = fadd <4 x double> %269, %274
  %276 = fadd <4 x double> %275, %270
  %277 = fadd <4 x double> %261, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %278 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %277
  %279 = fadd <4 x double> %261, %278
  %280 = fadd <4 x double> %279, %276
  %281 = and <4 x i64> %184, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %282 = bitcast <4 x i64> %281 to <4 x double>
  %283 = fsub <4 x double> %182, %282
  %284 = bitcast <4 x double> %214 to <4 x i64>
  %285 = and <4 x i64> %284, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %286 = bitcast <4 x i64> %285 to <4 x double>
  %287 = fsub <4 x double> %214, %286
  %288 = fmul <4 x double> %182, %214
  %289 = fmul <4 x double> %282, %286
  %290 = bitcast <4 x double> %288 to <4 x i64>
  %291 = xor <4 x i64> %290, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %292 = bitcast <4 x i64> %291 to <4 x double>
  %293 = fmul <4 x double> %283, %286
  %294 = fmul <4 x double> %287, %282
  %295 = fmul <4 x double> %283, %287
  %296 = fmul <4 x double> %214, %195
  %297 = fadd <4 x double> %289, %292
  %298 = fadd <4 x double> %293, %297
  %299 = fadd <4 x double> %294, %298
  %300 = fadd <4 x double> %295, %299
  %301 = fadd <4 x double> %296, %300
  %302 = fadd <4 x double> %277, %288
  %303 = fsub <4 x double> %277, %302
  %304 = fadd <4 x double> %288, %303
  %305 = fadd <4 x double> %304, %280
  %306 = fadd <4 x double> %301, %305
  %307 = ashr <4 x i32> %144, <i32 1, i32 1, i32 1, i32 1>
  %308 = add nsw <4 x i32> %307, <i32 1023, i32 1023, i32 1023, i32 1023>
  %309 = shufflevector <4 x i32> %308, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %310 = shufflevector <4 x i32> %308, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %311 = and <4 x i32> %309, <i32 0, i32 -1, i32 0, i32 -1>
  %312 = shl <4 x i32> %311, <i32 20, i32 20, i32 20, i32 20>
  %313 = and <4 x i32> %310, <i32 0, i32 -1, i32 0, i32 -1>
  %314 = shl <4 x i32> %313, <i32 20, i32 20, i32 20, i32 20>
  %315 = bitcast <4 x i32> %312 to <2 x i64>
  %316 = bitcast <4 x i32> %314 to <2 x i64>
  %317 = shufflevector <2 x i64> %315, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %318 = shufflevector <2 x i64> %316, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %319 = shufflevector <4 x i64> %317, <4 x i64> %318, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %320 = bitcast <4 x i64> %319 to <4 x double>
  %321 = fmul <4 x double> %302, %320
  %322 = sub <4 x i32> %144, %307
  %323 = add <4 x i32> %322, <i32 1023, i32 1023, i32 1023, i32 1023>
  %324 = shufflevector <4 x i32> %323, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %325 = shufflevector <4 x i32> %323, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %326 = and <4 x i32> %324, <i32 0, i32 -1, i32 0, i32 -1>
  %327 = shl <4 x i32> %326, <i32 20, i32 20, i32 20, i32 20>
  %328 = and <4 x i32> %325, <i32 0, i32 -1, i32 0, i32 -1>
  %329 = shl <4 x i32> %328, <i32 20, i32 20, i32 20, i32 20>
  %330 = bitcast <4 x i32> %327 to <2 x i64>
  %331 = bitcast <4 x i32> %329 to <2 x i64>
  %332 = shufflevector <2 x i64> %330, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %333 = shufflevector <2 x i64> %331, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %334 = shufflevector <4 x i64> %332, <4 x i64> %333, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %335 = bitcast <4 x i64> %334 to <4 x double>
  %336 = fmul <4 x double> %321, %335
  %337 = fmul <4 x double> %306, %320
  %338 = fmul <4 x double> %337, %335
  %339 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %112, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %340 = bitcast <4 x double> %339 to <4 x i64>
  %341 = bitcast <4 x double> %336 to <4 x i64>
  %342 = xor <4 x i64> %340, <i64 -1, i64 -1, i64 -1, i64 -1>
  %343 = and <4 x i64> %341, %342
  %344 = bitcast <4 x double> %338 to <4 x i64>
  %345 = and <4 x i64> %344, %342
  %346 = xor <4 x i64> %343, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %347 = xor <4 x i64> %345, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %348 = bitcast <4 x i64> %346 to <4 x double>
  %349 = bitcast <4 x i64> %347 to <4 x double>
  %350 = fadd <4 x double> %348, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %351 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %350
  %352 = fadd <4 x double> %351, %348
  %353 = fadd <4 x double> %352, %349
  %354 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %350, <4 x double> %127, <4 x double> %5) #6
  %355 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %353, <4 x double> %140, <4 x double> %5) #6
  %356 = fadd <4 x double> %354, %355
  %357 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %356, <4 x double> %7) #6
  %358 = bitcast <4 x double> %357 to <4 x i64>
  %359 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %360 = xor <4 x i64> %359, %358
  %361 = bitcast <4 x i64> %360 to <4 x double>
  %362 = fcmp uno <4 x double> %4, zeroinitializer
  %363 = sext <4 x i1> %362 to <4 x i64>
  %364 = bitcast <4 x i64> %363 to <4 x double>
  %365 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %361, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %364) #6
  ret <4 x double> %365
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_erfcd4_u15avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i8 17) #6
  %6 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00>, i8 17) #6
  %7 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00>, i8 17) #6
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01>, i8 17) #6
  %9 = and <4 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %10 = bitcast <4 x i64> %9 to <4 x double>
  %11 = fsub <4 x double> %4, %10
  %12 = fmul <4 x double> %4, %4
  %13 = fmul <4 x double> %10, %10
  %14 = bitcast <4 x double> %12 to <4 x i64>
  %15 = xor <4 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %16 = bitcast <4 x i64> %15 to <4 x double>
  %17 = fmul <4 x double> %11, %10
  %18 = fmul <4 x double> %11, %11
  %19 = fadd <4 x double> %13, %16
  %20 = fadd <4 x double> %17, %19
  %21 = fadd <4 x double> %17, %20
  %22 = fadd <4 x double> %18, %21
  %23 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %24 = bitcast <4 x double> %23 to <4 x i64>
  %25 = and <4 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <4 x i64> %25 to <4 x double>
  %27 = fsub <4 x double> %23, %26
  %28 = fsub <4 x double> %26, %23
  %29 = fmul <4 x double> %26, zeroinitializer
  %30 = fmul <4 x double> %27, zeroinitializer
  %31 = fmul <4 x double> %10, %26
  %32 = fmul <4 x double> %27, %10
  %33 = fmul <4 x double> %11, %26
  %34 = fmul <4 x double> %11, %27
  %35 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %31
  %36 = fsub <4 x double> %35, %32
  %37 = fsub <4 x double> %36, %33
  %38 = fsub <4 x double> %37, %34
  %39 = fmul <4 x double> %23, %38
  %40 = fadd <4 x double> %28, %27
  %41 = fadd <4 x double> %29, %40
  %42 = fadd <4 x double> %30, %41
  %43 = fadd <4 x double> %42, %39
  %44 = fmul <4 x double> %23, zeroinitializer
  %45 = fsub <4 x double> zeroinitializer, %44
  %46 = fmul <4 x double> %23, %45
  %47 = fadd <4 x double> %46, %43
  %48 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> %4, <4 x double> %6) #6
  %49 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %47, <4 x double> zeroinitializer, <4 x double> %6) #6
  %50 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %48, <4 x double> %12, <4 x double> %5) #6
  %51 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %49, <4 x double> %22, <4 x double> %5) #6
  %52 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x40D6CB9FD3B439A9, double 0x40D6CB9FD3B439A9, double 0x40D6CB9FD3B439A9, double 0x40D6CB9FD3B439A9>, <4 x double> <double 0xC04CCA024E41FBF2, double 0xC04CCA024E41FBF2, double 0xC04CCA024E41FBF2, double 0xC04CCA024E41FBF2>, <4 x double> %7) #6
  %53 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %52, <4 x double> <double 0x3D58315E6C186224, double 0x3D58315E6C186224, double 0x3D58315E6C186224, double 0x3D58315E6C186224>, <4 x double> %6) #6
  %54 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %53, <4 x double> <double 0x3BC00EFEFABE9897, double 0x3BC00EFEFABE9897, double 0x3BC00EFEFABE9897, double 0x3BC00EFEFABE9897>, <4 x double> %5) #6
  %55 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xC0E6ED9388CD091B, double 0xC0E6ED9388CD091B, double 0xC0E6ED9388CD091B, double 0xC0E6ED9388CD091B>, <4 x double> <double 0x407D2EDD0AE020CC, double 0x407D2EDD0AE020CC, double 0x407D2EDD0AE020CC, double 0x407D2EDD0AE020CC>, <4 x double> %7) #6
  %56 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %55, <4 x double> <double 0xBDAB33CF696F6246, double 0xBDAB33CF696F6246, double 0xBDAB33CF696F6246, double 0xBDAB33CF696F6246>, <4 x double> %6) #6
  %57 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %56, <4 x double> <double 0xBC0FE6EC06B043F2, double 0xBC0FE6EC06B043F2, double 0xBC0FE6EC06B043F2, double 0xBC0FE6EC06B043F2>, <4 x double> %5) #6
  %58 = fmul <4 x double> %50, %54
  %59 = fadd <4 x double> %58, %57
  %60 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x40DEFD81FD565E63, double 0x40DEFD81FD565E63, double 0x40DEFD81FD565E63, double 0x40DEFD81FD565E63>, <4 x double> <double 0xC09C1151CBEBE895, double 0xC09C1151CBEBE895, double 0xC09C1151CBEBE895, double 0xC09C1151CBEBE895>, <4 x double> %7) #6
  %61 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %60, <4 x double> <double 0x3DED1C000C3FE200, double 0x3DED1C000C3FE200, double 0x3DED1C000C3FE200, double 0x3DED1C000C3FE200>, <4 x double> %6) #6
  %62 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %61, <4 x double> <double 0x3C55A7F67BDE0C13, double 0x3C55A7F67BDE0C13, double 0x3C55A7F67BDE0C13, double 0x3C55A7F67BDE0C13>, <4 x double> %5) #6
  %63 = fmul <4 x double> %50, %59
  %64 = fadd <4 x double> %63, %62
  %65 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x40A955F72FDA349C, double 0x40A955F72FDA349C, double 0x40A955F72FDA349C, double 0x40A955F72FDA349C>, <4 x double> <double 0x40B103E466CE6960, double 0x40B103E466CE6960, double 0x40B103E466CE6960, double 0x40B103E466CE6960>, <4 x double> %7) #6
  %66 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %65, <4 x double> <double 0xBE23ACFF2B1B8BEC, double 0xBE23ACFF2B1B8BEC, double 0xBE23ACFF2B1B8BEC, double 0xBE23ACFF2B1B8BEC>, <4 x double> %6) #6
  %67 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %66, <4 x double> <double 0xBC9A15164BF4F369, double 0xBC9A15164BF4F369, double 0xBC9A15164BF4F369, double 0xBC9A15164BF4F369>, <4 x double> %5) #6
  %68 = fmul <4 x double> %50, %64
  %69 = fadd <4 x double> %68, %67
  %70 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xC0D3ACCB8514AB13, double 0xC0D3ACCB8514AB13, double 0xC0D3ACCB8514AB13, double 0xC0D3ACCB8514AB13>, <4 x double> <double 0xC0BD20424648FD63, double 0xC0BD20424648FD63, double 0xC0BD20424648FD63, double 0xC0BD20424648FD63>, <4 x double> %7) #6
  %71 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %70, <4 x double> <double 0x3E52C76D37FDB57D, double 0x3E52C76D37FDB57D, double 0x3E52C76D37FDB57D, double 0x3E52C76D37FDB57D>, <4 x double> %6) #6
  %72 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %71, <4 x double> <double 0x3CDD6F95068FEEA4, double 0x3CDD6F95068FEEA4, double 0x3CDD6F95068FEEA4, double 0x3CDD6F95068FEEA4>, <4 x double> %5) #6
  %73 = fmul <4 x double> %50, %69
  %74 = fadd <4 x double> %73, %72
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x40CE5A08EC3F1AF9, double 0x40CE5A08EC3F1AF9, double 0x40CE5A08EC3F1AF9, double 0x40CE5A08EC3F1AF9>, <4 x double> <double 0x40C2A8FD1A1289EB, double 0x40C2A8FD1A1289EB, double 0x40C2A8FD1A1289EB, double 0x40C2A8FD1A1289EB>, <4 x double> %7) #6
  %76 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %75, <4 x double> <double 0xBE7ABA200DE4015C, double 0xBE7ABA200DE4015C, double 0xBE7ABA200DE4015C, double 0xBE7ABA200DE4015C>, <4 x double> %6) #6
  %77 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %76, <4 x double> <double 0xBD1F56D9FF51274F, double 0xBD1F56D9FF51274F, double 0xBD1F56D9FF51274F, double 0xBD1F56D9FF51274F>, <4 x double> %5) #6
  %78 = fmul <4 x double> %50, %74
  %79 = fadd <4 x double> %78, %77
  %80 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xC0B806DFCAF3E8F0, double 0xC0B806DFCAF3E8F0, double 0xC0B806DFCAF3E8F0, double 0xC0B806DFCAF3E8F0>, <4 x double> <double 0xC0C27F028C42F7FD, double 0xC0C27F028C42F7FD, double 0xC0C27F028C42F7FD, double 0xC0C27F028C42F7FD>, <4 x double> %7) #6
  %81 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %80, <4 x double> <double 0x3E9D0EE6A4A80D73, double 0x3E9D0EE6A4A80D73, double 0x3E9D0EE6A4A80D73, double 0x3E9D0EE6A4A80D73>, <4 x double> %6) #6
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %81, <4 x double> <double 0x3D5F683984140301, double 0x3D5F683984140301, double 0x3D5F683984140301, double 0x3D5F683984140301>, <4 x double> %5) #6
  %83 = fmul <4 x double> %50, %79
  %84 = fadd <4 x double> %83, %82
  %85 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x40936030E9797DA0, double 0x40936030E9797DA0, double 0x40936030E9797DA0, double 0x40936030E9797DA0>, <4 x double> <double 0x40BCDB58257A0C6D, double 0x40BCDB58257A0C6D, double 0x40BCDB58257A0C6D, double 0x40BCDB58257A0C6D>, <4 x double> %7) #6
  %86 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %85, <4 x double> <double 0xBEB8137ED27E2624, double 0xBEB8137ED27E2624, double 0xBEB8137ED27E2624, double 0xBEB8137ED27E2624>, <4 x double> %6) #6
  %87 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %86, <4 x double> <double 0xBD9D8453B9E7FD78, double 0xBD9D8453B9E7FD78, double 0xBD9D8453B9E7FD78, double 0xBD9D8453B9E7FD78>, <4 x double> %5) #6
  %88 = fmul <4 x double> %50, %84
  %89 = fadd <4 x double> %88, %87
  %90 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xC054869BB9D7AF08, double 0xC054869BB9D7AF08, double 0xC054869BB9D7AF08, double 0xC054869BB9D7AF08>, <4 x double> <double 0xC0B1CDB68AB7C4E4, double 0xC0B1CDB68AB7C4E4, double 0xC0B1CDB68AB7C4E4, double 0xC0B1CDB68AB7C4E4>, <4 x double> %7) #6
  %91 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %90, <4 x double> <double 0x3ECD0697CBB9A376, double 0x3ECD0697CBB9A376, double 0x3ECD0697CBB9A376, double 0x3ECD0697CBB9A376>, <4 x double> %6) #6
  %92 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %91, <4 x double> <double 0x3DD9E6AD5DAB7037, double 0x3DD9E6AD5DAB7037, double 0x3DD9E6AD5DAB7037, double 0x3DD9E6AD5DAB7037>, <4 x double> %5) #6
  %93 = fmul <4 x double> %50, %89
  %94 = fadd <4 x double> %93, %92
  %95 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x4040365402C89D37, double 0x4040365402C89D37, double 0x4040365402C89D37, double 0x4040365402C89D37>, <4 x double> <double 0x40A13FBBE32520BC, double 0x40A13FBBE32520BC, double 0x40A13FBBE32520BC, double 0x40A13FBBE32520BC>, <4 x double> %7) #6
  %96 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %95, <4 x double> <double 0xBED4ECCCA37D22C1, double 0xBED4ECCCA37D22C1, double 0xBED4ECCCA37D22C1, double 0xBED4ECCCA37D22C1>, <4 x double> %6) #6
  %97 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %96, <4 x double> <double 0xBE151D7181C08BA0, double 0xBE151D7181C08BA0, double 0xBE151D7181C08BA0, double 0xBE151D7181C08BA0>, <4 x double> %5) #6
  %98 = fmul <4 x double> %50, %94
  %99 = fadd <4 x double> %98, %97
  %100 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xC03D3BF3C95EBAA1, double 0xC03D3BF3C95EBAA1, double 0xC03D3BF3C95EBAA1, double 0xC03D3BF3C95EBAA1>, <4 x double> <double 0xC089AE616A35F399, double 0xC089AE616A35F399, double 0xC089AE616A35F399, double 0xC089AE616A35F399>, <4 x double> %7) #6
  %101 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> <double 0xBEB5F5266774B791, double 0xBEB5F5266774B791, double 0xBEB5F5266774B791, double 0xBEB5F5266774B791>, <4 x double> %6) #6
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %101, <4 x double> <double 0x3E4FCC572062092A, double 0x3E4FCC572062092A, double 0x3E4FCC572062092A, double 0x3E4FCC572062092A>, <4 x double> %5) #6
  %103 = fmul <4 x double> %50, %99
  %104 = fadd <4 x double> %103, %102
  %105 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FD620B48EBD7FD2, double 0x3FD620B48EBD7FD2, double 0x3FD620B48EBD7FD2, double 0x3FD620B48EBD7FD2>, <4 x double> <double 0x406C5BB5D950D59F, double 0x406C5BB5D950D59F, double 0x406C5BB5D950D59F, double 0x406C5BB5D950D59F>, <4 x double> %7) #6
  %106 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %105, <4 x double> <double 0x3EFD9F88B02EA0EC, double 0x3EFD9F88B02EA0EC, double 0x3EFD9F88B02EA0EC, double 0x3EFD9F88B02EA0EC>, <4 x double> %6) #6
  %107 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %106, <4 x double> <double 0xBE85F742EC43E5BC, double 0xBE85F742EC43E5BC, double 0xBE85F742EC43E5BC, double 0xBE85F742EC43E5BC>, <4 x double> %5) #6
  %108 = fmul <4 x double> %50, %104
  %109 = fadd <4 x double> %108, %107
  %110 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x4015F57BD26EB8D7, double 0x4015F57BD26EB8D7, double 0x4015F57BD26EB8D7, double 0x4015F57BD26EB8D7>, <4 x double> <double 0xC0472AB3D15A1B99, double 0xC0472AB3D15A1B99, double 0xC0472AB3D15A1B99, double 0xC0472AB3D15A1B99>, <4 x double> %7) #6
  %111 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %110, <4 x double> <double 0xBF10C2E202FB0D80, double 0xBF10C2E202FB0D80, double 0xBF10C2E202FB0D80, double 0xBF10C2E202FB0D80>, <4 x double> %6) #6
  %112 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %111, <4 x double> <double 0x3EBB9E6C9DC6519D, double 0x3EBB9E6C9DC6519D, double 0x3EBB9E6C9DC6519D, double 0x3EBB9E6C9DC6519D>, <4 x double> %5) #6
  %113 = fmul <4 x double> %50, %109
  %114 = fadd <4 x double> %113, %112
  %115 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3F598ED6853E65C9, double 0x3F598ED6853E65C9, double 0x3F598ED6853E65C9, double 0x3F598ED6853E65C9>, <4 x double> <double 0x40231D60ED75C166, double 0x40231D60ED75C166, double 0x40231D60ED75C166, double 0x40231D60ED75C166>, <4 x double> %7) #6
  %116 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %115, <4 x double> <double 0xBEFAE939BE608207, double 0xBEFAE939BE608207, double 0xBEFAE939BE608207, double 0xBEFAE939BE608207>, <4 x double> %6) #6
  %117 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %116, <4 x double> <double 0xBEEF4D25C3E0C2E2, double 0xBEEF4D25C3E0C2E2, double 0xBEEF4D25C3E0C2E2, double 0xBEEF4D25C3E0C2E2>, <4 x double> %5) #6
  %118 = fmul <4 x double> %50, %114
  %119 = fadd <4 x double> %118, %117
  %120 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFF8AAF93486CD89, double 0xBFF8AAF93486CD89, double 0xBFF8AAF93486CD89, double 0xBFF8AAF93486CD89>, <4 x double> <double 0xC007AADCFF61A9EE, double 0xC007AADCFF61A9EE, double 0xC007AADCFF61A9EE, double 0xC007AADCFF61A9EE>, <4 x double> %7) #6
  %121 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %120, <4 x double> <double 0x3F4351BFC5997AEF, double 0x3F4351BFC5997AEF, double 0x3F4351BFC5997AEF, double 0x3F4351BFC5997AEF>, <4 x double> %6) #6
  %122 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %121, <4 x double> <double 0x3F1F9A326F9B89C2, double 0x3F1F9A326F9B89C2, double 0x3F1F9A326F9B89C2, double 0x3F1F9A326F9B89C2>, <4 x double> %5) #6
  %123 = fmul <4 x double> %50, %119
  %124 = fadd <4 x double> %123, %122
  %125 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3EC7AEAC5A2C6C34, double 0x3EC7AEAC5A2C6C34, double 0x3EC7AEAC5A2C6C34, double 0x3EC7AEAC5A2C6C34>, <4 x double> <double 0x3FC56155F28A44A2, double 0x3FC56155F28A44A2, double 0x3FC56155F28A44A2, double 0x3FC56155F28A44A2>, <4 x double> %7) #6
  %126 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %125, <4 x double> <double 0xBF5BC858BD2C3DEE, double 0xBF5BC858BD2C3DEE, double 0xBF5BC858BD2C3DEE, double 0xBF5BC858BD2C3DEE>, <4 x double> %6) #6
  %127 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %126, <4 x double> <double 0xBF4C02DB40040B83, double 0xBF4C02DB40040B83, double 0xBF4C02DB40040B83, double 0xBF4C02DB40040B83>, <4 x double> %5) #6
  %128 = fmul <4 x double> %50, %124
  %129 = fadd <4 x double> %128, %127
  %130 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3FE3FFFFD433AA8A, double 0x3FE3FFFFD433AA8A, double 0x3FE3FFFFD433AA8A, double 0x3FE3FFFFD433AA8A>, <4 x double> <double 0x3FE38258FA079AD9, double 0x3FE38258FA079AD9, double 0x3FE38258FA079AD9, double 0x3FE38258FA079AD9>, <4 x double> %7) #6
  %131 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %130, <4 x double> <double 0x3F2B61E95A64E1B4, double 0x3F2B61E95A64E1B4, double 0x3F2B61E95A64E1B4, double 0x3F2B61E95A64E1B4>, <4 x double> %6) #6
  %132 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %131, <4 x double> <double 0x3F7565BCD0E6A53F, double 0x3F7565BCD0E6A53F, double 0x3F7565BCD0E6A53F, double 0x3F7565BCD0E6A53F>, <4 x double> %5) #6
  %133 = fmul <4 x double> %50, %129
  %134 = fadd <4 x double> %133, %132
  %135 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3E1DEC4B817418DD, double 0x3E1DEC4B817418DD, double 0x3E1DEC4B817418DD, double 0x3E1DEC4B817418DD>, <4 x double> <double 0x3F515AA8B364E28B, double 0x3F515AA8B364E28B, double 0x3F515AA8B364E28B, double 0x3F515AA8B364E28B>, <4 x double> %7) #6
  %136 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %135, <4 x double> <double 0x3F93966FE5D12A2E, double 0x3F93966FE5D12A2E, double 0x3F93966FE5D12A2E, double 0x3F93966FE5D12A2E>, <4 x double> %6) #6
  %137 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %136, <4 x double> <double 0xBF9B82CE31288B51, double 0xBF9B82CE31288B51, double 0xBF9B82CE31288B51, double 0xBF9B82CE31288B51>, <4 x double> %5) #6
  %138 = fmul <4 x double> %50, %134
  %139 = fadd <4 x double> %138, %137
  %140 = bitcast <4 x double> %50 to <4 x i64>
  %141 = and <4 x i64> %140, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %142 = bitcast <4 x i64> %141 to <4 x double>
  %143 = fsub <4 x double> %50, %142
  %144 = bitcast <4 x double> %139 to <4 x i64>
  %145 = and <4 x i64> %144, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <4 x i64> %145 to <4 x double>
  %147 = fsub <4 x double> %139, %146
  %148 = fmul <4 x double> %50, %139
  %149 = fmul <4 x double> %142, %146
  %150 = bitcast <4 x double> %148 to <4 x i64>
  %151 = xor <4 x i64> %150, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %152 = bitcast <4 x i64> %151 to <4 x double>
  %153 = fmul <4 x double> %143, %146
  %154 = fmul <4 x double> %147, %142
  %155 = fmul <4 x double> %143, %147
  %156 = fmul <4 x double> %51, %139
  %157 = fadd <4 x double> %149, %152
  %158 = fadd <4 x double> %153, %157
  %159 = fadd <4 x double> %154, %158
  %160 = fadd <4 x double> %155, %159
  %161 = fadd <4 x double> %156, %160
  %162 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFE0000000038D52, double 0xBFE0000000038D52, double 0xBFE0000000038D52, double 0xBFE0000000038D52>, <4 x double> <double 0xBFE0006CA4753FC8, double 0xBFE0006CA4753FC8, double 0xBFE0006CA4753FC8, double 0xBFE0006CA4753FC8>, <4 x double> %7) #6
  %163 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %162, <4 x double> <double 0xBFBA4F4EAB8311A0, double 0xBFBA4F4EAB8311A0, double 0xBFBA4F4EAB8311A0, double 0xBFBA4F4EAB8311A0>, <4 x double> %6) #6
  %164 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %163, <4 x double> <double 0x3FBCE2F21A042BE2, double 0x3FBCE2F21A042BE2, double 0x3FBCE2F21A042BE2, double 0x3FBCE2F21A042BE2>, <4 x double> %5) #6
  %165 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBC8719E29ACB2723, double 0xBC8719E29ACB2723, double 0xBC8719E29ACB2723, double 0xBC8719E29ACB2723>, <4 x double> <double 0x3C7E64BB064EBF0B, double 0x3C7E64BB064EBF0B, double 0x3C7E64BB064EBF0B, double 0x3C7E64BB064EBF0B>, <4 x double> %7) #6
  %166 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %165, <4 x double> <double 0xBC5CBFA8068241AE, double 0xBC5CBFA8068241AE, double 0xBC5CBFA8068241AE, double 0xBC5CBFA8068241AE>, <4 x double> %6) #6
  %167 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %166, <4 x double> <double 0xBC52871BC5EF8ED7, double 0xBC52871BC5EF8ED7, double 0xBC52871BC5EF8ED7, double 0xBC52871BC5EF8ED7>, <4 x double> %5) #6
  %168 = fadd <4 x double> %148, %164
  %169 = fsub <4 x double> %168, %148
  %170 = fsub <4 x double> %168, %169
  %171 = fsub <4 x double> %148, %170
  %172 = fsub <4 x double> %164, %169
  %173 = fadd <4 x double> %172, %171
  %174 = fadd <4 x double> %167, %161
  %175 = fadd <4 x double> %173, %174
  %176 = bitcast <4 x double> %168 to <4 x i64>
  %177 = and <4 x i64> %176, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %178 = bitcast <4 x i64> %177 to <4 x double>
  %179 = fsub <4 x double> %168, %178
  %180 = fmul <4 x double> %50, %168
  %181 = fmul <4 x double> %142, %178
  %182 = bitcast <4 x double> %180 to <4 x i64>
  %183 = xor <4 x i64> %182, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %184 = bitcast <4 x i64> %183 to <4 x double>
  %185 = fmul <4 x double> %179, %142
  %186 = fmul <4 x double> %143, %178
  %187 = fmul <4 x double> %143, %179
  %188 = fmul <4 x double> %51, %168
  %189 = fmul <4 x double> %50, %175
  %190 = fadd <4 x double> %181, %184
  %191 = fadd <4 x double> %185, %190
  %192 = fadd <4 x double> %186, %191
  %193 = fadd <4 x double> %187, %192
  %194 = fadd <4 x double> %188, %193
  %195 = fadd <4 x double> %189, %194
  %196 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0x3D50B89397C75A64, double 0x3D50B89397C75A64, double 0x3D50B89397C75A64, double 0x3D50B89397C75A64>, <4 x double> <double 0x3EBADCB2F72A1080, double 0x3EBADCB2F72A1080, double 0x3EBADCB2F72A1080, double 0x3EBADCB2F72A1080>, <4 x double> %7) #6
  %197 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %196, <4 x double> <double 0xBFE45F306B230D62, double 0xBFE45F306B230D62, double 0xBFE45F306B230D62, double 0xBFE45F306B230D62>, <4 x double> %6) #6
  %198 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %197, <4 x double> <double 0xBFD812746B0379E7, double 0xBFD812746B0379E7, double 0xBFD812746B0379E7, double 0xBFD812746B0379E7>, <4 x double> %5) #6
  %199 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xB9ED96501FDC09B6, double 0xB9ED96501FDC09B6, double 0xB9ED96501FDC09B6, double 0xB9ED96501FDC09B6>, <4 x double> <double 0x3B2CF38C548C5245, double 0x3B2CF38C548C5245, double 0x3B2CF38C548C5245, double 0x3B2CF38C548C5245>, <4 x double> %7) #6
  %200 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %199, <4 x double> <double 0x3C619932A20CE10B, double 0x3C619932A20CE10B, double 0x3C619932A20CE10B, double 0x3C619932A20CE10B>, <4 x double> %6) #6
  %201 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %200, <4 x double> <double 0x3C6EE12E49CAD52E, double 0x3C6EE12E49CAD52E, double 0x3C6EE12E49CAD52E, double 0x3C6EE12E49CAD52E>, <4 x double> %5) #6
  %202 = fadd <4 x double> %180, %198
  %203 = fsub <4 x double> %202, %180
  %204 = fsub <4 x double> %202, %203
  %205 = fsub <4 x double> %180, %204
  %206 = fsub <4 x double> %198, %203
  %207 = fadd <4 x double> %206, %205
  %208 = fadd <4 x double> %201, %195
  %209 = fadd <4 x double> %207, %208
  %210 = bitcast <4 x double> %202 to <4 x i64>
  %211 = and <4 x i64> %210, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %212 = bitcast <4 x i64> %211 to <4 x double>
  %213 = fsub <4 x double> %202, %212
  %214 = fmul <4 x double> %50, %202
  %215 = fmul <4 x double> %142, %212
  %216 = bitcast <4 x double> %214 to <4 x i64>
  %217 = xor <4 x i64> %216, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %218 = bitcast <4 x i64> %217 to <4 x double>
  %219 = fmul <4 x double> %213, %142
  %220 = fmul <4 x double> %143, %212
  %221 = fmul <4 x double> %143, %213
  %222 = fmul <4 x double> %51, %202
  %223 = fmul <4 x double> %50, %209
  %224 = fadd <4 x double> %215, %218
  %225 = fadd <4 x double> %219, %224
  %226 = fadd <4 x double> %220, %225
  %227 = fadd <4 x double> %221, %226
  %228 = fadd <4 x double> %222, %227
  %229 = fadd <4 x double> %223, %228
  %230 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBFE250D048E7A1C6, double 0xBFE250D048E7A1C6, double 0xBFE250D048E7A1C6, double 0xBFE250D048E7A1C6>, <4 x double> <double 0xBFE250D055891FD0, double 0xBFE250D055891FD0, double 0xBFE250D055891FD0, double 0xBFE250D055891FD0>, <4 x double> %7) #6
  %231 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %230, <4 x double> <double 0xBFF20DD7505C75E8, double 0xBFF20DD7505C75E8, double 0xBFF20DD7505C75E8, double 0xBFF20DD7505C75E8>, <4 x double> %6) #6
  %232 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %231, <4 x double> <double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D, double 0x3FF20DD750429B6D>, <4 x double> %5) #6
  %233 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 0xBC7BA6EE6A6AB496, double 0xBC7BA6EE6A6AB496, double 0xBC7BA6EE6A6AB496, double 0xBC7BA6EE6A6AB496>, <4 x double> <double 0x3C81B3313996DEA7, double 0x3C81B3313996DEA7, double 0x3C81B3313996DEA7, double 0x3C81B3313996DEA7>, <4 x double> %7) #6
  %234 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %233, <4 x double> <double 0x3C9751223FE9154D, double 0x3C9751223FE9154D, double 0x3C9751223FE9154D, double 0x3C9751223FE9154D>, <4 x double> %6) #6
  %235 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %234, <4 x double> <double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D, double 0x3C71AE3A914FED6D>, <4 x double> %5) #6
  %236 = fadd <4 x double> %214, %232
  %237 = fsub <4 x double> %236, %214
  %238 = fsub <4 x double> %236, %237
  %239 = fsub <4 x double> %214, %238
  %240 = fsub <4 x double> %232, %237
  %241 = fadd <4 x double> %240, %239
  %242 = fadd <4 x double> %235, %229
  %243 = fadd <4 x double> %241, %242
  %244 = or <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %245 = bitcast <4 x i64> %244 to <4 x double>
  %246 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %245, <4 x double> %236, <4 x double> %6) #6
  %247 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %243, <4 x double> %6) #6
  %248 = bitcast <4 x double> %246 to <4 x i64>
  %249 = and <4 x i64> %248, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %250 = bitcast <4 x i64> %249 to <4 x double>
  %251 = fsub <4 x double> %246, %250
  %252 = fmul <4 x double> %246, %4
  %253 = fmul <4 x double> %10, %250
  %254 = bitcast <4 x double> %252 to <4 x i64>
  %255 = xor <4 x i64> %254, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %256 = bitcast <4 x i64> %255 to <4 x double>
  %257 = fmul <4 x double> %251, %10
  %258 = fmul <4 x double> %11, %250
  %259 = fmul <4 x double> %11, %251
  %260 = fmul <4 x double> %247, %4
  %261 = fadd <4 x double> %253, %256
  %262 = fadd <4 x double> %257, %261
  %263 = fadd <4 x double> %258, %262
  %264 = fadd <4 x double> %259, %263
  %265 = fadd <4 x double> %260, %264
  %266 = fadd <4 x double> %236, %252
  %267 = fsub <4 x double> %266, %252
  %268 = fsub <4 x double> %266, %267
  %269 = fsub <4 x double> %252, %268
  %270 = fsub <4 x double> %236, %267
  %271 = fadd <4 x double> %270, %269
  %272 = fadd <4 x double> %243, %265
  %273 = fadd <4 x double> %271, %272
  %274 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %266, <4 x double> %252, <4 x double> %6) #6
  %275 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %273, <4 x double> %265, <4 x double> %6) #6
  %276 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %274
  %277 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %276
  %278 = fsub <4 x double> %277, %274
  %279 = fadd <4 x double> %278, zeroinitializer
  %280 = fsub <4 x double> %279, %275
  %281 = fadd <4 x double> %274, %275
  %282 = fmul <4 x double> %281, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %283 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %282, i32 8) #6
  %284 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %283) #6
  %285 = fmul <4 x double> %283, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %286 = fadd <4 x double> %274, %285
  %287 = fsub <4 x double> %286, %274
  %288 = fsub <4 x double> %286, %287
  %289 = fsub <4 x double> %274, %288
  %290 = fsub <4 x double> %285, %287
  %291 = fadd <4 x double> %290, %289
  %292 = fadd <4 x double> %275, %291
  %293 = fmul <4 x double> %283, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %294 = fadd <4 x double> %293, %286
  %295 = fsub <4 x double> %294, %286
  %296 = fsub <4 x double> %294, %295
  %297 = fsub <4 x double> %286, %296
  %298 = fsub <4 x double> %293, %295
  %299 = fadd <4 x double> %298, %297
  %300 = fadd <4 x double> %299, %292
  %301 = bitcast <4 x double> %294 to <4 x i64>
  %302 = and <4 x i64> %301, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %303 = bitcast <4 x i64> %302 to <4 x double>
  %304 = fsub <4 x double> %294, %303
  %305 = fmul <4 x double> %294, %294
  %306 = fmul <4 x double> %303, %303
  %307 = bitcast <4 x double> %305 to <4 x i64>
  %308 = xor <4 x i64> %307, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %309 = bitcast <4 x i64> %308 to <4 x double>
  %310 = fadd <4 x double> %303, %303
  %311 = fmul <4 x double> %310, %304
  %312 = fmul <4 x double> %304, %304
  %313 = fadd <4 x double> %300, %300
  %314 = fmul <4 x double> %294, %313
  %315 = fadd <4 x double> %306, %309
  %316 = fadd <4 x double> %315, %311
  %317 = fadd <4 x double> %312, %316
  %318 = fadd <4 x double> %314, %317
  %319 = and <4 x i64> %307, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %320 = bitcast <4 x i64> %319 to <4 x double>
  %321 = fsub <4 x double> %305, %320
  %322 = fmul <4 x double> %305, %305
  %323 = fmul <4 x double> %320, %320
  %324 = bitcast <4 x double> %322 to <4 x i64>
  %325 = xor <4 x i64> %324, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %326 = bitcast <4 x i64> %325 to <4 x double>
  %327 = fadd <4 x double> %320, %320
  %328 = fmul <4 x double> %327, %321
  %329 = fmul <4 x double> %321, %321
  %330 = fadd <4 x double> %318, %318
  %331 = fmul <4 x double> %305, %330
  %332 = fadd <4 x double> %323, %326
  %333 = fadd <4 x double> %332, %328
  %334 = fadd <4 x double> %329, %333
  %335 = fadd <4 x double> %334, %331
  %336 = fmul <4 x double> %322, %322
  %337 = fmul <4 x double> %294, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %338 = fadd <4 x double> %337, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %339 = fmul <4 x double> %294, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %340 = fadd <4 x double> %339, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %341 = fmul <4 x double> %294, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %342 = fadd <4 x double> %341, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %343 = fmul <4 x double> %305, %340
  %344 = fadd <4 x double> %342, %343
  %345 = fmul <4 x double> %294, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %346 = fadd <4 x double> %345, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %347 = fmul <4 x double> %294, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %348 = fadd <4 x double> %347, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %349 = fmul <4 x double> %305, %346
  %350 = fadd <4 x double> %348, %349
  %351 = fmul <4 x double> %322, %344
  %352 = fadd <4 x double> %350, %351
  %353 = fmul <4 x double> %338, %336
  %354 = fadd <4 x double> %353, %352
  %355 = fmul <4 x double> %294, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %356 = fmul <4 x double> %303, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %357 = bitcast <4 x double> %355 to <4 x i64>
  %358 = xor <4 x i64> %357, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %359 = bitcast <4 x i64> %358 to <4 x double>
  %360 = fmul <4 x double> %304, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %361 = fmul <4 x double> %303, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %362 = fmul <4 x double> %304, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %363 = fmul <4 x double> %300, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %364 = fadd <4 x double> %356, %359
  %365 = fadd <4 x double> %360, %364
  %366 = fadd <4 x double> %361, %365
  %367 = fadd <4 x double> %362, %366
  %368 = fadd <4 x double> %363, %367
  %369 = fadd <4 x double> %355, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %370 = fsub <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %369
  %371 = fadd <4 x double> %355, %370
  %372 = fadd <4 x double> %371, %368
  %373 = bitcast <4 x double> %369 to <4 x i64>
  %374 = and <4 x i64> %373, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %375 = bitcast <4 x i64> %374 to <4 x double>
  %376 = fsub <4 x double> %369, %375
  %377 = fmul <4 x double> %294, %369
  %378 = fmul <4 x double> %303, %375
  %379 = bitcast <4 x double> %377 to <4 x i64>
  %380 = xor <4 x i64> %379, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %381 = bitcast <4 x i64> %380 to <4 x double>
  %382 = fmul <4 x double> %376, %303
  %383 = fmul <4 x double> %304, %375
  %384 = fmul <4 x double> %304, %376
  %385 = fmul <4 x double> %369, %300
  %386 = fmul <4 x double> %294, %372
  %387 = fadd <4 x double> %378, %381
  %388 = fadd <4 x double> %382, %387
  %389 = fadd <4 x double> %383, %388
  %390 = fadd <4 x double> %384, %389
  %391 = fadd <4 x double> %385, %390
  %392 = fadd <4 x double> %386, %391
  %393 = fadd <4 x double> %377, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %394 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %393
  %395 = fadd <4 x double> %377, %394
  %396 = fadd <4 x double> %395, %392
  %397 = bitcast <4 x double> %393 to <4 x i64>
  %398 = and <4 x i64> %397, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %399 = bitcast <4 x i64> %398 to <4 x double>
  %400 = fsub <4 x double> %393, %399
  %401 = fmul <4 x double> %294, %393
  %402 = fmul <4 x double> %303, %399
  %403 = bitcast <4 x double> %401 to <4 x i64>
  %404 = xor <4 x i64> %403, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %405 = bitcast <4 x i64> %404 to <4 x double>
  %406 = fmul <4 x double> %400, %303
  %407 = fmul <4 x double> %304, %399
  %408 = fmul <4 x double> %304, %400
  %409 = fmul <4 x double> %393, %300
  %410 = fmul <4 x double> %294, %396
  %411 = fadd <4 x double> %402, %405
  %412 = fadd <4 x double> %406, %411
  %413 = fadd <4 x double> %407, %412
  %414 = fadd <4 x double> %408, %413
  %415 = fadd <4 x double> %409, %414
  %416 = fadd <4 x double> %415, %410
  %417 = fadd <4 x double> %401, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %418 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %417
  %419 = fadd <4 x double> %401, %418
  %420 = fadd <4 x double> %419, %416
  %421 = and <4 x i64> %324, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %422 = bitcast <4 x i64> %421 to <4 x double>
  %423 = fsub <4 x double> %322, %422
  %424 = bitcast <4 x double> %354 to <4 x i64>
  %425 = and <4 x i64> %424, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %426 = bitcast <4 x i64> %425 to <4 x double>
  %427 = fsub <4 x double> %354, %426
  %428 = fmul <4 x double> %322, %354
  %429 = fmul <4 x double> %422, %426
  %430 = bitcast <4 x double> %428 to <4 x i64>
  %431 = xor <4 x i64> %430, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %432 = bitcast <4 x i64> %431 to <4 x double>
  %433 = fmul <4 x double> %423, %426
  %434 = fmul <4 x double> %427, %422
  %435 = fmul <4 x double> %423, %427
  %436 = fmul <4 x double> %354, %335
  %437 = fadd <4 x double> %429, %432
  %438 = fadd <4 x double> %433, %437
  %439 = fadd <4 x double> %434, %438
  %440 = fadd <4 x double> %435, %439
  %441 = fadd <4 x double> %436, %440
  %442 = fadd <4 x double> %417, %428
  %443 = fsub <4 x double> %417, %442
  %444 = fadd <4 x double> %428, %443
  %445 = fadd <4 x double> %444, %420
  %446 = fadd <4 x double> %441, %445
  %447 = ashr <4 x i32> %284, <i32 1, i32 1, i32 1, i32 1>
  %448 = add nsw <4 x i32> %447, <i32 1023, i32 1023, i32 1023, i32 1023>
  %449 = shufflevector <4 x i32> %448, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %450 = shufflevector <4 x i32> %448, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %451 = and <4 x i32> %449, <i32 0, i32 -1, i32 0, i32 -1>
  %452 = shl <4 x i32> %451, <i32 20, i32 20, i32 20, i32 20>
  %453 = and <4 x i32> %450, <i32 0, i32 -1, i32 0, i32 -1>
  %454 = shl <4 x i32> %453, <i32 20, i32 20, i32 20, i32 20>
  %455 = bitcast <4 x i32> %452 to <2 x i64>
  %456 = bitcast <4 x i32> %454 to <2 x i64>
  %457 = shufflevector <2 x i64> %455, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %458 = shufflevector <2 x i64> %456, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %459 = shufflevector <4 x i64> %457, <4 x i64> %458, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %460 = bitcast <4 x i64> %459 to <4 x double>
  %461 = fmul <4 x double> %442, %460
  %462 = sub <4 x i32> %284, %447
  %463 = add <4 x i32> %462, <i32 1023, i32 1023, i32 1023, i32 1023>
  %464 = shufflevector <4 x i32> %463, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %465 = shufflevector <4 x i32> %463, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %466 = and <4 x i32> %464, <i32 0, i32 -1, i32 0, i32 -1>
  %467 = shl <4 x i32> %466, <i32 20, i32 20, i32 20, i32 20>
  %468 = and <4 x i32> %465, <i32 0, i32 -1, i32 0, i32 -1>
  %469 = shl <4 x i32> %468, <i32 20, i32 20, i32 20, i32 20>
  %470 = bitcast <4 x i32> %467 to <2 x i64>
  %471 = bitcast <4 x i32> %469 to <2 x i64>
  %472 = shufflevector <2 x i64> %470, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %473 = shufflevector <2 x i64> %471, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %474 = shufflevector <4 x i64> %472, <4 x i64> %473, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %475 = bitcast <4 x i64> %474 to <4 x double>
  %476 = fmul <4 x double> %461, %475
  %477 = fmul <4 x double> %446, %460
  %478 = fmul <4 x double> %477, %475
  %479 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %274, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %480 = bitcast <4 x double> %479 to <4 x i64>
  %481 = bitcast <4 x double> %476 to <4 x i64>
  %482 = xor <4 x i64> %480, <i64 -1, i64 -1, i64 -1, i64 -1>
  %483 = and <4 x i64> %481, %482
  %484 = bitcast <4 x double> %478 to <4 x i64>
  %485 = and <4 x i64> %484, %482
  %486 = bitcast <4 x i64> %483 to <4 x double>
  %487 = bitcast <4 x i64> %485 to <4 x double>
  %488 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %486, <4 x double> %276, <4 x double> %5) #6
  %489 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %487, <4 x double> %280, <4 x double> %5) #6
  %490 = bitcast <4 x double> %488 to <4 x i64>
  %491 = and <4 x i64> %490, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %492 = bitcast <4 x i64> %491 to <4 x double>
  %493 = fsub <4 x double> %488, %492
  %494 = fmul <4 x double> %50, %488
  %495 = fmul <4 x double> %142, %492
  %496 = bitcast <4 x double> %494 to <4 x i64>
  %497 = xor <4 x i64> %496, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %498 = bitcast <4 x i64> %497 to <4 x double>
  %499 = fmul <4 x double> %493, %142
  %500 = fmul <4 x double> %143, %492
  %501 = fmul <4 x double> %143, %493
  %502 = fmul <4 x double> %51, %488
  %503 = fmul <4 x double> %50, %489
  %504 = fadd <4 x double> %495, %498
  %505 = fadd <4 x double> %499, %504
  %506 = fadd <4 x double> %500, %505
  %507 = fadd <4 x double> %501, %506
  %508 = fadd <4 x double> %502, %507
  %509 = fadd <4 x double> %503, %508
  %510 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %494, <4 x double> %488, <4 x double> %6) #6
  %511 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %509, <4 x double> %489, <4 x double> %6) #6
  %512 = fadd <4 x double> %510, %511
  %513 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> zeroinitializer, <4 x double> %512, <4 x double> %8) #6
  %514 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %515 = xor <4 x i64> %514, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %516 = bitcast <4 x i64> %515 to <4 x double>
  %517 = fcmp oeq <4 x double> %516, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %518 = sext <4 x i1> %517 to <4 x i64>
  %519 = fsub <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %513
  %520 = bitcast <4 x i64> %518 to <4 x double>
  %521 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %513, <4 x double> %519, <4 x double> %520) #6
  %522 = fcmp uno <4 x double> %0, zeroinitializer
  %523 = sext <4 x i1> %522 to <4 x i64>
  %524 = bitcast <4 x i64> %523 to <4 x double>
  %525 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %521, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %524) #6
  ret <4 x double> %525
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_sincospid4_u05avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  tail call void @Sleef_sincospid4_u05avx(%struct.vdouble2* sret %0, <4 x double> %1)
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_sincospid4_u35avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = fmul <4 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = lshr <4 x i32> %4, <i32 31, i32 31, i32 31, i32 31>
  %6 = xor <4 x i32> %5, <i32 1, i32 1, i32 1, i32 1>
  %7 = add <4 x i32> %6, %4
  %8 = and <4 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %3, %9
  %11 = fmul <4 x double> %10, %10
  %12 = fmul <4 x double> %11, <double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C>
  %13 = fadd <4 x double> %12, <double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5>
  %14 = fmul <4 x double> %11, %13
  %15 = fadd <4 x double> %14, <double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C>
  %16 = fmul <4 x double> %11, %15
  %17 = fadd <4 x double> %16, <double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE>
  %18 = fmul <4 x double> %11, %17
  %19 = fadd <4 x double> %18, <double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5>
  %20 = fmul <4 x double> %11, %19
  %21 = fadd <4 x double> %20, <double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43>
  %22 = fmul <4 x double> %11, %21
  %23 = fadd <4 x double> %22, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %24 = fmul <4 x double> %10, %23
  %25 = fmul <4 x double> %11, <double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3>
  %26 = fadd <4 x double> %25, <double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD>
  %27 = fmul <4 x double> %11, %26
  %28 = fadd <4 x double> %27, <double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707>
  %29 = fmul <4 x double> %11, %28
  %30 = fadd <4 x double> %29, <double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332>
  %31 = fmul <4 x double> %11, %30
  %32 = fadd <4 x double> %31, <double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF>
  %33 = fmul <4 x double> %11, %32
  %34 = fadd <4 x double> %33, <double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA>
  %35 = fmul <4 x double> %11, %34
  %36 = fadd <4 x double> %35, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %37 = fmul <4 x double> %11, %36
  %38 = fadd <4 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %39 = and <4 x i32> %7, <i32 2, i32 2, i32 2, i32 2>
  %40 = icmp eq <4 x i32> %39, zeroinitializer
  %41 = sitofp <4 x i1> %40 to <4 x double>
  %42 = fcmp oeq <4 x double> %41, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %43 = sext <4 x i1> %42 to <4 x i64>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %38, <4 x double> %24, <4 x double> %44) #6
  %46 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %24, <4 x double> %38, <4 x double> %44) #6
  %47 = and <4 x i32> %7, <i32 4, i32 4, i32 4, i32 4>
  %48 = icmp ne <4 x i32> %47, zeroinitializer
  %49 = sitofp <4 x i1> %48 to <4 x double>
  %50 = fcmp oeq <4 x double> %49, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %51 = select <4 x i1> %50, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %52 = bitcast <4 x double> %45 to <4 x i64>
  %53 = xor <4 x i64> %51, %52
  %54 = add <4 x i32> %8, <i32 2, i32 2, i32 2, i32 2>
  %55 = and <4 x i32> %54, <i32 4, i32 4, i32 4, i32 4>
  %56 = icmp ne <4 x i32> %55, zeroinitializer
  %57 = sitofp <4 x i1> %56 to <4 x double>
  %58 = fcmp oeq <4 x double> %57, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %59 = select <4 x i1> %58, <4 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <4 x i64> zeroinitializer
  %60 = bitcast <4 x double> %46 to <4 x i64>
  %61 = xor <4 x i64> %59, %60
  %62 = bitcast <4 x double> %1 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %64, <4 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i8 30) #6
  %66 = bitcast <4 x double> %65 to <4 x i64>
  %67 = xor <4 x i64> %66, <i64 -1, i64 -1, i64 -1, i64 -1>
  %68 = and <4 x i64> %53, %67
  %69 = and <4 x i64> %61, %67
  %70 = fcmp oeq <4 x double> %64, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %71 = sext <4 x i1> %70 to <4 x i64>
  %72 = or <4 x i64> %68, %71
  %73 = or <4 x i64> %69, %71
  %74 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %72, <4 x i64>* %74, align 32, !alias.scope !31
  %75 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %76 = bitcast <4 x double>* %75 to <4 x i64>*
  store <4 x i64> %73, <4 x i64>* %76, align 32, !alias.scope !31
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_modfd4_avx(%struct.vdouble2* noalias nocapture sret, <4 x double>) local_unnamed_addr #2 {
  %3 = fmul <4 x double> %1, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = sitofp <4 x i32> %4 to <4 x double>
  %6 = fmul <4 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <4 x double> %1, %6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %7) #6
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %7, %9
  %11 = bitcast <4 x double> %1 to <4 x i64>
  %12 = and <4 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %13, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 30) #6
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> zeroinitializer, <4 x double> %14) #6
  %16 = bitcast <4 x double> %15 to <4 x i64>
  %17 = and <4 x i64> %16, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %18 = and <4 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %19 = or <4 x i64> %17, %18
  %20 = fsub <4 x double> %1, %15
  %21 = bitcast <4 x double> %20 to <4 x i64>
  %22 = and <4 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = or <4 x i64> %22, %18
  %24 = bitcast %struct.vdouble2* %0 to <4 x i64>*
  store <4 x i64> %19, <4 x i64>* %24, align 32, !alias.scope !34
  %25 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %26 = bitcast <4 x double>* %25 to <4 x i64>*
  store <4 x i64> %23, <4 x i64>* %26, align 32, !alias.scope !34
  ret void
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_logd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fdiv <4 x double> %49, %50
  %52 = fmul <4 x double> %51, %51
  %53 = fmul <4 x double> %52, %52
  %54 = fmul <4 x double> %53, %53
  %55 = fmul <4 x double> %51, %52
  %56 = fmul <4 x double> %52, <double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D>
  %57 = fadd <4 x double> %56, <double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F>
  %58 = fmul <4 x double> %53, <double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39>
  %59 = fadd <4 x double> %58, %57
  %60 = fmul <4 x double> %52, <double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419>
  %61 = fadd <4 x double> %60, <double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987>
  %62 = fmul <4 x double> %52, <double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E>
  %63 = fadd <4 x double> %62, <double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F>
  %64 = fmul <4 x double> %53, %61
  %65 = fadd <4 x double> %63, %64
  %66 = fmul <4 x double> %54, %59
  %67 = fadd <4 x double> %66, %65
  %68 = bitcast <16 x i8> %48 to <4 x i32>
  %69 = sitofp <4 x i32> %68 to <4 x double>
  %70 = fmul <4 x double> %69, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %71 = fmul <4 x double> %51, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %72 = fadd <4 x double> %70, %71
  %73 = fmul <4 x double> %55, %67
  %74 = fadd <4 x double> %72, %73
  %75 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %76 = sext <4 x i1> %75 to <4 x i64>
  %77 = bitcast <4 x i64> %76 to <4 x double>
  %78 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %74, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %77) #6
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %80 = fcmp uno <4 x double> %5, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %81) #6
  %83 = fcmp oeq <4 x double> %5, zeroinitializer
  %84 = sext <4 x i1> %83 to <4 x i64>
  %85 = bitcast <4 x i64> %84 to <4 x double>
  %86 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %82, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %85) #6
  ret <4 x double> %86
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_logd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %101 = fadd <4 x double> %100, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %102 = fmul <4 x double> %98, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %105 = fadd <4 x double> %104, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %106 = fmul <4 x double> %97, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %107 = fadd <4 x double> %106, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %113 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %113, %116
  %118 = fmul <4 x double> %113, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %119 = fmul <4 x double> %116, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %116, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %124 = fmul <4 x double> %117, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %125 = fmul <4 x double> %117, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %126 = fmul <4 x double> %113, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %127 = fadd <4 x double> %119, %122
  %128 = fadd <4 x double> %123, %127
  %129 = fadd <4 x double> %124, %128
  %130 = fadd <4 x double> %125, %129
  %131 = fadd <4 x double> %126, %130
  %132 = fmul <4 x double> %74, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %133 = fmul <4 x double> %96, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %134 = fadd <4 x double> %118, %132
  %135 = fsub <4 x double> %118, %134
  %136 = fadd <4 x double> %132, %135
  %137 = fadd <4 x double> %131, %136
  %138 = fadd <4 x double> %137, %133
  %139 = fmul <4 x double> %74, %97
  %140 = fmul <4 x double> %139, %111
  %141 = fadd <4 x double> %134, %140
  %142 = fsub <4 x double> %134, %141
  %143 = fadd <4 x double> %140, %142
  %144 = fadd <4 x double> %143, %138
  %145 = fadd <4 x double> %141, %144
  %146 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %147 = sext <4 x i1> %146 to <4 x i64>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %148) #6
  %150 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %151 = fcmp uno <4 x double> %5, zeroinitializer
  %152 = select <4 x i1> %151, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %150
  %153 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %149, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %152) #6
  %154 = fcmp oeq <4 x double> %5, zeroinitializer
  %155 = sext <4 x i1> %154 to <4 x i64>
  %156 = bitcast <4 x i64> %155 to <4 x double>
  %157 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %153, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %156) #6
  ret <4 x double> %157
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_powd4_u10avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = tail call <4 x double> @Sleef_powd4_u10avx(<4 x double> %0, <4 x double> %1)
  ret <4 x double> %3
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_sinhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_sinhd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_coshd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_coshd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_tanhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_tanhd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_sinhd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %5, i32 8) #6
  %7 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %6) #6
  %8 = fmul <4 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <4 x double> %8, %4
  %10 = fmul <4 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <4 x double> %10, %9
  %12 = fmul <4 x double> %11, %11
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <4 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <4 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <4 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <4 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <4 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <4 x double> %12, %18
  %22 = fadd <4 x double> %20, %21
  %23 = fmul <4 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <4 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <4 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <4 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <4 x double> %12, %24
  %28 = fadd <4 x double> %26, %27
  %29 = fmul <4 x double> %13, %22
  %30 = fadd <4 x double> %28, %29
  %31 = fmul <4 x double> %16, %14
  %32 = fadd <4 x double> %31, %30
  %33 = fmul <4 x double> %11, %12
  %34 = fmul <4 x double> %33, %32
  %35 = fmul <4 x double> %12, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %36 = fadd <4 x double> %35, %34
  %37 = fadd <4 x double> %11, %36
  %38 = icmp eq <4 x i32> %7, zeroinitializer
  %39 = sitofp <4 x i1> %38 to <4 x double>
  %40 = fcmp oeq <4 x double> %39, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %41 = sext <4 x i1> %40 to <4 x i64>
  %42 = fadd <4 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %43 = ashr <4 x i32> %7, <i32 1, i32 1, i32 1, i32 1>
  %44 = add nsw <4 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023>
  %45 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %46 = shufflevector <4 x i32> %44, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %47 = and <4 x i32> %45, <i32 0, i32 -1, i32 0, i32 -1>
  %48 = shl <4 x i32> %47, <i32 20, i32 20, i32 20, i32 20>
  %49 = and <4 x i32> %46, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = bitcast <4 x i32> %48 to <2 x i64>
  %52 = bitcast <4 x i32> %50 to <2 x i64>
  %53 = shufflevector <2 x i64> %51, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %54 = shufflevector <2 x i64> %52, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %55 = shufflevector <4 x i64> %53, <4 x i64> %54, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %56 = bitcast <4 x i64> %55 to <4 x double>
  %57 = fmul <4 x double> %42, %56
  %58 = sub <4 x i32> %7, %43
  %59 = add <4 x i32> %58, <i32 1023, i32 1023, i32 1023, i32 1023>
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %61 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %62 = and <4 x i32> %60, <i32 0, i32 -1, i32 0, i32 -1>
  %63 = shl <4 x i32> %62, <i32 20, i32 20, i32 20, i32 20>
  %64 = and <4 x i32> %61, <i32 0, i32 -1, i32 0, i32 -1>
  %65 = shl <4 x i32> %64, <i32 20, i32 20, i32 20, i32 20>
  %66 = bitcast <4 x i32> %63 to <2 x i64>
  %67 = bitcast <4 x i32> %65 to <2 x i64>
  %68 = shufflevector <2 x i64> %66, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %69 = shufflevector <2 x i64> %67, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %70 = shufflevector <4 x i64> %68, <4 x i64> %69, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %71 = bitcast <4 x i64> %70 to <4 x double>
  %72 = fmul <4 x double> %57, %71
  %73 = fadd <4 x double> %72, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %74 = bitcast <4 x i64> %41 to <4 x double>
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %73, <4 x double> %37, <4 x double> %74) #6
  %76 = fadd <4 x double> %75, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %77 = fadd <4 x double> %75, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %78 = fdiv <4 x double> %76, %77
  %79 = fmul <4 x double> %75, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %80 = fmul <4 x double> %79, %78
  %81 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i8 30) #6
  %82 = fcmp uno <4 x double> %80, zeroinitializer
  %83 = select <4 x i1> %82, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %81
  %84 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %80, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %83) #6
  %85 = bitcast <4 x double> %84 to <4 x i64>
  %86 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %87 = xor <4 x i64> %86, %85
  %88 = fcmp uno <4 x double> %0, zeroinitializer
  %89 = bitcast <4 x i64> %87 to <4 x double>
  %90 = select <4 x i1> %88, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %89
  ret <4 x double> %90
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_coshd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %5, i32 8) #6
  %7 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %6) #6
  %8 = fmul <4 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <4 x double> %8, %4
  %10 = fmul <4 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <4 x double> %10, %9
  %12 = fmul <4 x double> %11, %11
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <4 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <4 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <4 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <4 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <4 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <4 x double> %12, %18
  %22 = fadd <4 x double> %20, %21
  %23 = fmul <4 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <4 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <4 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <4 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <4 x double> %12, %24
  %28 = fadd <4 x double> %26, %27
  %29 = fmul <4 x double> %13, %22
  %30 = fadd <4 x double> %28, %29
  %31 = fmul <4 x double> %16, %14
  %32 = fadd <4 x double> %31, %30
  %33 = fmul <4 x double> %11, %32
  %34 = fadd <4 x double> %33, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %35 = fmul <4 x double> %12, %34
  %36 = fadd <4 x double> %11, %35
  %37 = fadd <4 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %38 = ashr <4 x i32> %7, <i32 1, i32 1, i32 1, i32 1>
  %39 = add nsw <4 x i32> %38, <i32 1023, i32 1023, i32 1023, i32 1023>
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %41 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %42 = and <4 x i32> %40, <i32 0, i32 -1, i32 0, i32 -1>
  %43 = shl <4 x i32> %42, <i32 20, i32 20, i32 20, i32 20>
  %44 = and <4 x i32> %41, <i32 0, i32 -1, i32 0, i32 -1>
  %45 = shl <4 x i32> %44, <i32 20, i32 20, i32 20, i32 20>
  %46 = bitcast <4 x i32> %43 to <2 x i64>
  %47 = bitcast <4 x i32> %45 to <2 x i64>
  %48 = shufflevector <2 x i64> %46, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %49 = shufflevector <2 x i64> %47, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %50 = shufflevector <4 x i64> %48, <4 x i64> %49, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %51 = bitcast <4 x i64> %50 to <4 x double>
  %52 = fmul <4 x double> %37, %51
  %53 = sub <4 x i32> %7, %38
  %54 = add <4 x i32> %53, <i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %56 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %57 = and <4 x i32> %55, <i32 0, i32 -1, i32 0, i32 -1>
  %58 = shl <4 x i32> %57, <i32 20, i32 20, i32 20, i32 20>
  %59 = and <4 x i32> %56, <i32 0, i32 -1, i32 0, i32 -1>
  %60 = shl <4 x i32> %59, <i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <4 x i32> %58 to <2 x i64>
  %62 = bitcast <4 x i32> %60 to <2 x i64>
  %63 = shufflevector <2 x i64> %61, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %64 = shufflevector <2 x i64> %62, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %65 = shufflevector <4 x i64> %63, <4 x i64> %64, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %66 = bitcast <4 x i64> %65 to <4 x double>
  %67 = fmul <4 x double> %52, %66
  %68 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i8 30) #6
  %69 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %67, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %68) #6
  %70 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i8 17) #6
  %71 = bitcast <4 x double> %70 to <4 x i64>
  %72 = bitcast <4 x double> %69 to <4 x i64>
  %73 = xor <4 x i64> %71, <i64 -1, i64 -1, i64 -1, i64 -1>
  %74 = and <4 x i64> %73, %72
  %75 = bitcast <4 x i64> %74 to <4 x double>
  %76 = fdiv <4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %75
  %77 = fmul <4 x double> %75, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %78 = fadd <4 x double> %77, %76
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i8 30) #6
  %80 = fcmp uno <4 x double> %78, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %81) #6
  %83 = fcmp uno <4 x double> %0, zeroinitializer
  %84 = select <4 x i1> %83, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %82
  ret <4 x double> %84
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_tanhd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %6 = fmul <4 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %6, i32 8) #6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %7) #6
  %9 = fmul <4 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <4 x double> %5, %9
  %11 = fmul <4 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %12 = fadd <4 x double> %11, %10
  %13 = fmul <4 x double> %12, %12
  %14 = fmul <4 x double> %13, %13
  %15 = fmul <4 x double> %14, %14
  %16 = fmul <4 x double> %12, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %17 = fadd <4 x double> %16, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %18 = fmul <4 x double> %12, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %19 = fadd <4 x double> %18, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %20 = fmul <4 x double> %12, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %21 = fadd <4 x double> %20, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %22 = fmul <4 x double> %13, %19
  %23 = fadd <4 x double> %21, %22
  %24 = fmul <4 x double> %12, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %25 = fadd <4 x double> %24, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %26 = fmul <4 x double> %12, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %27 = fadd <4 x double> %26, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %28 = fmul <4 x double> %13, %25
  %29 = fadd <4 x double> %27, %28
  %30 = fmul <4 x double> %14, %23
  %31 = fadd <4 x double> %29, %30
  %32 = fmul <4 x double> %17, %15
  %33 = fadd <4 x double> %32, %31
  %34 = fmul <4 x double> %12, %13
  %35 = fmul <4 x double> %34, %33
  %36 = fmul <4 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %37 = fadd <4 x double> %36, %35
  %38 = fadd <4 x double> %12, %37
  %39 = icmp eq <4 x i32> %8, zeroinitializer
  %40 = sitofp <4 x i1> %39 to <4 x double>
  %41 = fcmp oeq <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %42 = sext <4 x i1> %41 to <4 x i64>
  %43 = fadd <4 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %44 = ashr <4 x i32> %8, <i32 1, i32 1, i32 1, i32 1>
  %45 = add nsw <4 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %47 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %48 = and <4 x i32> %46, <i32 0, i32 -1, i32 0, i32 -1>
  %49 = shl <4 x i32> %48, <i32 20, i32 20, i32 20, i32 20>
  %50 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %51 = shl <4 x i32> %50, <i32 20, i32 20, i32 20, i32 20>
  %52 = bitcast <4 x i32> %49 to <2 x i64>
  %53 = bitcast <4 x i32> %51 to <2 x i64>
  %54 = shufflevector <2 x i64> %52, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <4 x i64> %54, <4 x i64> %55, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %57 = bitcast <4 x i64> %56 to <4 x double>
  %58 = fmul <4 x double> %43, %57
  %59 = sub <4 x i32> %8, %44
  %60 = add <4 x i32> %59, <i32 1023, i32 1023, i32 1023, i32 1023>
  %61 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %62 = shufflevector <4 x i32> %60, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %63 = and <4 x i32> %61, <i32 0, i32 -1, i32 0, i32 -1>
  %64 = shl <4 x i32> %63, <i32 20, i32 20, i32 20, i32 20>
  %65 = and <4 x i32> %62, <i32 0, i32 -1, i32 0, i32 -1>
  %66 = shl <4 x i32> %65, <i32 20, i32 20, i32 20, i32 20>
  %67 = bitcast <4 x i32> %64 to <2 x i64>
  %68 = bitcast <4 x i32> %66 to <2 x i64>
  %69 = shufflevector <2 x i64> %67, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %70 = shufflevector <2 x i64> %68, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %71 = shufflevector <4 x i64> %69, <4 x i64> %70, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fmul <4 x double> %58, %72
  %74 = fadd <4 x double> %73, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %75 = bitcast <4 x i64> %42 to <4 x double>
  %76 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %74, <4 x double> %38, <4 x double> %75) #6
  %77 = fadd <4 x double> %76, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %78 = fdiv <4 x double> %76, %77
  %79 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i8 30) #6
  %80 = fcmp uno <4 x double> %78, zeroinitializer
  %81 = select <4 x i1> %80, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %79
  %82 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %78, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %81) #6
  %83 = bitcast <4 x double> %82 to <4 x i64>
  %84 = and <4 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %85 = xor <4 x i64> %84, %83
  %86 = fcmp uno <4 x double> %0, zeroinitializer
  %87 = bitcast <4 x i64> %85 to <4 x double>
  %88 = select <4 x i1> %86, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %87
  ret <4 x double> %88
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_asinhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_asinhd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_acoshd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_acoshd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_atanhd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_atanhd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_cbrtd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000, double 0x2D30000000000000>, i8 17) #6
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = fmul <4 x double> %4, <double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000, double 0x52B0000000000000>
  %8 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %4, <4 x double> %7, <4 x double> %5) #6
  %9 = bitcast <4 x double> %8 to <4 x i64>
  %10 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %11 = shufflevector <4 x i64> %9, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %12 = bitcast <2 x i64> %10 to <4 x i32>
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %14 = bitcast <4 x i32> %13 to <2 x i64>
  %15 = bitcast <2 x i64> %11 to <4 x i32>
  %16 = shufflevector <4 x i32> %15, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %17 = bitcast <4 x i32> %16 to <2 x i64>
  %18 = shufflevector <2 x i64> %17, <2 x i64> %14, <2 x i32> <i32 2, i32 1>
  %19 = bitcast <2 x i64> %18 to <4 x i32>
  %20 = lshr <4 x i32> %19, <i32 20, i32 20, i32 20, i32 20>
  %21 = and <4 x i64> %6, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %22) #6
  %24 = bitcast <4 x i32> %23 to <16 x i8>
  %25 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> <i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0, i8 -1, i8 3, i8 0, i8 0>, <16 x i8> <i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0, i8 43, i8 5, i8 0, i8 0>, <16 x i8> %24) #6
  %26 = bitcast <16 x i8> %25 to <4 x i32>
  %27 = sub <4 x i32> %20, %26
  %28 = add <4 x i32> %27, <i32 1, i32 1, i32 1, i32 1>
  %29 = xor <4 x i32> %27, <i32 -1, i32 -1, i32 -1, i32 -1>
  %30 = ashr <4 x i32> %29, <i32 1, i32 1, i32 1, i32 1>
  %31 = add nsw <4 x i32> %30, <i32 1023, i32 1023, i32 1023, i32 1023>
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %33 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %34 = and <4 x i32> %32, <i32 0, i32 -1, i32 0, i32 -1>
  %35 = shl <4 x i32> %34, <i32 20, i32 20, i32 20, i32 20>
  %36 = and <4 x i32> %33, <i32 0, i32 -1, i32 0, i32 -1>
  %37 = shl <4 x i32> %36, <i32 20, i32 20, i32 20, i32 20>
  %38 = bitcast <4 x i32> %35 to <2 x i64>
  %39 = bitcast <4 x i32> %37 to <2 x i64>
  %40 = shufflevector <2 x i64> %38, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %41 = shufflevector <2 x i64> %39, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %42 = shufflevector <4 x i64> %40, <4 x i64> %41, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %43 = bitcast <4 x i64> %42 to <4 x double>
  %44 = fmul <4 x double> %43, %0
  %45 = sub <4 x i32> %29, %30
  %46 = add <4 x i32> %45, <i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %48 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %49 = and <4 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1>
  %50 = shl <4 x i32> %49, <i32 20, i32 20, i32 20, i32 20>
  %51 = and <4 x i32> %48, <i32 0, i32 -1, i32 0, i32 -1>
  %52 = shl <4 x i32> %51, <i32 20, i32 20, i32 20, i32 20>
  %53 = bitcast <4 x i32> %50 to <2 x i64>
  %54 = bitcast <4 x i32> %52 to <2 x i64>
  %55 = shufflevector <2 x i64> %53, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %56 = shufflevector <2 x i64> %54, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %57 = shufflevector <4 x i64> %55, <4 x i64> %56, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %44, %58
  %60 = sitofp <4 x i32> %28 to <4 x double>
  %61 = fadd <4 x double> %60, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %62 = fmul <4 x double> %61, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %63 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %62) #6
  %64 = sitofp <4 x i32> %63 to <4 x double>
  %65 = fmul <4 x double> %64, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %66 = fsub <4 x double> %61, %65
  %67 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %66) #6
  %68 = icmp eq <4 x i32> %67, <i32 1, i32 1, i32 1, i32 1>
  %69 = sitofp <4 x i1> %68 to <4 x double>
  %70 = fcmp oeq <4 x double> %69, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %71 = sext <4 x i1> %70 to <4 x i64>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B>, <4 x double> %72) #6
  %74 = icmp eq <4 x i32> %67, <i32 2, i32 2, i32 2, i32 2>
  %75 = sitofp <4 x i1> %74 to <4 x double>
  %76 = fcmp oeq <4 x double> %75, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %77 = sext <4 x i1> %76 to <4 x i64>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %73, <4 x double> <double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D>, <4 x double> %78) #6
  %80 = add <4 x i32> %63, <i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %81 = ashr <4 x i32> %80, <i32 1, i32 1, i32 1, i32 1>
  %82 = add nsw <4 x i32> %81, <i32 1023, i32 1023, i32 1023, i32 1023>
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %84 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %85 = and <4 x i32> %83, <i32 0, i32 -1, i32 0, i32 -1>
  %86 = shl <4 x i32> %85, <i32 20, i32 20, i32 20, i32 20>
  %87 = and <4 x i32> %84, <i32 0, i32 -1, i32 0, i32 -1>
  %88 = shl <4 x i32> %87, <i32 20, i32 20, i32 20, i32 20>
  %89 = bitcast <4 x i32> %86 to <2 x i64>
  %90 = bitcast <4 x i32> %88 to <2 x i64>
  %91 = shufflevector <2 x i64> %89, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %92 = shufflevector <2 x i64> %90, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %93 = shufflevector <4 x i64> %91, <4 x i64> %92, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %94 = bitcast <4 x i64> %93 to <4 x double>
  %95 = fmul <4 x double> %79, %94
  %96 = sub <4 x i32> %80, %81
  %97 = add <4 x i32> %96, <i32 1023, i32 1023, i32 1023, i32 1023>
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %99 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %100 = and <4 x i32> %98, <i32 0, i32 -1, i32 0, i32 -1>
  %101 = shl <4 x i32> %100, <i32 20, i32 20, i32 20, i32 20>
  %102 = and <4 x i32> %99, <i32 0, i32 -1, i32 0, i32 -1>
  %103 = shl <4 x i32> %102, <i32 20, i32 20, i32 20, i32 20>
  %104 = bitcast <4 x i32> %101 to <2 x i64>
  %105 = bitcast <4 x i32> %103 to <2 x i64>
  %106 = shufflevector <2 x i64> %104, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %107 = shufflevector <2 x i64> %105, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %108 = shufflevector <4 x i64> %106, <4 x i64> %107, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %109 = bitcast <4 x i64> %108 to <4 x double>
  %110 = fmul <4 x double> %95, %109
  %111 = bitcast <4 x double> %110 to <4 x i64>
  %112 = bitcast <4 x double> %59 to <4 x i64>
  %113 = and <4 x i64> %112, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %114 = xor <4 x i64> %113, %111
  %115 = bitcast <4 x i64> %114 to <4 x double>
  %116 = and <4 x i64> %112, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %117 = bitcast <4 x i64> %116 to <4 x double>
  %118 = fmul <4 x double> %117, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %119 = fadd <4 x double> %118, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %120 = fmul <4 x double> %119, %117
  %121 = fadd <4 x double> %120, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %122 = fmul <4 x double> %121, %117
  %123 = fadd <4 x double> %122, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %124 = fmul <4 x double> %123, %117
  %125 = fadd <4 x double> %124, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %126 = fmul <4 x double> %125, %117
  %127 = fadd <4 x double> %126, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %128 = fmul <4 x double> %127, %127
  %129 = fmul <4 x double> %128, %128
  %130 = fmul <4 x double> %129, %117
  %131 = fsub <4 x double> %130, %127
  %132 = fmul <4 x double> %131, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %133 = fsub <4 x double> %127, %132
  %134 = fmul <4 x double> %133, %117
  %135 = fmul <4 x double> %133, %134
  %136 = fmul <4 x double> %135, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %137 = fmul <4 x double> %133, %135
  %138 = fadd <4 x double> %137, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %139 = fmul <4 x double> %136, %138
  %140 = fsub <4 x double> %135, %139
  %141 = fmul <4 x double> %140, %115
  ret <4 x double> %141
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_cbrtd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_cbrtd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_expm1d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_expm1d4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_log10d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192>
  %101 = fadd <4 x double> %100, <double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48>
  %102 = fmul <4 x double> %98, <double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74>
  %105 = fadd <4 x double> %104, <double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821>
  %106 = fmul <4 x double> %97, <double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88>
  %107 = fadd <4 x double> %106, <double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %113 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %113, %116
  %118 = fmul <4 x double> %113, <double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF>
  %119 = fmul <4 x double> %116, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %116, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %124 = fmul <4 x double> %117, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %125 = fmul <4 x double> %117, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %126 = fmul <4 x double> %113, <double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21>
  %127 = fadd <4 x double> %119, %122
  %128 = fadd <4 x double> %123, %127
  %129 = fadd <4 x double> %124, %128
  %130 = fadd <4 x double> %125, %129
  %131 = fadd <4 x double> %126, %130
  %132 = bitcast <4 x double> %74 to <4 x i64>
  %133 = and <4 x i64> %132, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %134 = bitcast <4 x i64> %133 to <4 x double>
  %135 = fsub <4 x double> %74, %134
  %136 = fmul <4 x double> %74, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %137 = fmul <4 x double> %134, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %138 = bitcast <4 x double> %136 to <4 x i64>
  %139 = xor <4 x i64> %138, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = fmul <4 x double> %135, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %142 = fmul <4 x double> %134, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %143 = fmul <4 x double> %135, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %144 = fmul <4 x double> %74, <double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F>
  %145 = fmul <4 x double> %96, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %146 = fadd <4 x double> %137, %140
  %147 = fadd <4 x double> %141, %146
  %148 = fadd <4 x double> %142, %147
  %149 = fadd <4 x double> %143, %148
  %150 = fadd <4 x double> %144, %149
  %151 = fadd <4 x double> %150, %145
  %152 = fadd <4 x double> %118, %136
  %153 = fsub <4 x double> %118, %152
  %154 = fadd <4 x double> %136, %153
  %155 = fadd <4 x double> %131, %154
  %156 = fadd <4 x double> %155, %151
  %157 = fmul <4 x double> %74, %97
  %158 = fmul <4 x double> %157, %111
  %159 = fadd <4 x double> %152, %158
  %160 = fsub <4 x double> %152, %159
  %161 = fadd <4 x double> %158, %160
  %162 = fadd <4 x double> %161, %156
  %163 = fadd <4 x double> %159, %162
  %164 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %165 = sext <4 x i1> %164 to <4 x i64>
  %166 = bitcast <4 x i64> %165 to <4 x double>
  %167 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %163, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %166) #6
  %168 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %169 = fcmp uno <4 x double> %5, zeroinitializer
  %170 = select <4 x i1> %169, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %168
  %171 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %167, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %170) #6
  %172 = fcmp oeq <4 x double> %5, zeroinitializer
  %173 = sext <4 x i1> %172 to <4 x i64>
  %174 = bitcast <4 x i64> %173 to <4 x double>
  %175 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %171, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %174) #6
  ret <4 x double> %175
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_log2d4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %49, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fsub <4 x double> %49, %50
  %52 = fsub <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %51
  %53 = fsub <4 x double> %40, %50
  %54 = fadd <4 x double> %53, %52
  %55 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %56 = fadd <4 x double> %55, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %57 = fsub <4 x double> %55, %56
  %58 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %57
  %59 = fsub <4 x double> %40, %56
  %60 = fadd <4 x double> %59, %58
  %61 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %55
  %62 = bitcast <4 x double> %55 to <4 x i64>
  %63 = and <4 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fsub <4 x double> %55, %64
  %66 = bitcast <4 x double> %61 to <4 x i64>
  %67 = and <4 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <4 x i64> %67 to <4 x double>
  %69 = fsub <4 x double> %61, %68
  %70 = bitcast <4 x double> %49 to <4 x i64>
  %71 = and <4 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <4 x i64> %71 to <4 x double>
  %73 = fsub <4 x double> %49, %72
  %74 = fmul <4 x double> %49, %61
  %75 = fmul <4 x double> %72, %68
  %76 = fsub <4 x double> %75, %74
  %77 = fmul <4 x double> %69, %72
  %78 = fmul <4 x double> %73, %68
  %79 = fmul <4 x double> %73, %69
  %80 = fmul <4 x double> %64, %68
  %81 = fmul <4 x double> %69, %64
  %82 = fmul <4 x double> %65, %68
  %83 = fmul <4 x double> %65, %69
  %84 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %80
  %85 = fsub <4 x double> %84, %81
  %86 = fsub <4 x double> %85, %82
  %87 = fsub <4 x double> %86, %83
  %88 = fmul <4 x double> %74, %87
  %89 = fadd <4 x double> %76, %77
  %90 = fadd <4 x double> %78, %89
  %91 = fadd <4 x double> %79, %90
  %92 = fadd <4 x double> %91, %88
  %93 = fmul <4 x double> %74, %60
  %94 = fsub <4 x double> %54, %93
  %95 = fmul <4 x double> %61, %94
  %96 = fadd <4 x double> %95, %92
  %97 = fmul <4 x double> %74, %74
  %98 = fmul <4 x double> %97, %97
  %99 = fmul <4 x double> %98, %98
  %100 = fmul <4 x double> %97, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %101 = fadd <4 x double> %100, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %102 = fmul <4 x double> %98, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %103 = fadd <4 x double> %102, %101
  %104 = fmul <4 x double> %97, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %105 = fadd <4 x double> %104, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %106 = fmul <4 x double> %97, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %107 = fadd <4 x double> %106, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %108 = fmul <4 x double> %98, %105
  %109 = fadd <4 x double> %107, %108
  %110 = fmul <4 x double> %99, %103
  %111 = fadd <4 x double> %110, %109
  %112 = bitcast <16 x i8> %48 to <4 x i32>
  %113 = sitofp <4 x i32> %112 to <4 x double>
  %114 = bitcast <4 x double> %74 to <4 x i64>
  %115 = and <4 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <4 x i64> %115 to <4 x double>
  %117 = fsub <4 x double> %74, %116
  %118 = fmul <4 x double> %74, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %119 = fmul <4 x double> %116, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %120 = bitcast <4 x double> %118 to <4 x i64>
  %121 = xor <4 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <4 x i64> %121 to <4 x double>
  %123 = fmul <4 x double> %117, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %124 = fmul <4 x double> %116, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %125 = fmul <4 x double> %117, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %126 = fmul <4 x double> %74, <double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1>
  %127 = fmul <4 x double> %96, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %128 = fadd <4 x double> %119, %122
  %129 = fadd <4 x double> %123, %128
  %130 = fadd <4 x double> %124, %129
  %131 = fadd <4 x double> %125, %130
  %132 = fadd <4 x double> %126, %131
  %133 = fadd <4 x double> %132, %127
  %134 = fadd <4 x double> %118, %113
  %135 = fsub <4 x double> %134, %113
  %136 = fsub <4 x double> %134, %135
  %137 = fsub <4 x double> %113, %136
  %138 = fsub <4 x double> %118, %135
  %139 = fadd <4 x double> %138, %137
  %140 = fadd <4 x double> %139, %133
  %141 = fmul <4 x double> %74, %97
  %142 = fmul <4 x double> %141, %111
  %143 = fadd <4 x double> %134, %142
  %144 = fsub <4 x double> %143, %134
  %145 = fsub <4 x double> %143, %144
  %146 = fsub <4 x double> %134, %145
  %147 = fsub <4 x double> %142, %144
  %148 = fadd <4 x double> %147, %146
  %149 = fadd <4 x double> %148, %140
  %150 = fadd <4 x double> %143, %149
  %151 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %152 = sext <4 x i1> %151 to <4 x i64>
  %153 = bitcast <4 x i64> %152 to <4 x double>
  %154 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %150, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %153) #6
  %155 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %156 = fcmp uno <4 x double> %5, zeroinitializer
  %157 = select <4 x i1> %156, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %155
  %158 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %154, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %157) #6
  %159 = fcmp oeq <4 x double> %5, zeroinitializer
  %160 = sext <4 x i1> %159 to <4 x i64>
  %161 = bitcast <4 x i64> %160 to <4 x double>
  %162 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %158, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %161) #6
  ret <4 x double> %162
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_log2d4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %3 = bitcast <4 x double> %2 to <4 x i64>
  %4 = fmul <4 x double> %0, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %5 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %4, <4 x double> %2) #6
  %6 = fmul <4 x double> %5, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %7 = bitcast <4 x double> %6 to <4 x i64>
  %8 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %9 = shufflevector <4 x i64> %7, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %10 = bitcast <2 x i64> %8 to <4 x i32>
  %11 = shufflevector <4 x i32> %10, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %12 = bitcast <4 x i32> %11 to <2 x i64>
  %13 = bitcast <2 x i64> %9 to <4 x i32>
  %14 = shufflevector <4 x i32> %13, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %15 = bitcast <4 x i32> %14 to <2 x i64>
  %16 = shufflevector <2 x i64> %15, <2 x i64> %12, <2 x i32> <i32 2, i32 1>
  %17 = bitcast <2 x i64> %16 to <4 x i32>
  %18 = lshr <4 x i32> %17, <i32 20, i32 20, i32 20, i32 20>
  %19 = and <4 x i32> %18, <i32 2047, i32 2047, i32 2047, i32 2047>
  %20 = add nsw <4 x i32> %19, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %21 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %19
  %22 = bitcast <4 x double> %5 to <4 x i64>
  %23 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %24 = shufflevector <4 x i64> %22, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %25 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %26 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %27 = and <4 x i32> %25, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = and <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = shl <4 x i32> %29, <i32 20, i32 20, i32 20, i32 20>
  %31 = bitcast <2 x i64> %23 to <4 x i32>
  %32 = add <4 x i32> %28, %31
  %33 = bitcast <2 x i64> %24 to <4 x i32>
  %34 = add <4 x i32> %30, %33
  %35 = bitcast <4 x i32> %32 to <2 x i64>
  %36 = bitcast <4 x i32> %34 to <2 x i64>
  %37 = shufflevector <2 x i64> %35, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %38 = shufflevector <2 x i64> %36, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %39 = shufflevector <4 x i64> %37, <4 x i64> %38, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %40 = bitcast <4 x i64> %39 to <4 x double>
  %41 = and <4 x i64> %3, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %42 = bitcast <4 x i64> %41 to <4 x double>
  %43 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %42) #6
  %44 = add nsw <4 x i32> %19, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %45 = bitcast <4 x i32> %20 to <16 x i8>
  %46 = bitcast <4 x i32> %44 to <16 x i8>
  %47 = bitcast <4 x i32> %43 to <16 x i8>
  %48 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %45, <16 x i8> %46, <16 x i8> %47) #6
  %49 = fadd <4 x double> %40, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %50 = fadd <4 x double> %40, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %51 = fdiv <4 x double> %49, %50
  %52 = fmul <4 x double> %51, %51
  %53 = fmul <4 x double> %52, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %54 = fadd <4 x double> %53, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %55 = fmul <4 x double> %52, %54
  %56 = fadd <4 x double> %55, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %57 = fmul <4 x double> %52, %56
  %58 = fadd <4 x double> %57, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %59 = fmul <4 x double> %52, %58
  %60 = fadd <4 x double> %59, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %61 = fmul <4 x double> %52, %60
  %62 = fadd <4 x double> %61, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %63 = fmul <4 x double> %52, %62
  %64 = fadd <4 x double> %63, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %65 = bitcast <16 x i8> %48 to <4 x i32>
  %66 = sitofp <4 x i32> %65 to <4 x double>
  %67 = bitcast <4 x double> %51 to <4 x i64>
  %68 = and <4 x i64> %67, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %69 = bitcast <4 x i64> %68 to <4 x double>
  %70 = fsub <4 x double> %51, %69
  %71 = fmul <4 x double> %51, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %72 = fmul <4 x double> %69, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %73 = bitcast <4 x double> %71 to <4 x i64>
  %74 = xor <4 x i64> %73, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %75 = bitcast <4 x i64> %74 to <4 x double>
  %76 = fmul <4 x double> %70, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %77 = fmul <4 x double> %69, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %78 = fmul <4 x double> %70, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %79 = fadd <4 x double> %72, %75
  %80 = fadd <4 x double> %76, %79
  %81 = fadd <4 x double> %77, %80
  %82 = fadd <4 x double> %78, %81
  %83 = fadd <4 x double> %71, %66
  %84 = fsub <4 x double> %66, %83
  %85 = fadd <4 x double> %71, %84
  %86 = fadd <4 x double> %85, %82
  %87 = fmul <4 x double> %51, %52
  %88 = fadd <4 x double> %83, %86
  %89 = fmul <4 x double> %87, %64
  %90 = fadd <4 x double> %88, %89
  %91 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %92 = sext <4 x i1> %91 to <4 x i64>
  %93 = bitcast <4 x i64> %92 to <4 x double>
  %94 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %90, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %93) #6
  %95 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %5, <4 x double> zeroinitializer, i8 17) #6
  %96 = fcmp uno <4 x double> %5, zeroinitializer
  %97 = select <4 x i1> %96, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %95
  %98 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %94, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %97) #6
  %99 = fcmp oeq <4 x double> %5, zeroinitializer
  %100 = sext <4 x i1> %99 to <4 x i64>
  %101 = bitcast <4 x i64> %100 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %98, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %101) #6
  ret <4 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_log1pd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %2, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %4 = bitcast <4 x double> %3 to <4 x i64>
  %5 = fmul <4 x double> %2, <double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000, double 0x43F0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %5, <4 x double> %3) #6
  %7 = fmul <4 x double> %6, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %10 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %11 = bitcast <2 x i64> %9 to <4 x i32>
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = bitcast <2 x i64> %10 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %16, <2 x i64> %13, <2 x i32> <i32 2, i32 1>
  %18 = bitcast <2 x i64> %17 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 20, i32 20, i32 20, i32 20>
  %20 = and <4 x i32> %19, <i32 2047, i32 2047, i32 2047, i32 2047>
  %21 = add nsw <4 x i32> %20, <i32 -1023, i32 -1023, i32 -1023, i32 -1023>
  %22 = sub nsw <4 x i32> <i32 1023, i32 1023, i32 1023, i32 1023>, %20
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> <i32 0, i32 0, i32 0, i32 1>
  %24 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> <i32 0, i32 2, i32 0, i32 3>
  %25 = and <4 x i32> %23, <i32 0, i32 -1, i32 0, i32 -1>
  %26 = shl <4 x i32> %25, <i32 20, i32 20, i32 20, i32 20>
  %27 = and <4 x i32> %24, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = shl <4 x i32> %27, <i32 20, i32 20, i32 20, i32 20>
  %29 = add <4 x i32> %26, <i32 0, i32 1072693248, i32 0, i32 1072693248>
  %30 = add <4 x i32> %28, <i32 0, i32 1072693248, i32 0, i32 1072693248>
  %31 = bitcast <4 x i32> %29 to <2 x i64>
  %32 = bitcast <4 x i32> %30 to <2 x i64>
  %33 = shufflevector <2 x i64> %31, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %34 = shufflevector <2 x i64> %32, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %35 = shufflevector <4 x i64> %33, <4 x i64> %34, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fadd <4 x double> %36, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %38 = fmul <4 x double> %36, %0
  %39 = fadd <4 x double> %38, %37
  %40 = and <4 x i64> %4, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %41 = bitcast <4 x i64> %40 to <4 x double>
  %42 = tail call <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double> %41) #6
  %43 = add nsw <4 x i32> %20, <i32 -1087, i32 -1087, i32 -1087, i32 -1087>
  %44 = bitcast <4 x i32> %21 to <16 x i8>
  %45 = bitcast <4 x i32> %43 to <16 x i8>
  %46 = bitcast <4 x i32> %42 to <16 x i8>
  %47 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %44, <16 x i8> %45, <16 x i8> %46) #6
  %48 = bitcast <16 x i8> %47 to <4 x i32>
  %49 = sitofp <4 x i32> %48 to <4 x double>
  %50 = bitcast <4 x double> %49 to <4 x i64>
  %51 = and <4 x i64> %50, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %52 = bitcast <4 x i64> %51 to <4 x double>
  %53 = fsub <4 x double> %49, %52
  %54 = fmul <4 x double> %49, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %55 = fmul <4 x double> %52, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %56 = bitcast <4 x double> %54 to <4 x i64>
  %57 = xor <4 x i64> %56, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fmul <4 x double> %52, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %60 = fmul <4 x double> %53, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %61 = fmul <4 x double> %53, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %62 = fmul <4 x double> %49, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %63 = fadd <4 x double> %55, %58
  %64 = fadd <4 x double> %59, %63
  %65 = fadd <4 x double> %60, %64
  %66 = fadd <4 x double> %61, %65
  %67 = fadd <4 x double> %62, %66
  %68 = fadd <4 x double> %39, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %69 = fsub <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %68
  %70 = fadd <4 x double> %39, %69
  %71 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %68
  %72 = bitcast <4 x double> %68 to <4 x i64>
  %73 = and <4 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = fsub <4 x double> %68, %74
  %76 = bitcast <4 x double> %71 to <4 x i64>
  %77 = and <4 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = fsub <4 x double> %71, %78
  %80 = bitcast <4 x double> %39 to <4 x i64>
  %81 = and <4 x i64> %80, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %82 = bitcast <4 x i64> %81 to <4 x double>
  %83 = fsub <4 x double> %39, %82
  %84 = fmul <4 x double> %39, %71
  %85 = fmul <4 x double> %82, %78
  %86 = fsub <4 x double> %85, %84
  %87 = fmul <4 x double> %79, %82
  %88 = fmul <4 x double> %83, %78
  %89 = fmul <4 x double> %83, %79
  %90 = fmul <4 x double> %74, %78
  %91 = fmul <4 x double> %79, %74
  %92 = fmul <4 x double> %75, %78
  %93 = fmul <4 x double> %75, %79
  %94 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %90
  %95 = fsub <4 x double> %94, %91
  %96 = fsub <4 x double> %95, %92
  %97 = fsub <4 x double> %96, %93
  %98 = fmul <4 x double> %84, %97
  %99 = fadd <4 x double> %86, %87
  %100 = fadd <4 x double> %88, %99
  %101 = fadd <4 x double> %89, %100
  %102 = fadd <4 x double> %101, %98
  %103 = fmul <4 x double> %84, %70
  %104 = fsub <4 x double> zeroinitializer, %103
  %105 = fmul <4 x double> %71, %104
  %106 = fadd <4 x double> %105, %102
  %107 = fmul <4 x double> %84, %84
  %108 = fmul <4 x double> %107, %107
  %109 = fmul <4 x double> %108, %108
  %110 = fmul <4 x double> %107, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %111 = fadd <4 x double> %110, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %112 = fmul <4 x double> %108, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %113 = fadd <4 x double> %112, %111
  %114 = fmul <4 x double> %107, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %115 = fadd <4 x double> %114, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %116 = fmul <4 x double> %107, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %117 = fadd <4 x double> %116, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %118 = fmul <4 x double> %108, %115
  %119 = fadd <4 x double> %117, %118
  %120 = fmul <4 x double> %109, %113
  %121 = fadd <4 x double> %120, %119
  %122 = fmul <4 x double> %84, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %123 = fmul <4 x double> %106, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %124 = fadd <4 x double> %54, %122
  %125 = fsub <4 x double> %54, %124
  %126 = fadd <4 x double> %122, %125
  %127 = fadd <4 x double> %67, %126
  %128 = fadd <4 x double> %127, %123
  %129 = fmul <4 x double> %84, %107
  %130 = fmul <4 x double> %129, %121
  %131 = fadd <4 x double> %124, %130
  %132 = fsub <4 x double> %124, %131
  %133 = fadd <4 x double> %130, %132
  %134 = fadd <4 x double> %133, %128
  %135 = fadd <4 x double> %131, %134
  %136 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433>, i8 30) #6
  %137 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %135, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %136) #6
  %138 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i8 17) #6
  %139 = fcmp uno <4 x double> %0, zeroinitializer
  %140 = select <4 x i1> %139, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %138
  %141 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %137, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %140) #6
  %142 = fcmp oeq <4 x double> %0, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %143 = sext <4 x i1> %142 to <4 x i64>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %141, <4 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <4 x double> %144) #6
  %146 = bitcast <4 x double> %0 to <4 x i64>
  %147 = xor <4 x i64> %146, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %148 = bitcast <4 x i64> %147 to <4 x double>
  %149 = fcmp oeq <4 x double> %148, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %150 = sext <4 x i1> %149 to <4 x i64>
  %151 = bitcast <4 x i64> %150 to <4 x double>
  %152 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <4 x double> %151) #6
  ret <4 x double> %152
}

; Function Attrs: norecurse nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fabsd4_avx(<4 x double>) local_unnamed_addr #3 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  ret <4 x double> %4
}

; Function Attrs: norecurse nounwind readnone uwtable
define <4 x double> @Sleef_cinz_copysignd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #3 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x double> %1 to <4 x i64>
  %6 = and <4 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = or <4 x i64> %6, %4
  %8 = bitcast <4 x i64> %7 to <4 x double>
  ret <4 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fmaxd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp uno <4 x double> %1, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %0, <4 x double> %1) #6
  %6 = bitcast <4 x i64> %4 to <4 x double>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %0, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fmind4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp uno <4 x double> %1, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %0, <4 x double> %1) #6
  %6 = bitcast <4 x i64> %4 to <4 x double>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %0, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fdimd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fsub <4 x double> %0, %1
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> zeroinitializer, i8 17) #6
  %5 = fcmp oeq <4 x double> %0, %1
  %6 = select <4 x i1> %5, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %4
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> zeroinitializer, <4 x double> %6) #6
  ret <4 x double> %7
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_truncd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 11) #6
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_floord4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = sitofp <4 x i32> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <4 x double> %0, %5
  %7 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %6) #6
  %8 = sitofp <4 x i32> %7 to <4 x double>
  %9 = fsub <4 x double> %6, %8
  %10 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %9, <4 x double> zeroinitializer, i8 17) #6
  %11 = fadd <4 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %11, <4 x double> %10) #6
  %13 = bitcast <4 x double> %0 to <4 x i64>
  %14 = and <4 x i64> %13, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %15, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %18 = fsub <4 x double> %0, %12
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = and <4 x i64> %19, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %21 = and <4 x i64> %13, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %22 = or <4 x i64> %20, %21
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = select <4 x i1> %16, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %17
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> %0, <4 x double> %24) #6
  ret <4 x double> %25
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_ceild4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fmul <4 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %2) #6
  %4 = sitofp <4 x i32> %3 to <4 x double>
  %5 = fmul <4 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <4 x double> %0, %5
  %7 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %6) #6
  %8 = sitofp <4 x i32> %7 to <4 x double>
  %9 = fsub <4 x double> %6, %8
  %10 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %9, <4 x double> zeroinitializer, i8 18) #6
  %11 = fadd <4 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %12 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %9, <4 x double> %10) #6
  %13 = bitcast <4 x double> %0 to <4 x i64>
  %14 = and <4 x i64> %13, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %15, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %18 = fsub <4 x double> %0, %12
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = and <4 x i64> %19, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %21 = and <4 x i64> %13, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %22 = or <4 x i64> %20, %21
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = select <4 x i1> %16, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %17
  %25 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> %0, <4 x double> %24) #6
  ret <4 x double> %25
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_roundd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = fadd <4 x double> %0, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %3 = fmul <4 x double> %2, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %3) #6
  %5 = sitofp <4 x i32> %4 to <4 x double>
  %6 = fmul <4 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <4 x double> %2, %6
  %8 = tail call <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double> %7) #6
  %9 = sitofp <4 x i32> %8 to <4 x double>
  %10 = fsub <4 x double> %7, %9
  %11 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %2, <4 x double> zeroinitializer, i8 18) #6
  %12 = fcmp oeq <4 x double> %10, zeroinitializer
  %13 = fadd <4 x double> %2, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %14 = select <4 x i1> %12, <4 x double> %11, <4 x double> zeroinitializer
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %13, <4 x double> %14) #6
  %16 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %10, <4 x double> zeroinitializer, i8 17) #6
  %17 = fadd <4 x double> %10, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> %17, <4 x double> %16) #6
  %19 = fcmp oeq <4 x double> %0, <double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF>
  %20 = sext <4 x i1> %19 to <4 x i64>
  %21 = bitcast <4 x i64> %20 to <4 x double>
  %22 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> zeroinitializer, <4 x double> %21) #6
  %23 = bitcast <4 x double> %0 to <4 x i64>
  %24 = and <4 x i64> %23, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %25 = bitcast <4 x i64> %24 to <4 x double>
  %26 = fcmp oeq <4 x double> %25, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %27 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %25, <4 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i8 29) #6
  %28 = fsub <4 x double> %22, %18
  %29 = bitcast <4 x double> %28 to <4 x i64>
  %30 = and <4 x i64> %29, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %31 = and <4 x i64> %23, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %32 = or <4 x i64> %30, %31
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = select <4 x i1> %26, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <4 x double> %27
  %35 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %33, <4 x double> %0, <4 x double> %34) #6
  ret <4 x double> %35
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_rintd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %0, i32 8) #6
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_nextafterd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = fcmp oeq <4 x double> %0, zeroinitializer
  %4 = sext <4 x i1> %3 to <4 x i64>
  %5 = bitcast <4 x double> %1 to <4 x i64>
  %6 = and <4 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = bitcast <4 x i64> %6 to <4 x double>
  %8 = bitcast <4 x i64> %4 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %7, <4 x double> %8) #6
  %10 = bitcast <4 x double> %9 to <4 x i64>
  %11 = shufflevector <4 x i64> %10, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %12 = shufflevector <4 x i64> %10, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %13 = and <4 x i64> %10, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %14 = xor <4 x i64> %13, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %15 = bitcast <4 x i64> %14 to <4 x double>
  %16 = fcmp oeq <4 x double> %15, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %17 = sext <4 x i1> %16 to <4 x i64>
  %18 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %1, <4 x double> %9, i8 29) #6
  %19 = bitcast <4 x double> %18 to <4 x i64>
  %20 = xor <4 x i64> %17, %19
  %21 = bitcast <2 x i64> %11 to <4 x i32>
  %22 = xor <4 x i32> %21, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %23 = add <4 x i32> %22, <i32 1, i32 0, i32 1, i32 0>
  %24 = bitcast <2 x i64> %12 to <4 x i32>
  %25 = xor <4 x i32> %24, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %26 = add <4 x i32> %25, <i32 1, i32 0, i32 1, i32 0>
  %27 = icmp eq <4 x i32> %23, <i32 0, i32 -1, i32 0, i32 -1>
  %28 = sext <4 x i1> %27 to <4 x i32>
  %29 = icmp eq <4 x i32> %26, <i32 0, i32 -1, i32 0, i32 -1>
  %30 = sext <4 x i1> %29 to <4 x i32>
  %31 = bitcast <4 x i32> %28 to <2 x i64>
  %32 = bitcast <4 x i32> %30 to <2 x i64>
  %33 = and <2 x i64> %31, <i64 1, i64 1>
  %34 = and <2 x i64> %32, <i64 1, i64 1>
  %35 = shufflevector <2 x i64> %33, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %36 = shufflevector <2 x i64> %34, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %37 = shufflevector <4 x i64> %35, <4 x i64> %36, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %38 = bitcast <4 x i64> %37 to <8 x float>
  %39 = shufflevector <8 x float> %38, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %40 = bitcast <8 x float> %39 to <4 x i64>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %42 = shufflevector <4 x i64> %40, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %43 = bitcast <2 x i64> %41 to <4 x i32>
  %44 = add <4 x i32> %23, %43
  %45 = bitcast <2 x i64> %42 to <4 x i32>
  %46 = add <4 x i32> %26, %45
  %47 = bitcast <4 x i32> %44 to <2 x i64>
  %48 = bitcast <4 x i32> %46 to <2 x i64>
  %49 = shufflevector <2 x i64> %47, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %50 = shufflevector <2 x i64> %48, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %51 = shufflevector <4 x i64> %49, <4 x i64> %50, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %52 = bitcast <4 x i64> %51 to <4 x double>
  %53 = bitcast <4 x i64> %20 to <4 x double>
  %54 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %52, <4 x double> %53) #6
  %55 = bitcast <4 x double> %54 to <4 x i64>
  %56 = shufflevector <4 x i64> %55, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %57 = shufflevector <4 x i64> %55, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %58 = fcmp une <4 x double> %9, %1
  %59 = sext <4 x i1> %58 to <4 x i64>
  %60 = and <4 x i64> %59, <i64 1, i64 1, i64 1, i64 1>
  %61 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %62 = shufflevector <4 x i64> %60, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %63 = bitcast <2 x i64> %56 to <4 x i32>
  %64 = bitcast <2 x i64> %61 to <4 x i32>
  %65 = sub <4 x i32> %63, %64
  %66 = bitcast <2 x i64> %57 to <4 x i32>
  %67 = bitcast <2 x i64> %62 to <4 x i32>
  %68 = sub <4 x i32> %66, %67
  %69 = bitcast <4 x i32> %65 to <2 x i64>
  %70 = bitcast <4 x i32> %68 to <2 x i64>
  %71 = icmp eq <4 x i32> %65, <i32 -1, i32 0, i32 -1, i32 0>
  %72 = sext <4 x i1> %71 to <4 x i32>
  %73 = icmp eq <4 x i32> %68, <i32 -1, i32 0, i32 -1, i32 0>
  %74 = sext <4 x i1> %73 to <4 x i32>
  %75 = bitcast <4 x i32> %72 to <2 x i64>
  %76 = bitcast <4 x i32> %74 to <2 x i64>
  %77 = and <2 x i64> %75, <i64 4294967295, i64 4294967295>
  %78 = and <2 x i64> %76, <i64 4294967295, i64 4294967295>
  %79 = shufflevector <2 x i64> %77, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %80 = shufflevector <2 x i64> %78, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %81 = shufflevector <4 x i64> %79, <4 x i64> %80, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %82 = bitcast <4 x i64> %81 to <8 x float>
  %83 = shufflevector <8 x float> %82, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %84 = bitcast <8 x float> %83 to <4 x i64>
  %85 = shufflevector <4 x i64> %84, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %86 = shufflevector <4 x i64> %84, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %87 = bitcast <2 x i64> %85 to <4 x i32>
  %88 = add <4 x i32> %65, %87
  %89 = bitcast <2 x i64> %86 to <4 x i32>
  %90 = add <4 x i32> %68, %89
  %91 = bitcast <4 x i32> %88 to <2 x i64>
  %92 = bitcast <4 x i32> %90 to <2 x i64>
  %93 = shufflevector <2 x i64> %91, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %94 = shufflevector <2 x i64> %92, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %95 = shufflevector <4 x i64> %93, <4 x i64> %94, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %96 = bitcast <4 x i64> %95 to <4 x double>
  %97 = shufflevector <2 x i64> %69, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %98 = shufflevector <2 x i64> %70, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %99 = shufflevector <4 x i64> %97, <4 x i64> %98, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %100 = bitcast <4 x i64> %99 to <4 x double>
  %101 = bitcast <4 x i64> %59 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %100, <4 x double> %96, <4 x double> %101) #6
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = shufflevector <4 x i64> %103, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %105 = shufflevector <4 x i64> %103, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %106 = bitcast <2 x i64> %104 to <4 x i32>
  %107 = xor <4 x i32> %106, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %108 = add <4 x i32> %107, <i32 1, i32 0, i32 1, i32 0>
  %109 = bitcast <2 x i64> %105 to <4 x i32>
  %110 = xor <4 x i32> %109, <i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %111 = add <4 x i32> %110, <i32 1, i32 0, i32 1, i32 0>
  %112 = icmp eq <4 x i32> %108, <i32 0, i32 -1, i32 0, i32 -1>
  %113 = sext <4 x i1> %112 to <4 x i32>
  %114 = icmp eq <4 x i32> %111, <i32 0, i32 -1, i32 0, i32 -1>
  %115 = sext <4 x i1> %114 to <4 x i32>
  %116 = bitcast <4 x i32> %113 to <2 x i64>
  %117 = bitcast <4 x i32> %115 to <2 x i64>
  %118 = and <2 x i64> %116, <i64 1, i64 1>
  %119 = and <2 x i64> %117, <i64 1, i64 1>
  %120 = shufflevector <2 x i64> %118, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %121 = shufflevector <2 x i64> %119, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %122 = shufflevector <4 x i64> %120, <4 x i64> %121, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %123 = bitcast <4 x i64> %122 to <8 x float>
  %124 = shufflevector <8 x float> %123, <8 x float> undef, <8 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6>
  %125 = bitcast <8 x float> %124 to <4 x i64>
  %126 = shufflevector <4 x i64> %125, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %127 = shufflevector <4 x i64> %125, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %128 = bitcast <2 x i64> %126 to <4 x i32>
  %129 = add <4 x i32> %108, %128
  %130 = bitcast <2 x i64> %127 to <4 x i32>
  %131 = add <4 x i32> %111, %130
  %132 = bitcast <4 x i32> %129 to <2 x i64>
  %133 = bitcast <4 x i32> %131 to <2 x i64>
  %134 = shufflevector <2 x i64> %132, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %135 = shufflevector <2 x i64> %133, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %136 = shufflevector <4 x i64> %134, <4 x i64> %135, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %137 = bitcast <4 x i64> %136 to <4 x double>
  %138 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %102, <4 x double> %137, <4 x double> %53) #6
  %139 = fcmp oeq <4 x double> %138, zeroinitializer
  %140 = fcmp une <4 x double> %9, zeroinitializer
  %141 = and <4 x i1> %139, %140
  %142 = sext <4 x i1> %141 to <4 x i64>
  %143 = bitcast <4 x i64> %13 to <4 x double>
  %144 = bitcast <4 x i64> %142 to <4 x double>
  %145 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %138, <4 x double> %143, <4 x double> %144) #6
  %146 = fcmp oeq <4 x double> %9, zeroinitializer
  %147 = fcmp oeq <4 x double> %1, zeroinitializer
  %148 = and <4 x i1> %146, %147
  %149 = sext <4 x i1> %148 to <4 x i64>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %145, <4 x double> %1, <4 x double> %150) #6
  %152 = fcmp uno <4 x double> %9, %1
  %153 = sext <4 x i1> %152 to <4 x i64>
  %154 = bitcast <4 x i64> %153 to <4 x double>
  %155 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %151, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %154) #6
  ret <4 x double> %155
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_frfrexpd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %6 = fmul <4 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %6, <4 x double> %5) #6
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = and <4 x i64> %8, <i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313>
  %10 = or <4 x i64> %9, <i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912>
  %11 = bitcast <4 x i64> %10 to <4 x double>
  %12 = and <4 x i64> %8, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <4 x i64> %12 to <4 x double>
  %14 = fcmp oeq <4 x double> %13, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %15 = sext <4 x i1> %14 to <4 x i64>
  %16 = and <4 x i64> %8, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %17 = or <4 x i64> %16, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = bitcast <4 x i64> %15 to <4 x double>
  %20 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %18, <4 x double> %19) #6
  %21 = fcmp oeq <4 x double> %7, zeroinitializer
  %22 = sext <4 x i1> %21 to <4 x i64>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %20, <4 x double> %7, <4 x double> %23) #6
  ret <4 x double> %24
}

; Function Attrs: nounwind readnone uwtable
define <2 x i64> @Sleef_cinz_expfrexpd4_avx(<4 x double>) local_unnamed_addr #0 {
  %2 = bitcast <4 x double> %0 to <4 x i64>
  %3 = and <4 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <4 x i64> %3 to <4 x double>
  %5 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %4, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %6 = fmul <4 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %6, <4 x double> %5) #6
  %8 = bitcast <4 x double> %7 to <4 x i64>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %10 = shufflevector <4 x i64> %8, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %11 = bitcast <2 x i64> %9 to <4 x i32>
  %12 = shufflevector <4 x i32> %11, <4 x i32> undef, <4 x i32> <i32 1, i32 3, i32 undef, i32 undef>
  %13 = bitcast <4 x i32> %12 to <2 x i64>
  %14 = bitcast <2 x i64> %10 to <4 x i32>
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> <i32 undef, i32 undef, i32 1, i32 3>
  %16 = bitcast <4 x i32> %15 to <2 x i64>
  %17 = shufflevector <2 x i64> %16, <2 x i64> %13, <2 x i32> <i32 2, i32 1>
  %18 = bitcast <2 x i64> %17 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 20, i32 20, i32 20, i32 20>
  %20 = and <4 x i32> %19, <i32 2047, i32 2047, i32 2047, i32 2047>
  %21 = add nsw <4 x i32> %20, <i32 -1022, i32 -1022, i32 -1022, i32 -1022>
  %22 = fcmp ueq <4 x double> %7, zeroinitializer
  %23 = and <4 x i64> %8, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %24 = bitcast <4 x i64> %23 to <4 x double>
  %25 = fcmp oeq <4 x double> %24, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %26 = or <4 x i1> %25, %22
  %27 = sext <4 x i1> %26 to <4 x i64>
  %28 = shufflevector <4 x i64> %27, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %29 = bitcast <4 x i32> %21 to <16 x i8>
  %30 = bitcast <2 x i64> %28 to <16 x i8>
  %31 = tail call <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8> %29, <16 x i8> zeroinitializer, <16 x i8> %30) #6
  %32 = bitcast <16 x i8> %31 to <2 x i64>
  ret <2 x i64> %32
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fmad4_avx(<4 x double>, <4 x double>, <4 x double>) local_unnamed_addr #0 {
  %4 = fmul <4 x double> %0, %1
  %5 = fadd <4 x double> %4, %2
  %6 = bitcast <4 x double> %5 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300>, i8 17) #6
  %10 = fmul <4 x double> %0, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %1, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %1, <4 x double> %12, <4 x double> %9) #6
  %14 = fmul <4 x double> %2, <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %2, <4 x double> %14, <4 x double> %9) #6
  %16 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>, <4 x double> %9) #6
  %17 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300>, i8 30) #6
  %18 = fmul <4 x double> %11, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %11, <4 x double> %18, <4 x double> %17) #6
  %20 = fmul <4 x double> %13, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %21 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %13, <4 x double> %20, <4 x double> %17) #6
  %22 = fmul <4 x double> %15, <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>
  %23 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> %22, <4 x double> %17) #6
  %24 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %16, <4 x double> <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>, <4 x double> %17) #6
  %25 = bitcast <4 x double> %19 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %19, %27
  %29 = bitcast <4 x double> %21 to <4 x i64>
  %30 = and <4 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <4 x i64> %30 to <4 x double>
  %32 = fsub <4 x double> %21, %31
  %33 = fmul <4 x double> %19, %21
  %34 = fmul <4 x double> %27, %31
  %35 = bitcast <4 x double> %33 to <4 x i64>
  %36 = xor <4 x i64> %35, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %37 = bitcast <4 x i64> %36 to <4 x double>
  %38 = fmul <4 x double> %28, %31
  %39 = fmul <4 x double> %32, %27
  %40 = fmul <4 x double> %28, %32
  %41 = fadd <4 x double> %34, %37
  %42 = fadd <4 x double> %38, %41
  %43 = fadd <4 x double> %39, %42
  %44 = fadd <4 x double> %40, %43
  %45 = fadd <4 x double> %33, %23
  %46 = fsub <4 x double> %45, %33
  %47 = fsub <4 x double> %45, %46
  %48 = fsub <4 x double> %33, %47
  %49 = fsub <4 x double> %23, %46
  %50 = fadd <4 x double> %49, %48
  %51 = fadd <4 x double> %50, %44
  %52 = fcmp oeq <4 x double> %19, zeroinitializer
  %53 = fcmp oeq <4 x double> %21, zeroinitializer
  %54 = or <4 x i1> %53, %52
  %55 = sext <4 x i1> %54 to <4 x i64>
  %56 = fadd <4 x double> %45, %51
  %57 = bitcast <4 x i64> %55 to <4 x double>
  %58 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %56, <4 x double> %23, <4 x double> %57) #6
  %59 = bitcast <4 x double> %23 to <4 x i64>
  %60 = and <4 x i64> %59, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %61 = bitcast <4 x i64> %60 to <4 x double>
  %62 = fcmp oeq <4 x double> %61, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %63 = and <4 x i64> %25, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %64 = bitcast <4 x i64> %63 to <4 x double>
  %65 = fcmp une <4 x double> %64, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %66 = and <4 x i64> %29, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fcmp une <4 x double> %67, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %69 = fcmp ord <4 x double> %21, %19
  %70 = and <4 x i1> %65, %69
  %71 = and <4 x i1> %70, %68
  %72 = and <4 x i1> %71, %62
  %73 = sext <4 x i1> %72 to <4 x i64>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %23, <4 x double> %74) #6
  %76 = bitcast <4 x double> %75 to <4 x i64>
  %77 = and <4 x i64> %76, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %78 = bitcast <4 x i64> %77 to <4 x double>
  %79 = fcmp oeq <4 x double> %78, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %80 = fcmp uno <4 x double> %75, zeroinitializer
  %81 = or <4 x i1> %79, %80
  %82 = sext <4 x i1> %81 to <4 x i64>
  %83 = fmul <4 x double> %24, %58
  %84 = bitcast <4 x i64> %82 to <4 x double>
  %85 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %83, <4 x double> %75, <4 x double> %84) #6
  ret <4 x double> %85
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_sqrtd4_u05avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %3 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %2) #6
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i8 17) #6
  %5 = fmul <4 x double> %3, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> %5, <4 x double> %4) #6
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <4 x double> %4) #6
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %6, <4 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i8 30) #6
  %9 = fmul <4 x double> %6, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %6, <4 x double> %9, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %7, <4 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <4 x double> %8) #6
  %12 = fadd <4 x double> %10, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %13 = bitcast <4 x double> %12 to <4 x i64>
  %14 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %15 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = lshr <4 x i32> %16, <i32 1, i32 1, i32 1, i32 1>
  %18 = bitcast <2 x i64> %15 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 1, i32 1, i32 1, i32 1>
  %20 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %21 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %19
  %22 = bitcast <4 x i32> %20 to <2 x i64>
  %23 = bitcast <4 x i32> %21 to <2 x i64>
  %24 = shufflevector <2 x i64> %22, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %25 = shufflevector <2 x i64> %23, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %26 = shufflevector <4 x i64> %24, <4 x i64> %25, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fmul <4 x double> %10, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %29 = fmul <4 x double> %28, %27
  %30 = fmul <4 x double> %29, %27
  %31 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <4 x double> %31, %27
  %33 = fmul <4 x double> %28, %32
  %34 = fmul <4 x double> %32, %33
  %35 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %34
  %36 = fmul <4 x double> %32, %35
  %37 = fmul <4 x double> %28, %36
  %38 = fmul <4 x double> %36, %37
  %39 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %38
  %40 = fmul <4 x double> %36, %39
  %41 = fmul <4 x double> %10, %40
  %42 = bitcast <4 x double> %41 to <4 x i64>
  %43 = and <4 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %41, %44
  %46 = fmul <4 x double> %41, %41
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fmul <4 x double> %45, %44
  %52 = fmul <4 x double> %45, %45
  %53 = fadd <4 x double> %47, %50
  %54 = fadd <4 x double> %51, %53
  %55 = fadd <4 x double> %51, %54
  %56 = fadd <4 x double> %52, %55
  %57 = fadd <4 x double> %10, %46
  %58 = fsub <4 x double> %57, %10
  %59 = fsub <4 x double> %57, %58
  %60 = fsub <4 x double> %10, %59
  %61 = fsub <4 x double> %46, %58
  %62 = fadd <4 x double> %61, %60
  %63 = fadd <4 x double> %62, %56
  %64 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %41
  %65 = bitcast <4 x double> %64 to <4 x i64>
  %66 = and <4 x i64> %65, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fsub <4 x double> %64, %67
  %69 = fmul <4 x double> %44, %67
  %70 = fmul <4 x double> %68, %44
  %71 = fmul <4 x double> %45, %67
  %72 = fmul <4 x double> %45, %68
  %73 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %69
  %74 = fsub <4 x double> %73, %70
  %75 = fsub <4 x double> %74, %71
  %76 = fsub <4 x double> %75, %72
  %77 = fmul <4 x double> %64, %76
  %78 = bitcast <4 x double> %57 to <4 x i64>
  %79 = and <4 x i64> %78, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fsub <4 x double> %57, %80
  %82 = fmul <4 x double> %64, %57
  %83 = fmul <4 x double> %67, %80
  %84 = bitcast <4 x double> %82 to <4 x i64>
  %85 = xor <4 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fmul <4 x double> %81, %67
  %88 = fmul <4 x double> %68, %80
  %89 = fmul <4 x double> %68, %81
  %90 = fmul <4 x double> %57, %77
  %91 = fmul <4 x double> %64, %63
  %92 = fadd <4 x double> %83, %86
  %93 = fadd <4 x double> %87, %92
  %94 = fadd <4 x double> %88, %93
  %95 = fadd <4 x double> %89, %94
  %96 = fadd <4 x double> %95, %90
  %97 = fadd <4 x double> %91, %96
  %98 = fadd <4 x double> %82, %97
  %99 = fmul <4 x double> %11, %98
  %100 = fcmp oeq <4 x double> %10, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %101 = sext <4 x i1> %100 to <4 x i64>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %99, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %102) #6
  %104 = fcmp oeq <4 x double> %10, zeroinitializer
  %105 = sext <4 x i1> %104 to <4 x i64>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %103, <4 x double> %10, <4 x double> %106) #6
  ret <4 x double> %107
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_sqrtd4_u35avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %0, <4 x double> zeroinitializer, i8 17) #6
  %3 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %2) #6
  %4 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %3, <4 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i8 17) #6
  %5 = fmul <4 x double> %3, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %6 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %3, <4 x double> %5, <4 x double> %4) #6
  %7 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <4 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <4 x double> %4) #6
  %8 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %6, <4 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i8 30) #6
  %9 = fmul <4 x double> %6, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %10 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %6, <4 x double> %9, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %7, <4 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <4 x double> %8) #6
  %12 = fadd <4 x double> %10, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %13 = bitcast <4 x double> %12 to <4 x i64>
  %14 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %15 = shufflevector <4 x i64> %13, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %16 = bitcast <2 x i64> %14 to <4 x i32>
  %17 = lshr <4 x i32> %16, <i32 1, i32 1, i32 1, i32 1>
  %18 = bitcast <2 x i64> %15 to <4 x i32>
  %19 = lshr <4 x i32> %18, <i32 1, i32 1, i32 1, i32 1>
  %20 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %21 = sub nsw <4 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350>, %19
  %22 = bitcast <4 x i32> %20 to <2 x i64>
  %23 = bitcast <4 x i32> %21 to <2 x i64>
  %24 = shufflevector <2 x i64> %22, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %25 = shufflevector <2 x i64> %23, <2 x i64> undef, <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
  %26 = shufflevector <4 x i64> %24, <4 x i64> %25, <4 x i32> <i32 0, i32 1, i32 4, i32 5>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fmul <4 x double> %10, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %29 = fmul <4 x double> %28, %27
  %30 = fmul <4 x double> %29, %27
  %31 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <4 x double> %31, %27
  %33 = fmul <4 x double> %28, %32
  %34 = fmul <4 x double> %32, %33
  %35 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %34
  %36 = fmul <4 x double> %32, %35
  %37 = fmul <4 x double> %28, %36
  %38 = fmul <4 x double> %36, %37
  %39 = fsub <4 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %38
  %40 = fmul <4 x double> %36, %39
  %41 = fmul <4 x double> %10, %40
  %42 = bitcast <4 x double> %41 to <4 x i64>
  %43 = and <4 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <4 x i64> %43 to <4 x double>
  %45 = fsub <4 x double> %41, %44
  %46 = fmul <4 x double> %41, %41
  %47 = fmul <4 x double> %44, %44
  %48 = bitcast <4 x double> %46 to <4 x i64>
  %49 = xor <4 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <4 x i64> %49 to <4 x double>
  %51 = fmul <4 x double> %45, %44
  %52 = fmul <4 x double> %45, %45
  %53 = fadd <4 x double> %47, %50
  %54 = fadd <4 x double> %51, %53
  %55 = fadd <4 x double> %51, %54
  %56 = fadd <4 x double> %52, %55
  %57 = fadd <4 x double> %10, %46
  %58 = fsub <4 x double> %57, %10
  %59 = fsub <4 x double> %57, %58
  %60 = fsub <4 x double> %10, %59
  %61 = fsub <4 x double> %46, %58
  %62 = fadd <4 x double> %61, %60
  %63 = fadd <4 x double> %62, %56
  %64 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %41
  %65 = bitcast <4 x double> %64 to <4 x i64>
  %66 = and <4 x i64> %65, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %67 = bitcast <4 x i64> %66 to <4 x double>
  %68 = fsub <4 x double> %64, %67
  %69 = fmul <4 x double> %44, %67
  %70 = fmul <4 x double> %68, %44
  %71 = fmul <4 x double> %45, %67
  %72 = fmul <4 x double> %45, %68
  %73 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %69
  %74 = fsub <4 x double> %73, %70
  %75 = fsub <4 x double> %74, %71
  %76 = fsub <4 x double> %75, %72
  %77 = fmul <4 x double> %64, %76
  %78 = bitcast <4 x double> %57 to <4 x i64>
  %79 = and <4 x i64> %78, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fsub <4 x double> %57, %80
  %82 = fmul <4 x double> %64, %57
  %83 = fmul <4 x double> %67, %80
  %84 = bitcast <4 x double> %82 to <4 x i64>
  %85 = xor <4 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <4 x i64> %85 to <4 x double>
  %87 = fmul <4 x double> %81, %67
  %88 = fmul <4 x double> %68, %80
  %89 = fmul <4 x double> %68, %81
  %90 = fmul <4 x double> %57, %77
  %91 = fmul <4 x double> %64, %63
  %92 = fadd <4 x double> %83, %86
  %93 = fadd <4 x double> %87, %92
  %94 = fadd <4 x double> %88, %93
  %95 = fadd <4 x double> %89, %94
  %96 = fadd <4 x double> %95, %90
  %97 = fadd <4 x double> %91, %96
  %98 = fadd <4 x double> %82, %97
  %99 = fmul <4 x double> %11, %98
  %100 = fcmp oeq <4 x double> %10, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %101 = sext <4 x i1> %100 to <4 x i64>
  %102 = bitcast <4 x i64> %101 to <4 x double>
  %103 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %99, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %102) #6
  %104 = fcmp oeq <4 x double> %10, zeroinitializer
  %105 = sext <4 x i1> %104 to <4 x i64>
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %103, <4 x double> %10, <4 x double> %106) #6
  ret <4 x double> %107
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_hypotd4_u05avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %5, <4 x double> %8) #6
  %10 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %5, <4 x double> %8) #6
  %11 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %10, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %12 = fmul <4 x double> %9, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %9, <4 x double> %12, <4 x double> %11) #6
  %14 = fmul <4 x double> %10, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %15 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %10, <4 x double> %14, <4 x double> %11) #6
  %16 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %15
  %17 = bitcast <4 x double> %15 to <4 x i64>
  %18 = and <4 x i64> %17, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %19 = bitcast <4 x i64> %18 to <4 x double>
  %20 = fsub <4 x double> %15, %19
  %21 = bitcast <4 x double> %16 to <4 x i64>
  %22 = and <4 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <4 x i64> %22 to <4 x double>
  %24 = fsub <4 x double> %16, %23
  %25 = bitcast <4 x double> %13 to <4 x i64>
  %26 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <4 x i64> %26 to <4 x double>
  %28 = fsub <4 x double> %13, %27
  %29 = fmul <4 x double> %13, %16
  %30 = fmul <4 x double> %27, %23
  %31 = fsub <4 x double> %30, %29
  %32 = fmul <4 x double> %24, %27
  %33 = fmul <4 x double> %28, %23
  %34 = fmul <4 x double> %28, %24
  %35 = fmul <4 x double> %19, %23
  %36 = fmul <4 x double> %24, %19
  %37 = fmul <4 x double> %20, %23
  %38 = fmul <4 x double> %20, %24
  %39 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %35
  %40 = fsub <4 x double> %39, %36
  %41 = fsub <4 x double> %40, %37
  %42 = fsub <4 x double> %41, %38
  %43 = fmul <4 x double> %29, %42
  %44 = fadd <4 x double> %31, %32
  %45 = fadd <4 x double> %33, %44
  %46 = fadd <4 x double> %34, %45
  %47 = fadd <4 x double> %46, %43
  %48 = fmul <4 x double> %29, zeroinitializer
  %49 = fsub <4 x double> zeroinitializer, %48
  %50 = fmul <4 x double> %16, %49
  %51 = fadd <4 x double> %50, %47
  %52 = bitcast <4 x double> %29 to <4 x i64>
  %53 = and <4 x i64> %52, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %54 = bitcast <4 x i64> %53 to <4 x double>
  %55 = fsub <4 x double> %29, %54
  %56 = fmul <4 x double> %29, %29
  %57 = fmul <4 x double> %54, %54
  %58 = bitcast <4 x double> %56 to <4 x i64>
  %59 = xor <4 x i64> %58, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %60 = bitcast <4 x i64> %59 to <4 x double>
  %61 = fadd <4 x double> %54, %54
  %62 = fmul <4 x double> %61, %55
  %63 = fmul <4 x double> %55, %55
  %64 = fadd <4 x double> %51, %51
  %65 = fmul <4 x double> %29, %64
  %66 = fadd <4 x double> %57, %60
  %67 = fadd <4 x double> %66, %62
  %68 = fadd <4 x double> %63, %67
  %69 = fadd <4 x double> %68, %65
  %70 = fadd <4 x double> %56, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %71 = fsub <4 x double> %70, %56
  %72 = fsub <4 x double> %70, %71
  %73 = fsub <4 x double> %56, %72
  %74 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %71
  %75 = fadd <4 x double> %74, %73
  %76 = fadd <4 x double> %75, %69
  %77 = fadd <4 x double> %70, %76
  %78 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %77) #6
  %79 = bitcast <4 x double> %78 to <4 x i64>
  %80 = and <4 x i64> %79, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %81 = bitcast <4 x i64> %80 to <4 x double>
  %82 = fsub <4 x double> %78, %81
  %83 = fmul <4 x double> %78, %78
  %84 = fmul <4 x double> %81, %81
  %85 = bitcast <4 x double> %83 to <4 x i64>
  %86 = xor <4 x i64> %85, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %87 = bitcast <4 x i64> %86 to <4 x double>
  %88 = fmul <4 x double> %82, %81
  %89 = fmul <4 x double> %82, %82
  %90 = fadd <4 x double> %84, %87
  %91 = fadd <4 x double> %88, %90
  %92 = fadd <4 x double> %88, %91
  %93 = fadd <4 x double> %89, %92
  %94 = fadd <4 x double> %83, %70
  %95 = fsub <4 x double> %94, %70
  %96 = fsub <4 x double> %94, %95
  %97 = fsub <4 x double> %70, %96
  %98 = fsub <4 x double> %83, %95
  %99 = fadd <4 x double> %98, %97
  %100 = fadd <4 x double> %93, %76
  %101 = fadd <4 x double> %99, %100
  %102 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %78
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = and <4 x i64> %103, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %105 = bitcast <4 x i64> %104 to <4 x double>
  %106 = fsub <4 x double> %102, %105
  %107 = fmul <4 x double> %81, %105
  %108 = fmul <4 x double> %106, %81
  %109 = fmul <4 x double> %82, %105
  %110 = fmul <4 x double> %82, %106
  %111 = fsub <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %107
  %112 = fsub <4 x double> %111, %108
  %113 = fsub <4 x double> %112, %109
  %114 = fsub <4 x double> %113, %110
  %115 = fmul <4 x double> %102, %114
  %116 = bitcast <4 x double> %94 to <4 x i64>
  %117 = and <4 x i64> %116, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %118 = bitcast <4 x i64> %117 to <4 x double>
  %119 = fsub <4 x double> %94, %118
  %120 = fmul <4 x double> %102, %94
  %121 = fmul <4 x double> %105, %118
  %122 = bitcast <4 x double> %120 to <4 x i64>
  %123 = xor <4 x i64> %122, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %124 = bitcast <4 x i64> %123 to <4 x double>
  %125 = fmul <4 x double> %119, %105
  %126 = fmul <4 x double> %106, %118
  %127 = fmul <4 x double> %106, %119
  %128 = fmul <4 x double> %94, %115
  %129 = fmul <4 x double> %102, %101
  %130 = fadd <4 x double> %121, %124
  %131 = fadd <4 x double> %125, %130
  %132 = fadd <4 x double> %126, %131
  %133 = fadd <4 x double> %127, %132
  %134 = fadd <4 x double> %128, %133
  %135 = fadd <4 x double> %134, %129
  %136 = fmul <4 x double> %120, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %137 = fmul <4 x double> %135, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %138 = bitcast <4 x double> %136 to <4 x i64>
  %139 = and <4 x i64> %138, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %140 = bitcast <4 x i64> %139 to <4 x double>
  %141 = fsub <4 x double> %136, %140
  %142 = bitcast <4 x double> %10 to <4 x i64>
  %143 = and <4 x i64> %142, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %144 = bitcast <4 x i64> %143 to <4 x double>
  %145 = fsub <4 x double> %10, %144
  %146 = fmul <4 x double> %10, %136
  %147 = fmul <4 x double> %144, %140
  %148 = bitcast <4 x double> %146 to <4 x i64>
  %149 = xor <4 x i64> %148, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %150 = bitcast <4 x i64> %149 to <4 x double>
  %151 = fmul <4 x double> %141, %144
  %152 = fmul <4 x double> %145, %140
  %153 = fmul <4 x double> %145, %141
  %154 = fmul <4 x double> %10, %137
  %155 = fadd <4 x double> %147, %150
  %156 = fadd <4 x double> %151, %155
  %157 = fadd <4 x double> %152, %156
  %158 = fadd <4 x double> %153, %157
  %159 = fadd <4 x double> %158, %154
  %160 = fadd <4 x double> %146, %159
  %161 = fcmp uno <4 x double> %160, zeroinitializer
  %162 = sext <4 x i1> %161 to <4 x i64>
  %163 = bitcast <4 x i64> %162 to <4 x double>
  %164 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %160, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %163) #6
  %165 = fcmp oeq <4 x double> %9, zeroinitializer
  %166 = sext <4 x i1> %165 to <4 x i64>
  %167 = bitcast <4 x i64> %166 to <4 x double>
  %168 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %164, <4 x double> %10, <4 x double> %167) #6
  %169 = fcmp uno <4 x double> %8, %5
  %170 = sext <4 x i1> %169 to <4 x i64>
  %171 = bitcast <4 x i64> %170 to <4 x double>
  %172 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %168, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %171) #6
  %173 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %174 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %175 = or <4 x i1> %174, %173
  %176 = sext <4 x i1> %175 to <4 x i64>
  %177 = bitcast <4 x i64> %176 to <4 x double>
  %178 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %172, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %177) #6
  ret <4 x double> %178
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_hypotd4_u35avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.min.pd.256(<4 x double> %5, <4 x double> %8) #6
  %10 = tail call <4 x double> @llvm.x86.avx.max.pd.256(<4 x double> %5, <4 x double> %8) #6
  %11 = fdiv <4 x double> %9, %10
  %12 = fmul <4 x double> %11, %11
  %13 = fadd <4 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = tail call <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double> %13) #6
  %15 = fmul <4 x double> %10, %14
  %16 = fcmp oeq <4 x double> %9, zeroinitializer
  %17 = sext <4 x i1> %16 to <4 x i64>
  %18 = bitcast <4 x i64> %17 to <4 x double>
  %19 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %15, <4 x double> %10, <4 x double> %18) #6
  %20 = fcmp uno <4 x double> %8, %5
  %21 = sext <4 x i1> %20 to <4 x i64>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %19, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %22) #6
  %24 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %25 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %26 = or <4 x i1> %25, %24
  %27 = sext <4 x i1> %26 to <4 x i64>
  %28 = bitcast <4 x i64> %27 to <4 x double>
  %29 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %23, <4 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <4 x double> %28) #6
  ret <4 x double> %29
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_fmodd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i8 17) #6
  %10 = fmul <4 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %12, <4 x double> %9) #6
  %14 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %15 = bitcast <4 x double> %14 to <4 x i64>
  %16 = add <4 x i64> %15, <i64 -1, i64 -1, i64 -1, i64 -1>
  %17 = bitcast <4 x i64> %16 to <4 x double>
  %18 = fcmp oeq <4 x double> %14, zeroinitializer
  %19 = sext <4 x i1> %18 to <4 x i64>
  %20 = bitcast <4 x i64> %19 to <4 x double>
  %21 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %17, <4 x double> zeroinitializer, <4 x double> %20) #6
  %22 = fmul <4 x double> %13, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %23 = fadd <4 x double> %13, %13
  %24 = bitcast <4 x double> %13 to <4 x i64>
  %25 = xor <4 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = bitcast <4 x i64> %25 to <4 x double>
  %27 = and <4 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <4 x i64> %27 to <4 x double>
  %29 = fsub <4 x double> %26, %28
  br label %30

; <label>:30:                                     ; preds = %30, %2
  %31 = phi i32 [ 0, %2 ], [ %92, %30 ]
  %32 = phi <4 x double> [ zeroinitializer, %2 ], [ %84, %30 ]
  %33 = phi <4 x double> [ %11, %2 ], [ %82, %30 ]
  %34 = bitcast <4 x double> %33 to <4 x i64>
  %35 = add <4 x i64> %34, <i64 -1, i64 -1, i64 -1, i64 -1>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = fcmp oeq <4 x double> %33, zeroinitializer
  %38 = sext <4 x i1> %37 to <4 x i64>
  %39 = bitcast <4 x i64> %38 to <4 x double>
  %40 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %36, <4 x double> zeroinitializer, <4 x double> %39) #6
  %41 = fmul <4 x double> %21, %40
  %42 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %41, i32 11) #6
  %43 = bitcast <4 x double> %42 to <4 x i64>
  %44 = and <4 x i64> %43, <i64 -2, i64 -2, i64 -2, i64 -2>
  %45 = bitcast <4 x i64> %44 to <4 x double>
  %46 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %22, <4 x double> %33, i8 30) #6
  %47 = bitcast <4 x double> %46 to <4 x i64>
  %48 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %33, <4 x double> %13, i8 29) #6
  %49 = bitcast <4 x double> %48 to <4 x i64>
  %50 = and <4 x i64> %49, %47
  %51 = bitcast <4 x i64> %50 to <4 x double>
  %52 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %45, <4 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, <4 x double> %51) #6
  %53 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %23, <4 x double> %33, i8 30) #6
  %54 = bitcast <4 x double> %53 to <4 x i64>
  %55 = and <4 x i64> %54, %49
  %56 = bitcast <4 x i64> %55 to <4 x double>
  %57 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %52, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %56) #6
  %58 = bitcast <4 x double> %57 to <4 x i64>
  %59 = and <4 x i64> %58, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %60 = bitcast <4 x i64> %59 to <4 x double>
  %61 = fsub <4 x double> %57, %60
  %62 = fmul <4 x double> %57, %26
  %63 = fmul <4 x double> %28, %60
  %64 = bitcast <4 x double> %62 to <4 x i64>
  %65 = xor <4 x i64> %64, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %66 = bitcast <4 x i64> %65 to <4 x double>
  %67 = fmul <4 x double> %61, %28
  %68 = fmul <4 x double> %29, %60
  %69 = fmul <4 x double> %29, %61
  %70 = fadd <4 x double> %63, %66
  %71 = fadd <4 x double> %67, %70
  %72 = fadd <4 x double> %68, %71
  %73 = fadd <4 x double> %69, %72
  %74 = fadd <4 x double> %33, %62
  %75 = fsub <4 x double> %74, %33
  %76 = fsub <4 x double> %74, %75
  %77 = fsub <4 x double> %33, %76
  %78 = fsub <4 x double> %62, %75
  %79 = fadd <4 x double> %78, %77
  %80 = fadd <4 x double> %32, %73
  %81 = fadd <4 x double> %79, %80
  %82 = fadd <4 x double> %74, %81
  %83 = fsub <4 x double> %74, %82
  %84 = fadd <4 x double> %81, %83
  %85 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %82, <4 x double> %13, i8 17) #6
  %86 = bitcast <4 x double> %85 to <4 x i64>
  %87 = shufflevector <4 x i64> %86, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %88 = shufflevector <4 x i64> %86, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %89 = and <2 x i64> %88, %87
  %90 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %89, <2 x i64> <i64 -1, i64 -1>) #6
  %91 = icmp eq i32 %90, 0
  %92 = add nuw nsw i32 %31, 1
  %93 = icmp ult i32 %92, 21
  %94 = and i1 %93, %91
  br i1 %94, label %30, label %95

; <label>:95:                                     ; preds = %30
  %96 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <4 x double> %9) #6
  %97 = fmul <4 x double> %82, %96
  %98 = fadd <4 x double> %82, %84
  %99 = fcmp oeq <4 x double> %98, %13
  %100 = sext <4 x i1> %99 to <4 x i64>
  %101 = bitcast <4 x i64> %100 to <4 x double>
  %102 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %97, <4 x double> zeroinitializer, <4 x double> %101) #6
  %103 = bitcast <4 x double> %102 to <4 x i64>
  %104 = and <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = xor <4 x i64> %104, %103
  %106 = bitcast <4 x i64> %105 to <4 x double>
  %107 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %11, <4 x double> %13, i8 17) #6
  %108 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %106, <4 x double> %0, <4 x double> %107) #6
  %109 = fcmp oeq <4 x double> %13, zeroinitializer
  %110 = sext <4 x i1> %109 to <4 x i64>
  %111 = bitcast <4 x i64> %110 to <4 x double>
  %112 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %108, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %111) #6
  ret <4 x double> %112
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_remainderd4_avx(<4 x double>, <4 x double>) local_unnamed_addr #0 {
  %3 = bitcast <4 x double> %0 to <4 x i64>
  %4 = and <4 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <4 x i64> %4 to <4 x double>
  %6 = bitcast <4 x double> %1 to <4 x i64>
  %7 = and <4 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <4 x i64> %7 to <4 x double>
  %9 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %8, <4 x double> <double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000>, i8 17) #6
  %10 = fmul <4 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %5, <4 x double> %10, <4 x double> %9) #6
  %12 = fmul <4 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %8, <4 x double> %12, <4 x double> %9) #6
  %14 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <4 x double> %9) #6
  %15 = fdiv <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %16 = fmul <4 x double> %13, <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>
  %17 = fmul <4 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %18 = bitcast <4 x double> %13 to <4 x i64>
  %19 = xor <4 x i64> %18, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = bitcast <4 x i64> %19 to <4 x double>
  %21 = and <4 x i64> %19, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %22 = bitcast <4 x i64> %21 to <4 x double>
  %23 = fsub <4 x double> %20, %22
  br label %24

; <label>:24:                                     ; preds = %54, %2
  %25 = phi i32 [ 0, %2 ], [ %99, %54 ]
  %26 = phi <4 x i64> [ zeroinitializer, %2 ], [ %71, %54 ]
  %27 = phi <4 x double> [ zeroinitializer, %2 ], [ %98, %54 ]
  %28 = phi <4 x double> [ %11, %2 ], [ %96, %54 ]
  %29 = fmul <4 x double> %15, %28
  %30 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %29, i32 8) #6
  %31 = bitcast <4 x double> %30 to <4 x i64>
  %32 = and <4 x i64> %31, <i64 -2, i64 -2, i64 -2, i64 -2>
  %33 = bitcast <4 x i64> %32 to <4 x double>
  %34 = bitcast <4 x double> %28 to <4 x i64>
  %35 = and <4 x i64> %34, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %36 = bitcast <4 x i64> %35 to <4 x double>
  %37 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %36, <4 x double> %16, i8 17) #6
  %38 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %33, <4 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <4 x double> %37) #6
  %39 = tail call <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double> %36, <4 x double> %17, i8 17) #6
  %40 = bitcast <4 x double> %39 to <4 x i64>
  %41 = fcmp oeq <4 x double> %17, %36
  %42 = xor <4 x i64> %26, <i64 -1, i64 -1, i64 -1, i64 -1>
  %43 = select <4 x i1> %41, <4 x i64> %42, <4 x i64> zeroinitializer
  %44 = or <4 x i64> %43, %40
  %45 = bitcast <4 x i64> %44 to <4 x double>
  %46 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %38, <4 x double> zeroinitializer, <4 x double> %45) #6
  %47 = fcmp oeq <4 x double> %46, zeroinitializer
  %48 = sext <4 x i1> %47 to <4 x i64>
  %49 = shufflevector <4 x i64> %48, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  %50 = shufflevector <4 x i64> %48, <4 x i64> undef, <2 x i32> <i32 2, i32 3>
  %51 = and <2 x i64> %50, %49
  %52 = tail call i32 @llvm.x86.sse41.ptestc(<2 x i64> %51, <2 x i64> <i64 -1, i64 -1>) #6
  %53 = icmp eq i32 %52, 0
  br i1 %53, label %54, label %101

; <label>:54:                                     ; preds = %24
  %55 = fmul <4 x double> %46, %20
  %56 = bitcast <4 x double> %55 to <4 x i64>
  %57 = and <4 x i64> %56, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %58 = bitcast <4 x i64> %57 to <4 x double>
  %59 = fcmp oeq <4 x double> %58, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %60 = sext <4 x i1> %59 to <4 x i64>
  %61 = and <4 x i64> %34, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = xor <4 x i64> %61, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %63 = bitcast <4 x i64> %62 to <4 x double>
  %64 = fadd <4 x double> %46, %63
  %65 = bitcast <4 x i64> %60 to <4 x double>
  %66 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %46, <4 x double> %64, <4 x double> %65) #6
  %67 = fmul <4 x double> %66, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %68 = tail call <4 x double> @llvm.x86.avx.round.pd.256(<4 x double> %67, i32 11) #6
  %69 = fcmp une <4 x double> %68, %67
  %70 = sext <4 x i1> %69 to <4 x i64>
  %71 = xor <4 x i64> %26, %70
  %72 = bitcast <4 x double> %66 to <4 x i64>
  %73 = and <4 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <4 x i64> %73 to <4 x double>
  %75 = fsub <4 x double> %66, %74
  %76 = fmul <4 x double> %66, %20
  %77 = fmul <4 x double> %22, %74
  %78 = bitcast <4 x double> %76 to <4 x i64>
  %79 = xor <4 x i64> %78, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = bitcast <4 x i64> %79 to <4 x double>
  %81 = fmul <4 x double> %75, %22
  %82 = fmul <4 x double> %23, %74
  %83 = fmul <4 x double> %23, %75
  %84 = fadd <4 x double> %77, %80
  %85 = fadd <4 x double> %81, %84
  %86 = fadd <4 x double> %82, %85
  %87 = fadd <4 x double> %83, %86
  %88 = fadd <4 x double> %28, %76
  %89 = fsub <4 x double> %88, %28
  %90 = fsub <4 x double> %88, %89
  %91 = fsub <4 x double> %28, %90
  %92 = fsub <4 x double> %76, %89
  %93 = fadd <4 x double> %92, %91
  %94 = fadd <4 x double> %27, %87
  %95 = fadd <4 x double> %93, %94
  %96 = fadd <4 x double> %88, %95
  %97 = fsub <4 x double> %88, %96
  %98 = fadd <4 x double> %95, %97
  %99 = add nuw nsw i32 %25, 1
  %100 = icmp ult i32 %99, 21
  br i1 %100, label %24, label %101

; <label>:101:                                    ; preds = %24, %54
  %102 = phi <4 x double> [ %28, %24 ], [ %96, %54 ]
  %103 = fmul <4 x double> %14, %102
  %104 = bitcast <4 x double> %103 to <4 x i64>
  %105 = and <4 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %106 = xor <4 x i64> %105, %104
  %107 = bitcast <4 x i64> %106 to <4 x double>
  %108 = fcmp oeq <4 x double> %8, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %109 = sext <4 x i1> %108 to <4 x i64>
  %110 = fcmp oeq <4 x double> %5, <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %111 = sext <4 x i1> %110 to <4 x i64>
  %112 = bitcast <4 x i64> %111 to <4 x double>
  %113 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %0, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %112) #6
  %114 = bitcast <4 x i64> %109 to <4 x double>
  %115 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %107, <4 x double> %113, <4 x double> %114) #6
  %116 = fcmp oeq <4 x double> %13, zeroinitializer
  %117 = sext <4 x i1> %116 to <4 x i64>
  %118 = bitcast <4 x i64> %117 to <4 x double>
  %119 = tail call <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double> %115, <4 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <4 x double> %118) #6
  ret <4 x double> %119
}

; Function Attrs: nounwind uwtable
define <4 x double> @Sleef_cinz_tgammad4_u10avx(<4 x double>) local_unnamed_addr #2 {
  %2 = tail call <4 x double> @Sleef_tgammad4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind uwtable
define <4 x double> @Sleef_cinz_lgammad4_u10avx(<4 x double>) local_unnamed_addr #2 {
  %2 = tail call <4 x double> @Sleef_lgammad4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_erfd4_u10avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_erfd4_u10avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <4 x double> @Sleef_cinz_erfcd4_u15avx(<4 x double>) local_unnamed_addr #0 {
  %2 = tail call <4 x double> @Sleef_erfcd4_u15avx(<4 x double> %0)
  ret <4 x double> %2
}

; Function Attrs: nounwind uwtable
define i32 @Sleef_getIntd4_avx(i32) local_unnamed_addr #2 {
  %2 = alloca [4 x i32], align 16
  %3 = add i32 %0, -1
  %4 = icmp ult i32 %3, 10
  br i1 %4, label %5, label %13

; <label>:5:                                      ; preds = %1
  %6 = bitcast [4 x i32]* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %6) #6
  %7 = getelementptr inbounds [4 x i32], [4 x i32]* %2, i64 0, i64 0
  call void @Sleef_x86CpuID(i32* nonnull %7, i32 1, i32 0) #6
  %8 = getelementptr inbounds [4 x i32], [4 x i32]* %2, i64 0, i64 2
  %9 = load i32, i32* %8, align 8, !tbaa !37
  %10 = and i32 %9, 268435456
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %6) #6
  %11 = icmp eq i32 %10, 0
  %12 = select i1 %11, i32 0, i32 3
  br label %13

; <label>:13:                                     ; preds = %1, %5
  %14 = phi i32 [ %12, %5 ], [ 0, %1 ]
  ret i32 %14
}

; Function Attrs: norecurse nounwind readnone uwtable
define i8* @Sleef_getPtrd4_avx(i32) local_unnamed_addr #3 {
  %2 = icmp eq i32 %0, 0
  %3 = select i1 %2, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str, i64 0, i64 0), i8* null
  ret i8* %3
}

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.blendv.pd.256(<4 x double>, <4 x double>, <4 x double>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.avx.cvt.pd2dq.256(<4 x double>) #4

; Function Attrs: nounwind readnone
declare i32 @llvm.x86.sse41.ptestc(<2 x i64>, <2 x i64>) #4

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.cmp.pd.256(<4 x double>, <4 x double>, i8) #4

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.round.pd.256(<4 x double>, i32) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse41.pblendvb(<16 x i8>, <16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.avx.cvtt.pd2dq.256(<4 x double>) #4

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.sqrt.pd.256(<4 x double>) #4

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.max.pd.256(<4 x double>, <4 x double>) #4

; Function Attrs: nounwind readnone
declare <4 x double> @llvm.x86.avx.min.pd.256(<4 x double>, <4 x double>) #4

declare void @Sleef_x86CpuID(i32*, i32, i32) local_unnamed_addr #5

attributes #0 = { nounwind readnone uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind readnone uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)"}
!2 = !{!"branch_weights", i32 1, i32 2000}
!3 = !{!4, !4, i64 0}
!4 = !{!"double", !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C/C++ TBAA"}
!7 = !{!8}
!8 = distinct !{!8, !9, !"rempi: argument 0"}
!9 = distinct !{!9, !"rempi"}
!10 = !{!11}
!11 = distinct !{!11, !12, !"rempi: argument 0"}
!12 = distinct !{!12, !"rempi"}
!13 = !{!14}
!14 = distinct !{!14, !15, !"rempi: argument 0"}
!15 = distinct !{!15, !"rempi"}
!16 = !{!17}
!17 = distinct !{!17, !18, !"rempi: argument 0"}
!18 = distinct !{!18, !"rempi"}
!19 = !{!20}
!20 = distinct !{!20, !21, !"rempi: argument 0"}
!21 = distinct !{!21, !"rempi"}
!22 = !{!23}
!23 = distinct !{!23, !24, !"rempi: argument 0"}
!24 = distinct !{!24, !"rempi"}
!25 = !{!26}
!26 = distinct !{!26, !27, !"rempi: argument 0"}
!27 = distinct !{!27, !"rempi"}
!28 = !{!29}
!29 = distinct !{!29, !30, !"rempi: argument 0"}
!30 = distinct !{!30, !"rempi"}
!31 = !{!32}
!32 = distinct !{!32, !33, !"Sleef_sincospid4_u35avx: argument 0"}
!33 = distinct !{!33, !"Sleef_sincospid4_u35avx"}
!34 = !{!35}
!35 = distinct !{!35, !36, !"Sleef_modfd4_avx: argument 0"}
!36 = distinct !{!36, !"Sleef_modfd4_avx"}
!37 = !{!38, !38, i64 0}
!38 = !{!"int", !5, i64 0}
