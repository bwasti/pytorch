; ModuleID = '/home/bwasti/pytorch/sleef/src/libm/sleefsimddp.c'
source_filename = "/home/bwasti/pytorch/sleef/src/libm/sleefsimddp.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

%struct.vdouble2 = type { <8 x double>, <8 x double> }
%struct.dd2 = type { %struct.vdouble2, %struct.vdouble2 }

@.str = private unnamed_addr constant [13 x i8] c"AVX512FNOFMA\00", align 1
@rempitabdp = external constant [0 x double], align 8

; Function Attrs: norecurse nounwind readnone uwtable
define <8 x double> @Sleef_ldexpd8_avx512fnofma(<8 x double>, <4 x i64>) local_unnamed_addr #0 {
  %3 = bitcast <4 x i64> %1 to <8 x i32>
  %4 = ashr <8 x i32> %3, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %5 = add <8 x i32> %4, %3
  %6 = ashr <8 x i32> %5, <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %7 = sub nsw <8 x i32> %6, %4
  %8 = shl nsw <8 x i32> %7, <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7>
  %9 = shl <8 x i32> %7, <i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9, i32 9>
  %10 = add nsw <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %11 = bitcast <8 x i32> %10 to <4 x i64>
  %12 = shufflevector <4 x i64> %11, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <8 x i64> %12 to <16 x i32>
  %14 = icmp sgt <16 x i32> %13, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = select <16 x i1> %14, <16 x i32> %13, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %16 = icmp slt <16 x i32> %15, <i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %17 = select <16 x i1> %16, <16 x i32> %15, <16 x i32> <i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %18 = shufflevector <16 x i32> %17, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %19 = shufflevector <16 x i32> %18, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %20 = shl <16 x i32> %19, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %21 = bitcast <16 x i32> %20 to <8 x double>
  %22 = fmul <8 x double> %21, %0
  %23 = fmul <8 x double> %22, %21
  %24 = fmul <8 x double> %23, %21
  %25 = fmul <8 x double> %24, %21
  %26 = add <8 x i32> %3, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %27 = sub <8 x i32> %26, %9
  %28 = bitcast <8 x i32> %27 to <4 x i64>
  %29 = shufflevector <4 x i64> %28, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %30 = bitcast <8 x i64> %29 to <16 x i32>
  %31 = shufflevector <16 x i32> %30, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %32 = shufflevector <16 x i32> %31, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %33 = shl <16 x i32> %32, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %34 = bitcast <16 x i32> %33 to <8 x double>
  %35 = fmul <8 x double> %25, %34
  ret <8 x double> %35
}

; Function Attrs: nounwind readnone uwtable
define <4 x i64> @Sleef_ilogbd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %4, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %6 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %5, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %7 = sitofp <8 x i32> %6 to <8 x double>
  %8 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %9 = bitcast i8 %8 to <8 x i1>
  %10 = select <8 x i1> %9, <8 x double> <double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000, double 0xC1E0000000000000>, <8 x double> %7
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %12 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %13 = or i8 %12, %11
  %14 = bitcast i8 %13 to <8 x i1>
  %15 = select <8 x i1> %14, <8 x double> <double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000, double 0x41DFFFFFFFC00000>, <8 x double> %10
  %16 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %15, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %17 = bitcast <8 x i32> %16 to <4 x i64>
  ret <4 x i64> %17
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture) #2

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sind8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %15, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %8, i32 8, <8 x double> %8, i8 -1, i32 4) #7
  %10 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %9, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %11 = fmul <8 x double> %9, <double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18>
  %12 = fadd <8 x double> %11, %0
  %13 = fmul <8 x double> %9, <double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07>
  %14 = fadd <8 x double> %13, %12
  br label %233

; <label>:15:                                     ; preds = %1
  %16 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %17 = icmp eq i8 %16, -1
  br i1 %17, label %18, label %41, !prof !2

; <label>:18:                                     ; preds = %15
  %19 = fmul <8 x double> %0, <double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883>
  %20 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %19, i32 11, <8 x double> %19, i8 -1, i32 4) #7
  %21 = fmul <8 x double> %20, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %22 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %23 = fsub <8 x double> %22, %21
  %24 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %23, i32 8, <8 x double> %23, i8 -1, i32 4) #7
  %25 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %24, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %26 = fmul <8 x double> %21, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %27 = fadd <8 x double> %26, %0
  %28 = fmul <8 x double> %24, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %29 = fadd <8 x double> %28, %27
  %30 = fmul <8 x double> %21, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %31 = fadd <8 x double> %30, %29
  %32 = fmul <8 x double> %24, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %33 = fadd <8 x double> %32, %31
  %34 = fmul <8 x double> %21, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %35 = fadd <8 x double> %34, %33
  %36 = fmul <8 x double> %24, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %37 = fadd <8 x double> %36, %35
  %38 = fadd <8 x double> %21, %24
  %39 = fmul <8 x double> %38, <double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A>
  %40 = fadd <8 x double> %39, %37
  br label %233

; <label>:41:                                     ; preds = %15
  %42 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %43 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %42, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %44 = ashr <8 x i32> %43, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %45 = xor <8 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = and <8 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = and <8 x i32> %46, %45
  %48 = add nsw <8 x i32> %47, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %49 = bitcast <8 x i32> %48 to <4 x i64>
  %50 = shufflevector <4 x i64> %49, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <8 x i64> %50 to <16 x i32>
  %52 = icmp sgt <16 x i32> %51, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %53 = select <16 x i1> %52, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %54 = shufflevector <16 x i32> %53, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %55 = shufflevector <16 x i32> %54, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %56 = shl <16 x i32> %55, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %57 = bitcast <8 x double> %0 to <16 x i32>
  %58 = add <16 x i32> %56, %57
  %59 = bitcast <16 x i32> %58 to <8 x double>
  %60 = ashr <8 x i32> %48, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %61 = bitcast <8 x i32> %60 to <4 x i64>
  %62 = xor <4 x i64> %61, <i64 -1, i64 -1, i64 -1, i64 -1>
  %63 = and <4 x i64> %62, %49
  %64 = bitcast <4 x i64> %63 to <8 x i32>
  %65 = shl <8 x i32> %64, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %66 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !3
  %67 = bitcast <16 x i32> %58 to <8 x i64>
  %68 = and <8 x i64> %67, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %69 = bitcast <8 x i64> %68 to <8 x double>
  %70 = fsub <8 x double> %59, %69
  %71 = bitcast <8 x double> %66 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %66, %73
  %75 = fmul <8 x double> %66, %59
  %76 = fmul <8 x double> %73, %69
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %70, %73
  %81 = fmul <8 x double> %74, %69
  %82 = fmul <8 x double> %74, %70
  %83 = fadd <8 x double> %76, %79
  %84 = fadd <8 x double> %80, %83
  %85 = fadd <8 x double> %81, %84
  %86 = fadd <8 x double> %82, %85
  %87 = fmul <8 x double> %75, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %88 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %87, i32 8, <8 x double> %87, i8 -1, i32 4) #7
  %89 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %75, i32 8, <8 x double> %75, i8 -1, i32 4) #7
  %90 = fmul <8 x double> %89, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %91 = fsub <8 x double> %88, %90
  %92 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %91, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %93 = fmul <8 x double> %88, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %94 = fsub <8 x double> %75, %93
  %95 = fadd <8 x double> %94, %86
  %96 = fsub <8 x double> %94, %95
  %97 = fadd <8 x double> %86, %96
  %98 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !3
  %99 = bitcast <8 x double> %98 to <8 x i64>
  %100 = and <8 x i64> %99, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %101 = bitcast <8 x i64> %100 to <8 x double>
  %102 = fsub <8 x double> %98, %101
  %103 = fmul <8 x double> %98, %59
  %104 = fmul <8 x double> %101, %69
  %105 = bitcast <8 x double> %103 to <8 x i64>
  %106 = xor <8 x i64> %105, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %107 = bitcast <8 x i64> %106 to <8 x double>
  %108 = fmul <8 x double> %70, %101
  %109 = fmul <8 x double> %102, %69
  %110 = fmul <8 x double> %102, %70
  %111 = fadd <8 x double> %104, %107
  %112 = fadd <8 x double> %108, %111
  %113 = fadd <8 x double> %109, %112
  %114 = fadd <8 x double> %110, %113
  %115 = fadd <8 x double> %103, %95
  %116 = fsub <8 x double> %115, %95
  %117 = fsub <8 x double> %115, %116
  %118 = fsub <8 x double> %95, %117
  %119 = fsub <8 x double> %103, %116
  %120 = fadd <8 x double> %119, %118
  %121 = fadd <8 x double> %114, %97
  %122 = fadd <8 x double> %121, %120
  %123 = fmul <8 x double> %115, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %124 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %123, i32 8, <8 x double> %123, i8 -1, i32 4) #7
  %125 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %115, i32 8, <8 x double> %115, i8 -1, i32 4) #7
  %126 = fmul <8 x double> %125, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %127 = fsub <8 x double> %124, %126
  %128 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %127, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %129 = fmul <8 x double> %124, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %130 = fsub <8 x double> %115, %129
  %131 = add <8 x i32> %128, %92
  %132 = fadd <8 x double> %130, %122
  %133 = fsub <8 x double> %130, %132
  %134 = fadd <8 x double> %122, %133
  %135 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !3
  %136 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !3
  %137 = bitcast <8 x double> %135 to <8 x i64>
  %138 = and <8 x i64> %137, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %139 = bitcast <8 x i64> %138 to <8 x double>
  %140 = fsub <8 x double> %135, %139
  %141 = fmul <8 x double> %135, %59
  %142 = fmul <8 x double> %139, %69
  %143 = bitcast <8 x double> %141 to <8 x i64>
  %144 = xor <8 x i64> %143, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = fmul <8 x double> %140, %69
  %147 = fmul <8 x double> %70, %139
  %148 = fmul <8 x double> %140, %70
  %149 = fmul <8 x double> %136, %59
  %150 = fadd <8 x double> %142, %145
  %151 = fadd <8 x double> %146, %150
  %152 = fadd <8 x double> %147, %151
  %153 = fadd <8 x double> %148, %152
  %154 = fadd <8 x double> %149, %153
  %155 = fadd <8 x double> %141, %132
  %156 = fsub <8 x double> %155, %132
  %157 = fsub <8 x double> %155, %156
  %158 = fsub <8 x double> %132, %157
  %159 = fsub <8 x double> %141, %156
  %160 = fadd <8 x double> %159, %158
  %161 = fadd <8 x double> %154, %134
  %162 = fadd <8 x double> %161, %160
  %163 = fadd <8 x double> %155, %162
  %164 = fsub <8 x double> %155, %163
  %165 = fadd <8 x double> %162, %164
  %166 = bitcast <8 x double> %163 to <8 x i64>
  %167 = and <8 x i64> %166, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %168 = bitcast <8 x i64> %167 to <8 x double>
  %169 = fsub <8 x double> %163, %168
  %170 = fmul <8 x double> %163, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %171 = fmul <8 x double> %168, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %172 = bitcast <8 x double> %170 to <8 x i64>
  %173 = xor <8 x i64> %172, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %174 = bitcast <8 x i64> %173 to <8 x double>
  %175 = fmul <8 x double> %169, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %176 = fmul <8 x double> %168, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %177 = fmul <8 x double> %169, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %178 = fmul <8 x double> %163, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %179 = fmul <8 x double> %165, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %180 = fadd <8 x double> %171, %174
  %181 = fadd <8 x double> %175, %180
  %182 = fadd <8 x double> %176, %181
  %183 = fadd <8 x double> %177, %182
  %184 = fadd <8 x double> %178, %183
  %185 = fadd <8 x double> %179, %184
  %186 = and <8 x i64> %67, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %187 = bitcast <8 x i64> %186 to <8 x double>
  %188 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %187, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %189 = bitcast i8 %188 to <8 x i1>
  %190 = select <8 x i1> %189, <8 x double> %59, <8 x double> %170
  %191 = select <8 x i1> %189, <8 x double> zeroinitializer, <8 x double> %185
  %192 = bitcast <8 x i32> %131 to <4 x i64>
  %193 = shl <8 x i32> %131, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %194 = and <8 x i32> %193, <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %195 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %190, <8 x double> zeroinitializer, i32 30, i8 -1, i32 4) #7
  %196 = zext i8 %195 to i16
  %197 = bitcast i16 %196 to <16 x i1>
  %198 = select <16 x i1> %197, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %199 = bitcast <16 x i32> %198 to <8 x i64>
  %200 = shufflevector <8 x i64> %199, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %201 = bitcast <4 x i64> %200 to <8 x i32>
  %202 = add <8 x i32> %194, %201
  %203 = ashr <8 x i32> %202, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %204 = and <4 x i64> %192, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %205 = shufflevector <4 x i64> %204, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %206 = bitcast <8 x i64> %205 to <16 x i32>
  %207 = icmp eq <16 x i32> %206, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %208 = bitcast <8 x double> %190 to <8 x i64>
  %209 = and <8 x i64> %208, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %210 = xor <8 x i64> %209, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %211 = bitcast <8 x i64> %210 to <8 x double>
  %212 = xor <8 x i64> %209, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %213 = bitcast <8 x i64> %212 to <8 x double>
  %214 = fadd <8 x double> %190, %211
  %215 = fsub <8 x double> %214, %190
  %216 = fsub <8 x double> %214, %215
  %217 = fsub <8 x double> %190, %216
  %218 = fsub <8 x double> %211, %215
  %219 = fadd <8 x double> %218, %217
  %220 = fadd <8 x double> %191, %213
  %221 = fadd <8 x double> %219, %220
  %222 = bitcast <16 x i1> %207 to <2 x i8>
  %223 = extractelement <2 x i8> %222, i32 0
  %224 = bitcast i8 %223 to <8 x i1>
  %225 = select <8 x i1> %224, <8 x double> %214, <8 x double> %190
  %226 = select <8 x i1> %224, <8 x double> %221, <8 x double> %191
  %227 = fadd <8 x double> %225, %226
  %228 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %229 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %230 = or i8 %229, %228
  %231 = bitcast i8 %230 to <8 x i1>
  %232 = select <8 x i1> %231, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %227
  br label %233

; <label>:233:                                    ; preds = %18, %41, %7
  %234 = phi <8 x i32> [ %10, %7 ], [ %25, %18 ], [ %203, %41 ]
  %235 = phi <8 x double> [ %14, %7 ], [ %40, %18 ], [ %232, %41 ]
  %236 = bitcast <8 x i32> %234 to <4 x i64>
  %237 = fmul <8 x double> %235, %235
  %238 = and <4 x i64> %236, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %239 = shufflevector <4 x i64> %238, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %240 = bitcast <8 x i64> %239 to <16 x i32>
  %241 = icmp eq <16 x i32> %240, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %242 = bitcast <16 x i1> %241 to <2 x i8>
  %243 = extractelement <2 x i8> %242, i32 0
  %244 = bitcast i8 %243 to <8 x i1>
  %245 = select <8 x i1> %244, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %246 = bitcast <8 x double> %235 to <8 x i64>
  %247 = xor <8 x i64> %245, %246
  %248 = bitcast <8 x i64> %247 to <8 x double>
  %249 = fmul <8 x double> %237, %237
  %250 = fmul <8 x double> %249, %249
  %251 = fmul <8 x double> %237, <double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE>
  %252 = fadd <8 x double> %251, <double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592>
  %253 = fmul <8 x double> %237, <double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF>
  %254 = fadd <8 x double> %253, <double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966>
  %255 = fmul <8 x double> %249, %252
  %256 = fadd <8 x double> %254, %255
  %257 = fmul <8 x double> %237, <double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786>
  %258 = fadd <8 x double> %257, <double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50>
  %259 = fmul <8 x double> %237, <double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7>
  %260 = fadd <8 x double> %259, <double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F>
  %261 = fmul <8 x double> %249, %258
  %262 = fadd <8 x double> %260, %261
  %263 = fmul <8 x double> %250, %256
  %264 = fadd <8 x double> %262, %263
  %265 = fmul <8 x double> %237, %264
  %266 = fadd <8 x double> %265, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %267 = fmul <8 x double> %266, %248
  %268 = fmul <8 x double> %237, %267
  %269 = fadd <8 x double> %268, %248
  %270 = icmp eq <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %271 = select <8 x i1> %270, <8 x double> %0, <8 x double> %269
  ret <8 x double> %271
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sind8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %17, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %8, i32 8, <8 x double> %8, i8 -1, i32 4) #7
  %10 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %9, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %11 = fmul <8 x double> %9, <double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18, double 0xC00921FB54442D18>
  %12 = fadd <8 x double> %11, %0
  %13 = fmul <8 x double> %9, <double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07, double 0xBCA1A62633145C07>
  %14 = fadd <8 x double> %13, %12
  %15 = fsub <8 x double> %12, %14
  %16 = fadd <8 x double> %13, %15
  br label %266

; <label>:17:                                     ; preds = %1
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %19 = icmp eq i8 %18, -1
  br i1 %19, label %20, label %72, !prof !2

; <label>:20:                                     ; preds = %17
  %21 = fmul <8 x double> %0, <double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883, double 0x3E545F306DC9C883>
  %22 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %21, i32 11, <8 x double> %21, i8 -1, i32 4) #7
  %23 = fmul <8 x double> %22, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %24 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %25 = fsub <8 x double> %24, %23
  %26 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %25, i32 8, <8 x double> %25, i8 -1, i32 4) #7
  %27 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %26, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %28 = fmul <8 x double> %23, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %29 = fadd <8 x double> %28, %0
  %30 = fmul <8 x double> %26, <double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000, double 0xC00921FB50000000>
  %31 = fadd <8 x double> %30, %29
  %32 = fsub <8 x double> %29, %31
  %33 = fadd <8 x double> %30, %32
  %34 = fmul <8 x double> %23, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %35 = fadd <8 x double> %34, %31
  %36 = fsub <8 x double> %35, %31
  %37 = fsub <8 x double> %35, %36
  %38 = fsub <8 x double> %31, %37
  %39 = fsub <8 x double> %34, %36
  %40 = fadd <8 x double> %39, %38
  %41 = fadd <8 x double> %33, %40
  %42 = fmul <8 x double> %26, <double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000, double 0xBE6110B460000000>
  %43 = fadd <8 x double> %42, %35
  %44 = fsub <8 x double> %43, %35
  %45 = fsub <8 x double> %43, %44
  %46 = fsub <8 x double> %35, %45
  %47 = fsub <8 x double> %42, %44
  %48 = fadd <8 x double> %47, %46
  %49 = fadd <8 x double> %48, %41
  %50 = fmul <8 x double> %23, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %51 = fadd <8 x double> %50, %43
  %52 = fsub <8 x double> %51, %43
  %53 = fsub <8 x double> %51, %52
  %54 = fsub <8 x double> %43, %53
  %55 = fsub <8 x double> %50, %52
  %56 = fadd <8 x double> %55, %54
  %57 = fadd <8 x double> %56, %49
  %58 = fmul <8 x double> %26, <double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000, double 0xBCA1A62630000000>
  %59 = fadd <8 x double> %58, %51
  %60 = fsub <8 x double> %59, %51
  %61 = fsub <8 x double> %59, %60
  %62 = fsub <8 x double> %51, %61
  %63 = fsub <8 x double> %58, %60
  %64 = fadd <8 x double> %63, %62
  %65 = fadd <8 x double> %64, %57
  %66 = fadd <8 x double> %23, %26
  %67 = fmul <8 x double> %66, <double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A, double 0xBAF8A2E03707344A>
  %68 = fadd <8 x double> %67, %59
  %69 = fsub <8 x double> %59, %68
  %70 = fadd <8 x double> %67, %69
  %71 = fadd <8 x double> %70, %65
  br label %266

; <label>:72:                                     ; preds = %17
  %73 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %74 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %73, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %75 = ashr <8 x i32> %74, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %76 = xor <8 x i32> %75, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %77 = and <8 x i32> %74, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %78 = and <8 x i32> %77, %76
  %79 = add nsw <8 x i32> %78, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %80 = bitcast <8 x i32> %79 to <4 x i64>
  %81 = shufflevector <4 x i64> %80, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %82 = bitcast <8 x i64> %81 to <16 x i32>
  %83 = icmp sgt <16 x i32> %82, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %84 = select <16 x i1> %83, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = shufflevector <16 x i32> %84, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %86 = shufflevector <16 x i32> %85, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %87 = shl <16 x i32> %86, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %88 = bitcast <8 x double> %0 to <16 x i32>
  %89 = add <16 x i32> %87, %88
  %90 = bitcast <16 x i32> %89 to <8 x double>
  %91 = ashr <8 x i32> %79, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %92 = bitcast <8 x i32> %91 to <4 x i64>
  %93 = xor <4 x i64> %92, <i64 -1, i64 -1, i64 -1, i64 -1>
  %94 = and <4 x i64> %93, %80
  %95 = bitcast <4 x i64> %94 to <8 x i32>
  %96 = shl <8 x i32> %95, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %97 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %96, i8 -1, i32 8) #7, !noalias !6
  %98 = bitcast <16 x i32> %89 to <8 x i64>
  %99 = and <8 x i64> %98, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %100 = bitcast <8 x i64> %99 to <8 x double>
  %101 = fsub <8 x double> %90, %100
  %102 = bitcast <8 x double> %97 to <8 x i64>
  %103 = and <8 x i64> %102, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %104 = bitcast <8 x i64> %103 to <8 x double>
  %105 = fsub <8 x double> %97, %104
  %106 = fmul <8 x double> %97, %90
  %107 = fmul <8 x double> %104, %100
  %108 = bitcast <8 x double> %106 to <8 x i64>
  %109 = xor <8 x i64> %108, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %110 = bitcast <8 x i64> %109 to <8 x double>
  %111 = fmul <8 x double> %101, %104
  %112 = fmul <8 x double> %105, %100
  %113 = fmul <8 x double> %105, %101
  %114 = fadd <8 x double> %107, %110
  %115 = fadd <8 x double> %111, %114
  %116 = fadd <8 x double> %112, %115
  %117 = fadd <8 x double> %113, %116
  %118 = fmul <8 x double> %106, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %119 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %118, i32 8, <8 x double> %118, i8 -1, i32 4) #7
  %120 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %106, i32 8, <8 x double> %106, i8 -1, i32 4) #7
  %121 = fmul <8 x double> %120, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %122 = fsub <8 x double> %119, %121
  %123 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %122, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %124 = fmul <8 x double> %119, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %125 = fsub <8 x double> %106, %124
  %126 = fadd <8 x double> %125, %117
  %127 = fsub <8 x double> %125, %126
  %128 = fadd <8 x double> %117, %127
  %129 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %96, i8 -1, i32 8) #7, !noalias !6
  %130 = bitcast <8 x double> %129 to <8 x i64>
  %131 = and <8 x i64> %130, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %132 = bitcast <8 x i64> %131 to <8 x double>
  %133 = fsub <8 x double> %129, %132
  %134 = fmul <8 x double> %129, %90
  %135 = fmul <8 x double> %132, %100
  %136 = bitcast <8 x double> %134 to <8 x i64>
  %137 = xor <8 x i64> %136, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %138 = bitcast <8 x i64> %137 to <8 x double>
  %139 = fmul <8 x double> %101, %132
  %140 = fmul <8 x double> %133, %100
  %141 = fmul <8 x double> %133, %101
  %142 = fadd <8 x double> %135, %138
  %143 = fadd <8 x double> %139, %142
  %144 = fadd <8 x double> %140, %143
  %145 = fadd <8 x double> %141, %144
  %146 = fadd <8 x double> %134, %126
  %147 = fsub <8 x double> %146, %126
  %148 = fsub <8 x double> %146, %147
  %149 = fsub <8 x double> %126, %148
  %150 = fsub <8 x double> %134, %147
  %151 = fadd <8 x double> %150, %149
  %152 = fadd <8 x double> %145, %128
  %153 = fadd <8 x double> %152, %151
  %154 = fmul <8 x double> %146, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %155 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %154, i32 8, <8 x double> %154, i8 -1, i32 4) #7
  %156 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %146, i32 8, <8 x double> %146, i8 -1, i32 4) #7
  %157 = fmul <8 x double> %156, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %158 = fsub <8 x double> %155, %157
  %159 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %158, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %160 = fmul <8 x double> %155, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %161 = fsub <8 x double> %146, %160
  %162 = add <8 x i32> %159, %123
  %163 = fadd <8 x double> %161, %153
  %164 = fsub <8 x double> %161, %163
  %165 = fadd <8 x double> %153, %164
  %166 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %96, i8 -1, i32 8) #7, !noalias !6
  %167 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %96, i8 -1, i32 8) #7, !noalias !6
  %168 = bitcast <8 x double> %166 to <8 x i64>
  %169 = and <8 x i64> %168, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %170 = bitcast <8 x i64> %169 to <8 x double>
  %171 = fsub <8 x double> %166, %170
  %172 = fmul <8 x double> %166, %90
  %173 = fmul <8 x double> %170, %100
  %174 = bitcast <8 x double> %172 to <8 x i64>
  %175 = xor <8 x i64> %174, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %176 = bitcast <8 x i64> %175 to <8 x double>
  %177 = fmul <8 x double> %171, %100
  %178 = fmul <8 x double> %101, %170
  %179 = fmul <8 x double> %171, %101
  %180 = fmul <8 x double> %167, %90
  %181 = fadd <8 x double> %173, %176
  %182 = fadd <8 x double> %177, %181
  %183 = fadd <8 x double> %178, %182
  %184 = fadd <8 x double> %179, %183
  %185 = fadd <8 x double> %180, %184
  %186 = fadd <8 x double> %172, %163
  %187 = fsub <8 x double> %186, %163
  %188 = fsub <8 x double> %186, %187
  %189 = fsub <8 x double> %163, %188
  %190 = fsub <8 x double> %172, %187
  %191 = fadd <8 x double> %190, %189
  %192 = fadd <8 x double> %185, %165
  %193 = fadd <8 x double> %192, %191
  %194 = fadd <8 x double> %186, %193
  %195 = fsub <8 x double> %186, %194
  %196 = fadd <8 x double> %193, %195
  %197 = bitcast <8 x double> %194 to <8 x i64>
  %198 = and <8 x i64> %197, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %199 = bitcast <8 x i64> %198 to <8 x double>
  %200 = fsub <8 x double> %194, %199
  %201 = fmul <8 x double> %194, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %202 = fmul <8 x double> %199, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %203 = bitcast <8 x double> %201 to <8 x i64>
  %204 = xor <8 x i64> %203, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %205 = bitcast <8 x i64> %204 to <8 x double>
  %206 = fmul <8 x double> %200, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %207 = fmul <8 x double> %199, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %208 = fmul <8 x double> %200, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %209 = fmul <8 x double> %194, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %210 = fmul <8 x double> %196, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %211 = fadd <8 x double> %202, %205
  %212 = fadd <8 x double> %206, %211
  %213 = fadd <8 x double> %207, %212
  %214 = fadd <8 x double> %208, %213
  %215 = fadd <8 x double> %209, %214
  %216 = fadd <8 x double> %210, %215
  %217 = and <8 x i64> %98, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %218 = bitcast <8 x i64> %217 to <8 x double>
  %219 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %218, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %220 = bitcast i8 %219 to <8 x i1>
  %221 = select <8 x i1> %220, <8 x double> %90, <8 x double> %201
  %222 = select <8 x i1> %220, <8 x double> zeroinitializer, <8 x double> %216
  %223 = bitcast <8 x i32> %162 to <4 x i64>
  %224 = shl <8 x i32> %162, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %225 = and <8 x i32> %224, <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %226 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %221, <8 x double> zeroinitializer, i32 30, i8 -1, i32 4) #7
  %227 = zext i8 %226 to i16
  %228 = bitcast i16 %227 to <16 x i1>
  %229 = select <16 x i1> %228, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %230 = bitcast <16 x i32> %229 to <8 x i64>
  %231 = shufflevector <8 x i64> %230, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %232 = bitcast <4 x i64> %231 to <8 x i32>
  %233 = add <8 x i32> %225, %232
  %234 = ashr <8 x i32> %233, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %235 = and <4 x i64> %223, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %236 = shufflevector <4 x i64> %235, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %237 = bitcast <8 x i64> %236 to <16 x i32>
  %238 = icmp eq <16 x i32> %237, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %239 = bitcast <8 x double> %221 to <8 x i64>
  %240 = and <8 x i64> %239, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %241 = xor <8 x i64> %240, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %242 = bitcast <8 x i64> %241 to <8 x double>
  %243 = xor <8 x i64> %240, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %244 = bitcast <8 x i64> %243 to <8 x double>
  %245 = fadd <8 x double> %221, %242
  %246 = fsub <8 x double> %245, %221
  %247 = fsub <8 x double> %245, %246
  %248 = fsub <8 x double> %221, %247
  %249 = fsub <8 x double> %242, %246
  %250 = fadd <8 x double> %249, %248
  %251 = fadd <8 x double> %222, %244
  %252 = fadd <8 x double> %250, %251
  %253 = bitcast <16 x i1> %238 to <2 x i8>
  %254 = extractelement <2 x i8> %253, i32 0
  %255 = bitcast i8 %254 to <8 x i1>
  %256 = select <8 x i1> %255, <8 x double> %245, <8 x double> %221
  %257 = select <8 x i1> %255, <8 x double> %252, <8 x double> %222
  %258 = fadd <8 x double> %256, %257
  %259 = fsub <8 x double> %256, %258
  %260 = fadd <8 x double> %257, %259
  %261 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %262 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %263 = or i8 %262, %261
  %264 = bitcast i8 %263 to <8 x i1>
  %265 = select <8 x i1> %264, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %258
  br label %266

; <label>:266:                                    ; preds = %20, %72, %7
  %267 = phi <8 x double> [ %265, %72 ], [ %68, %20 ], [ %14, %7 ]
  %268 = phi <8 x double> [ %260, %72 ], [ %71, %20 ], [ %16, %7 ]
  %269 = phi <8 x i32> [ %234, %72 ], [ %27, %20 ], [ %10, %7 ]
  %270 = bitcast <8 x i32> %269 to <4 x i64>
  %271 = bitcast <8 x double> %267 to <8 x i64>
  %272 = and <8 x i64> %271, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %273 = bitcast <8 x i64> %272 to <8 x double>
  %274 = fsub <8 x double> %267, %273
  %275 = fmul <8 x double> %267, %267
  %276 = fmul <8 x double> %273, %273
  %277 = bitcast <8 x double> %275 to <8 x i64>
  %278 = xor <8 x i64> %277, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %279 = bitcast <8 x i64> %278 to <8 x double>
  %280 = fadd <8 x double> %273, %273
  %281 = fmul <8 x double> %280, %274
  %282 = fmul <8 x double> %274, %274
  %283 = fadd <8 x double> %268, %268
  %284 = fmul <8 x double> %267, %283
  %285 = fadd <8 x double> %276, %279
  %286 = fadd <8 x double> %285, %281
  %287 = fadd <8 x double> %282, %286
  %288 = fadd <8 x double> %284, %287
  %289 = fmul <8 x double> %275, %275
  %290 = fmul <8 x double> %289, %289
  %291 = fmul <8 x double> %275, <double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D>
  %292 = fadd <8 x double> %291, <double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350>
  %293 = fmul <8 x double> %275, <double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67>
  %294 = fadd <8 x double> %293, <double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959>
  %295 = fmul <8 x double> %275, <double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED>
  %296 = fadd <8 x double> %295, <double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225>
  %297 = fmul <8 x double> %289, %294
  %298 = fadd <8 x double> %296, %297
  %299 = fmul <8 x double> %290, %292
  %300 = fadd <8 x double> %299, %298
  %301 = fmul <8 x double> %275, %300
  %302 = fadd <8 x double> %301, <double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9>
  %303 = fmul <8 x double> %275, %302
  %304 = fadd <8 x double> %303, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %305 = fsub <8 x double> <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>, %304
  %306 = fadd <8 x double> %303, %305
  %307 = bitcast <8 x double> %304 to <8 x i64>
  %308 = and <8 x i64> %307, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %309 = bitcast <8 x i64> %308 to <8 x double>
  %310 = fsub <8 x double> %304, %309
  %311 = and <8 x i64> %277, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %312 = bitcast <8 x i64> %311 to <8 x double>
  %313 = fsub <8 x double> %275, %312
  %314 = fmul <8 x double> %275, %304
  %315 = fmul <8 x double> %312, %309
  %316 = bitcast <8 x double> %314 to <8 x i64>
  %317 = xor <8 x i64> %316, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %318 = bitcast <8 x i64> %317 to <8 x double>
  %319 = fmul <8 x double> %310, %312
  %320 = fmul <8 x double> %313, %309
  %321 = fmul <8 x double> %313, %310
  %322 = fmul <8 x double> %288, %304
  %323 = fmul <8 x double> %275, %306
  %324 = fadd <8 x double> %315, %318
  %325 = fadd <8 x double> %319, %324
  %326 = fadd <8 x double> %320, %325
  %327 = fadd <8 x double> %321, %326
  %328 = fadd <8 x double> %322, %327
  %329 = fadd <8 x double> %323, %328
  %330 = fadd <8 x double> %314, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %331 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %330
  %332 = fadd <8 x double> %314, %331
  %333 = fadd <8 x double> %332, %329
  %334 = bitcast <8 x double> %330 to <8 x i64>
  %335 = and <8 x i64> %334, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %336 = bitcast <8 x i64> %335 to <8 x double>
  %337 = fsub <8 x double> %330, %336
  %338 = fmul <8 x double> %268, %336
  %339 = fmul <8 x double> %333, %273
  %340 = fmul <8 x double> %274, %337
  %341 = fmul <8 x double> %337, %273
  %342 = fmul <8 x double> %274, %336
  %343 = fmul <8 x double> %273, %336
  %344 = fadd <8 x double> %338, %339
  %345 = fadd <8 x double> %340, %344
  %346 = fadd <8 x double> %341, %345
  %347 = fadd <8 x double> %342, %346
  %348 = fadd <8 x double> %343, %347
  %349 = and <4 x i64> %270, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %350 = shufflevector <4 x i64> %349, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %351 = bitcast <8 x i64> %350 to <16 x i32>
  %352 = icmp eq <16 x i32> %351, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %353 = bitcast <16 x i1> %352 to <2 x i8>
  %354 = extractelement <2 x i8> %353, i32 0
  %355 = bitcast i8 %354 to <8 x i1>
  %356 = select <8 x i1> %355, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %357 = bitcast <8 x double> %348 to <8 x i64>
  %358 = xor <8 x i64> %356, %357
  %359 = bitcast <8 x i64> %358 to <8 x double>
  %360 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %361 = bitcast i8 %360 to <8 x i1>
  %362 = select <8 x i1> %361, <8 x double> %0, <8 x double> %359
  ret <8 x double> %362
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cosd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %18, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %9 = fadd <8 x double> %8, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %9, i32 8, <8 x double> %9, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %10, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %12 = fadd <8 x double> %11, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %13 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %12, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %14 = fmul <8 x double> %12, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %15 = fadd <8 x double> %14, %0
  %16 = fmul <8 x double> %12, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %17 = fadd <8 x double> %16, %15
  br label %241

; <label>:18:                                     ; preds = %1
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %20 = icmp eq i8 %19, -1
  br i1 %20, label %21, label %49, !prof !2

; <label>:21:                                     ; preds = %18
  %22 = fmul <8 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %23 = fadd <8 x double> %22, <double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883>
  %24 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %23, i32 11, <8 x double> %23, i8 -1, i32 4) #7
  %25 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %26 = fmul <8 x double> %24, <double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000>
  %27 = fadd <8 x double> %26, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %28 = fadd <8 x double> %25, %27
  %29 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %28, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %30 = fmul <8 x double> %24, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %31 = shl <8 x i32> %29, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %32 = or <8 x i32> %31, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %33 = sitofp <8 x i32> %32 to <8 x double>
  %34 = fmul <8 x double> %30, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %35 = fadd <8 x double> %34, %0
  %36 = fmul <8 x double> %33, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %37 = fadd <8 x double> %35, %36
  %38 = fmul <8 x double> %30, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %39 = fadd <8 x double> %38, %37
  %40 = fmul <8 x double> %33, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %41 = fadd <8 x double> %40, %39
  %42 = fmul <8 x double> %30, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %43 = fadd <8 x double> %42, %41
  %44 = fmul <8 x double> %33, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %45 = fadd <8 x double> %44, %43
  %46 = fadd <8 x double> %30, %33
  %47 = fmul <8 x double> %46, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %48 = fadd <8 x double> %47, %45
  br label %241

; <label>:49:                                     ; preds = %18
  %50 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %51 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %50, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %52 = ashr <8 x i32> %51, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %53 = xor <8 x i32> %52, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %54 = and <8 x i32> %51, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = and <8 x i32> %54, %53
  %56 = add nsw <8 x i32> %55, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %57 = bitcast <8 x i32> %56 to <4 x i64>
  %58 = shufflevector <4 x i64> %57, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <8 x i64> %58 to <16 x i32>
  %60 = icmp sgt <16 x i32> %59, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %61 = select <16 x i1> %60, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %62 = shufflevector <16 x i32> %61, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %63 = shufflevector <16 x i32> %62, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %64 = shl <16 x i32> %63, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %65 = bitcast <8 x double> %0 to <16 x i32>
  %66 = add <16 x i32> %64, %65
  %67 = bitcast <16 x i32> %66 to <8 x double>
  %68 = ashr <8 x i32> %56, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %69 = bitcast <8 x i32> %68 to <4 x i64>
  %70 = xor <4 x i64> %69, <i64 -1, i64 -1, i64 -1, i64 -1>
  %71 = and <4 x i64> %70, %57
  %72 = bitcast <4 x i64> %71 to <8 x i32>
  %73 = shl <8 x i32> %72, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %74 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %73, i8 -1, i32 8) #7, !noalias !9
  %75 = bitcast <16 x i32> %66 to <8 x i64>
  %76 = and <8 x i64> %75, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %77 = bitcast <8 x i64> %76 to <8 x double>
  %78 = fsub <8 x double> %67, %77
  %79 = bitcast <8 x double> %74 to <8 x i64>
  %80 = and <8 x i64> %79, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %81 = bitcast <8 x i64> %80 to <8 x double>
  %82 = fsub <8 x double> %74, %81
  %83 = fmul <8 x double> %74, %67
  %84 = fmul <8 x double> %81, %77
  %85 = bitcast <8 x double> %83 to <8 x i64>
  %86 = xor <8 x i64> %85, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %87 = bitcast <8 x i64> %86 to <8 x double>
  %88 = fmul <8 x double> %78, %81
  %89 = fmul <8 x double> %82, %77
  %90 = fmul <8 x double> %82, %78
  %91 = fadd <8 x double> %84, %87
  %92 = fadd <8 x double> %88, %91
  %93 = fadd <8 x double> %89, %92
  %94 = fadd <8 x double> %90, %93
  %95 = fmul <8 x double> %83, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %96 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %95, i32 8, <8 x double> %95, i8 -1, i32 4) #7
  %97 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %83, i32 8, <8 x double> %83, i8 -1, i32 4) #7
  %98 = fmul <8 x double> %97, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %99 = fsub <8 x double> %96, %98
  %100 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %99, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %101 = fmul <8 x double> %96, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %102 = fsub <8 x double> %83, %101
  %103 = fadd <8 x double> %102, %94
  %104 = fsub <8 x double> %102, %103
  %105 = fadd <8 x double> %94, %104
  %106 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %73, i8 -1, i32 8) #7, !noalias !9
  %107 = bitcast <8 x double> %106 to <8 x i64>
  %108 = and <8 x i64> %107, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %109 = bitcast <8 x i64> %108 to <8 x double>
  %110 = fsub <8 x double> %106, %109
  %111 = fmul <8 x double> %106, %67
  %112 = fmul <8 x double> %109, %77
  %113 = bitcast <8 x double> %111 to <8 x i64>
  %114 = xor <8 x i64> %113, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %115 = bitcast <8 x i64> %114 to <8 x double>
  %116 = fmul <8 x double> %78, %109
  %117 = fmul <8 x double> %110, %77
  %118 = fmul <8 x double> %110, %78
  %119 = fadd <8 x double> %112, %115
  %120 = fadd <8 x double> %116, %119
  %121 = fadd <8 x double> %117, %120
  %122 = fadd <8 x double> %118, %121
  %123 = fadd <8 x double> %111, %103
  %124 = fsub <8 x double> %123, %103
  %125 = fsub <8 x double> %123, %124
  %126 = fsub <8 x double> %103, %125
  %127 = fsub <8 x double> %111, %124
  %128 = fadd <8 x double> %127, %126
  %129 = fadd <8 x double> %122, %105
  %130 = fadd <8 x double> %129, %128
  %131 = fmul <8 x double> %123, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %132 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %131, i32 8, <8 x double> %131, i8 -1, i32 4) #7
  %133 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %123, i32 8, <8 x double> %123, i8 -1, i32 4) #7
  %134 = fmul <8 x double> %133, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %135 = fsub <8 x double> %132, %134
  %136 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %135, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %137 = fmul <8 x double> %132, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %138 = fsub <8 x double> %123, %137
  %139 = add <8 x i32> %136, %100
  %140 = fadd <8 x double> %138, %130
  %141 = fsub <8 x double> %138, %140
  %142 = fadd <8 x double> %130, %141
  %143 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %73, i8 -1, i32 8) #7, !noalias !9
  %144 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %73, i8 -1, i32 8) #7, !noalias !9
  %145 = bitcast <8 x double> %143 to <8 x i64>
  %146 = and <8 x i64> %145, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %147 = bitcast <8 x i64> %146 to <8 x double>
  %148 = fsub <8 x double> %143, %147
  %149 = fmul <8 x double> %143, %67
  %150 = fmul <8 x double> %147, %77
  %151 = bitcast <8 x double> %149 to <8 x i64>
  %152 = xor <8 x i64> %151, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %153 = bitcast <8 x i64> %152 to <8 x double>
  %154 = fmul <8 x double> %148, %77
  %155 = fmul <8 x double> %78, %147
  %156 = fmul <8 x double> %148, %78
  %157 = fmul <8 x double> %144, %67
  %158 = fadd <8 x double> %150, %153
  %159 = fadd <8 x double> %154, %158
  %160 = fadd <8 x double> %155, %159
  %161 = fadd <8 x double> %156, %160
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %149, %140
  %164 = fsub <8 x double> %163, %140
  %165 = fsub <8 x double> %163, %164
  %166 = fsub <8 x double> %140, %165
  %167 = fsub <8 x double> %149, %164
  %168 = fadd <8 x double> %167, %166
  %169 = fadd <8 x double> %162, %142
  %170 = fadd <8 x double> %169, %168
  %171 = fadd <8 x double> %163, %170
  %172 = fsub <8 x double> %163, %171
  %173 = fadd <8 x double> %170, %172
  %174 = bitcast <8 x double> %171 to <8 x i64>
  %175 = and <8 x i64> %174, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %176 = bitcast <8 x i64> %175 to <8 x double>
  %177 = fsub <8 x double> %171, %176
  %178 = fmul <8 x double> %171, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %179 = fmul <8 x double> %176, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %180 = bitcast <8 x double> %178 to <8 x i64>
  %181 = xor <8 x i64> %180, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %182 = bitcast <8 x i64> %181 to <8 x double>
  %183 = fmul <8 x double> %177, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %184 = fmul <8 x double> %176, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %185 = fmul <8 x double> %177, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %186 = fmul <8 x double> %171, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %187 = fmul <8 x double> %173, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %188 = fadd <8 x double> %179, %182
  %189 = fadd <8 x double> %183, %188
  %190 = fadd <8 x double> %184, %189
  %191 = fadd <8 x double> %185, %190
  %192 = fadd <8 x double> %186, %191
  %193 = fadd <8 x double> %187, %192
  %194 = and <8 x i64> %75, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %195 = bitcast <8 x i64> %194 to <8 x double>
  %196 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %195, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %197 = bitcast i8 %196 to <8 x i1>
  %198 = select <8 x i1> %197, <8 x double> %67, <8 x double> %178
  %199 = select <8 x i1> %197, <8 x double> zeroinitializer, <8 x double> %193
  %200 = bitcast <8 x i32> %139 to <4 x i64>
  %201 = shl <8 x i32> %139, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %202 = and <8 x i32> %201, <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %203 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %198, <8 x double> zeroinitializer, i32 30, i8 -1, i32 4) #7
  %204 = zext i8 %203 to i16
  %205 = bitcast i16 %204 to <16 x i1>
  %206 = select <16 x i1> %205, <16 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %207 = bitcast <16 x i32> %206 to <8 x i64>
  %208 = shufflevector <8 x i64> %207, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %209 = bitcast <4 x i64> %208 to <8 x i32>
  %210 = add <8 x i32> %202, %209
  %211 = ashr <8 x i32> %210, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %212 = and <4 x i64> %200, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %213 = shufflevector <4 x i64> %212, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %214 = bitcast <8 x i64> %213 to <16 x i32>
  %215 = icmp eq <16 x i32> %214, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %216 = bitcast i8 %203 to <8 x i1>
  %217 = select <8 x i1> %216, <8 x i64> zeroinitializer, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %218 = xor <8 x i64> %217, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %219 = bitcast <8 x i64> %218 to <8 x double>
  %220 = xor <8 x i64> %217, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %221 = bitcast <8 x i64> %220 to <8 x double>
  %222 = fadd <8 x double> %198, %219
  %223 = fsub <8 x double> %222, %198
  %224 = fsub <8 x double> %222, %223
  %225 = fsub <8 x double> %198, %224
  %226 = fsub <8 x double> %219, %223
  %227 = fadd <8 x double> %226, %225
  %228 = fadd <8 x double> %199, %221
  %229 = fadd <8 x double> %227, %228
  %230 = bitcast <16 x i1> %215 to <2 x i8>
  %231 = extractelement <2 x i8> %230, i32 0
  %232 = bitcast i8 %231 to <8 x i1>
  %233 = select <8 x i1> %232, <8 x double> %222, <8 x double> %198
  %234 = select <8 x i1> %232, <8 x double> %229, <8 x double> %199
  %235 = fadd <8 x double> %233, %234
  %236 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %237 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %238 = or i8 %237, %236
  %239 = bitcast i8 %238 to <8 x i1>
  %240 = select <8 x i1> %239, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %235
  br label %241

; <label>:241:                                    ; preds = %21, %49, %7
  %242 = phi <8 x i32> [ %13, %7 ], [ %32, %21 ], [ %211, %49 ]
  %243 = phi <8 x double> [ %17, %7 ], [ %48, %21 ], [ %240, %49 ]
  %244 = bitcast <8 x i32> %242 to <4 x i64>
  %245 = fmul <8 x double> %243, %243
  %246 = and <4 x i64> %244, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %247 = shufflevector <4 x i64> %246, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %248 = bitcast <8 x i64> %247 to <16 x i32>
  %249 = icmp eq <16 x i32> %248, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %250 = bitcast <16 x i1> %249 to <2 x i8>
  %251 = extractelement <2 x i8> %250, i32 0
  %252 = bitcast i8 %251 to <8 x i1>
  %253 = select <8 x i1> %252, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %254 = bitcast <8 x double> %243 to <8 x i64>
  %255 = xor <8 x i64> %253, %254
  %256 = bitcast <8 x i64> %255 to <8 x double>
  %257 = fmul <8 x double> %245, %245
  %258 = fmul <8 x double> %257, %257
  %259 = fmul <8 x double> %245, <double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE, double 0xBC62622B22D526BE>
  %260 = fadd <8 x double> %259, <double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592, double 0x3CE94FA618796592>
  %261 = fmul <8 x double> %245, <double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF, double 0xBD6AE7EA531357BF>
  %262 = fadd <8 x double> %261, <double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966, double 0x3DE6124601C23966>
  %263 = fmul <8 x double> %257, %260
  %264 = fadd <8 x double> %262, %263
  %265 = fmul <8 x double> %245, <double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786, double 0xBE5AE64567CB5786>
  %266 = fadd <8 x double> %265, <double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50, double 0x3EC71DE3A5568A50>
  %267 = fmul <8 x double> %245, <double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7, double 0xBF2A01A01A019FC7>
  %268 = fadd <8 x double> %267, <double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F, double 0x3F8111111111110F>
  %269 = fmul <8 x double> %257, %266
  %270 = fadd <8 x double> %268, %269
  %271 = fmul <8 x double> %258, %264
  %272 = fadd <8 x double> %270, %271
  %273 = fmul <8 x double> %245, %272
  %274 = fadd <8 x double> %273, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %275 = fmul <8 x double> %274, %256
  %276 = fmul <8 x double> %245, %275
  %277 = fadd <8 x double> %276, %256
  ret <8 x double> %277
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cosd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %26, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %9 = fadd <8 x double> %8, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %9, i32 8, <8 x double> %9, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %10, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %12 = fadd <8 x double> %11, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %13 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %12, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %14 = fmul <8 x double> %12, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %15 = fadd <8 x double> %14, %0
  %16 = fsub <8 x double> %15, %0
  %17 = fsub <8 x double> %15, %16
  %18 = fsub <8 x double> %0, %17
  %19 = fsub <8 x double> %14, %16
  %20 = fadd <8 x double> %19, %18
  %21 = fmul <8 x double> %12, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %22 = fadd <8 x double> %21, %15
  %23 = fsub <8 x double> %15, %22
  %24 = fadd <8 x double> %21, %23
  %25 = fadd <8 x double> %24, %20
  br label %283

; <label>:26:                                     ; preds = %1
  %27 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %28 = icmp eq i8 %27, -1
  br i1 %28, label %29, label %89, !prof !2

; <label>:29:                                     ; preds = %26
  %30 = fmul <8 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %31 = fadd <8 x double> %30, <double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883, double 0xBE545F306DC9C883>
  %32 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %31, i32 11, <8 x double> %31, i8 -1, i32 4) #7
  %33 = fmul <8 x double> %0, <double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883, double 0x3FD45F306DC9C883>
  %34 = fmul <8 x double> %32, <double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000, double 0xC160000000000000>
  %35 = fadd <8 x double> %34, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %36 = fadd <8 x double> %33, %35
  %37 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %36, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %38 = fmul <8 x double> %32, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %39 = shl <8 x i32> %37, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %40 = or <8 x i32> %39, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %41 = sitofp <8 x i32> %40 to <8 x double>
  %42 = fmul <8 x double> %38, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %43 = fadd <8 x double> %42, %0
  %44 = fmul <8 x double> %41, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %45 = fadd <8 x double> %43, %44
  %46 = fsub <8 x double> %45, %43
  %47 = fsub <8 x double> %45, %46
  %48 = fsub <8 x double> %43, %47
  %49 = fsub <8 x double> %44, %46
  %50 = fadd <8 x double> %49, %48
  %51 = fmul <8 x double> %38, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %52 = fadd <8 x double> %51, %45
  %53 = fsub <8 x double> %52, %45
  %54 = fsub <8 x double> %52, %53
  %55 = fsub <8 x double> %45, %54
  %56 = fsub <8 x double> %51, %53
  %57 = fadd <8 x double> %56, %55
  %58 = fadd <8 x double> %50, %57
  %59 = fmul <8 x double> %41, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %60 = fadd <8 x double> %59, %52
  %61 = fsub <8 x double> %60, %52
  %62 = fsub <8 x double> %60, %61
  %63 = fsub <8 x double> %52, %62
  %64 = fsub <8 x double> %59, %61
  %65 = fadd <8 x double> %64, %63
  %66 = fadd <8 x double> %65, %58
  %67 = fmul <8 x double> %38, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %68 = fadd <8 x double> %67, %60
  %69 = fsub <8 x double> %68, %60
  %70 = fsub <8 x double> %68, %69
  %71 = fsub <8 x double> %60, %70
  %72 = fsub <8 x double> %67, %69
  %73 = fadd <8 x double> %72, %71
  %74 = fadd <8 x double> %73, %66
  %75 = fmul <8 x double> %41, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %76 = fadd <8 x double> %75, %68
  %77 = fsub <8 x double> %76, %68
  %78 = fsub <8 x double> %76, %77
  %79 = fsub <8 x double> %68, %78
  %80 = fsub <8 x double> %75, %77
  %81 = fadd <8 x double> %80, %79
  %82 = fadd <8 x double> %81, %74
  %83 = fadd <8 x double> %38, %41
  %84 = fmul <8 x double> %83, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %85 = fadd <8 x double> %84, %76
  %86 = fsub <8 x double> %76, %85
  %87 = fadd <8 x double> %84, %86
  %88 = fadd <8 x double> %87, %82
  br label %283

; <label>:89:                                     ; preds = %26
  %90 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %91 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %90, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %92 = ashr <8 x i32> %91, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %93 = xor <8 x i32> %92, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %94 = and <8 x i32> %91, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %95 = and <8 x i32> %94, %93
  %96 = add nsw <8 x i32> %95, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %97 = bitcast <8 x i32> %96 to <4 x i64>
  %98 = shufflevector <4 x i64> %97, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %99 = bitcast <8 x i64> %98 to <16 x i32>
  %100 = icmp sgt <16 x i32> %99, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %101 = select <16 x i1> %100, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %102 = shufflevector <16 x i32> %101, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %103 = shufflevector <16 x i32> %102, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %104 = shl <16 x i32> %103, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %105 = bitcast <8 x double> %0 to <16 x i32>
  %106 = add <16 x i32> %104, %105
  %107 = bitcast <16 x i32> %106 to <8 x double>
  %108 = ashr <8 x i32> %96, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %109 = bitcast <8 x i32> %108 to <4 x i64>
  %110 = xor <4 x i64> %109, <i64 -1, i64 -1, i64 -1, i64 -1>
  %111 = and <4 x i64> %110, %97
  %112 = bitcast <4 x i64> %111 to <8 x i32>
  %113 = shl <8 x i32> %112, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %114 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %113, i8 -1, i32 8) #7, !noalias !12
  %115 = bitcast <16 x i32> %106 to <8 x i64>
  %116 = and <8 x i64> %115, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %117 = bitcast <8 x i64> %116 to <8 x double>
  %118 = fsub <8 x double> %107, %117
  %119 = bitcast <8 x double> %114 to <8 x i64>
  %120 = and <8 x i64> %119, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %121 = bitcast <8 x i64> %120 to <8 x double>
  %122 = fsub <8 x double> %114, %121
  %123 = fmul <8 x double> %114, %107
  %124 = fmul <8 x double> %121, %117
  %125 = bitcast <8 x double> %123 to <8 x i64>
  %126 = xor <8 x i64> %125, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %127 = bitcast <8 x i64> %126 to <8 x double>
  %128 = fmul <8 x double> %118, %121
  %129 = fmul <8 x double> %122, %117
  %130 = fmul <8 x double> %122, %118
  %131 = fadd <8 x double> %124, %127
  %132 = fadd <8 x double> %128, %131
  %133 = fadd <8 x double> %129, %132
  %134 = fadd <8 x double> %130, %133
  %135 = fmul <8 x double> %123, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %136 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %135, i32 8, <8 x double> %135, i8 -1, i32 4) #7
  %137 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %123, i32 8, <8 x double> %123, i8 -1, i32 4) #7
  %138 = fmul <8 x double> %137, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %139 = fsub <8 x double> %136, %138
  %140 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %139, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %141 = fmul <8 x double> %136, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %142 = fsub <8 x double> %123, %141
  %143 = fadd <8 x double> %142, %134
  %144 = fsub <8 x double> %142, %143
  %145 = fadd <8 x double> %134, %144
  %146 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %113, i8 -1, i32 8) #7, !noalias !12
  %147 = bitcast <8 x double> %146 to <8 x i64>
  %148 = and <8 x i64> %147, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <8 x i64> %148 to <8 x double>
  %150 = fsub <8 x double> %146, %149
  %151 = fmul <8 x double> %146, %107
  %152 = fmul <8 x double> %149, %117
  %153 = bitcast <8 x double> %151 to <8 x i64>
  %154 = xor <8 x i64> %153, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %155 = bitcast <8 x i64> %154 to <8 x double>
  %156 = fmul <8 x double> %118, %149
  %157 = fmul <8 x double> %150, %117
  %158 = fmul <8 x double> %150, %118
  %159 = fadd <8 x double> %152, %155
  %160 = fadd <8 x double> %156, %159
  %161 = fadd <8 x double> %157, %160
  %162 = fadd <8 x double> %158, %161
  %163 = fadd <8 x double> %151, %143
  %164 = fsub <8 x double> %163, %143
  %165 = fsub <8 x double> %163, %164
  %166 = fsub <8 x double> %143, %165
  %167 = fsub <8 x double> %151, %164
  %168 = fadd <8 x double> %167, %166
  %169 = fadd <8 x double> %162, %145
  %170 = fadd <8 x double> %169, %168
  %171 = fmul <8 x double> %163, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %172 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %171, i32 8, <8 x double> %171, i8 -1, i32 4) #7
  %173 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %163, i32 8, <8 x double> %163, i8 -1, i32 4) #7
  %174 = fmul <8 x double> %173, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %175 = fsub <8 x double> %172, %174
  %176 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %175, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %177 = fmul <8 x double> %172, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %178 = fsub <8 x double> %163, %177
  %179 = add <8 x i32> %176, %140
  %180 = fadd <8 x double> %178, %170
  %181 = fsub <8 x double> %178, %180
  %182 = fadd <8 x double> %170, %181
  %183 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %113, i8 -1, i32 8) #7, !noalias !12
  %184 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %113, i8 -1, i32 8) #7, !noalias !12
  %185 = bitcast <8 x double> %183 to <8 x i64>
  %186 = and <8 x i64> %185, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %187 = bitcast <8 x i64> %186 to <8 x double>
  %188 = fsub <8 x double> %183, %187
  %189 = fmul <8 x double> %183, %107
  %190 = fmul <8 x double> %187, %117
  %191 = bitcast <8 x double> %189 to <8 x i64>
  %192 = xor <8 x i64> %191, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %193 = bitcast <8 x i64> %192 to <8 x double>
  %194 = fmul <8 x double> %188, %117
  %195 = fmul <8 x double> %118, %187
  %196 = fmul <8 x double> %188, %118
  %197 = fmul <8 x double> %184, %107
  %198 = fadd <8 x double> %190, %193
  %199 = fadd <8 x double> %194, %198
  %200 = fadd <8 x double> %195, %199
  %201 = fadd <8 x double> %196, %200
  %202 = fadd <8 x double> %197, %201
  %203 = fadd <8 x double> %189, %180
  %204 = fsub <8 x double> %203, %180
  %205 = fsub <8 x double> %203, %204
  %206 = fsub <8 x double> %180, %205
  %207 = fsub <8 x double> %189, %204
  %208 = fadd <8 x double> %207, %206
  %209 = fadd <8 x double> %202, %182
  %210 = fadd <8 x double> %209, %208
  %211 = fadd <8 x double> %203, %210
  %212 = fsub <8 x double> %203, %211
  %213 = fadd <8 x double> %210, %212
  %214 = bitcast <8 x double> %211 to <8 x i64>
  %215 = and <8 x i64> %214, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %216 = bitcast <8 x i64> %215 to <8 x double>
  %217 = fsub <8 x double> %211, %216
  %218 = fmul <8 x double> %211, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %219 = fmul <8 x double> %216, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %220 = bitcast <8 x double> %218 to <8 x i64>
  %221 = xor <8 x i64> %220, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %222 = bitcast <8 x i64> %221 to <8 x double>
  %223 = fmul <8 x double> %217, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %224 = fmul <8 x double> %216, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %225 = fmul <8 x double> %217, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %226 = fmul <8 x double> %211, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %227 = fmul <8 x double> %213, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %228 = fadd <8 x double> %219, %222
  %229 = fadd <8 x double> %223, %228
  %230 = fadd <8 x double> %224, %229
  %231 = fadd <8 x double> %225, %230
  %232 = fadd <8 x double> %226, %231
  %233 = fadd <8 x double> %227, %232
  %234 = and <8 x i64> %115, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %235 = bitcast <8 x i64> %234 to <8 x double>
  %236 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %235, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %237 = bitcast i8 %236 to <8 x i1>
  %238 = select <8 x i1> %237, <8 x double> %107, <8 x double> %218
  %239 = select <8 x i1> %237, <8 x double> zeroinitializer, <8 x double> %233
  %240 = bitcast <8 x i32> %179 to <4 x i64>
  %241 = shl <8 x i32> %179, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %242 = and <8 x i32> %241, <i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6, i32 6>
  %243 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %238, <8 x double> zeroinitializer, i32 30, i8 -1, i32 4) #7
  %244 = zext i8 %243 to i16
  %245 = bitcast i16 %244 to <16 x i1>
  %246 = select <16 x i1> %245, <16 x i32> <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %247 = bitcast <16 x i32> %246 to <8 x i64>
  %248 = shufflevector <8 x i64> %247, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %249 = bitcast <4 x i64> %248 to <8 x i32>
  %250 = add <8 x i32> %242, %249
  %251 = ashr <8 x i32> %250, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %252 = and <4 x i64> %240, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %253 = shufflevector <4 x i64> %252, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %254 = bitcast <8 x i64> %253 to <16 x i32>
  %255 = icmp eq <16 x i32> %254, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %256 = bitcast i8 %243 to <8 x i1>
  %257 = select <8 x i1> %256, <8 x i64> zeroinitializer, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %258 = xor <8 x i64> %257, <i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456, i64 -4613618979930100456>
  %259 = bitcast <8 x i64> %258 to <8 x double>
  %260 = xor <8 x i64> %257, <i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169, i64 -4858919839960114169>
  %261 = bitcast <8 x i64> %260 to <8 x double>
  %262 = fadd <8 x double> %238, %259
  %263 = fsub <8 x double> %262, %238
  %264 = fsub <8 x double> %262, %263
  %265 = fsub <8 x double> %238, %264
  %266 = fsub <8 x double> %259, %263
  %267 = fadd <8 x double> %266, %265
  %268 = fadd <8 x double> %239, %261
  %269 = fadd <8 x double> %267, %268
  %270 = bitcast <16 x i1> %255 to <2 x i8>
  %271 = extractelement <2 x i8> %270, i32 0
  %272 = bitcast i8 %271 to <8 x i1>
  %273 = select <8 x i1> %272, <8 x double> %262, <8 x double> %238
  %274 = select <8 x i1> %272, <8 x double> %269, <8 x double> %239
  %275 = fadd <8 x double> %273, %274
  %276 = fsub <8 x double> %273, %275
  %277 = fadd <8 x double> %274, %276
  %278 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %279 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %280 = or i8 %279, %278
  %281 = bitcast i8 %280 to <8 x i1>
  %282 = select <8 x i1> %281, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %275
  br label %283

; <label>:283:                                    ; preds = %29, %89, %7
  %284 = phi <8 x double> [ %282, %89 ], [ %85, %29 ], [ %22, %7 ]
  %285 = phi <8 x double> [ %277, %89 ], [ %88, %29 ], [ %25, %7 ]
  %286 = phi <8 x i32> [ %251, %89 ], [ %40, %29 ], [ %13, %7 ]
  %287 = bitcast <8 x i32> %286 to <4 x i64>
  %288 = bitcast <8 x double> %284 to <8 x i64>
  %289 = and <8 x i64> %288, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %290 = bitcast <8 x i64> %289 to <8 x double>
  %291 = fsub <8 x double> %284, %290
  %292 = fmul <8 x double> %284, %284
  %293 = fmul <8 x double> %290, %290
  %294 = bitcast <8 x double> %292 to <8 x i64>
  %295 = xor <8 x i64> %294, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %296 = bitcast <8 x i64> %295 to <8 x double>
  %297 = fadd <8 x double> %290, %290
  %298 = fmul <8 x double> %297, %291
  %299 = fmul <8 x double> %291, %291
  %300 = fadd <8 x double> %285, %285
  %301 = fmul <8 x double> %284, %300
  %302 = fadd <8 x double> %293, %296
  %303 = fadd <8 x double> %302, %298
  %304 = fadd <8 x double> %299, %303
  %305 = fadd <8 x double> %301, %304
  %306 = fmul <8 x double> %292, %292
  %307 = fmul <8 x double> %306, %306
  %308 = fmul <8 x double> %292, <double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D, double 0x3CE8811A03B2B11D>
  %309 = fadd <8 x double> %308, <double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350, double 0xBD6AE422BC319350>
  %310 = fmul <8 x double> %292, <double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67, double 0x3DE6123C74705F67>
  %311 = fadd <8 x double> %310, <double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959, double 0xBE5AE6454BAA2959>
  %312 = fmul <8 x double> %292, <double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED, double 0x3EC71DE3A525FBED>
  %313 = fadd <8 x double> %312, <double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225, double 0xBF2A01A01A014225>
  %314 = fmul <8 x double> %306, %311
  %315 = fadd <8 x double> %313, %314
  %316 = fmul <8 x double> %307, %309
  %317 = fadd <8 x double> %316, %315
  %318 = fmul <8 x double> %292, %317
  %319 = fadd <8 x double> %318, <double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9, double 0x3F811111111110B9>
  %320 = fmul <8 x double> %292, %319
  %321 = fadd <8 x double> %320, <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>
  %322 = fsub <8 x double> <double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555, double 0xBFC5555555555555>, %321
  %323 = fadd <8 x double> %320, %322
  %324 = bitcast <8 x double> %321 to <8 x i64>
  %325 = and <8 x i64> %324, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %326 = bitcast <8 x i64> %325 to <8 x double>
  %327 = fsub <8 x double> %321, %326
  %328 = and <8 x i64> %294, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %329 = bitcast <8 x i64> %328 to <8 x double>
  %330 = fsub <8 x double> %292, %329
  %331 = fmul <8 x double> %292, %321
  %332 = fmul <8 x double> %329, %326
  %333 = bitcast <8 x double> %331 to <8 x i64>
  %334 = xor <8 x i64> %333, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %335 = bitcast <8 x i64> %334 to <8 x double>
  %336 = fmul <8 x double> %327, %329
  %337 = fmul <8 x double> %330, %326
  %338 = fmul <8 x double> %330, %327
  %339 = fmul <8 x double> %305, %321
  %340 = fmul <8 x double> %292, %323
  %341 = fadd <8 x double> %332, %335
  %342 = fadd <8 x double> %336, %341
  %343 = fadd <8 x double> %337, %342
  %344 = fadd <8 x double> %338, %343
  %345 = fadd <8 x double> %339, %344
  %346 = fadd <8 x double> %340, %345
  %347 = fadd <8 x double> %331, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %348 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %347
  %349 = fadd <8 x double> %331, %348
  %350 = fadd <8 x double> %349, %346
  %351 = bitcast <8 x double> %347 to <8 x i64>
  %352 = and <8 x i64> %351, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %353 = bitcast <8 x i64> %352 to <8 x double>
  %354 = fsub <8 x double> %347, %353
  %355 = fmul <8 x double> %285, %353
  %356 = fmul <8 x double> %350, %290
  %357 = fmul <8 x double> %291, %354
  %358 = fmul <8 x double> %354, %290
  %359 = fmul <8 x double> %291, %353
  %360 = fmul <8 x double> %290, %353
  %361 = fadd <8 x double> %355, %356
  %362 = fadd <8 x double> %357, %361
  %363 = fadd <8 x double> %358, %362
  %364 = fadd <8 x double> %359, %363
  %365 = fadd <8 x double> %360, %364
  %366 = and <4 x i64> %287, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %367 = shufflevector <4 x i64> %366, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %368 = bitcast <8 x i64> %367 to <16 x i32>
  %369 = icmp eq <16 x i32> %368, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %370 = bitcast <16 x i1> %369 to <2 x i8>
  %371 = extractelement <2 x i8> %370, i32 0
  %372 = bitcast i8 %371 to <8 x i1>
  %373 = select <8 x i1> %372, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %374 = bitcast <8 x double> %365 to <8 x i64>
  %375 = xor <8 x i64> %373, %374
  %376 = bitcast <8 x i64> %375 to <8 x double>
  ret <8 x double> %376
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincosd8_u35avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = bitcast <8 x double> %1 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %7 = icmp eq i8 %6, -1
  br i1 %7, label %8, label %16, !prof !2

; <label>:8:                                      ; preds = %2
  %9 = fmul <8 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %9, i32 8, <8 x double> %9, i8 -1, i32 4) #7
  %11 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %10, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %12 = fmul <8 x double> %10, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %13 = fadd <8 x double> %12, %1
  %14 = fmul <8 x double> %10, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %15 = fadd <8 x double> %14, %13
  br label %199

; <label>:16:                                     ; preds = %2
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %18 = icmp eq i8 %17, -1
  br i1 %18, label %19, label %42, !prof !2

; <label>:19:                                     ; preds = %16
  %20 = fmul <8 x double> %1, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %21 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %20, i32 11, <8 x double> %20, i8 -1, i32 4) #7
  %22 = fmul <8 x double> %21, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %23 = fmul <8 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %24 = fsub <8 x double> %23, %22
  %25 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %24, i32 8, <8 x double> %24, i8 -1, i32 4) #7
  %26 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %25, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %27 = fmul <8 x double> %22, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %28 = fadd <8 x double> %27, %1
  %29 = fmul <8 x double> %25, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %30 = fadd <8 x double> %29, %28
  %31 = fmul <8 x double> %22, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %32 = fadd <8 x double> %31, %30
  %33 = fmul <8 x double> %25, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %34 = fadd <8 x double> %33, %32
  %35 = fmul <8 x double> %22, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %36 = fadd <8 x double> %35, %34
  %37 = fmul <8 x double> %25, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %38 = fadd <8 x double> %37, %36
  %39 = fadd <8 x double> %22, %25
  %40 = fmul <8 x double> %39, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %41 = fadd <8 x double> %40, %38
  br label %199

; <label>:42:                                     ; preds = %16
  %43 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %44 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %43, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %45 = ashr <8 x i32> %44, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %46 = xor <8 x i32> %45, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = and <8 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %48 = and <8 x i32> %47, %46
  %49 = add nsw <8 x i32> %48, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %50 = bitcast <8 x i32> %49 to <4 x i64>
  %51 = shufflevector <4 x i64> %50, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <8 x i64> %51 to <16 x i32>
  %53 = icmp sgt <16 x i32> %52, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %54 = select <16 x i1> %53, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %55 = shufflevector <16 x i32> %54, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %56 = shufflevector <16 x i32> %55, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %57 = shl <16 x i32> %56, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %58 = bitcast <8 x double> %1 to <16 x i32>
  %59 = add <16 x i32> %57, %58
  %60 = bitcast <16 x i32> %59 to <8 x double>
  %61 = ashr <8 x i32> %49, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %62 = bitcast <8 x i32> %61 to <4 x i64>
  %63 = xor <4 x i64> %62, <i64 -1, i64 -1, i64 -1, i64 -1>
  %64 = and <4 x i64> %63, %50
  %65 = bitcast <4 x i64> %64 to <8 x i32>
  %66 = shl <8 x i32> %65, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %67 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %66, i8 -1, i32 8) #7, !noalias !15
  %68 = bitcast <16 x i32> %59 to <8 x i64>
  %69 = and <8 x i64> %68, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %70 = bitcast <8 x i64> %69 to <8 x double>
  %71 = fsub <8 x double> %60, %70
  %72 = bitcast <8 x double> %67 to <8 x i64>
  %73 = and <8 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <8 x i64> %73 to <8 x double>
  %75 = fsub <8 x double> %67, %74
  %76 = fmul <8 x double> %67, %60
  %77 = fmul <8 x double> %74, %70
  %78 = bitcast <8 x double> %76 to <8 x i64>
  %79 = xor <8 x i64> %78, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = bitcast <8 x i64> %79 to <8 x double>
  %81 = fmul <8 x double> %71, %74
  %82 = fmul <8 x double> %75, %70
  %83 = fmul <8 x double> %75, %71
  %84 = fadd <8 x double> %77, %80
  %85 = fadd <8 x double> %81, %84
  %86 = fadd <8 x double> %82, %85
  %87 = fadd <8 x double> %83, %86
  %88 = fmul <8 x double> %76, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %89 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %88, i32 8, <8 x double> %88, i8 -1, i32 4) #7
  %90 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %76, i32 8, <8 x double> %76, i8 -1, i32 4) #7
  %91 = fmul <8 x double> %90, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %92 = fsub <8 x double> %89, %91
  %93 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %92, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %94 = fmul <8 x double> %89, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %95 = fsub <8 x double> %76, %94
  %96 = fadd <8 x double> %95, %87
  %97 = fsub <8 x double> %95, %96
  %98 = fadd <8 x double> %87, %97
  %99 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %66, i8 -1, i32 8) #7, !noalias !15
  %100 = bitcast <8 x double> %99 to <8 x i64>
  %101 = and <8 x i64> %100, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %102 = bitcast <8 x i64> %101 to <8 x double>
  %103 = fsub <8 x double> %99, %102
  %104 = fmul <8 x double> %99, %60
  %105 = fmul <8 x double> %102, %70
  %106 = bitcast <8 x double> %104 to <8 x i64>
  %107 = xor <8 x i64> %106, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %108 = bitcast <8 x i64> %107 to <8 x double>
  %109 = fmul <8 x double> %71, %102
  %110 = fmul <8 x double> %103, %70
  %111 = fmul <8 x double> %103, %71
  %112 = fadd <8 x double> %105, %108
  %113 = fadd <8 x double> %109, %112
  %114 = fadd <8 x double> %110, %113
  %115 = fadd <8 x double> %111, %114
  %116 = fadd <8 x double> %104, %96
  %117 = fsub <8 x double> %116, %96
  %118 = fsub <8 x double> %116, %117
  %119 = fsub <8 x double> %96, %118
  %120 = fsub <8 x double> %104, %117
  %121 = fadd <8 x double> %120, %119
  %122 = fadd <8 x double> %115, %98
  %123 = fadd <8 x double> %122, %121
  %124 = fmul <8 x double> %116, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %125 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %124, i32 8, <8 x double> %124, i8 -1, i32 4) #7
  %126 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %116, i32 8, <8 x double> %116, i8 -1, i32 4) #7
  %127 = fmul <8 x double> %126, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %128 = fsub <8 x double> %125, %127
  %129 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %128, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %130 = fmul <8 x double> %125, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %131 = fsub <8 x double> %116, %130
  %132 = add <8 x i32> %129, %93
  %133 = fadd <8 x double> %131, %123
  %134 = fsub <8 x double> %131, %133
  %135 = fadd <8 x double> %123, %134
  %136 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %66, i8 -1, i32 8) #7, !noalias !15
  %137 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %66, i8 -1, i32 8) #7, !noalias !15
  %138 = bitcast <8 x double> %136 to <8 x i64>
  %139 = and <8 x i64> %138, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %140 = bitcast <8 x i64> %139 to <8 x double>
  %141 = fsub <8 x double> %136, %140
  %142 = fmul <8 x double> %136, %60
  %143 = fmul <8 x double> %140, %70
  %144 = bitcast <8 x double> %142 to <8 x i64>
  %145 = xor <8 x i64> %144, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fmul <8 x double> %141, %70
  %148 = fmul <8 x double> %71, %140
  %149 = fmul <8 x double> %141, %71
  %150 = fmul <8 x double> %137, %60
  %151 = fadd <8 x double> %143, %146
  %152 = fadd <8 x double> %147, %151
  %153 = fadd <8 x double> %148, %152
  %154 = fadd <8 x double> %149, %153
  %155 = fadd <8 x double> %150, %154
  %156 = fadd <8 x double> %142, %133
  %157 = fsub <8 x double> %156, %133
  %158 = fsub <8 x double> %156, %157
  %159 = fsub <8 x double> %133, %158
  %160 = fsub <8 x double> %142, %157
  %161 = fadd <8 x double> %160, %159
  %162 = fadd <8 x double> %155, %135
  %163 = fadd <8 x double> %162, %161
  %164 = fadd <8 x double> %156, %163
  %165 = fsub <8 x double> %156, %164
  %166 = fadd <8 x double> %163, %165
  %167 = bitcast <8 x double> %164 to <8 x i64>
  %168 = and <8 x i64> %167, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %169 = bitcast <8 x i64> %168 to <8 x double>
  %170 = fsub <8 x double> %164, %169
  %171 = fmul <8 x double> %164, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %172 = fmul <8 x double> %169, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %173 = bitcast <8 x double> %171 to <8 x i64>
  %174 = xor <8 x i64> %173, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %175 = bitcast <8 x i64> %174 to <8 x double>
  %176 = fmul <8 x double> %170, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %177 = fmul <8 x double> %169, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %178 = fmul <8 x double> %170, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %179 = fmul <8 x double> %164, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %180 = fmul <8 x double> %166, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %181 = fadd <8 x double> %172, %175
  %182 = fadd <8 x double> %176, %181
  %183 = fadd <8 x double> %177, %182
  %184 = fadd <8 x double> %178, %183
  %185 = fadd <8 x double> %179, %184
  %186 = fadd <8 x double> %180, %185
  %187 = and <8 x i64> %68, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %188 = bitcast <8 x i64> %187 to <8 x double>
  %189 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %188, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %190 = bitcast i8 %189 to <8 x i1>
  %191 = select <8 x i1> %190, <8 x double> %60, <8 x double> %171
  %192 = select <8 x i1> %190, <8 x double> zeroinitializer, <8 x double> %186
  %193 = fadd <8 x double> %191, %192
  %194 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %195 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %196 = or i8 %195, %194
  %197 = bitcast i8 %196 to <8 x i1>
  %198 = select <8 x i1> %197, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %193
  br label %199

; <label>:199:                                    ; preds = %19, %42, %8
  %200 = phi <8 x i32> [ %11, %8 ], [ %26, %19 ], [ %132, %42 ]
  %201 = phi <8 x double> [ %15, %8 ], [ %41, %19 ], [ %198, %42 ]
  %202 = bitcast <8 x i32> %200 to <4 x i64>
  %203 = fmul <8 x double> %201, %201
  %204 = fmul <8 x double> %203, <double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B>
  %205 = fadd <8 x double> %204, <double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8>
  %206 = fmul <8 x double> %203, %205
  %207 = fadd <8 x double> %206, <double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C>
  %208 = fmul <8 x double> %203, %207
  %209 = fadd <8 x double> %208, <double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A>
  %210 = fmul <8 x double> %203, %209
  %211 = fadd <8 x double> %210, <double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135>
  %212 = fmul <8 x double> %203, %211
  %213 = fadd <8 x double> %212, <double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542>
  %214 = fmul <8 x double> %203, %213
  %215 = fmul <8 x double> %201, %214
  %216 = fadd <8 x double> %201, %215
  %217 = icmp eq <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %218 = select <8 x i1> %217, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %216
  %219 = fmul <8 x double> %203, <double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE>
  %220 = fadd <8 x double> %219, <double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05>
  %221 = fmul <8 x double> %203, %220
  %222 = fadd <8 x double> %221, <double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C>
  %223 = fmul <8 x double> %203, %222
  %224 = fadd <8 x double> %223, <double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025>
  %225 = fmul <8 x double> %203, %224
  %226 = fadd <8 x double> %225, <double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96>
  %227 = fmul <8 x double> %203, %226
  %228 = fadd <8 x double> %227, <double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545>
  %229 = fmul <8 x double> %203, %228
  %230 = fadd <8 x double> %229, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %231 = fmul <8 x double> %203, %230
  %232 = fadd <8 x double> %231, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %233 = and <4 x i64> %202, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %234 = shufflevector <4 x i64> %233, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %235 = bitcast <8 x i64> %234 to <16 x i32>
  %236 = icmp eq <16 x i32> %235, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %237 = bitcast <16 x i1> %236 to <2 x i8>
  %238 = extractelement <2 x i8> %237, i32 0
  %239 = bitcast i8 %238 to <8 x i1>
  %240 = select <8 x i1> %239, <8 x double> %218, <8 x double> %232
  %241 = select <8 x i1> %239, <8 x double> %232, <8 x double> %218
  %242 = and <4 x i64> %202, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %243 = shufflevector <4 x i64> %242, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %244 = bitcast <8 x i64> %243 to <16 x i32>
  %245 = icmp eq <16 x i32> %244, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %246 = bitcast <16 x i1> %245 to <2 x i8>
  %247 = extractelement <2 x i8> %246, i32 0
  %248 = bitcast i8 %247 to <8 x i1>
  %249 = select <8 x i1> %248, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %250 = bitcast <8 x double> %240 to <8 x i64>
  %251 = xor <8 x i64> %249, %250
  %252 = add <8 x i32> %200, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %253 = bitcast <8 x i32> %252 to <4 x i64>
  %254 = and <4 x i64> %253, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %255 = shufflevector <4 x i64> %254, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %256 = bitcast <8 x i64> %255 to <16 x i32>
  %257 = icmp eq <16 x i32> %256, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %258 = bitcast <16 x i1> %257 to <2 x i8>
  %259 = extractelement <2 x i8> %258, i32 0
  %260 = bitcast i8 %259 to <8 x i1>
  %261 = select <8 x i1> %260, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %262 = bitcast <8 x double> %241 to <8 x i64>
  %263 = xor <8 x i64> %261, %262
  %264 = bitcast %struct.vdouble2* %0 to <8 x i64>*
  store <8 x i64> %251, <8 x i64>* %264, align 64
  %265 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %266 = bitcast <8 x double>* %265 to <8 x i64>*
  store <8 x i64> %263, <8 x i64>* %266, align 64
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincosd8_u10avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = bitcast <8 x double> %1 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %7 = icmp eq i8 %6, -1
  br i1 %7, label %8, label %18, !prof !2

; <label>:8:                                      ; preds = %2
  %9 = fmul <8 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %9, i32 8, <8 x double> %9, i8 -1, i32 4) #7
  %11 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %10, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %12 = fmul <8 x double> %10, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %13 = fadd <8 x double> %12, %1
  %14 = fmul <8 x double> %10, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %15 = fadd <8 x double> %14, %13
  %16 = fsub <8 x double> %13, %15
  %17 = fadd <8 x double> %14, %16
  br label %230

; <label>:18:                                     ; preds = %2
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %20 = icmp eq i8 %19, -1
  br i1 %20, label %21, label %73, !prof !2

; <label>:21:                                     ; preds = %18
  %22 = fmul <8 x double> %1, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %23 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %22, i32 11, <8 x double> %22, i8 -1, i32 4) #7
  %24 = fmul <8 x double> %23, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %25 = fmul <8 x double> %1, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %26 = fsub <8 x double> %25, %24
  %27 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %26, i32 8, <8 x double> %26, i8 -1, i32 4) #7
  %28 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %27, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %29 = fmul <8 x double> %24, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %30 = fadd <8 x double> %29, %1
  %31 = fmul <8 x double> %27, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %32 = fadd <8 x double> %31, %30
  %33 = fsub <8 x double> %30, %32
  %34 = fadd <8 x double> %31, %33
  %35 = fmul <8 x double> %24, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %36 = fadd <8 x double> %35, %32
  %37 = fsub <8 x double> %36, %32
  %38 = fsub <8 x double> %36, %37
  %39 = fsub <8 x double> %32, %38
  %40 = fsub <8 x double> %35, %37
  %41 = fadd <8 x double> %40, %39
  %42 = fadd <8 x double> %34, %41
  %43 = fmul <8 x double> %27, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %44 = fadd <8 x double> %43, %36
  %45 = fsub <8 x double> %44, %36
  %46 = fsub <8 x double> %44, %45
  %47 = fsub <8 x double> %36, %46
  %48 = fsub <8 x double> %43, %45
  %49 = fadd <8 x double> %48, %47
  %50 = fadd <8 x double> %49, %42
  %51 = fmul <8 x double> %24, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %52 = fadd <8 x double> %51, %44
  %53 = fsub <8 x double> %52, %44
  %54 = fsub <8 x double> %52, %53
  %55 = fsub <8 x double> %44, %54
  %56 = fsub <8 x double> %51, %53
  %57 = fadd <8 x double> %56, %55
  %58 = fadd <8 x double> %57, %50
  %59 = fmul <8 x double> %27, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %60 = fadd <8 x double> %59, %52
  %61 = fsub <8 x double> %60, %52
  %62 = fsub <8 x double> %60, %61
  %63 = fsub <8 x double> %52, %62
  %64 = fsub <8 x double> %59, %61
  %65 = fadd <8 x double> %64, %63
  %66 = fadd <8 x double> %65, %58
  %67 = fadd <8 x double> %24, %27
  %68 = fmul <8 x double> %67, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %69 = fadd <8 x double> %68, %60
  %70 = fsub <8 x double> %60, %69
  %71 = fadd <8 x double> %68, %70
  %72 = fadd <8 x double> %71, %66
  br label %230

; <label>:73:                                     ; preds = %18
  %74 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %75 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %74, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %76 = ashr <8 x i32> %75, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %77 = xor <8 x i32> %76, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %78 = and <8 x i32> %75, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %79 = and <8 x i32> %78, %77
  %80 = add nsw <8 x i32> %79, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %81 = bitcast <8 x i32> %80 to <4 x i64>
  %82 = shufflevector <4 x i64> %81, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %83 = bitcast <8 x i64> %82 to <16 x i32>
  %84 = icmp sgt <16 x i32> %83, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %85 = select <16 x i1> %84, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %86 = shufflevector <16 x i32> %85, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %87 = shufflevector <16 x i32> %86, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %88 = shl <16 x i32> %87, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %89 = bitcast <8 x double> %1 to <16 x i32>
  %90 = add <16 x i32> %88, %89
  %91 = bitcast <16 x i32> %90 to <8 x double>
  %92 = ashr <8 x i32> %80, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %93 = bitcast <8 x i32> %92 to <4 x i64>
  %94 = xor <4 x i64> %93, <i64 -1, i64 -1, i64 -1, i64 -1>
  %95 = and <4 x i64> %94, %81
  %96 = bitcast <4 x i64> %95 to <8 x i32>
  %97 = shl <8 x i32> %96, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %98 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %97, i8 -1, i32 8) #7, !noalias !18
  %99 = bitcast <16 x i32> %90 to <8 x i64>
  %100 = and <8 x i64> %99, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %101 = bitcast <8 x i64> %100 to <8 x double>
  %102 = fsub <8 x double> %91, %101
  %103 = bitcast <8 x double> %98 to <8 x i64>
  %104 = and <8 x i64> %103, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = fsub <8 x double> %98, %105
  %107 = fmul <8 x double> %98, %91
  %108 = fmul <8 x double> %105, %101
  %109 = bitcast <8 x double> %107 to <8 x i64>
  %110 = xor <8 x i64> %109, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %111 = bitcast <8 x i64> %110 to <8 x double>
  %112 = fmul <8 x double> %102, %105
  %113 = fmul <8 x double> %106, %101
  %114 = fmul <8 x double> %106, %102
  %115 = fadd <8 x double> %108, %111
  %116 = fadd <8 x double> %112, %115
  %117 = fadd <8 x double> %113, %116
  %118 = fadd <8 x double> %114, %117
  %119 = fmul <8 x double> %107, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %120 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %119, i32 8, <8 x double> %119, i8 -1, i32 4) #7
  %121 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %107, i32 8, <8 x double> %107, i8 -1, i32 4) #7
  %122 = fmul <8 x double> %121, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %123 = fsub <8 x double> %120, %122
  %124 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %123, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %125 = fmul <8 x double> %120, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %126 = fsub <8 x double> %107, %125
  %127 = fadd <8 x double> %126, %118
  %128 = fsub <8 x double> %126, %127
  %129 = fadd <8 x double> %118, %128
  %130 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %97, i8 -1, i32 8) #7, !noalias !18
  %131 = bitcast <8 x double> %130 to <8 x i64>
  %132 = and <8 x i64> %131, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %133 = bitcast <8 x i64> %132 to <8 x double>
  %134 = fsub <8 x double> %130, %133
  %135 = fmul <8 x double> %130, %91
  %136 = fmul <8 x double> %133, %101
  %137 = bitcast <8 x double> %135 to <8 x i64>
  %138 = xor <8 x i64> %137, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %139 = bitcast <8 x i64> %138 to <8 x double>
  %140 = fmul <8 x double> %102, %133
  %141 = fmul <8 x double> %134, %101
  %142 = fmul <8 x double> %134, %102
  %143 = fadd <8 x double> %136, %139
  %144 = fadd <8 x double> %140, %143
  %145 = fadd <8 x double> %141, %144
  %146 = fadd <8 x double> %142, %145
  %147 = fadd <8 x double> %135, %127
  %148 = fsub <8 x double> %147, %127
  %149 = fsub <8 x double> %147, %148
  %150 = fsub <8 x double> %127, %149
  %151 = fsub <8 x double> %135, %148
  %152 = fadd <8 x double> %151, %150
  %153 = fadd <8 x double> %146, %129
  %154 = fadd <8 x double> %153, %152
  %155 = fmul <8 x double> %147, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %156 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %155, i32 8, <8 x double> %155, i8 -1, i32 4) #7
  %157 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %147, i32 8, <8 x double> %147, i8 -1, i32 4) #7
  %158 = fmul <8 x double> %157, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %159 = fsub <8 x double> %156, %158
  %160 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %159, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %161 = fmul <8 x double> %156, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %162 = fsub <8 x double> %147, %161
  %163 = add <8 x i32> %160, %124
  %164 = fadd <8 x double> %162, %154
  %165 = fsub <8 x double> %162, %164
  %166 = fadd <8 x double> %154, %165
  %167 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %97, i8 -1, i32 8) #7, !noalias !18
  %168 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %97, i8 -1, i32 8) #7, !noalias !18
  %169 = bitcast <8 x double> %167 to <8 x i64>
  %170 = and <8 x i64> %169, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %171 = bitcast <8 x i64> %170 to <8 x double>
  %172 = fsub <8 x double> %167, %171
  %173 = fmul <8 x double> %167, %91
  %174 = fmul <8 x double> %171, %101
  %175 = bitcast <8 x double> %173 to <8 x i64>
  %176 = xor <8 x i64> %175, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %177 = bitcast <8 x i64> %176 to <8 x double>
  %178 = fmul <8 x double> %172, %101
  %179 = fmul <8 x double> %102, %171
  %180 = fmul <8 x double> %172, %102
  %181 = fmul <8 x double> %168, %91
  %182 = fadd <8 x double> %174, %177
  %183 = fadd <8 x double> %178, %182
  %184 = fadd <8 x double> %179, %183
  %185 = fadd <8 x double> %180, %184
  %186 = fadd <8 x double> %181, %185
  %187 = fadd <8 x double> %173, %164
  %188 = fsub <8 x double> %187, %164
  %189 = fsub <8 x double> %187, %188
  %190 = fsub <8 x double> %164, %189
  %191 = fsub <8 x double> %173, %188
  %192 = fadd <8 x double> %191, %190
  %193 = fadd <8 x double> %186, %166
  %194 = fadd <8 x double> %193, %192
  %195 = fadd <8 x double> %187, %194
  %196 = fsub <8 x double> %187, %195
  %197 = fadd <8 x double> %194, %196
  %198 = bitcast <8 x double> %195 to <8 x i64>
  %199 = and <8 x i64> %198, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %200 = bitcast <8 x i64> %199 to <8 x double>
  %201 = fsub <8 x double> %195, %200
  %202 = fmul <8 x double> %195, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %203 = fmul <8 x double> %200, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %204 = bitcast <8 x double> %202 to <8 x i64>
  %205 = xor <8 x i64> %204, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %206 = bitcast <8 x i64> %205 to <8 x double>
  %207 = fmul <8 x double> %201, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %208 = fmul <8 x double> %200, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %209 = fmul <8 x double> %201, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %210 = fmul <8 x double> %195, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %211 = fmul <8 x double> %197, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %212 = fadd <8 x double> %203, %206
  %213 = fadd <8 x double> %207, %212
  %214 = fadd <8 x double> %208, %213
  %215 = fadd <8 x double> %209, %214
  %216 = fadd <8 x double> %210, %215
  %217 = fadd <8 x double> %211, %216
  %218 = and <8 x i64> %99, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %219 = bitcast <8 x i64> %218 to <8 x double>
  %220 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %219, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %221 = bitcast i8 %220 to <8 x i1>
  %222 = select <8 x i1> %221, <8 x double> %91, <8 x double> %202
  %223 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %224 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %225 = or i8 %224, %223
  %226 = bitcast i8 %225 to <8 x i1>
  %227 = select <8 x i1> %226, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %222
  %228 = select <8 x i1> %221, <8 x double> zeroinitializer, <8 x double> %217
  %229 = select <8 x i1> %226, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %228
  br label %230

; <label>:230:                                    ; preds = %21, %73, %8
  %231 = phi <8 x double> [ %227, %73 ], [ %69, %21 ], [ %15, %8 ]
  %232 = phi <8 x double> [ %229, %73 ], [ %72, %21 ], [ %17, %8 ]
  %233 = phi <8 x i32> [ %163, %73 ], [ %28, %21 ], [ %11, %8 ]
  %234 = bitcast <8 x i32> %233 to <4 x i64>
  %235 = bitcast <8 x double> %231 to <8 x i64>
  %236 = and <8 x i64> %235, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %237 = bitcast <8 x i64> %236 to <8 x double>
  %238 = fsub <8 x double> %231, %237
  %239 = fmul <8 x double> %232, %237
  %240 = fmul <8 x double> %238, %238
  %241 = fmul <8 x double> %238, %237
  %242 = fadd <8 x double> %241, %241
  %243 = fmul <8 x double> %237, %237
  %244 = fadd <8 x double> %239, %239
  %245 = fadd <8 x double> %244, %240
  %246 = fadd <8 x double> %245, %242
  %247 = fadd <8 x double> %243, %246
  %248 = fmul <8 x double> %247, <double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B, double 0x3DE5D82500BECB6B>
  %249 = fadd <8 x double> %248, <double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8, double 0xBE5AE5E1E6F6F6D8>
  %250 = fmul <8 x double> %247, %249
  %251 = fadd <8 x double> %250, <double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C, double 0x3EC71DE3503EAE9C>
  %252 = fmul <8 x double> %247, %251
  %253 = fadd <8 x double> %252, <double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A, double 0xBF2A01A019B64F6A>
  %254 = fmul <8 x double> %247, %253
  %255 = fadd <8 x double> %254, <double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135, double 0x3F8111111110F135>
  %256 = fmul <8 x double> %247, %255
  %257 = fadd <8 x double> %256, <double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542, double 0xBFC5555555555542>
  %258 = fmul <8 x double> %231, %247
  %259 = fmul <8 x double> %258, %257
  %260 = fadd <8 x double> %231, %259
  %261 = fsub <8 x double> %231, %260
  %262 = fadd <8 x double> %259, %261
  %263 = fadd <8 x double> %232, %262
  %264 = fadd <8 x double> %260, %263
  %265 = icmp eq <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %266 = select <8 x i1> %265, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %264
  %267 = fmul <8 x double> %247, <double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE, double 0xBDA8FBF9C1BDB8CE>
  %268 = fadd <8 x double> %267, <double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05, double 0x3E21EEA016409F05>
  %269 = fmul <8 x double> %247, %268
  %270 = fadd <8 x double> %269, <double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C, double 0xBE927E4F8130BE9C>
  %271 = fmul <8 x double> %247, %270
  %272 = fadd <8 x double> %271, <double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025, double 0x3EFA01A019C8F025>
  %273 = fmul <8 x double> %247, %272
  %274 = fadd <8 x double> %273, <double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96, double 0xBF56C16C16C14C96>
  %275 = fmul <8 x double> %247, %274
  %276 = fadd <8 x double> %275, <double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545, double 0x3FA5555555555545>
  %277 = fmul <8 x double> %247, %276
  %278 = fadd <8 x double> %277, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %279 = bitcast <8 x double> %247 to <8 x i64>
  %280 = and <8 x i64> %279, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %281 = bitcast <8 x i64> %280 to <8 x double>
  %282 = fsub <8 x double> %247, %281
  %283 = bitcast <8 x double> %278 to <8 x i64>
  %284 = and <8 x i64> %283, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %285 = bitcast <8 x i64> %284 to <8 x double>
  %286 = fsub <8 x double> %278, %285
  %287 = fmul <8 x double> %247, %278
  %288 = fmul <8 x double> %281, %285
  %289 = bitcast <8 x double> %287 to <8 x i64>
  %290 = xor <8 x i64> %289, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %291 = bitcast <8 x i64> %290 to <8 x double>
  %292 = fmul <8 x double> %282, %285
  %293 = fmul <8 x double> %286, %281
  %294 = fmul <8 x double> %282, %286
  %295 = fadd <8 x double> %288, %291
  %296 = fadd <8 x double> %292, %295
  %297 = fadd <8 x double> %293, %296
  %298 = fadd <8 x double> %294, %297
  %299 = fadd <8 x double> %287, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %300 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %299
  %301 = fadd <8 x double> %287, %300
  %302 = fadd <8 x double> %301, %298
  %303 = fadd <8 x double> %299, %302
  %304 = and <4 x i64> %234, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %305 = shufflevector <4 x i64> %304, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %306 = bitcast <8 x i64> %305 to <16 x i32>
  %307 = icmp eq <16 x i32> %306, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %308 = bitcast <16 x i1> %307 to <2 x i8>
  %309 = extractelement <2 x i8> %308, i32 0
  %310 = bitcast i8 %309 to <8 x i1>
  %311 = select <8 x i1> %310, <8 x double> %266, <8 x double> %303
  %312 = select <8 x i1> %310, <8 x double> %303, <8 x double> %266
  %313 = and <4 x i64> %234, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %314 = shufflevector <4 x i64> %313, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %315 = bitcast <8 x i64> %314 to <16 x i32>
  %316 = icmp eq <16 x i32> %315, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %317 = bitcast <16 x i1> %316 to <2 x i8>
  %318 = extractelement <2 x i8> %317, i32 0
  %319 = bitcast i8 %318 to <8 x i1>
  %320 = select <8 x i1> %319, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %321 = bitcast <8 x double> %311 to <8 x i64>
  %322 = xor <8 x i64> %320, %321
  %323 = add <8 x i32> %233, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %324 = bitcast <8 x i32> %323 to <4 x i64>
  %325 = and <4 x i64> %324, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %326 = shufflevector <4 x i64> %325, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %327 = bitcast <8 x i64> %326 to <16 x i32>
  %328 = icmp eq <16 x i32> %327, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %329 = bitcast <16 x i1> %328 to <2 x i8>
  %330 = extractelement <2 x i8> %329, i32 0
  %331 = bitcast i8 %330 to <8 x i1>
  %332 = select <8 x i1> %331, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %333 = bitcast <8 x double> %312 to <8 x i64>
  %334 = xor <8 x i64> %332, %333
  %335 = bitcast %struct.vdouble2* %0 to <8 x i64>*
  store <8 x i64> %322, <8 x i64>* %335, align 64
  %336 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %337 = bitcast <8 x double>* %336 to <8 x i64>*
  store <8 x i64> %334, <8 x i64>* %337, align 64
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincospid8_u05avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = fmul <8 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = lshr <8 x i32> %4, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %6 = xor <8 x i32> %5, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %7 = add <8 x i32> %6, %4
  %8 = bitcast <8 x i32> %7 to <4 x i64>
  %9 = and <8 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %10 = sitofp <8 x i32> %9 to <8 x double>
  %11 = fsub <8 x double> %3, %10
  %12 = fmul <8 x double> %11, %11
  %13 = bitcast <8 x double> %11 to <8 x i64>
  %14 = and <8 x i64> %13, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %15 = bitcast <8 x i64> %14 to <8 x double>
  %16 = fsub <8 x double> %11, %15
  %17 = fmul <8 x double> %15, %15
  %18 = bitcast <8 x double> %12 to <8 x i64>
  %19 = xor <8 x i64> %18, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = bitcast <8 x i64> %19 to <8 x double>
  %21 = fmul <8 x double> %16, %15
  %22 = fmul <8 x double> %16, %16
  %23 = fadd <8 x double> %17, %20
  %24 = fadd <8 x double> %21, %23
  %25 = fadd <8 x double> %21, %24
  %26 = fadd <8 x double> %22, %25
  %27 = fmul <8 x double> %12, <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>
  %28 = fadd <8 x double> %27, <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>
  %29 = fmul <8 x double> %12, %28
  %30 = fadd <8 x double> %29, <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>
  %31 = fmul <8 x double> %12, %30
  %32 = fadd <8 x double> %31, <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>
  %33 = fmul <8 x double> %12, %32
  %34 = fadd <8 x double> %33, <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>
  %35 = fmul <8 x double> %12, %34
  %36 = fadd <8 x double> %35, <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>
  %37 = fmul <8 x double> %12, %36
  %38 = fadd <8 x double> %37, <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>
  %39 = fsub <8 x double> %38, %37
  %40 = fsub <8 x double> %38, %39
  %41 = fsub <8 x double> %37, %40
  %42 = fsub <8 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>, %39
  %43 = fadd <8 x double> %42, %41
  %44 = fadd <8 x double> %43, <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>
  %45 = and <8 x i64> %18, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %46 = bitcast <8 x i64> %45 to <8 x double>
  %47 = fsub <8 x double> %12, %46
  %48 = bitcast <8 x double> %38 to <8 x i64>
  %49 = and <8 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fsub <8 x double> %38, %50
  %52 = fmul <8 x double> %12, %38
  %53 = fmul <8 x double> %46, %50
  %54 = bitcast <8 x double> %52 to <8 x i64>
  %55 = xor <8 x i64> %54, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %56 = bitcast <8 x i64> %55 to <8 x double>
  %57 = fmul <8 x double> %47, %50
  %58 = fmul <8 x double> %51, %46
  %59 = fmul <8 x double> %47, %51
  %60 = fmul <8 x double> %12, %44
  %61 = fmul <8 x double> %26, %38
  %62 = fadd <8 x double> %53, %56
  %63 = fadd <8 x double> %57, %62
  %64 = fadd <8 x double> %58, %63
  %65 = fadd <8 x double> %59, %64
  %66 = fadd <8 x double> %60, %65
  %67 = fadd <8 x double> %61, %66
  %68 = fadd <8 x double> %52, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %69 = fsub <8 x double> %68, %52
  %70 = fsub <8 x double> %68, %69
  %71 = fsub <8 x double> %52, %70
  %72 = fsub <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %69
  %73 = fadd <8 x double> %72, %71
  %74 = fadd <8 x double> %67, <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>
  %75 = fadd <8 x double> %73, %74
  %76 = bitcast <8 x double> %68 to <8 x i64>
  %77 = and <8 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fsub <8 x double> %68, %78
  %80 = fmul <8 x double> %11, %68
  %81 = fmul <8 x double> %15, %78
  %82 = bitcast <8 x double> %80 to <8 x i64>
  %83 = xor <8 x i64> %82, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %84 = bitcast <8 x i64> %83 to <8 x double>
  %85 = fmul <8 x double> %79, %15
  %86 = fmul <8 x double> %16, %78
  %87 = fmul <8 x double> %16, %79
  %88 = fmul <8 x double> %11, %75
  %89 = fadd <8 x double> %81, %84
  %90 = fadd <8 x double> %85, %89
  %91 = fadd <8 x double> %86, %90
  %92 = fadd <8 x double> %87, %91
  %93 = fadd <8 x double> %92, %88
  %94 = fadd <8 x double> %80, %93
  %95 = bitcast <8 x double> %1 to <8 x i64>
  %96 = icmp eq <8 x i64> %95, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %97 = select <8 x i1> %96, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %94
  %98 = fmul <8 x double> %12, <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>
  %99 = fadd <8 x double> %98, <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>
  %100 = fmul <8 x double> %12, %99
  %101 = fadd <8 x double> %100, <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>
  %102 = fmul <8 x double> %12, %101
  %103 = fadd <8 x double> %102, <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>
  %104 = fmul <8 x double> %12, %103
  %105 = fadd <8 x double> %104, <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>
  %106 = fmul <8 x double> %12, %105
  %107 = fadd <8 x double> %106, <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>
  %108 = fmul <8 x double> %12, %107
  %109 = fadd <8 x double> %108, <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>
  %110 = fsub <8 x double> %109, %108
  %111 = fsub <8 x double> %109, %110
  %112 = fsub <8 x double> %108, %111
  %113 = fsub <8 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, %110
  %114 = fadd <8 x double> %113, %112
  %115 = fadd <8 x double> %114, <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>
  %116 = bitcast <8 x double> %109 to <8 x i64>
  %117 = and <8 x i64> %116, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %118 = bitcast <8 x i64> %117 to <8 x double>
  %119 = fsub <8 x double> %109, %118
  %120 = fmul <8 x double> %12, %109
  %121 = fmul <8 x double> %46, %118
  %122 = bitcast <8 x double> %120 to <8 x i64>
  %123 = xor <8 x i64> %122, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %124 = bitcast <8 x i64> %123 to <8 x double>
  %125 = fmul <8 x double> %47, %118
  %126 = fmul <8 x double> %119, %46
  %127 = fmul <8 x double> %47, %119
  %128 = fmul <8 x double> %12, %115
  %129 = fmul <8 x double> %26, %109
  %130 = fadd <8 x double> %121, %124
  %131 = fadd <8 x double> %125, %130
  %132 = fadd <8 x double> %126, %131
  %133 = fadd <8 x double> %127, %132
  %134 = fadd <8 x double> %128, %133
  %135 = fadd <8 x double> %129, %134
  %136 = fadd <8 x double> %120, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %137 = fsub <8 x double> %136, %120
  %138 = fsub <8 x double> %136, %137
  %139 = fsub <8 x double> %120, %138
  %140 = fsub <8 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, %137
  %141 = fadd <8 x double> %140, %139
  %142 = fadd <8 x double> %135, <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>
  %143 = fadd <8 x double> %141, %142
  %144 = bitcast <8 x double> %136 to <8 x i64>
  %145 = and <8 x i64> %144, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fsub <8 x double> %136, %146
  %148 = fmul <8 x double> %12, %136
  %149 = fmul <8 x double> %46, %146
  %150 = bitcast <8 x double> %148 to <8 x i64>
  %151 = xor <8 x i64> %150, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %152 = bitcast <8 x i64> %151 to <8 x double>
  %153 = fmul <8 x double> %147, %46
  %154 = fmul <8 x double> %47, %146
  %155 = fmul <8 x double> %47, %147
  %156 = fmul <8 x double> %26, %136
  %157 = fmul <8 x double> %12, %143
  %158 = fadd <8 x double> %149, %152
  %159 = fadd <8 x double> %153, %158
  %160 = fadd <8 x double> %154, %159
  %161 = fadd <8 x double> %155, %160
  %162 = fadd <8 x double> %156, %161
  %163 = fadd <8 x double> %162, %157
  %164 = fadd <8 x double> %148, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %165 = fsub <8 x double> %164, %148
  %166 = fsub <8 x double> %164, %165
  %167 = fsub <8 x double> %148, %166
  %168 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %165
  %169 = fadd <8 x double> %168, %167
  %170 = fadd <8 x double> %169, %163
  %171 = fadd <8 x double> %164, %170
  %172 = and <4 x i64> %8, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %173 = shufflevector <4 x i64> %172, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %174 = bitcast <8 x i64> %173 to <16 x i32>
  %175 = icmp eq <16 x i32> %174, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %176 = bitcast <16 x i1> %175 to <2 x i8>
  %177 = extractelement <2 x i8> %176, i32 0
  %178 = bitcast i8 %177 to <8 x i1>
  %179 = select <8 x i1> %178, <8 x double> %97, <8 x double> %171
  %180 = select <8 x i1> %178, <8 x double> %171, <8 x double> %97
  %181 = and <4 x i64> %8, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %182 = shufflevector <4 x i64> %181, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %183 = bitcast <8 x i64> %182 to <16 x i32>
  %184 = icmp eq <16 x i32> %183, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %185 = bitcast <16 x i1> %184 to <2 x i8>
  %186 = extractelement <2 x i8> %185, i32 0
  %187 = bitcast i8 %186 to <8 x i1>
  %188 = select <8 x i1> %187, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %189 = bitcast <8 x double> %179 to <8 x i64>
  %190 = xor <8 x i64> %188, %189
  %191 = add <8 x i32> %9, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %192 = bitcast <8 x i32> %191 to <4 x i64>
  %193 = and <4 x i64> %192, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %194 = shufflevector <4 x i64> %193, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %195 = bitcast <8 x i64> %194 to <16 x i32>
  %196 = icmp eq <16 x i32> %195, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %197 = bitcast <16 x i1> %196 to <2 x i8>
  %198 = extractelement <2 x i8> %197, i32 0
  %199 = bitcast i8 %198 to <8 x i1>
  %200 = select <8 x i1> %199, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %201 = bitcast <8 x double> %180 to <8 x i64>
  %202 = xor <8 x i64> %200, %201
  %203 = and <8 x i64> %95, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %204 = bitcast <8 x i64> %203 to <8 x double>
  %205 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %204, <8 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i32 30, i8 -1, i32 4) #7
  %206 = bitcast i8 %205 to <8 x i1>
  %207 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %204, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %208 = bitcast i8 %207 to <8 x i1>
  %209 = bitcast <8 x i64> %190 to <8 x double>
  %210 = select <8 x i1> %206, <8 x double> zeroinitializer, <8 x double> %209
  %211 = select <8 x i1> %208, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %210
  %212 = bitcast <8 x i64> %202 to <8 x double>
  %213 = select <8 x i1> %206, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %212
  %214 = select <8 x i1> %208, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %213
  %215 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 0
  store <8 x double> %211, <8 x double>* %215, align 64
  %216 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  store <8 x double> %214, <8 x double>* %216, align 64
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_sincospid8_u35avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = fmul <8 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = lshr <8 x i32> %4, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %6 = xor <8 x i32> %5, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %7 = add <8 x i32> %6, %4
  %8 = bitcast <8 x i32> %7 to <4 x i64>
  %9 = and <8 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %10 = sitofp <8 x i32> %9 to <8 x double>
  %11 = fsub <8 x double> %3, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %12, <double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C>
  %14 = fadd <8 x double> %13, <double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5>
  %15 = fmul <8 x double> %12, %14
  %16 = fadd <8 x double> %15, <double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C>
  %17 = fmul <8 x double> %12, %16
  %18 = fadd <8 x double> %17, <double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE>
  %19 = fmul <8 x double> %12, %18
  %20 = fadd <8 x double> %19, <double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5>
  %21 = fmul <8 x double> %12, %20
  %22 = fadd <8 x double> %21, <double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43>
  %23 = fmul <8 x double> %12, %22
  %24 = fadd <8 x double> %23, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %25 = fmul <8 x double> %11, %24
  %26 = fmul <8 x double> %12, <double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3>
  %27 = fadd <8 x double> %26, <double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD>
  %28 = fmul <8 x double> %12, %27
  %29 = fadd <8 x double> %28, <double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707>
  %30 = fmul <8 x double> %12, %29
  %31 = fadd <8 x double> %30, <double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332>
  %32 = fmul <8 x double> %12, %31
  %33 = fadd <8 x double> %32, <double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF>
  %34 = fmul <8 x double> %12, %33
  %35 = fadd <8 x double> %34, <double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA>
  %36 = fmul <8 x double> %12, %35
  %37 = fadd <8 x double> %36, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %38 = fmul <8 x double> %12, %37
  %39 = fadd <8 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %40 = and <4 x i64> %8, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = bitcast <8 x i64> %41 to <16 x i32>
  %43 = icmp eq <16 x i32> %42, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %44 = bitcast <16 x i1> %43 to <2 x i8>
  %45 = extractelement <2 x i8> %44, i32 0
  %46 = bitcast i8 %45 to <8 x i1>
  %47 = select <8 x i1> %46, <8 x double> %25, <8 x double> %39
  %48 = select <8 x i1> %46, <8 x double> %39, <8 x double> %25
  %49 = and <4 x i64> %8, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %50 = shufflevector <4 x i64> %49, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <8 x i64> %50 to <16 x i32>
  %52 = icmp eq <16 x i32> %51, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %53 = bitcast <16 x i1> %52 to <2 x i8>
  %54 = extractelement <2 x i8> %53, i32 0
  %55 = bitcast i8 %54 to <8 x i1>
  %56 = select <8 x i1> %55, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %57 = bitcast <8 x double> %47 to <8 x i64>
  %58 = xor <8 x i64> %56, %57
  %59 = add <8 x i32> %9, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %60 = bitcast <8 x i32> %59 to <4 x i64>
  %61 = and <4 x i64> %60, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %62 = shufflevector <4 x i64> %61, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %63 = bitcast <8 x i64> %62 to <16 x i32>
  %64 = icmp eq <16 x i32> %63, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <16 x i1> %64 to <2 x i8>
  %66 = extractelement <2 x i8> %65, i32 0
  %67 = bitcast i8 %66 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %69 = bitcast <8 x double> %48 to <8 x i64>
  %70 = xor <8 x i64> %68, %69
  %71 = bitcast <8 x double> %1 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %73, <8 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i32 30, i8 -1, i32 4) #7
  %75 = bitcast i8 %74 to <8 x i1>
  %76 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %73, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %77 = bitcast i8 %76 to <8 x i1>
  %78 = bitcast <8 x i64> %58 to <8 x double>
  %79 = select <8 x i1> %75, <8 x double> zeroinitializer, <8 x double> %78
  %80 = select <8 x i1> %77, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %79
  %81 = bitcast <8 x i64> %70 to <8 x double>
  %82 = select <8 x i1> %75, <8 x double> zeroinitializer, <8 x double> %81
  %83 = select <8 x i1> %77, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %82
  %84 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 0
  store <8 x double> %80, <8 x double>* %84, align 64
  %85 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  store <8 x double> %83, <8 x double>* %85, align 64
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_modfd8_avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = fmul <8 x double> %1, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = sitofp <8 x i32> %4 to <8 x double>
  %6 = fmul <8 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <8 x double> %1, %6
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %9 = sitofp <8 x i32> %8 to <8 x double>
  %10 = fsub <8 x double> %7, %9
  %11 = bitcast <8 x double> %1 to <8 x i64>
  %12 = and <8 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <8 x i64> %12 to <8 x double>
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 30, i8 -1, i32 4) #7
  %15 = bitcast i8 %14 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> zeroinitializer, <8 x double> %10
  %17 = bitcast <8 x double> %16 to <8 x i64>
  %18 = and <8 x i64> %17, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %19 = and <8 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = or <8 x i64> %18, %19
  %21 = fsub <8 x double> %1, %16
  %22 = bitcast <8 x double> %21 to <8 x i64>
  %23 = and <8 x i64> %22, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %24 = or <8 x i64> %23, %19
  %25 = bitcast %struct.vdouble2* %0 to <8 x i64>*
  store <8 x i64> %20, <8 x i64>* %25, align 64
  %26 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %27 = bitcast <8 x double>* %26 to <8 x i64>*
  store <8 x i64> %24, <8 x i64>* %27, align 64
  ret void
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sinpid8_u05avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = lshr <8 x i32> %3, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %5 = xor <8 x i32> %4, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %6 = add <8 x i32> %5, %3
  %7 = bitcast <8 x i32> %6 to <4 x i64>
  %8 = and <4 x i64> %7, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <8 x i64> %9 to <16 x i32>
  %11 = icmp eq <16 x i32> %10, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = and <8 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %13 = sitofp <8 x i32> %12 to <8 x double>
  %14 = fsub <8 x double> %2, %13
  %15 = fmul <8 x double> %14, %14
  %16 = bitcast <8 x double> %14 to <8 x i64>
  %17 = and <8 x i64> %16, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %18 = bitcast <8 x i64> %17 to <8 x double>
  %19 = fsub <8 x double> %14, %18
  %20 = fmul <8 x double> %18, %18
  %21 = bitcast <8 x double> %15 to <8 x i64>
  %22 = xor <8 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fmul <8 x double> %19, %18
  %25 = fmul <8 x double> %19, %19
  %26 = fadd <8 x double> %20, %23
  %27 = fadd <8 x double> %24, %26
  %28 = fadd <8 x double> %24, %27
  %29 = fadd <8 x double> %25, %28
  %30 = bitcast <16 x i1> %11 to <2 x i8>
  %31 = extractelement <2 x i8> %30, i32 0
  %32 = bitcast i8 %31 to <8 x i1>
  %33 = select <8 x i1> %32, <8 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <8 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>
  %34 = select <8 x i1> %32, <8 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <8 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>
  %35 = fmul <8 x double> %15, %33
  %36 = fadd <8 x double> %34, %35
  %37 = select <8 x i1> %32, <8 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <8 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>
  %38 = fmul <8 x double> %15, %36
  %39 = fadd <8 x double> %37, %38
  %40 = select <8 x i1> %32, <8 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <8 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>
  %41 = fmul <8 x double> %15, %39
  %42 = fadd <8 x double> %40, %41
  %43 = select <8 x i1> %32, <8 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <8 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>
  %44 = fmul <8 x double> %15, %42
  %45 = fadd <8 x double> %43, %44
  %46 = select <8 x i1> %32, <8 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <8 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>
  %47 = fmul <8 x double> %15, %45
  %48 = fadd <8 x double> %46, %47
  %49 = fmul <8 x double> %15, %48
  %50 = select <8 x i1> %32, <8 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <8 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>
  %51 = select <8 x i1> %32, <8 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <8 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>
  %52 = fadd <8 x double> %50, %49
  %53 = fsub <8 x double> %52, %49
  %54 = fsub <8 x double> %52, %53
  %55 = fsub <8 x double> %49, %54
  %56 = fsub <8 x double> %50, %53
  %57 = fadd <8 x double> %56, %55
  %58 = fadd <8 x double> %51, %57
  %59 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %60 = bitcast <8 x i64> %59 to <8 x double>
  %61 = fsub <8 x double> %15, %60
  %62 = bitcast <8 x double> %52 to <8 x i64>
  %63 = and <8 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <8 x i64> %63 to <8 x double>
  %65 = fsub <8 x double> %52, %64
  %66 = fmul <8 x double> %15, %52
  %67 = fmul <8 x double> %60, %64
  %68 = bitcast <8 x double> %66 to <8 x i64>
  %69 = xor <8 x i64> %68, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %70 = bitcast <8 x i64> %69 to <8 x double>
  %71 = fmul <8 x double> %61, %64
  %72 = fmul <8 x double> %65, %60
  %73 = fmul <8 x double> %61, %65
  %74 = fmul <8 x double> %15, %58
  %75 = fmul <8 x double> %29, %52
  %76 = fadd <8 x double> %67, %70
  %77 = fadd <8 x double> %71, %76
  %78 = fadd <8 x double> %72, %77
  %79 = fadd <8 x double> %73, %78
  %80 = fadd <8 x double> %74, %79
  %81 = fadd <8 x double> %75, %80
  %82 = select <8 x i1> %32, <8 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %83 = select <8 x i1> %32, <8 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <8 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>
  %84 = fadd <8 x double> %82, %66
  %85 = fsub <8 x double> %84, %66
  %86 = fsub <8 x double> %84, %85
  %87 = fsub <8 x double> %66, %86
  %88 = fsub <8 x double> %82, %85
  %89 = fadd <8 x double> %88, %87
  %90 = fadd <8 x double> %83, %81
  %91 = fadd <8 x double> %89, %90
  %92 = select <8 x i1> %32, <8 x double> %15, <8 x double> %14
  %93 = select <8 x i1> %32, <8 x double> %29, <8 x double> zeroinitializer
  %94 = bitcast <8 x double> %84 to <8 x i64>
  %95 = and <8 x i64> %94, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = fsub <8 x double> %84, %96
  %98 = bitcast <8 x double> %92 to <8 x i64>
  %99 = and <8 x i64> %98, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %100 = bitcast <8 x i64> %99 to <8 x double>
  %101 = fsub <8 x double> %92, %100
  %102 = fmul <8 x double> %92, %84
  %103 = fmul <8 x double> %100, %96
  %104 = bitcast <8 x double> %102 to <8 x i64>
  %105 = xor <8 x i64> %104, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %106 = bitcast <8 x i64> %105 to <8 x double>
  %107 = fmul <8 x double> %97, %100
  %108 = fmul <8 x double> %101, %96
  %109 = fmul <8 x double> %101, %97
  %110 = fmul <8 x double> %93, %84
  %111 = fmul <8 x double> %92, %91
  %112 = fadd <8 x double> %103, %106
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %108, %113
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %116, %111
  %118 = fadd <8 x double> %102, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %119 = fsub <8 x double> %118, %102
  %120 = fsub <8 x double> %118, %119
  %121 = fsub <8 x double> %102, %120
  %122 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %119
  %123 = fadd <8 x double> %122, %121
  %124 = fadd <8 x double> %123, %117
  %125 = select <8 x i1> %32, <8 x double> %118, <8 x double> %102
  %126 = select <8 x i1> %32, <8 x double> %124, <8 x double> %117
  %127 = and <4 x i64> %7, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %128 = shufflevector <4 x i64> %127, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %129 = bitcast <8 x i64> %128 to <16 x i32>
  %130 = icmp eq <16 x i32> %129, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %131 = bitcast <16 x i1> %130 to <2 x i8>
  %132 = extractelement <2 x i8> %131, i32 0
  %133 = bitcast i8 %132 to <8 x i1>
  %134 = select <8 x i1> %133, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %135 = bitcast <8 x double> %125 to <8 x i64>
  %136 = xor <8 x i64> %134, %135
  %137 = bitcast <8 x double> %126 to <8 x i64>
  %138 = xor <8 x i64> %134, %137
  %139 = bitcast <8 x i64> %136 to <8 x double>
  %140 = bitcast <8 x i64> %138 to <8 x double>
  %141 = fadd <8 x double> %139, %140
  %142 = bitcast <8 x double> %0 to <8 x i64>
  %143 = icmp eq <8 x i64> %142, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %144 = and <8 x i64> %142, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %145, <8 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i32 30, i8 -1, i32 4) #7
  %147 = bitcast i8 %146 to <8 x i1>
  %148 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %145, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %149 = bitcast i8 %148 to <8 x i1>
  %150 = select <8 x i1> %143, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %141
  %151 = select <8 x i1> %147, <8 x double> zeroinitializer, <8 x double> %150
  %152 = select <8 x i1> %149, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %151
  ret <8 x double> %152
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cospid8_u05avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = lshr <8 x i32> %3, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %5 = xor <8 x i32> %4, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %6 = add <8 x i32> %5, %3
  %7 = bitcast <8 x i32> %6 to <4 x i64>
  %8 = and <4 x i64> %7, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %9 = shufflevector <4 x i64> %8, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <8 x i64> %9 to <16 x i32>
  %11 = icmp eq <16 x i32> %10, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = and <8 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %13 = sitofp <8 x i32> %12 to <8 x double>
  %14 = fsub <8 x double> %2, %13
  %15 = fmul <8 x double> %14, %14
  %16 = bitcast <8 x double> %14 to <8 x i64>
  %17 = and <8 x i64> %16, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %18 = bitcast <8 x i64> %17 to <8 x double>
  %19 = fsub <8 x double> %14, %18
  %20 = fmul <8 x double> %18, %18
  %21 = bitcast <8 x double> %15 to <8 x i64>
  %22 = xor <8 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fmul <8 x double> %19, %18
  %25 = fmul <8 x double> %19, %19
  %26 = fadd <8 x double> %20, %23
  %27 = fadd <8 x double> %24, %26
  %28 = fadd <8 x double> %24, %27
  %29 = fadd <8 x double> %25, %28
  %30 = bitcast <16 x i1> %11 to <2 x i8>
  %31 = extractelement <2 x i8> %30, i32 0
  %32 = bitcast i8 %31 to <8 x i1>
  %33 = select <8 x i1> %32, <8 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <8 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>
  %34 = select <8 x i1> %32, <8 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <8 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>
  %35 = fmul <8 x double> %15, %33
  %36 = fadd <8 x double> %34, %35
  %37 = select <8 x i1> %32, <8 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <8 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>
  %38 = fmul <8 x double> %15, %36
  %39 = fadd <8 x double> %37, %38
  %40 = select <8 x i1> %32, <8 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <8 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>
  %41 = fmul <8 x double> %15, %39
  %42 = fadd <8 x double> %40, %41
  %43 = select <8 x i1> %32, <8 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <8 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>
  %44 = fmul <8 x double> %15, %42
  %45 = fadd <8 x double> %43, %44
  %46 = select <8 x i1> %32, <8 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <8 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>
  %47 = fmul <8 x double> %15, %45
  %48 = fadd <8 x double> %46, %47
  %49 = fmul <8 x double> %15, %48
  %50 = select <8 x i1> %32, <8 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <8 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>
  %51 = select <8 x i1> %32, <8 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <8 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>
  %52 = fadd <8 x double> %50, %49
  %53 = fsub <8 x double> %52, %49
  %54 = fsub <8 x double> %52, %53
  %55 = fsub <8 x double> %49, %54
  %56 = fsub <8 x double> %50, %53
  %57 = fadd <8 x double> %56, %55
  %58 = fadd <8 x double> %51, %57
  %59 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %60 = bitcast <8 x i64> %59 to <8 x double>
  %61 = fsub <8 x double> %15, %60
  %62 = bitcast <8 x double> %52 to <8 x i64>
  %63 = and <8 x i64> %62, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %64 = bitcast <8 x i64> %63 to <8 x double>
  %65 = fsub <8 x double> %52, %64
  %66 = fmul <8 x double> %15, %52
  %67 = fmul <8 x double> %60, %64
  %68 = bitcast <8 x double> %66 to <8 x i64>
  %69 = xor <8 x i64> %68, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %70 = bitcast <8 x i64> %69 to <8 x double>
  %71 = fmul <8 x double> %61, %64
  %72 = fmul <8 x double> %65, %60
  %73 = fmul <8 x double> %61, %65
  %74 = fmul <8 x double> %15, %58
  %75 = fmul <8 x double> %29, %52
  %76 = fadd <8 x double> %67, %70
  %77 = fadd <8 x double> %71, %76
  %78 = fadd <8 x double> %72, %77
  %79 = fadd <8 x double> %73, %78
  %80 = fadd <8 x double> %74, %79
  %81 = fadd <8 x double> %75, %80
  %82 = select <8 x i1> %32, <8 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %83 = select <8 x i1> %32, <8 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <8 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>
  %84 = fadd <8 x double> %82, %66
  %85 = fsub <8 x double> %84, %66
  %86 = fsub <8 x double> %84, %85
  %87 = fsub <8 x double> %66, %86
  %88 = fsub <8 x double> %82, %85
  %89 = fadd <8 x double> %88, %87
  %90 = fadd <8 x double> %83, %81
  %91 = fadd <8 x double> %89, %90
  %92 = select <8 x i1> %32, <8 x double> %15, <8 x double> %14
  %93 = select <8 x i1> %32, <8 x double> %29, <8 x double> zeroinitializer
  %94 = bitcast <8 x double> %84 to <8 x i64>
  %95 = and <8 x i64> %94, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = fsub <8 x double> %84, %96
  %98 = bitcast <8 x double> %92 to <8 x i64>
  %99 = and <8 x i64> %98, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %100 = bitcast <8 x i64> %99 to <8 x double>
  %101 = fsub <8 x double> %92, %100
  %102 = fmul <8 x double> %92, %84
  %103 = fmul <8 x double> %100, %96
  %104 = bitcast <8 x double> %102 to <8 x i64>
  %105 = xor <8 x i64> %104, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %106 = bitcast <8 x i64> %105 to <8 x double>
  %107 = fmul <8 x double> %97, %100
  %108 = fmul <8 x double> %101, %96
  %109 = fmul <8 x double> %101, %97
  %110 = fmul <8 x double> %93, %84
  %111 = fmul <8 x double> %92, %91
  %112 = fadd <8 x double> %103, %106
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %108, %113
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %116, %111
  %118 = fadd <8 x double> %102, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %119 = fsub <8 x double> %118, %102
  %120 = fsub <8 x double> %118, %119
  %121 = fsub <8 x double> %102, %120
  %122 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %119
  %123 = fadd <8 x double> %122, %121
  %124 = fadd <8 x double> %123, %117
  %125 = select <8 x i1> %32, <8 x double> %118, <8 x double> %102
  %126 = select <8 x i1> %32, <8 x double> %124, <8 x double> %117
  %127 = add <8 x i32> %12, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %128 = bitcast <8 x i32> %127 to <4 x i64>
  %129 = and <4 x i64> %128, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %130 = shufflevector <4 x i64> %129, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %131 = bitcast <8 x i64> %130 to <16 x i32>
  %132 = icmp eq <16 x i32> %131, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %133 = bitcast <16 x i1> %132 to <2 x i8>
  %134 = extractelement <2 x i8> %133, i32 0
  %135 = bitcast i8 %134 to <8 x i1>
  %136 = select <8 x i1> %135, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %137 = bitcast <8 x double> %125 to <8 x i64>
  %138 = xor <8 x i64> %136, %137
  %139 = bitcast <8 x double> %126 to <8 x i64>
  %140 = xor <8 x i64> %136, %139
  %141 = bitcast <8 x i64> %138 to <8 x double>
  %142 = bitcast <8 x i64> %140 to <8 x double>
  %143 = fadd <8 x double> %141, %142
  %144 = bitcast <8 x double> %0 to <8 x i64>
  %145 = and <8 x i64> %144, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %146, <8 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i32 30, i8 -1, i32 4) #7
  %148 = bitcast i8 %147 to <8 x i1>
  %149 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %146, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %150 = bitcast i8 %149 to <8 x i1>
  %151 = select <8 x i1> %148, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %143
  %152 = select <8 x i1> %150, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %151
  ret <8 x double> %152
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_tand8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %15, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %8, i32 8, <8 x double> %8, i8 -1, i32 4) #7
  %10 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %9, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %11 = fmul <8 x double> %9, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %12 = fadd <8 x double> %11, %0
  %13 = fmul <8 x double> %9, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %14 = fadd <8 x double> %13, %12
  br label %198

; <label>:15:                                     ; preds = %1
  %16 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06, double 1.000000e+06>, i32 17, i8 -1, i32 4) #7
  %17 = icmp eq i8 %16, -1
  br i1 %17, label %18, label %41, !prof !2

; <label>:18:                                     ; preds = %15
  %19 = fmul <8 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %20 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %19, i32 11, <8 x double> %19, i8 -1, i32 4) #7
  %21 = fmul <8 x double> %20, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %22 = fmul <8 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %23 = fsub <8 x double> %22, %21
  %24 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %23, i32 8, <8 x double> %23, i8 -1, i32 4) #7
  %25 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %24, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %26 = fmul <8 x double> %21, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %27 = fadd <8 x double> %26, %0
  %28 = fmul <8 x double> %24, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %29 = fadd <8 x double> %28, %27
  %30 = fmul <8 x double> %21, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %31 = fadd <8 x double> %30, %29
  %32 = fmul <8 x double> %24, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %33 = fadd <8 x double> %32, %31
  %34 = fmul <8 x double> %21, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %35 = fadd <8 x double> %34, %33
  %36 = fmul <8 x double> %24, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %37 = fadd <8 x double> %36, %35
  %38 = fadd <8 x double> %21, %24
  %39 = fmul <8 x double> %38, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %40 = fadd <8 x double> %39, %37
  br label %198

; <label>:41:                                     ; preds = %15
  %42 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %43 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %42, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %44 = ashr <8 x i32> %43, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %45 = xor <8 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = and <8 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %47 = and <8 x i32> %46, %45
  %48 = add nsw <8 x i32> %47, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %49 = bitcast <8 x i32> %48 to <4 x i64>
  %50 = shufflevector <4 x i64> %49, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <8 x i64> %50 to <16 x i32>
  %52 = icmp sgt <16 x i32> %51, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %53 = select <16 x i1> %52, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %54 = shufflevector <16 x i32> %53, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %55 = shufflevector <16 x i32> %54, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %56 = shl <16 x i32> %55, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %57 = bitcast <8 x double> %0 to <16 x i32>
  %58 = add <16 x i32> %56, %57
  %59 = bitcast <16 x i32> %58 to <8 x double>
  %60 = ashr <8 x i32> %48, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %61 = bitcast <8 x i32> %60 to <4 x i64>
  %62 = xor <4 x i64> %61, <i64 -1, i64 -1, i64 -1, i64 -1>
  %63 = and <4 x i64> %62, %49
  %64 = bitcast <4 x i64> %63 to <8 x i32>
  %65 = shl <8 x i32> %64, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %66 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !21
  %67 = bitcast <16 x i32> %58 to <8 x i64>
  %68 = and <8 x i64> %67, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %69 = bitcast <8 x i64> %68 to <8 x double>
  %70 = fsub <8 x double> %59, %69
  %71 = bitcast <8 x double> %66 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %66, %73
  %75 = fmul <8 x double> %66, %59
  %76 = fmul <8 x double> %73, %69
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %70, %73
  %81 = fmul <8 x double> %74, %69
  %82 = fmul <8 x double> %74, %70
  %83 = fadd <8 x double> %76, %79
  %84 = fadd <8 x double> %80, %83
  %85 = fadd <8 x double> %81, %84
  %86 = fadd <8 x double> %82, %85
  %87 = fmul <8 x double> %75, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %88 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %87, i32 8, <8 x double> %87, i8 -1, i32 4) #7
  %89 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %75, i32 8, <8 x double> %75, i8 -1, i32 4) #7
  %90 = fmul <8 x double> %89, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %91 = fsub <8 x double> %88, %90
  %92 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %91, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %93 = fmul <8 x double> %88, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %94 = fsub <8 x double> %75, %93
  %95 = fadd <8 x double> %94, %86
  %96 = fsub <8 x double> %94, %95
  %97 = fadd <8 x double> %86, %96
  %98 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !21
  %99 = bitcast <8 x double> %98 to <8 x i64>
  %100 = and <8 x i64> %99, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %101 = bitcast <8 x i64> %100 to <8 x double>
  %102 = fsub <8 x double> %98, %101
  %103 = fmul <8 x double> %98, %59
  %104 = fmul <8 x double> %101, %69
  %105 = bitcast <8 x double> %103 to <8 x i64>
  %106 = xor <8 x i64> %105, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %107 = bitcast <8 x i64> %106 to <8 x double>
  %108 = fmul <8 x double> %70, %101
  %109 = fmul <8 x double> %102, %69
  %110 = fmul <8 x double> %102, %70
  %111 = fadd <8 x double> %104, %107
  %112 = fadd <8 x double> %108, %111
  %113 = fadd <8 x double> %109, %112
  %114 = fadd <8 x double> %110, %113
  %115 = fadd <8 x double> %103, %95
  %116 = fsub <8 x double> %115, %95
  %117 = fsub <8 x double> %115, %116
  %118 = fsub <8 x double> %95, %117
  %119 = fsub <8 x double> %103, %116
  %120 = fadd <8 x double> %119, %118
  %121 = fadd <8 x double> %114, %97
  %122 = fadd <8 x double> %121, %120
  %123 = fmul <8 x double> %115, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %124 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %123, i32 8, <8 x double> %123, i8 -1, i32 4) #7
  %125 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %115, i32 8, <8 x double> %115, i8 -1, i32 4) #7
  %126 = fmul <8 x double> %125, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %127 = fsub <8 x double> %124, %126
  %128 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %127, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %129 = fmul <8 x double> %124, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %130 = fsub <8 x double> %115, %129
  %131 = add <8 x i32> %128, %92
  %132 = fadd <8 x double> %130, %122
  %133 = fsub <8 x double> %130, %132
  %134 = fadd <8 x double> %122, %133
  %135 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !21
  %136 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %65, i8 -1, i32 8) #7, !noalias !21
  %137 = bitcast <8 x double> %135 to <8 x i64>
  %138 = and <8 x i64> %137, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %139 = bitcast <8 x i64> %138 to <8 x double>
  %140 = fsub <8 x double> %135, %139
  %141 = fmul <8 x double> %135, %59
  %142 = fmul <8 x double> %139, %69
  %143 = bitcast <8 x double> %141 to <8 x i64>
  %144 = xor <8 x i64> %143, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = fmul <8 x double> %140, %69
  %147 = fmul <8 x double> %70, %139
  %148 = fmul <8 x double> %140, %70
  %149 = fmul <8 x double> %136, %59
  %150 = fadd <8 x double> %142, %145
  %151 = fadd <8 x double> %146, %150
  %152 = fadd <8 x double> %147, %151
  %153 = fadd <8 x double> %148, %152
  %154 = fadd <8 x double> %149, %153
  %155 = fadd <8 x double> %141, %132
  %156 = fsub <8 x double> %155, %132
  %157 = fsub <8 x double> %155, %156
  %158 = fsub <8 x double> %132, %157
  %159 = fsub <8 x double> %141, %156
  %160 = fadd <8 x double> %159, %158
  %161 = fadd <8 x double> %154, %134
  %162 = fadd <8 x double> %161, %160
  %163 = fadd <8 x double> %155, %162
  %164 = fsub <8 x double> %155, %163
  %165 = fadd <8 x double> %162, %164
  %166 = bitcast <8 x double> %163 to <8 x i64>
  %167 = and <8 x i64> %166, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %168 = bitcast <8 x i64> %167 to <8 x double>
  %169 = fsub <8 x double> %163, %168
  %170 = fmul <8 x double> %163, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %171 = fmul <8 x double> %168, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %172 = bitcast <8 x double> %170 to <8 x i64>
  %173 = xor <8 x i64> %172, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %174 = bitcast <8 x i64> %173 to <8 x double>
  %175 = fmul <8 x double> %169, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %176 = fmul <8 x double> %168, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %177 = fmul <8 x double> %169, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %178 = fmul <8 x double> %163, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %179 = fmul <8 x double> %165, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %180 = fadd <8 x double> %171, %174
  %181 = fadd <8 x double> %175, %180
  %182 = fadd <8 x double> %176, %181
  %183 = fadd <8 x double> %177, %182
  %184 = fadd <8 x double> %178, %183
  %185 = fadd <8 x double> %179, %184
  %186 = and <8 x i64> %67, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %187 = bitcast <8 x i64> %186 to <8 x double>
  %188 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %187, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %189 = bitcast i8 %188 to <8 x i1>
  %190 = select <8 x i1> %189, <8 x double> %59, <8 x double> %170
  %191 = select <8 x i1> %189, <8 x double> zeroinitializer, <8 x double> %185
  %192 = fadd <8 x double> %190, %191
  %193 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %194 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %195 = or i8 %194, %193
  %196 = bitcast i8 %195 to <8 x i1>
  %197 = select <8 x i1> %196, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %192
  br label %198

; <label>:198:                                    ; preds = %18, %41, %7
  %199 = phi <8 x i32> [ %10, %7 ], [ %25, %18 ], [ %131, %41 ]
  %200 = phi <8 x double> [ %14, %7 ], [ %40, %18 ], [ %197, %41 ]
  %201 = bitcast <8 x i32> %199 to <4 x i64>
  %202 = fmul <8 x double> %200, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %203 = fmul <8 x double> %202, %202
  %204 = fmul <8 x double> %203, %203
  %205 = fmul <8 x double> %204, %204
  %206 = fmul <8 x double> %203, <double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED>
  %207 = fadd <8 x double> %206, <double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF>
  %208 = fmul <8 x double> %203, <double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93>
  %209 = fadd <8 x double> %208, <double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959>
  %210 = fmul <8 x double> %204, %207
  %211 = fadd <8 x double> %209, %210
  %212 = fmul <8 x double> %203, <double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090>
  %213 = fadd <8 x double> %212, <double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5>
  %214 = fmul <8 x double> %203, <double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06>
  %215 = fadd <8 x double> %214, <double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933>
  %216 = fmul <8 x double> %204, %213
  %217 = fadd <8 x double> %215, %216
  %218 = fmul <8 x double> %205, %211
  %219 = fadd <8 x double> %217, %218
  %220 = fmul <8 x double> %203, %219
  %221 = fadd <8 x double> %220, <double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568>
  %222 = fmul <8 x double> %202, %221
  %223 = fmul <8 x double> %203, %222
  %224 = fadd <8 x double> %202, %223
  %225 = fmul <8 x double> %224, %224
  %226 = fadd <8 x double> %225, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %227 = fmul <8 x double> %224, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %228 = and <4 x i64> %201, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %229 = shufflevector <4 x i64> %228, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %230 = bitcast <8 x i64> %229 to <16 x i32>
  %231 = icmp eq <16 x i32> %230, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %232 = bitcast <8 x double> %226 to <8 x i64>
  %233 = xor <8 x i64> %232, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %234 = bitcast <8 x i64> %233 to <8 x double>
  %235 = bitcast <16 x i1> %231 to <2 x i8>
  %236 = extractelement <2 x i8> %235, i32 0
  %237 = bitcast i8 %236 to <8 x i1>
  %238 = select <8 x i1> %237, <8 x double> %234, <8 x double> %227
  %239 = select <8 x i1> %237, <8 x double> %227, <8 x double> %226
  %240 = fdiv <8 x double> %238, %239
  %241 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %242 = bitcast i8 %241 to <8 x i1>
  %243 = select <8 x i1> %242, <8 x double> %0, <8 x double> %240
  ret <8 x double> %243
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_tand8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01, double 1.500000e+01>, i32 17, i8 -1, i32 4) #7
  %6 = icmp eq i8 %5, -1
  br i1 %6, label %7, label %17, !prof !2

; <label>:7:                                      ; preds = %1
  %8 = fmul <8 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %8, i32 8, <8 x double> %8, i8 -1, i32 4) #7
  %10 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %9, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %11 = fmul <8 x double> %9, <double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18, double 0xBFF921FB54442D18>
  %12 = fadd <8 x double> %11, %0
  %13 = fmul <8 x double> %9, <double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07, double 0xBC91A62633145C07>
  %14 = fadd <8 x double> %13, %12
  %15 = fsub <8 x double> %12, %14
  %16 = fadd <8 x double> %13, %15
  br label %256

; <label>:17:                                     ; preds = %1
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14, double 1.000000e+14>, i32 17, i8 -1, i32 4) #7
  %19 = icmp eq i8 %18, -1
  br i1 %19, label %20, label %99, !prof !2

; <label>:20:                                     ; preds = %17
  %21 = fmul <8 x double> %0, <double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883, double 0x3E645F306DC9C883>
  %22 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %21, i32 11, <8 x double> %21, i8 -1, i32 4) #7
  %23 = fmul <8 x double> %22, <double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000, double 0x4170000000000000>
  %24 = and <8 x i64> %2, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = fsub <8 x double> %0, %25
  %27 = fmul <8 x double> %0, <double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883, double 0x3FE45F306DC9C883>
  %28 = fmul <8 x double> %25, <double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000>
  %29 = bitcast <8 x double> %27 to <8 x i64>
  %30 = xor <8 x i64> %29, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fmul <8 x double> %25, <double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000>
  %33 = fmul <8 x double> %26, <double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000, double 0x3FE45F3068000000>
  %34 = fmul <8 x double> %26, <double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000, double 0x3E4727220C000000>
  %35 = fmul <8 x double> %0, <double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056, double 0xBC86B01EC5417056>
  %36 = fadd <8 x double> %28, %31
  %37 = fadd <8 x double> %32, %36
  %38 = fadd <8 x double> %33, %37
  %39 = fadd <8 x double> %34, %38
  %40 = fadd <8 x double> %35, %39
  %41 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %42 = bitcast i8 %41 to <8 x i1>
  %43 = select <8 x i1> %42, <8 x double> <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %44 = fsub <8 x double> %43, %23
  %45 = fadd <8 x double> %27, %44
  %46 = fsub <8 x double> %45, %27
  %47 = fsub <8 x double> %45, %46
  %48 = fsub <8 x double> %27, %47
  %49 = fsub <8 x double> %44, %46
  %50 = fadd <8 x double> %49, %48
  %51 = fadd <8 x double> %40, %50
  %52 = fadd <8 x double> %45, %51
  %53 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %52, i32 11, <8 x double> %52, i8 -1, i32 4) #7
  %54 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %53, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %55 = fmul <8 x double> %23, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %56 = fadd <8 x double> %55, %0
  %57 = fmul <8 x double> %53, <double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000, double 0xBFF921FB50000000>
  %58 = fadd <8 x double> %56, %57
  %59 = fsub <8 x double> %56, %58
  %60 = fadd <8 x double> %57, %59
  %61 = fmul <8 x double> %23, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %62 = fadd <8 x double> %61, %58
  %63 = fsub <8 x double> %62, %58
  %64 = fsub <8 x double> %62, %63
  %65 = fsub <8 x double> %58, %64
  %66 = fsub <8 x double> %61, %63
  %67 = fadd <8 x double> %66, %65
  %68 = fadd <8 x double> %60, %67
  %69 = fmul <8 x double> %53, <double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000, double 0xBE5110B460000000>
  %70 = fadd <8 x double> %69, %62
  %71 = fsub <8 x double> %70, %62
  %72 = fsub <8 x double> %70, %71
  %73 = fsub <8 x double> %62, %72
  %74 = fsub <8 x double> %69, %71
  %75 = fadd <8 x double> %74, %73
  %76 = fadd <8 x double> %75, %68
  %77 = fmul <8 x double> %23, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %78 = fadd <8 x double> %77, %70
  %79 = fsub <8 x double> %78, %70
  %80 = fsub <8 x double> %78, %79
  %81 = fsub <8 x double> %70, %80
  %82 = fsub <8 x double> %77, %79
  %83 = fadd <8 x double> %82, %81
  %84 = fadd <8 x double> %83, %76
  %85 = fmul <8 x double> %53, <double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000, double 0xBC91A62630000000>
  %86 = fadd <8 x double> %85, %78
  %87 = fsub <8 x double> %86, %78
  %88 = fsub <8 x double> %86, %87
  %89 = fsub <8 x double> %78, %88
  %90 = fsub <8 x double> %85, %87
  %91 = fadd <8 x double> %90, %89
  %92 = fadd <8 x double> %91, %84
  %93 = fadd <8 x double> %23, %53
  %94 = fmul <8 x double> %93, <double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A, double 0xBAE8A2E03707344A>
  %95 = fadd <8 x double> %94, %86
  %96 = fsub <8 x double> %86, %95
  %97 = fadd <8 x double> %94, %96
  %98 = fadd <8 x double> %97, %92
  br label %256

; <label>:99:                                     ; preds = %17
  %100 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %101 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %100, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %102 = ashr <8 x i32> %101, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %103 = xor <8 x i32> %102, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %104 = and <8 x i32> %101, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %105 = and <8 x i32> %104, %103
  %106 = add nsw <8 x i32> %105, <i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55, i32 -55>
  %107 = bitcast <8 x i32> %106 to <4 x i64>
  %108 = shufflevector <4 x i64> %107, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %109 = bitcast <8 x i64> %108 to <16 x i32>
  %110 = icmp sgt <16 x i32> %109, <i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 645, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %111 = select <16 x i1> %110, <16 x i32> <i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 -64, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %112 = shufflevector <16 x i32> %111, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %113 = shufflevector <16 x i32> %112, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %114 = shl <16 x i32> %113, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %115 = bitcast <8 x double> %0 to <16 x i32>
  %116 = add <16 x i32> %114, %115
  %117 = bitcast <16 x i32> %116 to <8 x double>
  %118 = ashr <8 x i32> %106, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %119 = bitcast <8 x i32> %118 to <4 x i64>
  %120 = xor <4 x i64> %119, <i64 -1, i64 -1, i64 -1, i64 -1>
  %121 = and <4 x i64> %120, %107
  %122 = bitcast <4 x i64> %121 to <8 x i32>
  %123 = shl <8 x i32> %122, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %124 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast ([0 x double]* @rempitabdp to i8*), <8 x i32> %123, i8 -1, i32 8) #7, !noalias !24
  %125 = bitcast <16 x i32> %116 to <8 x i64>
  %126 = and <8 x i64> %125, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %127 = bitcast <8 x i64> %126 to <8 x double>
  %128 = fsub <8 x double> %117, %127
  %129 = bitcast <8 x double> %124 to <8 x i64>
  %130 = and <8 x i64> %129, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %131 = bitcast <8 x i64> %130 to <8 x double>
  %132 = fsub <8 x double> %124, %131
  %133 = fmul <8 x double> %124, %117
  %134 = fmul <8 x double> %131, %127
  %135 = bitcast <8 x double> %133 to <8 x i64>
  %136 = xor <8 x i64> %135, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %137 = bitcast <8 x i64> %136 to <8 x double>
  %138 = fmul <8 x double> %128, %131
  %139 = fmul <8 x double> %132, %127
  %140 = fmul <8 x double> %132, %128
  %141 = fadd <8 x double> %134, %137
  %142 = fadd <8 x double> %138, %141
  %143 = fadd <8 x double> %139, %142
  %144 = fadd <8 x double> %140, %143
  %145 = fmul <8 x double> %133, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %146 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %145, i32 8, <8 x double> %145, i8 -1, i32 4) #7
  %147 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %133, i32 8, <8 x double> %133, i8 -1, i32 4) #7
  %148 = fmul <8 x double> %147, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %149 = fsub <8 x double> %146, %148
  %150 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %149, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %151 = fmul <8 x double> %146, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %152 = fsub <8 x double> %133, %151
  %153 = fadd <8 x double> %152, %144
  %154 = fsub <8 x double> %152, %153
  %155 = fadd <8 x double> %144, %154
  %156 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 1) to i8*), <8 x i32> %123, i8 -1, i32 8) #7, !noalias !24
  %157 = bitcast <8 x double> %156 to <8 x i64>
  %158 = and <8 x i64> %157, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %159 = bitcast <8 x i64> %158 to <8 x double>
  %160 = fsub <8 x double> %156, %159
  %161 = fmul <8 x double> %156, %117
  %162 = fmul <8 x double> %159, %127
  %163 = bitcast <8 x double> %161 to <8 x i64>
  %164 = xor <8 x i64> %163, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %165 = bitcast <8 x i64> %164 to <8 x double>
  %166 = fmul <8 x double> %128, %159
  %167 = fmul <8 x double> %160, %127
  %168 = fmul <8 x double> %160, %128
  %169 = fadd <8 x double> %162, %165
  %170 = fadd <8 x double> %166, %169
  %171 = fadd <8 x double> %167, %170
  %172 = fadd <8 x double> %168, %171
  %173 = fadd <8 x double> %161, %153
  %174 = fsub <8 x double> %173, %153
  %175 = fsub <8 x double> %173, %174
  %176 = fsub <8 x double> %153, %175
  %177 = fsub <8 x double> %161, %174
  %178 = fadd <8 x double> %177, %176
  %179 = fadd <8 x double> %172, %155
  %180 = fadd <8 x double> %179, %178
  %181 = fmul <8 x double> %173, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %182 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %181, i32 8, <8 x double> %181, i8 -1, i32 4) #7
  %183 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %173, i32 8, <8 x double> %173, i8 -1, i32 4) #7
  %184 = fmul <8 x double> %183, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %185 = fsub <8 x double> %182, %184
  %186 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %185, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %187 = fmul <8 x double> %182, <double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01, double 2.500000e-01>
  %188 = fsub <8 x double> %173, %187
  %189 = add <8 x i32> %186, %150
  %190 = fadd <8 x double> %188, %180
  %191 = fsub <8 x double> %188, %190
  %192 = fadd <8 x double> %180, %191
  %193 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 2) to i8*), <8 x i32> %123, i8 -1, i32 8) #7, !noalias !24
  %194 = tail call <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double> zeroinitializer, i8* bitcast (double* getelementptr inbounds ([0 x double], [0 x double]* @rempitabdp, i64 0, i64 3) to i8*), <8 x i32> %123, i8 -1, i32 8) #7, !noalias !24
  %195 = bitcast <8 x double> %193 to <8 x i64>
  %196 = and <8 x i64> %195, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %197 = bitcast <8 x i64> %196 to <8 x double>
  %198 = fsub <8 x double> %193, %197
  %199 = fmul <8 x double> %193, %117
  %200 = fmul <8 x double> %197, %127
  %201 = bitcast <8 x double> %199 to <8 x i64>
  %202 = xor <8 x i64> %201, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %203 = bitcast <8 x i64> %202 to <8 x double>
  %204 = fmul <8 x double> %198, %127
  %205 = fmul <8 x double> %128, %197
  %206 = fmul <8 x double> %198, %128
  %207 = fmul <8 x double> %194, %117
  %208 = fadd <8 x double> %200, %203
  %209 = fadd <8 x double> %204, %208
  %210 = fadd <8 x double> %205, %209
  %211 = fadd <8 x double> %206, %210
  %212 = fadd <8 x double> %207, %211
  %213 = fadd <8 x double> %199, %190
  %214 = fsub <8 x double> %213, %190
  %215 = fsub <8 x double> %213, %214
  %216 = fsub <8 x double> %190, %215
  %217 = fsub <8 x double> %199, %214
  %218 = fadd <8 x double> %217, %216
  %219 = fadd <8 x double> %212, %192
  %220 = fadd <8 x double> %219, %218
  %221 = fadd <8 x double> %213, %220
  %222 = fsub <8 x double> %213, %221
  %223 = fadd <8 x double> %220, %222
  %224 = bitcast <8 x double> %221 to <8 x i64>
  %225 = and <8 x i64> %224, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %226 = bitcast <8 x i64> %225 to <8 x double>
  %227 = fsub <8 x double> %221, %226
  %228 = fmul <8 x double> %221, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %229 = fmul <8 x double> %226, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %230 = bitcast <8 x double> %228 to <8 x i64>
  %231 = xor <8 x i64> %230, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %232 = bitcast <8 x i64> %231 to <8 x double>
  %233 = fmul <8 x double> %227, <double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000, double 0x401921FB50000000>
  %234 = fmul <8 x double> %226, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %235 = fmul <8 x double> %227, <double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000, double 0x3E7110B460000000>
  %236 = fmul <8 x double> %221, <double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07, double 0x3CB1A62633145C07>
  %237 = fmul <8 x double> %223, <double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18, double 0x401921FB54442D18>
  %238 = fadd <8 x double> %229, %232
  %239 = fadd <8 x double> %233, %238
  %240 = fadd <8 x double> %234, %239
  %241 = fadd <8 x double> %235, %240
  %242 = fadd <8 x double> %236, %241
  %243 = fadd <8 x double> %237, %242
  %244 = and <8 x i64> %125, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %245 = bitcast <8 x i64> %244 to <8 x double>
  %246 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %245, <8 x double> <double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666, double 0x3FE6666666666666>, i32 17, i8 -1, i32 4) #7
  %247 = bitcast i8 %246 to <8 x i1>
  %248 = select <8 x i1> %247, <8 x double> %117, <8 x double> %228
  %249 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %250 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %251 = or i8 %250, %249
  %252 = bitcast i8 %251 to <8 x i1>
  %253 = select <8 x i1> %252, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %248
  %254 = select <8 x i1> %247, <8 x double> zeroinitializer, <8 x double> %243
  %255 = select <8 x i1> %252, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %254
  br label %256

; <label>:256:                                    ; preds = %20, %99, %7
  %257 = phi <8 x double> [ %253, %99 ], [ %95, %20 ], [ %14, %7 ]
  %258 = phi <8 x double> [ %255, %99 ], [ %98, %20 ], [ %16, %7 ]
  %259 = phi <8 x i32> [ %189, %99 ], [ %54, %20 ], [ %10, %7 ]
  %260 = bitcast <8 x i32> %259 to <4 x i64>
  %261 = fmul <8 x double> %257, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %262 = fmul <8 x double> %258, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %263 = bitcast <8 x double> %261 to <8 x i64>
  %264 = and <8 x i64> %263, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %265 = bitcast <8 x i64> %264 to <8 x double>
  %266 = fsub <8 x double> %261, %265
  %267 = fmul <8 x double> %261, %261
  %268 = fmul <8 x double> %265, %265
  %269 = bitcast <8 x double> %267 to <8 x i64>
  %270 = xor <8 x i64> %269, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %271 = bitcast <8 x i64> %270 to <8 x double>
  %272 = fadd <8 x double> %265, %265
  %273 = fmul <8 x double> %272, %266
  %274 = fmul <8 x double> %266, %266
  %275 = fadd <8 x double> %262, %262
  %276 = fmul <8 x double> %261, %275
  %277 = fadd <8 x double> %268, %271
  %278 = fadd <8 x double> %277, %273
  %279 = fadd <8 x double> %274, %278
  %280 = fadd <8 x double> %276, %279
  %281 = fmul <8 x double> %267, %267
  %282 = fmul <8 x double> %281, %281
  %283 = fmul <8 x double> %267, <double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED, double 0x3F35445F555134ED>
  %284 = fadd <8 x double> %283, <double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF, double 0x3F4269BE400DE3AF>
  %285 = fmul <8 x double> %267, <double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93, double 0x3F57EEF631E20B93>
  %286 = fadd <8 x double> %285, <double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959, double 0x3F6D6C27C371C959>
  %287 = fmul <8 x double> %281, %284
  %288 = fadd <8 x double> %286, %287
  %289 = fmul <8 x double> %267, <double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090, double 0x3F8226E7BFA35090>
  %290 = fadd <8 x double> %289, <double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5, double 0x3F9664F4729F98E5>
  %291 = fmul <8 x double> %267, <double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06, double 0x3FABA1BA1BDCEC06>
  %292 = fadd <8 x double> %291, <double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933, double 0x3FC111111110E933>
  %293 = fmul <8 x double> %281, %290
  %294 = fadd <8 x double> %292, %293
  %295 = fmul <8 x double> %282, %288
  %296 = fadd <8 x double> %294, %295
  %297 = fmul <8 x double> %267, %296
  %298 = fadd <8 x double> %297, <double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568, double 0x3FD5555555555568>
  %299 = and <8 x i64> %269, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %300 = bitcast <8 x i64> %299 to <8 x double>
  %301 = fsub <8 x double> %267, %300
  %302 = fmul <8 x double> %261, %267
  %303 = fmul <8 x double> %265, %300
  %304 = bitcast <8 x double> %302 to <8 x i64>
  %305 = xor <8 x i64> %304, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %306 = bitcast <8 x i64> %305 to <8 x double>
  %307 = fmul <8 x double> %301, %265
  %308 = fmul <8 x double> %266, %300
  %309 = fmul <8 x double> %266, %301
  %310 = fmul <8 x double> %267, %262
  %311 = fmul <8 x double> %261, %280
  %312 = fadd <8 x double> %303, %306
  %313 = fadd <8 x double> %307, %312
  %314 = fadd <8 x double> %308, %313
  %315 = fadd <8 x double> %309, %314
  %316 = fadd <8 x double> %310, %315
  %317 = fadd <8 x double> %311, %316
  %318 = and <8 x i64> %304, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %319 = bitcast <8 x i64> %318 to <8 x double>
  %320 = fsub <8 x double> %302, %319
  %321 = bitcast <8 x double> %298 to <8 x i64>
  %322 = and <8 x i64> %321, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %323 = bitcast <8 x i64> %322 to <8 x double>
  %324 = fsub <8 x double> %298, %323
  %325 = fmul <8 x double> %302, %298
  %326 = fmul <8 x double> %319, %323
  %327 = bitcast <8 x double> %325 to <8 x i64>
  %328 = xor <8 x i64> %327, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %329 = bitcast <8 x i64> %328 to <8 x double>
  %330 = fmul <8 x double> %320, %323
  %331 = fmul <8 x double> %324, %319
  %332 = fmul <8 x double> %320, %324
  %333 = fmul <8 x double> %298, %317
  %334 = fadd <8 x double> %326, %329
  %335 = fadd <8 x double> %330, %334
  %336 = fadd <8 x double> %331, %335
  %337 = fadd <8 x double> %332, %336
  %338 = fadd <8 x double> %333, %337
  %339 = fadd <8 x double> %261, %325
  %340 = fsub <8 x double> %261, %339
  %341 = fadd <8 x double> %325, %340
  %342 = fadd <8 x double> %262, %341
  %343 = fadd <8 x double> %342, %338
  %344 = bitcast <8 x double> %339 to <8 x i64>
  %345 = and <8 x i64> %344, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %346 = bitcast <8 x i64> %345 to <8 x double>
  %347 = fsub <8 x double> %339, %346
  %348 = fmul <8 x double> %339, %339
  %349 = fmul <8 x double> %346, %346
  %350 = bitcast <8 x double> %348 to <8 x i64>
  %351 = xor <8 x i64> %350, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %352 = bitcast <8 x i64> %351 to <8 x double>
  %353 = fadd <8 x double> %346, %346
  %354 = fmul <8 x double> %353, %347
  %355 = fmul <8 x double> %347, %347
  %356 = fadd <8 x double> %343, %343
  %357 = fmul <8 x double> %339, %356
  %358 = fadd <8 x double> %349, %352
  %359 = fadd <8 x double> %358, %354
  %360 = fadd <8 x double> %355, %359
  %361 = fadd <8 x double> %360, %357
  %362 = fadd <8 x double> %348, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %363 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %362
  %364 = fadd <8 x double> %348, %363
  %365 = fadd <8 x double> %364, %361
  %366 = fmul <8 x double> %339, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %367 = fmul <8 x double> %343, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %368 = and <4 x i64> %260, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %369 = shufflevector <4 x i64> %368, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %370 = bitcast <8 x i64> %369 to <16 x i32>
  %371 = icmp eq <16 x i32> %370, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %372 = bitcast <8 x double> %362 to <8 x i64>
  %373 = xor <8 x i64> %372, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %374 = bitcast <8 x double> %365 to <8 x i64>
  %375 = xor <8 x i64> %374, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %376 = bitcast <8 x i64> %373 to <8 x double>
  %377 = bitcast <8 x i64> %375 to <8 x double>
  %378 = bitcast <16 x i1> %371 to <2 x i8>
  %379 = extractelement <2 x i8> %378, i32 0
  %380 = bitcast i8 %379 to <8 x i1>
  %381 = select <8 x i1> %380, <8 x double> %376, <8 x double> %366
  %382 = select <8 x i1> %380, <8 x double> %377, <8 x double> %367
  %383 = select <8 x i1> %380, <8 x double> %366, <8 x double> %362
  %384 = select <8 x i1> %380, <8 x double> %367, <8 x double> %365
  %385 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %383
  %386 = bitcast <8 x double> %383 to <8 x i64>
  %387 = and <8 x i64> %386, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %388 = bitcast <8 x i64> %387 to <8 x double>
  %389 = fsub <8 x double> %383, %388
  %390 = bitcast <8 x double> %385 to <8 x i64>
  %391 = and <8 x i64> %390, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %392 = bitcast <8 x i64> %391 to <8 x double>
  %393 = fsub <8 x double> %385, %392
  %394 = bitcast <8 x double> %381 to <8 x i64>
  %395 = and <8 x i64> %394, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %396 = bitcast <8 x i64> %395 to <8 x double>
  %397 = fsub <8 x double> %381, %396
  %398 = fmul <8 x double> %385, %381
  %399 = fmul <8 x double> %392, %396
  %400 = fsub <8 x double> %399, %398
  %401 = fmul <8 x double> %393, %396
  %402 = fmul <8 x double> %397, %392
  %403 = fmul <8 x double> %393, %397
  %404 = fmul <8 x double> %388, %392
  %405 = fmul <8 x double> %393, %388
  %406 = fmul <8 x double> %389, %392
  %407 = fmul <8 x double> %389, %393
  %408 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %404
  %409 = fsub <8 x double> %408, %405
  %410 = fsub <8 x double> %409, %406
  %411 = fsub <8 x double> %410, %407
  %412 = fmul <8 x double> %398, %411
  %413 = fadd <8 x double> %401, %400
  %414 = fadd <8 x double> %402, %413
  %415 = fadd <8 x double> %403, %414
  %416 = fadd <8 x double> %412, %415
  %417 = fmul <8 x double> %398, %384
  %418 = fsub <8 x double> %382, %417
  %419 = fmul <8 x double> %385, %418
  %420 = fadd <8 x double> %416, %419
  %421 = fadd <8 x double> %398, %420
  %422 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %423 = bitcast i8 %422 to <8 x i1>
  %424 = select <8 x i1> %423, <8 x double> %0, <8 x double> %421
  ret <8 x double> %424
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_atan2d8_u35avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = icmp slt <8 x i64> %6, zeroinitializer
  %8 = shufflevector <8 x i1> %7, <8 x i1> <i1 false, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %9 = select <16 x i1> %8, <16 x i32> <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %10 = bitcast <16 x i32> %9 to <8 x i64>
  %11 = shufflevector <8 x i64> %10, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %12 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <8 x i64> %12 to <8 x double>
  %14 = bitcast <4 x i64> %11 to <8 x i32>
  %15 = add <8 x i32> %14, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %16 = bitcast <8 x i32> %15 to <4 x i64>
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> %5, i32 17, i8 -1, i32 4) #7
  %18 = zext i8 %17 to i16
  %19 = shufflevector <4 x i64> %16, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %20 = bitcast <8 x i64> %19 to <16 x i32>
  %21 = bitcast i16 %18 to <16 x i1>
  %22 = select <16 x i1> %21, <16 x i32> %20, <16 x i32> %9
  %23 = bitcast <16 x i32> %22 to <8 x i64>
  %24 = shufflevector <8 x i64> %23, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %25 = or <8 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = bitcast i8 %17 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x i64> %25, <8 x i64> %4
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %13, <8 x double> %5, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %30 = fdiv <8 x double> %28, %29
  %31 = fmul <8 x double> %30, %30
  %32 = fmul <8 x double> %31, %31
  %33 = fmul <8 x double> %32, %32
  %34 = fmul <8 x double> %33, %33
  %35 = fmul <8 x double> %34, %34
  %36 = fmul <8 x double> %31, <double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF>
  %37 = fadd <8 x double> %36, <double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA>
  %38 = fmul <8 x double> %32, <double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F>
  %39 = fadd <8 x double> %38, %37
  %40 = fmul <8 x double> %31, <double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20>
  %41 = fadd <8 x double> %40, <double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56>
  %42 = fmul <8 x double> %31, <double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286>
  %43 = fadd <8 x double> %42, <double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC>
  %44 = fmul <8 x double> %32, %41
  %45 = fadd <8 x double> %43, %44
  %46 = fmul <8 x double> %31, <double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E>
  %47 = fadd <8 x double> %46, <double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638>
  %48 = fmul <8 x double> %31, <double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE>
  %49 = fadd <8 x double> %48, <double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA>
  %50 = fmul <8 x double> %32, %47
  %51 = fadd <8 x double> %49, %50
  %52 = fmul <8 x double> %33, %45
  %53 = fadd <8 x double> %51, %52
  %54 = fmul <8 x double> %31, <double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622>
  %55 = fadd <8 x double> %54, <double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0>
  %56 = fmul <8 x double> %31, <double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1>
  %57 = fadd <8 x double> %56, <double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8>
  %58 = fmul <8 x double> %32, %55
  %59 = fadd <8 x double> %57, %58
  %60 = fmul <8 x double> %31, <double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F>
  %61 = fadd <8 x double> %60, <double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB>
  %62 = fmul <8 x double> %31, <double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD>
  %63 = fadd <8 x double> %62, <double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5>
  %64 = fmul <8 x double> %32, %61
  %65 = fadd <8 x double> %63, %64
  %66 = fmul <8 x double> %33, %59
  %67 = fadd <8 x double> %65, %66
  %68 = fmul <8 x double> %34, %53
  %69 = fadd <8 x double> %67, %68
  %70 = fmul <8 x double> %39, %35
  %71 = fadd <8 x double> %70, %69
  %72 = fmul <8 x double> %31, %71
  %73 = fmul <8 x double> %30, %72
  %74 = fadd <8 x double> %30, %73
  %75 = bitcast <4 x i64> %24 to <8 x i32>
  %76 = sitofp <8 x i32> %75 to <8 x double>
  %77 = fmul <8 x double> %76, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %78 = fadd <8 x double> %77, %74
  %79 = bitcast <8 x double> %78 to <8 x i64>
  %80 = and <8 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %81 = xor <8 x i64> %80, %79
  %82 = bitcast <8 x i64> %81 to <8 x double>
  %83 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %84 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %85 = or i8 %84, %83
  %86 = or <8 x i64> %80, <i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352>
  %87 = bitcast i8 %83 to <8 x i1>
  %88 = bitcast <8 x i64> %86 to <8 x double>
  %89 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %88
  %90 = select <8 x i1> %87, <8 x double> %89, <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %91 = bitcast i8 %85 to <8 x i1>
  %92 = select <8 x i1> %91, <8 x double> %90, <8 x double> %82
  %93 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %94 = or <8 x i64> %80, <i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856>
  %95 = bitcast <8 x i64> %94 to <8 x double>
  %96 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %95
  %97 = select <8 x i1> %87, <8 x double> %96, <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %98 = bitcast i8 %93 to <8 x i1>
  %99 = select <8 x i1> %98, <8 x double> %97, <8 x double> %92
  %100 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %101 = ashr <8 x i64> %6, <i64 63, i64 63, i64 63, i64 63, i64 63, i64 63, i64 63, i64 63>
  %102 = and <8 x i64> %101, <i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848>
  %103 = bitcast i8 %100 to <8 x i1>
  %104 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %105 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %106 = or i8 %105, %104
  %107 = bitcast <8 x double> %99 to <8 x i64>
  %108 = select <8 x i1> %103, <8 x i64> %102, <8 x i64> %107
  %109 = and <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %110 = xor <8 x i64> %108, %109
  %111 = bitcast i8 %106 to <8 x i1>
  %112 = bitcast <8 x i64> %110 to <8 x double>
  %113 = select <8 x i1> %111, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %112
  ret <8 x double> %113
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_atan2d8_u10avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %1 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001, double 0x4000000000001>, i32 17, i8 -1, i32 4) #7
  %7 = fmul <8 x double> %1, <double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000>
  %8 = bitcast i8 %6 to <8 x i1>
  %9 = select <8 x i1> %8, <8 x double> %7, <8 x double> %1
  %10 = fmul <8 x double> %0, <double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000, double 0x4340000000000000>
  %11 = select <8 x i1> %8, <8 x double> %10, <8 x double> %0
  %12 = bitcast <8 x double> %11 to <8 x i64>
  %13 = and <8 x i64> %12, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %14 = bitcast <8 x i64> %13 to <8 x double>
  %15 = bitcast <8 x double> %9 to <8 x i64>
  %16 = icmp slt <8 x i64> %15, zeroinitializer
  %17 = shufflevector <8 x i1> %16, <8 x i1> <i1 false, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %18 = select <16 x i1> %17, <16 x i32> <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %19 = bitcast <16 x i32> %18 to <8 x i64>
  %20 = shufflevector <8 x i64> %19, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %21 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %22 = bitcast i8 %21 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %24 = xor <8 x i64> %23, %15
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = bitcast <8 x i64> %23 to <8 x double>
  %27 = bitcast <4 x i64> %20 to <8 x i32>
  %28 = add <8 x i32> %27, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %29 = bitcast <8 x i32> %28 to <4 x i64>
  %30 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %25, <8 x double> %14, i32 17, i8 -1, i32 4) #7
  %31 = zext i8 %30 to i16
  %32 = shufflevector <4 x i64> %29, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %33 = bitcast <8 x i64> %32 to <16 x i32>
  %34 = bitcast i16 %31 to <16 x i1>
  %35 = select <16 x i1> %34, <16 x i32> %33, <16 x i32> %18
  %36 = bitcast <16 x i32> %35 to <8 x i64>
  %37 = shufflevector <8 x i64> %36, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %38 = xor <8 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %39 = xor <8 x i64> %23, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %40 = bitcast <8 x i64> %39 to <8 x double>
  %41 = bitcast i8 %30 to <8 x i1>
  %42 = select <8 x i1> %41, <8 x i64> %38, <8 x i64> %13
  %43 = bitcast <8 x i64> %42 to <8 x double>
  %44 = select <8 x i1> %41, <8 x double> %40, <8 x double> zeroinitializer
  %45 = select <8 x i1> %41, <8 x i64> %13, <8 x i64> %24
  %46 = bitcast <8 x i64> %45 to <8 x double>
  %47 = select <8 x i1> %41, <8 x double> zeroinitializer, <8 x double> %26
  %48 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %46
  %49 = and <8 x i64> %45, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fsub <8 x double> %46, %50
  %52 = bitcast <8 x double> %48 to <8 x i64>
  %53 = and <8 x i64> %52, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %54 = bitcast <8 x i64> %53 to <8 x double>
  %55 = fsub <8 x double> %48, %54
  %56 = and <8 x i64> %42, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %57 = bitcast <8 x i64> %56 to <8 x double>
  %58 = fsub <8 x double> %43, %57
  %59 = fmul <8 x double> %48, %43
  %60 = fmul <8 x double> %57, %54
  %61 = fsub <8 x double> %60, %59
  %62 = fmul <8 x double> %55, %57
  %63 = fmul <8 x double> %58, %54
  %64 = fmul <8 x double> %58, %55
  %65 = fmul <8 x double> %50, %54
  %66 = fmul <8 x double> %55, %50
  %67 = fmul <8 x double> %51, %54
  %68 = fmul <8 x double> %51, %55
  %69 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %65
  %70 = fsub <8 x double> %69, %66
  %71 = fsub <8 x double> %70, %67
  %72 = fsub <8 x double> %71, %68
  %73 = fmul <8 x double> %59, %72
  %74 = fadd <8 x double> %61, %62
  %75 = fadd <8 x double> %63, %74
  %76 = fadd <8 x double> %64, %75
  %77 = fadd <8 x double> %76, %73
  %78 = fmul <8 x double> %47, %59
  %79 = fsub <8 x double> %44, %78
  %80 = fmul <8 x double> %48, %79
  %81 = fadd <8 x double> %80, %77
  %82 = bitcast <8 x double> %59 to <8 x i64>
  %83 = and <8 x i64> %82, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %84 = bitcast <8 x i64> %83 to <8 x double>
  %85 = fsub <8 x double> %59, %84
  %86 = fmul <8 x double> %59, %59
  %87 = fmul <8 x double> %84, %84
  %88 = bitcast <8 x double> %86 to <8 x i64>
  %89 = xor <8 x i64> %88, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %90 = bitcast <8 x i64> %89 to <8 x double>
  %91 = fadd <8 x double> %84, %84
  %92 = fmul <8 x double> %91, %85
  %93 = fmul <8 x double> %85, %85
  %94 = fadd <8 x double> %81, %81
  %95 = fmul <8 x double> %59, %94
  %96 = fadd <8 x double> %87, %90
  %97 = fadd <8 x double> %96, %92
  %98 = fadd <8 x double> %93, %97
  %99 = fadd <8 x double> %98, %95
  %100 = fadd <8 x double> %86, %99
  %101 = fsub <8 x double> %86, %100
  %102 = fadd <8 x double> %99, %101
  %103 = fmul <8 x double> %100, %100
  %104 = fmul <8 x double> %103, %103
  %105 = fmul <8 x double> %104, %104
  %106 = fmul <8 x double> %100, <double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72>
  %107 = fadd <8 x double> %106, <double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE>
  %108 = fmul <8 x double> %100, <double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98>
  %109 = fadd <8 x double> %108, <double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE>
  %110 = fmul <8 x double> %103, %107
  %111 = fadd <8 x double> %109, %110
  %112 = fmul <8 x double> %100, <double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3>
  %113 = fadd <8 x double> %112, <double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5>
  %114 = fmul <8 x double> %100, <double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320>
  %115 = fadd <8 x double> %114, <double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7>
  %116 = fmul <8 x double> %103, %113
  %117 = fadd <8 x double> %115, %116
  %118 = fmul <8 x double> %104, %111
  %119 = fadd <8 x double> %117, %118
  %120 = fmul <8 x double> %100, <double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD>
  %121 = fadd <8 x double> %120, <double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577>
  %122 = fmul <8 x double> %100, <double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6>
  %123 = fadd <8 x double> %122, <double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E>
  %124 = fmul <8 x double> %103, %121
  %125 = fadd <8 x double> %123, %124
  %126 = fmul <8 x double> %100, <double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B>
  %127 = fadd <8 x double> %126, <double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6>
  %128 = fmul <8 x double> %100, <double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10>
  %129 = fadd <8 x double> %128, <double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC>
  %130 = fmul <8 x double> %103, %127
  %131 = fadd <8 x double> %129, %130
  %132 = fmul <8 x double> %104, %125
  %133 = fadd <8 x double> %131, %132
  %134 = fmul <8 x double> %105, %119
  %135 = fadd <8 x double> %133, %134
  %136 = fmul <8 x double> %100, %135
  %137 = fadd <8 x double> %136, <double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B>
  %138 = fmul <8 x double> %100, %137
  %139 = fadd <8 x double> %138, <double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7>
  %140 = fmul <8 x double> %100, %139
  %141 = fadd <8 x double> %140, <double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0>
  %142 = fmul <8 x double> %100, %141
  %143 = fadd <8 x double> %142, <double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A>
  %144 = bitcast <8 x double> %100 to <8 x i64>
  %145 = and <8 x i64> %144, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fsub <8 x double> %100, %146
  %148 = fmul <8 x double> %59, %100
  %149 = fmul <8 x double> %84, %146
  %150 = bitcast <8 x double> %148 to <8 x i64>
  %151 = xor <8 x i64> %150, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %152 = bitcast <8 x i64> %151 to <8 x double>
  %153 = fmul <8 x double> %85, %146
  %154 = fmul <8 x double> %147, %84
  %155 = fmul <8 x double> %85, %147
  %156 = fmul <8 x double> %59, %102
  %157 = fmul <8 x double> %81, %100
  %158 = fadd <8 x double> %149, %152
  %159 = fadd <8 x double> %153, %158
  %160 = fadd <8 x double> %154, %159
  %161 = fadd <8 x double> %155, %160
  %162 = fadd <8 x double> %156, %161
  %163 = fadd <8 x double> %157, %162
  %164 = and <8 x i64> %150, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %165 = bitcast <8 x i64> %164 to <8 x double>
  %166 = fsub <8 x double> %148, %165
  %167 = bitcast <8 x double> %143 to <8 x i64>
  %168 = and <8 x i64> %167, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %169 = bitcast <8 x i64> %168 to <8 x double>
  %170 = fsub <8 x double> %143, %169
  %171 = fmul <8 x double> %148, %143
  %172 = fmul <8 x double> %165, %169
  %173 = bitcast <8 x double> %171 to <8 x i64>
  %174 = xor <8 x i64> %173, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %175 = bitcast <8 x i64> %174 to <8 x double>
  %176 = fmul <8 x double> %166, %169
  %177 = fmul <8 x double> %170, %165
  %178 = fmul <8 x double> %166, %170
  %179 = fmul <8 x double> %163, %143
  %180 = fadd <8 x double> %172, %175
  %181 = fadd <8 x double> %176, %180
  %182 = fadd <8 x double> %177, %181
  %183 = fadd <8 x double> %178, %182
  %184 = fadd <8 x double> %179, %183
  %185 = fadd <8 x double> %59, %171
  %186 = fsub <8 x double> %59, %185
  %187 = fadd <8 x double> %171, %186
  %188 = fadd <8 x double> %81, %187
  %189 = fadd <8 x double> %188, %184
  %190 = bitcast <4 x i64> %37 to <8 x i32>
  %191 = sitofp <8 x i32> %190 to <8 x double>
  %192 = bitcast <8 x double> %191 to <8 x i64>
  %193 = and <8 x i64> %192, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %194 = bitcast <8 x i64> %193 to <8 x double>
  %195 = fsub <8 x double> %191, %194
  %196 = fmul <8 x double> %191, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %197 = fmul <8 x double> %194, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %198 = bitcast <8 x double> %196 to <8 x i64>
  %199 = xor <8 x i64> %198, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %200 = bitcast <8 x i64> %199 to <8 x double>
  %201 = fmul <8 x double> %194, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %202 = fmul <8 x double> %195, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %203 = fmul <8 x double> %195, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %204 = fmul <8 x double> %191, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %205 = fadd <8 x double> %197, %200
  %206 = fadd <8 x double> %201, %205
  %207 = fadd <8 x double> %202, %206
  %208 = fadd <8 x double> %203, %207
  %209 = fadd <8 x double> %204, %208
  %210 = fadd <8 x double> %196, %185
  %211 = fsub <8 x double> %196, %210
  %212 = fadd <8 x double> %185, %211
  %213 = fadd <8 x double> %209, %212
  %214 = fadd <8 x double> %213, %189
  %215 = fadd <8 x double> %210, %214
  %216 = bitcast <8 x double> %215 to <8 x i64>
  %217 = and <8 x i64> %15, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %218 = xor <8 x i64> %217, %216
  %219 = bitcast <8 x i64> %218 to <8 x double>
  %220 = and <8 x i64> %15, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %221 = bitcast <8 x i64> %220 to <8 x double>
  %222 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %221, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %223 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %224 = or i8 %223, %222
  %225 = or <8 x i64> %217, <i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352>
  %226 = bitcast i8 %222 to <8 x i1>
  %227 = bitcast <8 x i64> %225 to <8 x double>
  %228 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %227
  %229 = select <8 x i1> %226, <8 x double> %228, <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %230 = bitcast i8 %224 to <8 x i1>
  %231 = select <8 x i1> %230, <8 x double> %229, <8 x double> %219
  %232 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %14, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %233 = or <8 x i64> %217, <i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856, i64 4605249457297304856>
  %234 = bitcast <8 x i64> %233 to <8 x double>
  %235 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %234
  %236 = select <8 x i1> %226, <8 x double> %235, <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %237 = bitcast i8 %232 to <8 x i1>
  %238 = select <8 x i1> %237, <8 x double> %236, <8 x double> %231
  %239 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %11, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %240 = ashr <8 x i64> %15, <i64 63, i64 63, i64 63, i64 63, i64 63, i64 63, i64 63, i64 63>
  %241 = and <8 x i64> %240, <i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848, i64 4614256656552045848>
  %242 = bitcast i8 %239 to <8 x i1>
  %243 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> %9, i32 4, i8 -1, i32 4) #7
  %244 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %11, <8 x double> %11, i32 4, i8 -1, i32 4) #7
  %245 = or i8 %244, %243
  %246 = bitcast <8 x double> %238 to <8 x i64>
  %247 = select <8 x i1> %242, <8 x i64> %241, <8 x i64> %246
  %248 = and <8 x i64> %12, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %249 = xor <8 x i64> %247, %248
  %250 = bitcast i8 %245 to <8 x i1>
  %251 = bitcast <8 x i64> %249 to <8 x double>
  %252 = select <8 x i1> %250, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %251
  ret <8 x double> %252
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_asind8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, %0
  %7 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %8 = fmul <8 x double> %7, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %9 = bitcast i8 %5 to <8 x i1>
  %10 = select <8 x i1> %9, <8 x double> %6, <8 x double> %8
  %11 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %12 = select <8 x i1> %9, <8 x double> %4, <8 x double> %11
  %13 = fmul <8 x double> %10, %10
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %14, %14
  %16 = fmul <8 x double> %10, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %17 = fadd <8 x double> %16, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %18 = fmul <8 x double> %10, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %19 = fadd <8 x double> %18, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %20 = fmul <8 x double> %13, %17
  %21 = fadd <8 x double> %19, %20
  %22 = fmul <8 x double> %10, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %23 = fadd <8 x double> %22, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %24 = fmul <8 x double> %10, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %25 = fadd <8 x double> %24, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %26 = fmul <8 x double> %13, %23
  %27 = fadd <8 x double> %25, %26
  %28 = fmul <8 x double> %10, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %29 = fadd <8 x double> %28, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %30 = fmul <8 x double> %10, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %31 = fadd <8 x double> %30, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %32 = fmul <8 x double> %13, %29
  %33 = fadd <8 x double> %31, %32
  %34 = fmul <8 x double> %14, %27
  %35 = fadd <8 x double> %33, %34
  %36 = fmul <8 x double> %15, %21
  %37 = fadd <8 x double> %36, %35
  %38 = fmul <8 x double> %12, %10
  %39 = fmul <8 x double> %38, %37
  %40 = fadd <8 x double> %12, %39
  %41 = fmul <8 x double> %40, <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %42 = fadd <8 x double> %41, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %43 = select <8 x i1> %9, <8 x double> %40, <8 x double> %42
  %44 = bitcast <8 x double> %43 to <8 x i64>
  %45 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %46 = xor <8 x i64> %45, %44
  %47 = bitcast <8 x i64> %46 to <8 x double>
  ret <8 x double> %47
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_asind8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, %0
  %7 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %8 = fmul <8 x double> %7, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %9 = bitcast i8 %5 to <8 x i1>
  %10 = select <8 x i1> %9, <8 x double> %6, <8 x double> %8
  %11 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %12 = bitcast <8 x double> %11 to <8 x i64>
  %13 = and <8 x i64> %12, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %14 = bitcast <8 x i64> %13 to <8 x double>
  %15 = fsub <8 x double> %11, %14
  %16 = fmul <8 x double> %11, %11
  %17 = fmul <8 x double> %14, %14
  %18 = bitcast <8 x double> %16 to <8 x i64>
  %19 = xor <8 x i64> %18, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = bitcast <8 x i64> %19 to <8 x double>
  %21 = fmul <8 x double> %15, %14
  %22 = fmul <8 x double> %15, %15
  %23 = fadd <8 x double> %17, %20
  %24 = fadd <8 x double> %21, %23
  %25 = fadd <8 x double> %21, %24
  %26 = fadd <8 x double> %22, %25
  %27 = fadd <8 x double> %16, %10
  %28 = fsub <8 x double> %27, %10
  %29 = fsub <8 x double> %27, %28
  %30 = fsub <8 x double> %10, %29
  %31 = fsub <8 x double> %16, %28
  %32 = fadd <8 x double> %31, %30
  %33 = fadd <8 x double> %32, %26
  %34 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %11
  %35 = bitcast <8 x double> %34 to <8 x i64>
  %36 = and <8 x i64> %35, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %37 = bitcast <8 x i64> %36 to <8 x double>
  %38 = fsub <8 x double> %34, %37
  %39 = fmul <8 x double> %14, %37
  %40 = fmul <8 x double> %38, %14
  %41 = fmul <8 x double> %15, %37
  %42 = fmul <8 x double> %15, %38
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %34, %46
  %48 = bitcast <8 x double> %27 to <8 x i64>
  %49 = and <8 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fsub <8 x double> %27, %50
  %52 = fmul <8 x double> %34, %27
  %53 = fmul <8 x double> %37, %50
  %54 = bitcast <8 x double> %52 to <8 x i64>
  %55 = xor <8 x i64> %54, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %56 = bitcast <8 x i64> %55 to <8 x double>
  %57 = fmul <8 x double> %51, %37
  %58 = fmul <8 x double> %38, %50
  %59 = fmul <8 x double> %38, %51
  %60 = fmul <8 x double> %27, %47
  %61 = fmul <8 x double> %34, %33
  %62 = fadd <8 x double> %53, %56
  %63 = fadd <8 x double> %57, %62
  %64 = fadd <8 x double> %58, %63
  %65 = fadd <8 x double> %59, %64
  %66 = fadd <8 x double> %65, %60
  %67 = fadd <8 x double> %61, %66
  %68 = fmul <8 x double> %52, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %69 = fmul <8 x double> %67, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %70 = select <8 x i1> %9, <8 x double> %4, <8 x double> %68
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %72 = bitcast i8 %71 to <8 x i1>
  %73 = select <8 x i1> %72, <8 x double> zeroinitializer, <8 x double> %70
  %74 = or i8 %71, %5
  %75 = bitcast i8 %74 to <8 x i1>
  %76 = select <8 x i1> %75, <8 x double> zeroinitializer, <8 x double> %69
  %77 = fmul <8 x double> %10, %10
  %78 = fmul <8 x double> %77, %77
  %79 = fmul <8 x double> %78, %78
  %80 = fmul <8 x double> %10, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %81 = fadd <8 x double> %80, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %82 = fmul <8 x double> %10, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %83 = fadd <8 x double> %82, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %84 = fmul <8 x double> %77, %81
  %85 = fadd <8 x double> %83, %84
  %86 = fmul <8 x double> %10, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %87 = fadd <8 x double> %86, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %88 = fmul <8 x double> %10, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %89 = fadd <8 x double> %88, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %90 = fmul <8 x double> %77, %87
  %91 = fadd <8 x double> %89, %90
  %92 = fmul <8 x double> %10, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %93 = fadd <8 x double> %92, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %94 = fmul <8 x double> %10, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %95 = fadd <8 x double> %94, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %96 = fmul <8 x double> %77, %93
  %97 = fadd <8 x double> %95, %96
  %98 = fmul <8 x double> %78, %91
  %99 = fadd <8 x double> %97, %98
  %100 = fmul <8 x double> %79, %85
  %101 = fadd <8 x double> %100, %99
  %102 = fmul <8 x double> %10, %73
  %103 = fmul <8 x double> %102, %101
  %104 = fsub <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %73
  %105 = fsub <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>, %104
  %106 = fsub <8 x double> %105, %73
  %107 = fadd <8 x double> %106, <double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07, double 0x3C81A62633145C07>
  %108 = fsub <8 x double> %107, %76
  %109 = fsub <8 x double> %104, %103
  %110 = fsub <8 x double> %104, %109
  %111 = fsub <8 x double> %110, %103
  %112 = fadd <8 x double> %111, %108
  %113 = fadd <8 x double> %73, %103
  %114 = fadd <8 x double> %109, %112
  %115 = fmul <8 x double> %114, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %116 = select <8 x i1> %9, <8 x double> %113, <8 x double> %115
  %117 = bitcast <8 x double> %116 to <8 x i64>
  %118 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %119 = xor <8 x i64> %118, %117
  %120 = bitcast <8 x i64> %119 to <8 x double>
  ret <8 x double> %120
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_acosd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i32 17, i8 -1, i32 4) #7
  %6 = zext i8 %5 to i16
  %7 = fmul <8 x double> %0, %0
  %8 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %9 = fmul <8 x double> %8, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = bitcast i8 %5 to <8 x i1>
  %11 = select <8 x i1> %10, <8 x double> %7, <8 x double> %9
  %12 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %13 = select <8 x i1> %10, <8 x double> %4, <8 x double> %12
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %15 = bitcast i8 %14 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> zeroinitializer, <8 x double> %13
  %17 = fmul <8 x double> %11, %11
  %18 = fmul <8 x double> %17, %17
  %19 = fmul <8 x double> %18, %18
  %20 = fmul <8 x double> %11, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %21 = fadd <8 x double> %20, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %22 = fmul <8 x double> %11, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %23 = fadd <8 x double> %22, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %24 = fmul <8 x double> %17, %21
  %25 = fadd <8 x double> %23, %24
  %26 = fmul <8 x double> %11, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %27 = fadd <8 x double> %26, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %28 = fmul <8 x double> %11, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %29 = fadd <8 x double> %28, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %30 = fmul <8 x double> %17, %27
  %31 = fadd <8 x double> %29, %30
  %32 = fmul <8 x double> %11, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %33 = fadd <8 x double> %32, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %34 = fmul <8 x double> %11, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %35 = fadd <8 x double> %34, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %36 = fmul <8 x double> %17, %33
  %37 = fadd <8 x double> %35, %36
  %38 = fmul <8 x double> %18, %31
  %39 = fadd <8 x double> %37, %38
  %40 = fmul <8 x double> %19, %25
  %41 = fadd <8 x double> %40, %39
  %42 = fmul <8 x double> %11, %16
  %43 = fmul <8 x double> %42, %41
  %44 = bitcast <8 x double> %16 to <8 x i64>
  %45 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %46 = xor <8 x i64> %45, %44
  %47 = bitcast <8 x i64> %46 to <8 x double>
  %48 = bitcast <8 x double> %43 to <8 x i64>
  %49 = xor <8 x i64> %45, %48
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fadd <8 x double> %47, %50
  %52 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %51
  %53 = fadd <8 x double> %16, %43
  %54 = fmul <8 x double> %53, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %55 = select <8 x i1> %10, <8 x double> %52, <8 x double> %54
  %56 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %57 = zext i8 %56 to i16
  %58 = bitcast i16 %6 to <16 x i1>
  %59 = bitcast i16 %57 to <16 x i1>
  %60 = xor <16 x i1> %58, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %61 = and <16 x i1> %60, %59
  %62 = bitcast <8 x double> %55 to <8 x i64>
  %63 = xor <8 x i64> %62, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %64 = bitcast <8 x i64> %63 to <8 x double>
  %65 = fadd <8 x double> %64, <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>
  %66 = bitcast <16 x i1> %61 to <2 x i8>
  %67 = extractelement <2 x i8> %66, i32 0
  %68 = bitcast i8 %67 to <8 x i1>
  %69 = select <8 x i1> %68, <8 x double> %65, <8 x double> %55
  ret <8 x double> %69
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_acosd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i32 17, i8 -1, i32 4) #7
  %6 = zext i8 %5 to i16
  %7 = fmul <8 x double> %0, %0
  %8 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %9 = fmul <8 x double> %8, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = bitcast i8 %5 to <8 x i1>
  %11 = select <8 x i1> %10, <8 x double> %7, <8 x double> %9
  %12 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %13 = bitcast <8 x double> %12 to <8 x i64>
  %14 = and <8 x i64> %13, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %15 = bitcast <8 x i64> %14 to <8 x double>
  %16 = fsub <8 x double> %12, %15
  %17 = fmul <8 x double> %12, %12
  %18 = fmul <8 x double> %15, %15
  %19 = bitcast <8 x double> %17 to <8 x i64>
  %20 = xor <8 x i64> %19, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %21 = bitcast <8 x i64> %20 to <8 x double>
  %22 = fmul <8 x double> %16, %15
  %23 = fmul <8 x double> %16, %16
  %24 = fadd <8 x double> %18, %21
  %25 = fadd <8 x double> %22, %24
  %26 = fadd <8 x double> %22, %25
  %27 = fadd <8 x double> %23, %26
  %28 = fadd <8 x double> %17, %11
  %29 = fsub <8 x double> %28, %11
  %30 = fsub <8 x double> %28, %29
  %31 = fsub <8 x double> %11, %30
  %32 = fsub <8 x double> %17, %29
  %33 = fadd <8 x double> %32, %31
  %34 = fadd <8 x double> %33, %27
  %35 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %12
  %36 = bitcast <8 x double> %35 to <8 x i64>
  %37 = and <8 x i64> %36, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %38 = bitcast <8 x i64> %37 to <8 x double>
  %39 = fsub <8 x double> %35, %38
  %40 = fmul <8 x double> %15, %38
  %41 = fmul <8 x double> %39, %15
  %42 = fmul <8 x double> %16, %38
  %43 = fmul <8 x double> %16, %39
  %44 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fsub <8 x double> %46, %43
  %48 = fmul <8 x double> %35, %47
  %49 = bitcast <8 x double> %28 to <8 x i64>
  %50 = and <8 x i64> %49, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %51 = bitcast <8 x i64> %50 to <8 x double>
  %52 = fsub <8 x double> %28, %51
  %53 = fmul <8 x double> %35, %28
  %54 = fmul <8 x double> %38, %51
  %55 = bitcast <8 x double> %53 to <8 x i64>
  %56 = xor <8 x i64> %55, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %57 = bitcast <8 x i64> %56 to <8 x double>
  %58 = fmul <8 x double> %52, %38
  %59 = fmul <8 x double> %39, %51
  %60 = fmul <8 x double> %39, %52
  %61 = fmul <8 x double> %28, %48
  %62 = fmul <8 x double> %35, %34
  %63 = fadd <8 x double> %54, %57
  %64 = fadd <8 x double> %58, %63
  %65 = fadd <8 x double> %59, %64
  %66 = fadd <8 x double> %60, %65
  %67 = fadd <8 x double> %66, %61
  %68 = fadd <8 x double> %62, %67
  %69 = fmul <8 x double> %53, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %70 = fmul <8 x double> %68, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %71 = select <8 x i1> %10, <8 x double> %4, <8 x double> %69
  %72 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %73 = bitcast i8 %72 to <8 x i1>
  %74 = select <8 x i1> %73, <8 x double> zeroinitializer, <8 x double> %71
  %75 = or i8 %72, %5
  %76 = bitcast i8 %75 to <8 x i1>
  %77 = select <8 x i1> %76, <8 x double> zeroinitializer, <8 x double> %70
  %78 = fmul <8 x double> %11, %11
  %79 = fmul <8 x double> %78, %78
  %80 = fmul <8 x double> %79, %79
  %81 = fmul <8 x double> %11, <double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47, double 0x3FA02FF4C7428A47>
  %82 = fadd <8 x double> %81, <double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8, double 0xBF9032E75CCD4AE8>
  %83 = fmul <8 x double> %11, <double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742, double 0x3F93C0E0817E9742>
  %84 = fadd <8 x double> %83, <double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E, double 0x3F7B0EF96B727E7E>
  %85 = fmul <8 x double> %78, %82
  %86 = fadd <8 x double> %84, %85
  %87 = fmul <8 x double> %11, <double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F, double 0x3F88E3FD48D0FB6F>
  %88 = fadd <8 x double> %87, <double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC, double 0x3F8C70DDF81249FC>
  %89 = fmul <8 x double> %11, <double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2, double 0x3F91C6B5042EC6B2>
  %90 = fadd <8 x double> %89, <double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E, double 0x3F96E89F8578B64E>
  %91 = fmul <8 x double> %78, %88
  %92 = fadd <8 x double> %90, %91
  %93 = fmul <8 x double> %11, <double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA, double 0x3F9F1C72C5FD95BA>
  %94 = fadd <8 x double> %93, <double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3, double 0x3FA6DB6DB407C2B3>
  %95 = fmul <8 x double> %11, <double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0, double 0x3FB3333333375CD0>
  %96 = fadd <8 x double> %95, <double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4, double 0x3FC55555555552F4>
  %97 = fmul <8 x double> %78, %94
  %98 = fadd <8 x double> %96, %97
  %99 = fmul <8 x double> %79, %92
  %100 = fadd <8 x double> %98, %99
  %101 = fmul <8 x double> %80, %86
  %102 = fadd <8 x double> %101, %100
  %103 = fmul <8 x double> %11, %74
  %104 = fmul <8 x double> %103, %102
  %105 = bitcast <8 x double> %74 to <8 x i64>
  %106 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %107 = xor <8 x i64> %106, %105
  %108 = bitcast <8 x i64> %107 to <8 x double>
  %109 = bitcast <8 x double> %104 to <8 x i64>
  %110 = xor <8 x i64> %106, %109
  %111 = bitcast <8 x i64> %110 to <8 x double>
  %112 = fadd <8 x double> %108, %111
  %113 = fsub <8 x double> %108, %112
  %114 = fadd <8 x double> %113, %111
  %115 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %112
  %116 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %115
  %117 = fsub <8 x double> %116, %112
  %118 = fadd <8 x double> %117, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %119 = fsub <8 x double> %118, %114
  %120 = fadd <8 x double> %74, %104
  %121 = fsub <8 x double> %74, %120
  %122 = fadd <8 x double> %104, %121
  %123 = fadd <8 x double> %122, %77
  %124 = fmul <8 x double> %120, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %125 = fmul <8 x double> %123, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %126 = select <8 x i1> %10, <8 x double> %115, <8 x double> %124
  %127 = select <8 x i1> %10, <8 x double> %119, <8 x double> %125
  %128 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %129 = zext i8 %128 to i16
  %130 = bitcast i16 %6 to <16 x i1>
  %131 = bitcast i16 %129 to <16 x i1>
  %132 = xor <16 x i1> %130, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %133 = and <16 x i1> %132, %131
  %134 = fsub <8 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, %126
  %135 = fsub <8 x double> <double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18, double 0x400921FB54442D18>, %134
  %136 = fsub <8 x double> %135, %126
  %137 = fadd <8 x double> %136, <double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07, double 0x3CA1A62633145C07>
  %138 = fsub <8 x double> %137, %127
  %139 = bitcast <16 x i1> %133 to <2 x i8>
  %140 = extractelement <2 x i8> %139, i32 0
  %141 = bitcast i8 %140 to <8 x i1>
  %142 = select <8 x i1> %141, <8 x double> %134, <8 x double> %126
  %143 = select <8 x i1> %141, <8 x double> %138, <8 x double> %127
  %144 = fadd <8 x double> %142, %143
  ret <8 x double> %144
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_atand8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %6 = bitcast i8 %5 to <8 x i1>
  %7 = select <8 x i1> %6, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %8 = or <8 x i64> %7, <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %9 = bitcast <8 x i64> %8 to <8 x double>
  %10 = bitcast <8 x i64> %7 to <8 x double>
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> %4, i32 17, i8 -1, i32 4) #7
  %12 = zext i8 %11 to i16
  %13 = bitcast i16 %12 to <16 x i1>
  %14 = select <16 x i1> %13, <16 x i32> <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %15 = bitcast <16 x i32> %14 to <8 x i64>
  %16 = shufflevector <8 x i64> %15, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = xor <8 x i64> %7, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %18 = xor <8 x i64> %7, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %19 = bitcast <8 x i64> %18 to <8 x double>
  %20 = bitcast i8 %11 to <8 x i1>
  %21 = select <8 x i1> %20, <8 x i64> %17, <8 x i64> %3
  %22 = bitcast <8 x i64> %21 to <8 x double>
  %23 = select <8 x i1> %20, <8 x double> %19, <8 x double> zeroinitializer
  %24 = select <8 x i1> %20, <8 x i64> %3, <8 x i64> %8
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = select <8 x i1> %20, <8 x double> zeroinitializer, <8 x double> %10
  %27 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %25
  %28 = and <8 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %29 = bitcast <8 x i64> %28 to <8 x double>
  %30 = fsub <8 x double> %25, %29
  %31 = bitcast <8 x double> %27 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fsub <8 x double> %27, %33
  %35 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %22, %36
  %38 = fmul <8 x double> %27, %22
  %39 = fmul <8 x double> %36, %33
  %40 = fsub <8 x double> %39, %38
  %41 = fmul <8 x double> %34, %36
  %42 = fmul <8 x double> %37, %33
  %43 = fmul <8 x double> %37, %34
  %44 = fmul <8 x double> %29, %33
  %45 = fmul <8 x double> %34, %29
  %46 = fmul <8 x double> %30, %33
  %47 = fmul <8 x double> %30, %34
  %48 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %44
  %49 = fsub <8 x double> %48, %45
  %50 = fsub <8 x double> %49, %46
  %51 = fsub <8 x double> %50, %47
  %52 = fmul <8 x double> %38, %51
  %53 = fadd <8 x double> %40, %41
  %54 = fadd <8 x double> %42, %53
  %55 = fadd <8 x double> %43, %54
  %56 = fadd <8 x double> %55, %52
  %57 = fmul <8 x double> %26, %38
  %58 = fsub <8 x double> %23, %57
  %59 = fmul <8 x double> %27, %58
  %60 = fadd <8 x double> %59, %56
  %61 = bitcast <8 x double> %38 to <8 x i64>
  %62 = and <8 x i64> %61, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %63 = bitcast <8 x i64> %62 to <8 x double>
  %64 = fsub <8 x double> %38, %63
  %65 = fmul <8 x double> %38, %38
  %66 = fmul <8 x double> %63, %63
  %67 = bitcast <8 x double> %65 to <8 x i64>
  %68 = xor <8 x i64> %67, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %69 = bitcast <8 x i64> %68 to <8 x double>
  %70 = fadd <8 x double> %63, %63
  %71 = fmul <8 x double> %70, %64
  %72 = fmul <8 x double> %64, %64
  %73 = fadd <8 x double> %60, %60
  %74 = fmul <8 x double> %38, %73
  %75 = fadd <8 x double> %66, %69
  %76 = fadd <8 x double> %75, %71
  %77 = fadd <8 x double> %72, %76
  %78 = fadd <8 x double> %77, %74
  %79 = fadd <8 x double> %65, %78
  %80 = fsub <8 x double> %65, %79
  %81 = fadd <8 x double> %78, %80
  %82 = fmul <8 x double> %79, %79
  %83 = fmul <8 x double> %82, %82
  %84 = fmul <8 x double> %83, %83
  %85 = fmul <8 x double> %79, <double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72, double 0x3EE64ADB3E06EE72>
  %86 = fadd <8 x double> %85, <double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE, double 0xBF2077212AA7D6CE>
  %87 = fmul <8 x double> %79, <double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98, double 0x3F471ECE4D9CED98>
  %88 = fadd <8 x double> %87, <double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE, double 0xBF64A20138B90CEE>
  %89 = fmul <8 x double> %82, %86
  %90 = fadd <8 x double> %88, %89
  %91 = fmul <8 x double> %79, <double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3, double 0x3F7A788EC28E9FB3>
  %92 = fadd <8 x double> %91, <double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5, double 0xBF8A45A2EA379DB5>
  %93 = fmul <8 x double> %79, <double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320, double 0x3F954D3ECCF8F320>
  %94 = fadd <8 x double> %93, <double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7, double 0xBF9D9805E7BA23E7>
  %95 = fmul <8 x double> %82, %92
  %96 = fadd <8 x double> %94, %95
  %97 = fmul <8 x double> %83, %90
  %98 = fadd <8 x double> %96, %97
  %99 = fmul <8 x double> %79, <double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD, double 0x3FA26BC6260B1BDD>
  %100 = fadd <8 x double> %99, <double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577, double 0xBFA56D2D526C0577>
  %101 = fmul <8 x double> %79, <double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6, double 0x3FA81B6EFB51F8A6>
  %102 = fadd <8 x double> %101, <double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E, double 0xBFAAE027D1895F2E>
  %103 = fmul <8 x double> %82, %100
  %104 = fadd <8 x double> %102, %103
  %105 = fmul <8 x double> %79, <double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B, double 0x3FAE1A556400767B>
  %106 = fadd <8 x double> %105, <double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6, double 0xBFB110C441E542D6>
  %107 = fmul <8 x double> %79, <double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10, double 0x3FB3B131F3B00D10>
  %108 = fadd <8 x double> %107, <double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC, double 0xBFB745D0AC14EFEC>
  %109 = fmul <8 x double> %82, %106
  %110 = fadd <8 x double> %108, %109
  %111 = fmul <8 x double> %83, %104
  %112 = fadd <8 x double> %110, %111
  %113 = fmul <8 x double> %84, %98
  %114 = fadd <8 x double> %112, %113
  %115 = fmul <8 x double> %79, %114
  %116 = fadd <8 x double> %115, <double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B, double 0x3FBC71C710B37A0B>
  %117 = fmul <8 x double> %79, %116
  %118 = fadd <8 x double> %117, <double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7, double 0xBFC249249211AFC7>
  %119 = fmul <8 x double> %79, %118
  %120 = fadd <8 x double> %119, <double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0, double 0x3FC9999999987CF0>
  %121 = fmul <8 x double> %79, %120
  %122 = fadd <8 x double> %121, <double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A, double 0xBFD555555555543A>
  %123 = bitcast <8 x double> %79 to <8 x i64>
  %124 = and <8 x i64> %123, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %125 = bitcast <8 x i64> %124 to <8 x double>
  %126 = fsub <8 x double> %79, %125
  %127 = fmul <8 x double> %38, %79
  %128 = fmul <8 x double> %63, %125
  %129 = bitcast <8 x double> %127 to <8 x i64>
  %130 = xor <8 x i64> %129, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %131 = bitcast <8 x i64> %130 to <8 x double>
  %132 = fmul <8 x double> %64, %125
  %133 = fmul <8 x double> %126, %63
  %134 = fmul <8 x double> %64, %126
  %135 = fmul <8 x double> %38, %81
  %136 = fmul <8 x double> %60, %79
  %137 = fadd <8 x double> %128, %131
  %138 = fadd <8 x double> %132, %137
  %139 = fadd <8 x double> %133, %138
  %140 = fadd <8 x double> %134, %139
  %141 = fadd <8 x double> %135, %140
  %142 = fadd <8 x double> %136, %141
  %143 = and <8 x i64> %129, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %144 = bitcast <8 x i64> %143 to <8 x double>
  %145 = fsub <8 x double> %127, %144
  %146 = bitcast <8 x double> %122 to <8 x i64>
  %147 = and <8 x i64> %146, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %148 = bitcast <8 x i64> %147 to <8 x double>
  %149 = fsub <8 x double> %122, %148
  %150 = fmul <8 x double> %127, %122
  %151 = fmul <8 x double> %144, %148
  %152 = bitcast <8 x double> %150 to <8 x i64>
  %153 = xor <8 x i64> %152, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %154 = bitcast <8 x i64> %153 to <8 x double>
  %155 = fmul <8 x double> %145, %148
  %156 = fmul <8 x double> %149, %144
  %157 = fmul <8 x double> %145, %149
  %158 = fmul <8 x double> %142, %122
  %159 = fadd <8 x double> %151, %154
  %160 = fadd <8 x double> %155, %159
  %161 = fadd <8 x double> %156, %160
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %158, %162
  %164 = fadd <8 x double> %38, %150
  %165 = fsub <8 x double> %38, %164
  %166 = fadd <8 x double> %150, %165
  %167 = fadd <8 x double> %60, %166
  %168 = fadd <8 x double> %167, %163
  %169 = bitcast <4 x i64> %16 to <8 x i32>
  %170 = sitofp <8 x i32> %169 to <8 x double>
  %171 = bitcast <8 x double> %170 to <8 x i64>
  %172 = and <8 x i64> %171, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %173 = bitcast <8 x i64> %172 to <8 x double>
  %174 = fsub <8 x double> %170, %173
  %175 = fmul <8 x double> %170, <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>
  %176 = fmul <8 x double> %173, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %177 = bitcast <8 x double> %175 to <8 x i64>
  %178 = xor <8 x i64> %177, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %179 = bitcast <8 x i64> %178 to <8 x double>
  %180 = fmul <8 x double> %173, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %181 = fmul <8 x double> %174, <double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000, double 0x3FF921FB50000000>
  %182 = fmul <8 x double> %174, <double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000, double 0x3E5110B460000000>
  %183 = fmul <8 x double> %170, <double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07, double 0x3C91A62633145C07>
  %184 = fadd <8 x double> %176, %179
  %185 = fadd <8 x double> %180, %184
  %186 = fadd <8 x double> %181, %185
  %187 = fadd <8 x double> %182, %186
  %188 = fadd <8 x double> %183, %187
  %189 = fadd <8 x double> %175, %164
  %190 = fsub <8 x double> %175, %189
  %191 = fadd <8 x double> %164, %190
  %192 = fadd <8 x double> %188, %191
  %193 = fadd <8 x double> %192, %168
  %194 = fadd <8 x double> %189, %193
  %195 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %196 = bitcast i8 %195 to <8 x i1>
  %197 = bitcast <8 x double> %194 to <8 x i64>
  %198 = select <8 x i1> %196, <8 x i64> <i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352, i64 4609753056924675352>, <8 x i64> %197
  %199 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %200 = xor <8 x i64> %198, %199
  %201 = bitcast <8 x i64> %200 to <8 x double>
  ret <8 x double> %201
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_atand8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = icmp slt <8 x i64> %2, zeroinitializer
  %4 = shufflevector <8 x i1> %3, <8 x i1> <i1 false, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>, <16 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
  %5 = select <16 x i1> %4, <16 x i32> <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %6 = bitcast <16 x i32> %5 to <8 x i64>
  %7 = shufflevector <8 x i64> %6, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %8 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %9 = bitcast <8 x i64> %8 to <8 x double>
  %10 = bitcast <4 x i64> %7 to <8 x i32>
  %11 = add <8 x i32> %10, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %12 = bitcast <8 x i32> %11 to <4 x i64>
  %13 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %9, i32 17, i8 -1, i32 4) #7
  %14 = zext i8 %13 to i16
  %15 = shufflevector <4 x i64> %12, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %16 = bitcast <8 x i64> %15 to <16 x i32>
  %17 = bitcast i16 %14 to <16 x i1>
  %18 = select <16 x i1> %17, <16 x i32> %16, <16 x i32> %5
  %19 = bitcast <16 x i32> %18 to <8 x i64>
  %20 = shufflevector <8 x i64> %19, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %21 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %9
  %22 = bitcast i8 %13 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x double> %21, <8 x double> %9
  %24 = fmul <8 x double> %23, %23
  %25 = fmul <8 x double> %24, %24
  %26 = fmul <8 x double> %25, %25
  %27 = fmul <8 x double> %26, %26
  %28 = fmul <8 x double> %27, %27
  %29 = fmul <8 x double> %24, <double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF, double 0x3F2B81666EB938AF>
  %30 = fadd <8 x double> %29, <double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA, double 0xBF521F657F3915DA>
  %31 = fmul <8 x double> %25, <double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F, double 0xBEF3CBF44A88555F>
  %32 = fadd <8 x double> %31, %30
  %33 = fmul <8 x double> %24, <double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20, double 0x3F6E5005F4C78C20>
  %34 = fadd <8 x double> %33, <double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56, double 0xBF82399E74A75E56>
  %35 = fmul <8 x double> %24, <double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286, double 0x3F90FF6A2A0D2286>
  %36 = fadd <8 x double> %35, <double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC, double 0xBF9A1006DE22CDAC>
  %37 = fmul <8 x double> %25, %34
  %38 = fadd <8 x double> %36, %37
  %39 = fmul <8 x double> %24, <double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E, double 0x3FA14C4D24651F2E>
  %40 = fadd <8 x double> %39, <double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638, double 0xBFA4DEE09915F638>
  %41 = fmul <8 x double> %24, <double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE, double 0x3FA7E4B31D8A55AE>
  %42 = fadd <8 x double> %41, <double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA, double 0xBFAACFE938E04FCA>
  %43 = fmul <8 x double> %25, %40
  %44 = fadd <8 x double> %42, %43
  %45 = fmul <8 x double> %26, %38
  %46 = fadd <8 x double> %44, %45
  %47 = fmul <8 x double> %24, <double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622, double 0x3FAE16A933B73622>
  %48 = fadd <8 x double> %47, <double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0, double 0xBFB11074E45F93E0>
  %49 = fmul <8 x double> %24, <double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1, double 0x3FB3B1283C0CA0B1>
  %50 = fadd <8 x double> %49, <double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8, double 0xBFB745CFD878FEE8>
  %51 = fmul <8 x double> %25, %48
  %52 = fadd <8 x double> %50, %51
  %53 = fmul <8 x double> %24, <double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F, double 0x3FBC71C704FB4F9F>
  %54 = fadd <8 x double> %53, <double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB, double 0xBFC2492491E100BB>
  %55 = fmul <8 x double> %24, <double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD, double 0x3FC999999997B9DD>
  %56 = fadd <8 x double> %55, <double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5, double 0xBFD55555555553C5>
  %57 = fmul <8 x double> %25, %54
  %58 = fadd <8 x double> %56, %57
  %59 = fmul <8 x double> %26, %52
  %60 = fadd <8 x double> %58, %59
  %61 = fmul <8 x double> %27, %46
  %62 = fadd <8 x double> %60, %61
  %63 = fmul <8 x double> %32, %28
  %64 = fadd <8 x double> %63, %62
  %65 = fmul <8 x double> %24, %64
  %66 = fmul <8 x double> %23, %65
  %67 = fadd <8 x double> %23, %66
  %68 = and <4 x i64> %20, <i64 4294967297, i64 4294967297, i64 4294967297, i64 4294967297>
  %69 = shufflevector <4 x i64> %68, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %70 = bitcast <8 x i64> %69 to <16 x i32>
  %71 = icmp eq <16 x i32> %70, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %72 = fsub <8 x double> <double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18, double 0x3FF921FB54442D18>, %67
  %73 = bitcast <16 x i1> %71 to <2 x i8>
  %74 = extractelement <2 x i8> %73, i32 0
  %75 = bitcast i8 %74 to <8 x i1>
  %76 = select <8 x i1> %75, <8 x double> %72, <8 x double> %67
  %77 = and <4 x i64> %20, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %78 = shufflevector <4 x i64> %77, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %79 = bitcast <8 x i64> %78 to <16 x i32>
  %80 = icmp eq <16 x i32> %79, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %81 = bitcast <16 x i1> %80 to <2 x i8>
  %82 = extractelement <2 x i8> %81, i32 0
  %83 = bitcast i8 %82 to <8 x i1>
  %84 = select <8 x i1> %83, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %85 = bitcast <8 x double> %76 to <8 x i64>
  %86 = xor <8 x i64> %84, %85
  %87 = bitcast <8 x i64> %86 to <8 x double>
  ret <8 x double> %87
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_logd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %7 = fadd <8 x double> %6, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %8 = fadd <8 x double> %6, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %9 = fdiv <8 x double> %7, %8
  %10 = fmul <8 x double> %9, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %9, %10
  %14 = fmul <8 x double> %10, <double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D>
  %15 = fadd <8 x double> %14, <double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F>
  %16 = fmul <8 x double> %11, <double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39>
  %17 = fadd <8 x double> %16, %15
  %18 = fmul <8 x double> %10, <double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419>
  %19 = fadd <8 x double> %18, <double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987>
  %20 = fmul <8 x double> %10, <double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E>
  %21 = fadd <8 x double> %20, <double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F>
  %22 = fmul <8 x double> %11, %19
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %12, %17
  %25 = fadd <8 x double> %24, %23
  %26 = fmul <8 x double> %3, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %27 = select <8 x i1> %5, <8 x double> <double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF>, <8 x double> %26
  %28 = fmul <8 x double> %9, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %29 = fadd <8 x double> %27, %28
  %30 = fmul <8 x double> %13, %25
  %31 = fadd <8 x double> %29, %30
  %32 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %31, <8 x double> %0, <8 x i64> <i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360>, i32 0, i8 -1, i32 4)
  ret <8 x double> %32
}

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double>, <8 x double>, <8 x i64>, i32, i8, i32) #4

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_expd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %2, i32 8, <8 x double> %2, i8 -1, i32 4) #7
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %5 = fmul <8 x double> %3, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %6 = fadd <8 x double> %5, %0
  %7 = fmul <8 x double> %3, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %8 = fadd <8 x double> %7, %6
  %9 = fmul <8 x double> %8, %8
  %10 = fmul <8 x double> %9, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %8, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %13 = fadd <8 x double> %12, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %14 = fmul <8 x double> %8, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %15 = fadd <8 x double> %14, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %16 = fmul <8 x double> %8, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %17 = fadd <8 x double> %16, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %18 = fmul <8 x double> %9, %15
  %19 = fadd <8 x double> %17, %18
  %20 = fmul <8 x double> %8, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %21 = fadd <8 x double> %20, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %22 = fmul <8 x double> %8, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %23 = fadd <8 x double> %22, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %24 = fmul <8 x double> %9, %21
  %25 = fadd <8 x double> %23, %24
  %26 = fmul <8 x double> %10, %19
  %27 = fadd <8 x double> %25, %26
  %28 = fmul <8 x double> %13, %11
  %29 = fadd <8 x double> %28, %27
  %30 = fmul <8 x double> %8, %29
  %31 = fadd <8 x double> %30, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %32 = fmul <8 x double> %9, %31
  %33 = fadd <8 x double> %8, %32
  %34 = fadd <8 x double> %33, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %35 = ashr <8 x i32> %4, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %36 = add nsw <8 x i32> %35, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %37 = bitcast <8 x i32> %36 to <4 x i64>
  %38 = shufflevector <4 x i64> %37, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %39 = bitcast <8 x i64> %38 to <16 x i32>
  %40 = shufflevector <16 x i32> %39, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %41 = shufflevector <16 x i32> %40, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %42 = shl <16 x i32> %41, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %43 = bitcast <16 x i32> %42 to <8 x double>
  %44 = fmul <8 x double> %34, %43
  %45 = add <8 x i32> %4, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = sub <8 x i32> %45, %35
  %47 = bitcast <8 x i32> %46 to <4 x i64>
  %48 = shufflevector <4 x i64> %47, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %49 = bitcast <8 x i64> %48 to <16 x i32>
  %50 = shufflevector <16 x i32> %49, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %51 = shufflevector <16 x i32> %50, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %52 = shl <16 x i32> %51, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %53 = bitcast <16 x i32> %52 to <8 x double>
  %54 = fmul <8 x double> %44, %53
  %55 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i32 30, i8 -1, i32 4) #7
  %56 = bitcast i8 %55 to <8 x i1>
  %57 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %58 = bitcast i8 %57 to <8 x i1>
  %59 = select <8 x i1> %56, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %54
  %60 = select <8 x i1> %58, <8 x double> zeroinitializer, <8 x double> %59
  ret <8 x double> %60
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_logd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %60 = fadd <8 x double> %59, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %61 = fmul <8 x double> %57, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %64 = fadd <8 x double> %63, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %65 = fmul <8 x double> %56, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %66 = fadd <8 x double> %65, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %6 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %6, %73
  %75 = fmul <8 x double> %6, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %76 = fmul <8 x double> %73, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %73, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %81 = fmul <8 x double> %74, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %82 = fmul <8 x double> %74, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %83 = fmul <8 x double> %6, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %84 = fadd <8 x double> %76, %79
  %85 = fadd <8 x double> %80, %84
  %86 = fadd <8 x double> %81, %85
  %87 = fadd <8 x double> %82, %86
  %88 = fadd <8 x double> %83, %87
  %89 = fmul <8 x double> %33, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %90 = fmul <8 x double> %55, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %91 = fadd <8 x double> %75, %89
  %92 = fsub <8 x double> %75, %91
  %93 = fadd <8 x double> %89, %92
  %94 = fadd <8 x double> %93, %88
  %95 = fadd <8 x double> %94, %90
  %96 = fmul <8 x double> %33, %56
  %97 = fmul <8 x double> %96, %70
  %98 = fadd <8 x double> %91, %97
  %99 = fsub <8 x double> %91, %98
  %100 = fadd <8 x double> %97, %99
  %101 = fadd <8 x double> %100, %95
  %102 = fadd <8 x double> %98, %101
  %103 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %102, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4)
  ret <8 x double> %103
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_powd8_u10avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %1, i32 11, <8 x double> %1, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> %1, i32 0, i8 -1, i32 4) #7
  %5 = fmul <8 x double> %1, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %5, i32 11, <8 x double> %5, i8 -1, i32 4) #7
  %7 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %6, <8 x double> %5, i32 4, i8 -1, i32 4) #7
  %8 = and i8 %7, %4
  %9 = bitcast <8 x double> %0 to <8 x i64>
  %10 = and <8 x i64> %9, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %11 = bitcast <8 x i64> %10 to <8 x double>
  %12 = fmul <8 x double> %11, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %13 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %12, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %15 = bitcast i8 %14 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %13
  %17 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %11, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %18 = fadd <8 x double> %17, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %19 = fadd <8 x double> %18, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %20 = fsub <8 x double> %18, %19
  %21 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %20
  %22 = fsub <8 x double> %17, %19
  %23 = fadd <8 x double> %22, %21
  %24 = fadd <8 x double> %17, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %25 = fadd <8 x double> %24, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %26 = fsub <8 x double> %24, %25
  %27 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %26
  %28 = fsub <8 x double> %17, %25
  %29 = fadd <8 x double> %28, %27
  %30 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %24
  %31 = bitcast <8 x double> %24 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fsub <8 x double> %24, %33
  %35 = bitcast <8 x double> %30 to <8 x i64>
  %36 = and <8 x i64> %35, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %37 = bitcast <8 x i64> %36 to <8 x double>
  %38 = fsub <8 x double> %30, %37
  %39 = bitcast <8 x double> %18 to <8 x i64>
  %40 = and <8 x i64> %39, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %41 = bitcast <8 x i64> %40 to <8 x double>
  %42 = fsub <8 x double> %18, %41
  %43 = fmul <8 x double> %18, %30
  %44 = fmul <8 x double> %41, %37
  %45 = fsub <8 x double> %44, %43
  %46 = fmul <8 x double> %38, %41
  %47 = fmul <8 x double> %42, %37
  %48 = fmul <8 x double> %42, %38
  %49 = fmul <8 x double> %33, %37
  %50 = fmul <8 x double> %38, %33
  %51 = fmul <8 x double> %34, %37
  %52 = fmul <8 x double> %34, %38
  %53 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %49
  %54 = fsub <8 x double> %53, %50
  %55 = fsub <8 x double> %54, %51
  %56 = fsub <8 x double> %55, %52
  %57 = fmul <8 x double> %43, %56
  %58 = fadd <8 x double> %45, %46
  %59 = fadd <8 x double> %47, %58
  %60 = fadd <8 x double> %48, %59
  %61 = fadd <8 x double> %60, %57
  %62 = fmul <8 x double> %43, %29
  %63 = fsub <8 x double> %23, %62
  %64 = fmul <8 x double> %30, %63
  %65 = fadd <8 x double> %64, %61
  %66 = bitcast <8 x double> %43 to <8 x i64>
  %67 = and <8 x i64> %66, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %68 = bitcast <8 x i64> %67 to <8 x double>
  %69 = fsub <8 x double> %43, %68
  %70 = fmul <8 x double> %43, %43
  %71 = fmul <8 x double> %68, %68
  %72 = bitcast <8 x double> %70 to <8 x i64>
  %73 = xor <8 x i64> %72, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %74 = bitcast <8 x i64> %73 to <8 x double>
  %75 = fadd <8 x double> %68, %68
  %76 = fmul <8 x double> %75, %69
  %77 = fmul <8 x double> %69, %69
  %78 = fadd <8 x double> %65, %65
  %79 = fmul <8 x double> %43, %78
  %80 = fadd <8 x double> %71, %74
  %81 = fadd <8 x double> %80, %76
  %82 = fadd <8 x double> %77, %81
  %83 = fadd <8 x double> %82, %79
  %84 = fmul <8 x double> %70, %70
  %85 = fmul <8 x double> %84, %84
  %86 = fmul <8 x double> %85, %85
  %87 = fmul <8 x double> %70, <double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11, double 0x3FBA6DEA6D1E9D11>
  %88 = fadd <8 x double> %87, <double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A, double 0x3FBE252DDF5F8D0A>
  %89 = fmul <8 x double> %70, <double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C, double 0x3FC110F384A1865C>
  %90 = fadd <8 x double> %89, <double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1, double 0x3FC3B13BB108EFD1>
  %91 = fmul <8 x double> %84, %88
  %92 = fadd <8 x double> %90, %91
  %93 = fmul <8 x double> %70, <double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1, double 0x3FC745D17248DAF1>
  %94 = fadd <8 x double> %93, <double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F, double 0x3FCC71C71C76197F>
  %95 = fmul <8 x double> %70, <double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200, double 0x3FD2492492492200>
  %96 = fadd <8 x double> %95, <double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B, double 0x3FD999999999999B>
  %97 = fmul <8 x double> %84, %94
  %98 = fadd <8 x double> %96, %97
  %99 = fmul <8 x double> %85, %92
  %100 = fadd <8 x double> %98, %99
  %101 = fmul <8 x double> %86, <double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3, double 0x3FBDC2EC09E714D3>
  %102 = fadd <8 x double> %101, %100
  %103 = bitcast <8 x double> %16 to <8 x i64>
  %104 = and <8 x i64> %103, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = fsub <8 x double> %16, %105
  %107 = fmul <8 x double> %16, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %108 = fmul <8 x double> %105, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %109 = bitcast <8 x double> %107 to <8 x i64>
  %110 = xor <8 x i64> %109, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %111 = bitcast <8 x i64> %110 to <8 x double>
  %112 = fmul <8 x double> %105, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %113 = fmul <8 x double> %106, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %114 = fmul <8 x double> %106, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %115 = fmul <8 x double> %16, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %116 = fadd <8 x double> %108, %111
  %117 = fadd <8 x double> %112, %116
  %118 = fadd <8 x double> %113, %117
  %119 = fadd <8 x double> %114, %118
  %120 = fadd <8 x double> %115, %119
  %121 = fmul <8 x double> %43, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %122 = fmul <8 x double> %65, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %123 = fadd <8 x double> %107, %121
  %124 = fsub <8 x double> %107, %123
  %125 = fadd <8 x double> %121, %124
  %126 = fadd <8 x double> %125, %120
  %127 = fadd <8 x double> %126, %122
  %128 = and <8 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %129 = bitcast <8 x i64> %128 to <8 x double>
  %130 = fsub <8 x double> %70, %129
  %131 = fmul <8 x double> %43, %70
  %132 = fmul <8 x double> %68, %129
  %133 = bitcast <8 x double> %131 to <8 x i64>
  %134 = xor <8 x i64> %133, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %135 = bitcast <8 x i64> %134 to <8 x double>
  %136 = fmul <8 x double> %130, %68
  %137 = fmul <8 x double> %69, %129
  %138 = fmul <8 x double> %69, %130
  %139 = fmul <8 x double> %70, %65
  %140 = fmul <8 x double> %43, %83
  %141 = fadd <8 x double> %132, %135
  %142 = fadd <8 x double> %136, %141
  %143 = fadd <8 x double> %137, %142
  %144 = fadd <8 x double> %138, %143
  %145 = fadd <8 x double> %144, %139
  %146 = fadd <8 x double> %145, %140
  %147 = and <8 x i64> %133, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %148 = bitcast <8 x i64> %147 to <8 x double>
  %149 = fsub <8 x double> %131, %148
  %150 = fmul <8 x double> %131, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %151 = fmul <8 x double> %148, <double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000>
  %152 = bitcast <8 x double> %150 to <8 x i64>
  %153 = xor <8 x i64> %152, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %154 = bitcast <8 x i64> %153 to <8 x double>
  %155 = fmul <8 x double> %149, <double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000, double 0x3FE5555550000000>
  %156 = fmul <8 x double> %148, <double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000>
  %157 = fmul <8 x double> %149, <double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000, double 0x3E45555554000000>
  %158 = fmul <8 x double> %131, <double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000, double 0x3C85F00000000000>
  %159 = fmul <8 x double> %146, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %160 = fadd <8 x double> %151, %154
  %161 = fadd <8 x double> %155, %160
  %162 = fadd <8 x double> %156, %161
  %163 = fadd <8 x double> %157, %162
  %164 = fadd <8 x double> %158, %163
  %165 = fadd <8 x double> %164, %159
  %166 = fadd <8 x double> %123, %150
  %167 = fsub <8 x double> %123, %166
  %168 = fadd <8 x double> %150, %167
  %169 = fadd <8 x double> %168, %127
  %170 = fadd <8 x double> %169, %165
  %171 = fmul <8 x double> %70, %131
  %172 = fmul <8 x double> %129, %148
  %173 = bitcast <8 x double> %171 to <8 x i64>
  %174 = xor <8 x i64> %173, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %175 = bitcast <8 x i64> %174 to <8 x double>
  %176 = fmul <8 x double> %130, %148
  %177 = fmul <8 x double> %149, %129
  %178 = fmul <8 x double> %130, %149
  %179 = fmul <8 x double> %70, %146
  %180 = fmul <8 x double> %131, %83
  %181 = fadd <8 x double> %172, %175
  %182 = fadd <8 x double> %176, %181
  %183 = fadd <8 x double> %177, %182
  %184 = fadd <8 x double> %178, %183
  %185 = fadd <8 x double> %184, %179
  %186 = fadd <8 x double> %180, %185
  %187 = and <8 x i64> %173, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %188 = bitcast <8 x i64> %187 to <8 x double>
  %189 = fsub <8 x double> %171, %188
  %190 = bitcast <8 x double> %102 to <8 x i64>
  %191 = and <8 x i64> %190, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %192 = bitcast <8 x i64> %191 to <8 x double>
  %193 = fsub <8 x double> %102, %192
  %194 = fmul <8 x double> %171, %102
  %195 = fmul <8 x double> %188, %192
  %196 = bitcast <8 x double> %194 to <8 x i64>
  %197 = xor <8 x i64> %196, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %198 = bitcast <8 x i64> %197 to <8 x double>
  %199 = fmul <8 x double> %189, %192
  %200 = fmul <8 x double> %193, %188
  %201 = fmul <8 x double> %189, %193
  %202 = fmul <8 x double> %102, %186
  %203 = fadd <8 x double> %195, %198
  %204 = fadd <8 x double> %199, %203
  %205 = fadd <8 x double> %200, %204
  %206 = fadd <8 x double> %201, %205
  %207 = fadd <8 x double> %206, %202
  %208 = fadd <8 x double> %166, %194
  %209 = fsub <8 x double> %166, %208
  %210 = fadd <8 x double> %194, %209
  %211 = fadd <8 x double> %210, %170
  %212 = fadd <8 x double> %211, %207
  %213 = bitcast <8 x double> %208 to <8 x i64>
  %214 = and <8 x i64> %213, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %215 = bitcast <8 x i64> %214 to <8 x double>
  %216 = fsub <8 x double> %208, %215
  %217 = bitcast <8 x double> %1 to <8 x i64>
  %218 = and <8 x i64> %217, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %219 = bitcast <8 x i64> %218 to <8 x double>
  %220 = fsub <8 x double> %1, %219
  %221 = fmul <8 x double> %208, %1
  %222 = fmul <8 x double> %219, %215
  %223 = bitcast <8 x double> %221 to <8 x i64>
  %224 = xor <8 x i64> %223, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %225 = bitcast <8 x i64> %224 to <8 x double>
  %226 = fmul <8 x double> %216, %219
  %227 = fmul <8 x double> %220, %215
  %228 = fmul <8 x double> %220, %216
  %229 = fmul <8 x double> %212, %1
  %230 = fadd <8 x double> %222, %225
  %231 = fadd <8 x double> %226, %230
  %232 = fadd <8 x double> %227, %231
  %233 = fadd <8 x double> %228, %232
  %234 = fadd <8 x double> %233, %229
  %235 = fadd <8 x double> %221, %234
  %236 = fmul <8 x double> %235, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %237 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %236, i32 8, <8 x double> %236, i8 -1, i32 4) #7
  %238 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %237, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %239 = fmul <8 x double> %237, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %240 = fadd <8 x double> %239, %221
  %241 = fsub <8 x double> %240, %221
  %242 = fsub <8 x double> %240, %241
  %243 = fsub <8 x double> %221, %242
  %244 = fsub <8 x double> %239, %241
  %245 = fadd <8 x double> %244, %243
  %246 = fadd <8 x double> %245, %234
  %247 = fmul <8 x double> %237, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %248 = fadd <8 x double> %247, %240
  %249 = fsub <8 x double> %248, %240
  %250 = fsub <8 x double> %248, %249
  %251 = fsub <8 x double> %240, %250
  %252 = fsub <8 x double> %247, %249
  %253 = fadd <8 x double> %252, %251
  %254 = fadd <8 x double> %253, %246
  %255 = fadd <8 x double> %248, %254
  %256 = fsub <8 x double> %248, %255
  %257 = fadd <8 x double> %254, %256
  %258 = fmul <8 x double> %255, %255
  %259 = fmul <8 x double> %258, %258
  %260 = fmul <8 x double> %259, %259
  %261 = fmul <8 x double> %255, <double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9, double 0x3E5AF559D51456B9>
  %262 = fadd <8 x double> %261, <double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD, double 0x3E928A8F696DB5AD>
  %263 = fmul <8 x double> %255, <double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E, double 0x3EC71DDFD27D265E>
  %264 = fadd <8 x double> %263, <double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B, double 0x3EFA0199EC6C491B>
  %265 = fmul <8 x double> %255, <double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D, double 0x3F2A01A01AE0C33D>
  %266 = fadd <8 x double> %265, <double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B, double 0x3F56C16C1828EC7B>
  %267 = fmul <8 x double> %258, %264
  %268 = fadd <8 x double> %266, %267
  %269 = fmul <8 x double> %255, <double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68, double 0x3F8111111110FB68>
  %270 = fadd <8 x double> %269, <double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90, double 0x3FA5555555550E90>
  %271 = fmul <8 x double> %255, <double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558, double 0x3FC5555555555558>
  %272 = fadd <8 x double> %271, <double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009, double 0x3FE0000000000009>
  %273 = fmul <8 x double> %258, %270
  %274 = fadd <8 x double> %272, %273
  %275 = fmul <8 x double> %259, %268
  %276 = fadd <8 x double> %274, %275
  %277 = fmul <8 x double> %262, %260
  %278 = fadd <8 x double> %277, %276
  %279 = fadd <8 x double> %255, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %280 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %279
  %281 = fadd <8 x double> %255, %280
  %282 = fadd <8 x double> %257, %281
  %283 = bitcast <8 x double> %255 to <8 x i64>
  %284 = and <8 x i64> %283, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %285 = bitcast <8 x i64> %284 to <8 x double>
  %286 = fsub <8 x double> %255, %285
  %287 = fmul <8 x double> %285, %285
  %288 = bitcast <8 x double> %258 to <8 x i64>
  %289 = xor <8 x i64> %288, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %290 = bitcast <8 x i64> %289 to <8 x double>
  %291 = fadd <8 x double> %285, %285
  %292 = fmul <8 x double> %291, %286
  %293 = fmul <8 x double> %286, %286
  %294 = fadd <8 x double> %257, %257
  %295 = fmul <8 x double> %255, %294
  %296 = fadd <8 x double> %287, %290
  %297 = fadd <8 x double> %296, %292
  %298 = fadd <8 x double> %293, %297
  %299 = fadd <8 x double> %295, %298
  %300 = and <8 x i64> %288, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %301 = bitcast <8 x i64> %300 to <8 x double>
  %302 = fsub <8 x double> %258, %301
  %303 = bitcast <8 x double> %278 to <8 x i64>
  %304 = and <8 x i64> %303, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %305 = bitcast <8 x i64> %304 to <8 x double>
  %306 = fsub <8 x double> %278, %305
  %307 = fmul <8 x double> %258, %278
  %308 = fmul <8 x double> %301, %305
  %309 = bitcast <8 x double> %307 to <8 x i64>
  %310 = xor <8 x i64> %309, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %311 = bitcast <8 x i64> %310 to <8 x double>
  %312 = fmul <8 x double> %302, %305
  %313 = fmul <8 x double> %306, %301
  %314 = fmul <8 x double> %302, %306
  %315 = fmul <8 x double> %278, %299
  %316 = fadd <8 x double> %308, %311
  %317 = fadd <8 x double> %312, %316
  %318 = fadd <8 x double> %313, %317
  %319 = fadd <8 x double> %314, %318
  %320 = fadd <8 x double> %315, %319
  %321 = fadd <8 x double> %279, %307
  %322 = fsub <8 x double> %279, %321
  %323 = fadd <8 x double> %307, %322
  %324 = fadd <8 x double> %282, %323
  %325 = fadd <8 x double> %324, %320
  %326 = fadd <8 x double> %321, %325
  %327 = ashr <8 x i32> %238, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %328 = add nsw <8 x i32> %327, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %329 = bitcast <8 x i32> %328 to <4 x i64>
  %330 = shufflevector <4 x i64> %329, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %331 = bitcast <8 x i64> %330 to <16 x i32>
  %332 = shufflevector <16 x i32> %331, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %333 = shufflevector <16 x i32> %332, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %334 = shl <16 x i32> %333, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %335 = bitcast <16 x i32> %334 to <8 x double>
  %336 = fmul <8 x double> %326, %335
  %337 = add <8 x i32> %238, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %338 = sub <8 x i32> %337, %327
  %339 = bitcast <8 x i32> %338 to <4 x i64>
  %340 = shufflevector <4 x i64> %339, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %341 = bitcast <8 x i64> %340 to <16 x i32>
  %342 = shufflevector <16 x i32> %341, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %343 = shufflevector <16 x i32> %342, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %344 = shl <16 x i32> %343, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %345 = bitcast <16 x i32> %344 to <8 x double>
  %346 = fmul <8 x double> %336, %345
  %347 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %221, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %348 = bitcast i8 %347 to <8 x i1>
  %349 = select <8 x i1> %348, <8 x double> zeroinitializer, <8 x double> %346
  %350 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %221, <8 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i32 30, i8 -1, i32 4) #7
  %351 = bitcast i8 %350 to <8 x i1>
  %352 = select <8 x i1> %351, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %349
  %353 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 30, i8 -1, i32 4) #7
  %354 = bitcast i8 %8 to <8 x i1>
  %355 = select <8 x i1> %354, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %356 = bitcast i8 %4 to <8 x i1>
  %357 = select <8 x i1> %356, <8 x double> %355, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>
  %358 = bitcast i8 %353 to <8 x i1>
  %359 = select <8 x i1> %358, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %357
  %360 = fmul <8 x double> %359, %352
  %361 = fadd <8 x double> %11, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %362 = bitcast <8 x double> %361 to <8 x i64>
  %363 = and <8 x i64> %217, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %364 = xor <8 x i64> %363, %362
  %365 = bitcast <8 x i64> %364 to <8 x double>
  %366 = and <8 x i64> %217, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %367 = bitcast <8 x i64> %366 to <8 x double>
  %368 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %367, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %369 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %365, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %370 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %365, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %371 = bitcast i8 %370 to <8 x i1>
  %372 = bitcast i8 %369 to <8 x i1>
  %373 = select <8 x i1> %371, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %374 = select <8 x i1> %372, <8 x double> zeroinitializer, <8 x double> %373
  %375 = bitcast i8 %368 to <8 x i1>
  %376 = select <8 x i1> %375, <8 x double> %374, <8 x double> %360
  %377 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %11, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %378 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %379 = or i8 %378, %377
  %380 = and <8 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %381 = or <8 x i64> %380, <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %382 = bitcast <8 x i64> %381 to <8 x double>
  %383 = select <8 x i1> %354, <8 x double> %382, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %384 = xor <8 x i64> %217, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %385 = bitcast <8 x i64> %384 to <8 x double>
  %386 = bitcast i8 %378 to <8 x i1>
  %387 = select <8 x i1> %386, <8 x double> %385, <8 x double> %1
  %388 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %387, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %389 = bitcast i8 %388 to <8 x i1>
  %390 = select <8 x i1> %389, <8 x double> zeroinitializer, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>
  %391 = fmul <8 x double> %383, %390
  %392 = bitcast i8 %379 to <8 x i1>
  %393 = select <8 x i1> %392, <8 x double> %391, <8 x double> %376
  %394 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %395 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %396 = or i8 %395, %394
  %397 = bitcast i8 %396 to <8 x i1>
  %398 = select <8 x i1> %397, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %393
  %399 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %400 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %401 = or i8 %400, %399
  %402 = bitcast i8 %401 to <8 x i1>
  %403 = select <8 x i1> %402, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %398
  ret <8 x double> %403
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sinhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fadd <8 x double> %4, zeroinitializer
  %6 = fmul <8 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %6, i32 8, <8 x double> %6, i8 -1, i32 4) #7
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = fmul <8 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <8 x double> %9, %4
  %11 = fsub <8 x double> %10, %4
  %12 = fsub <8 x double> %10, %11
  %13 = fsub <8 x double> %4, %12
  %14 = fsub <8 x double> %9, %11
  %15 = fadd <8 x double> %14, %13
  %16 = fadd <8 x double> %15, zeroinitializer
  %17 = fmul <8 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <8 x double> %17, %10
  %19 = fsub <8 x double> %18, %10
  %20 = fsub <8 x double> %18, %19
  %21 = fsub <8 x double> %10, %20
  %22 = fsub <8 x double> %17, %19
  %23 = fadd <8 x double> %22, %21
  %24 = fadd <8 x double> %23, %16
  %25 = bitcast <8 x double> %18 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %18, %27
  %29 = fmul <8 x double> %18, %18
  %30 = fmul <8 x double> %27, %27
  %31 = bitcast <8 x double> %29 to <8 x i64>
  %32 = xor <8 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fadd <8 x double> %27, %27
  %35 = fmul <8 x double> %34, %28
  %36 = fmul <8 x double> %28, %28
  %37 = fadd <8 x double> %24, %24
  %38 = fmul <8 x double> %18, %37
  %39 = fadd <8 x double> %30, %33
  %40 = fadd <8 x double> %39, %35
  %41 = fadd <8 x double> %36, %40
  %42 = fadd <8 x double> %38, %41
  %43 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <8 x i64> %43 to <8 x double>
  %45 = fsub <8 x double> %29, %44
  %46 = fmul <8 x double> %29, %29
  %47 = fmul <8 x double> %44, %44
  %48 = bitcast <8 x double> %46 to <8 x i64>
  %49 = xor <8 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fadd <8 x double> %44, %44
  %52 = fmul <8 x double> %51, %45
  %53 = fmul <8 x double> %45, %45
  %54 = fadd <8 x double> %42, %42
  %55 = fmul <8 x double> %29, %54
  %56 = fadd <8 x double> %47, %50
  %57 = fadd <8 x double> %56, %52
  %58 = fadd <8 x double> %53, %57
  %59 = fadd <8 x double> %58, %55
  %60 = fmul <8 x double> %46, %46
  %61 = fmul <8 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <8 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <8 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <8 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <8 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <8 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <8 x double> %29, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <8 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <8 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <8 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <8 x double> %29, %70
  %74 = fadd <8 x double> %72, %73
  %75 = fmul <8 x double> %46, %68
  %76 = fadd <8 x double> %74, %75
  %77 = fmul <8 x double> %62, %60
  %78 = fadd <8 x double> %77, %76
  %79 = fmul <8 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <8 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <8 x double> %79 to <8 x i64>
  %82 = xor <8 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <8 x i64> %82 to <8 x double>
  %84 = fmul <8 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <8 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <8 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <8 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <8 x double> %80, %83
  %89 = fadd <8 x double> %84, %88
  %90 = fadd <8 x double> %85, %89
  %91 = fadd <8 x double> %86, %90
  %92 = fadd <8 x double> %87, %91
  %93 = fadd <8 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <8 x double> %79, %94
  %96 = fadd <8 x double> %95, %92
  %97 = bitcast <8 x double> %93 to <8 x i64>
  %98 = and <8 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <8 x i64> %98 to <8 x double>
  %100 = fsub <8 x double> %93, %99
  %101 = fmul <8 x double> %18, %93
  %102 = fmul <8 x double> %27, %99
  %103 = bitcast <8 x double> %101 to <8 x i64>
  %104 = xor <8 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = fmul <8 x double> %100, %27
  %107 = fmul <8 x double> %28, %99
  %108 = fmul <8 x double> %28, %100
  %109 = fmul <8 x double> %93, %24
  %110 = fmul <8 x double> %18, %96
  %111 = fadd <8 x double> %102, %105
  %112 = fadd <8 x double> %106, %111
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %108, %113
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <8 x double> %101, %118
  %120 = fadd <8 x double> %119, %116
  %121 = bitcast <8 x double> %117 to <8 x i64>
  %122 = and <8 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <8 x i64> %122 to <8 x double>
  %124 = fsub <8 x double> %117, %123
  %125 = fmul <8 x double> %18, %117
  %126 = fmul <8 x double> %27, %123
  %127 = bitcast <8 x double> %125 to <8 x i64>
  %128 = xor <8 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <8 x i64> %128 to <8 x double>
  %130 = fmul <8 x double> %124, %27
  %131 = fmul <8 x double> %28, %123
  %132 = fmul <8 x double> %28, %124
  %133 = fmul <8 x double> %117, %24
  %134 = fmul <8 x double> %18, %120
  %135 = fadd <8 x double> %126, %129
  %136 = fadd <8 x double> %130, %135
  %137 = fadd <8 x double> %131, %136
  %138 = fadd <8 x double> %132, %137
  %139 = fadd <8 x double> %133, %138
  %140 = fadd <8 x double> %139, %134
  %141 = fadd <8 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <8 x double> %125, %142
  %144 = fadd <8 x double> %143, %140
  %145 = and <8 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fsub <8 x double> %46, %146
  %148 = bitcast <8 x double> %78 to <8 x i64>
  %149 = and <8 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <8 x i64> %149 to <8 x double>
  %151 = fsub <8 x double> %78, %150
  %152 = fmul <8 x double> %46, %78
  %153 = fmul <8 x double> %146, %150
  %154 = bitcast <8 x double> %152 to <8 x i64>
  %155 = xor <8 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <8 x i64> %155 to <8 x double>
  %157 = fmul <8 x double> %147, %150
  %158 = fmul <8 x double> %151, %146
  %159 = fmul <8 x double> %147, %151
  %160 = fmul <8 x double> %78, %59
  %161 = fadd <8 x double> %153, %156
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %158, %162
  %164 = fadd <8 x double> %159, %163
  %165 = fadd <8 x double> %160, %164
  %166 = fadd <8 x double> %141, %152
  %167 = fsub <8 x double> %141, %166
  %168 = fadd <8 x double> %152, %167
  %169 = fadd <8 x double> %168, %144
  %170 = fadd <8 x double> %165, %169
  %171 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <8 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = bitcast <8 x i32> %172 to <4 x i64>
  %174 = shufflevector <4 x i64> %173, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %175 = bitcast <8 x i64> %174 to <16 x i32>
  %176 = shufflevector <16 x i32> %175, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %177 = shufflevector <16 x i32> %176, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %178 = shl <16 x i32> %177, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <16 x i32> %178 to <8 x double>
  %180 = fmul <8 x double> %166, %179
  %181 = add <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %182 = sub <8 x i32> %181, %171
  %183 = bitcast <8 x i32> %182 to <4 x i64>
  %184 = shufflevector <4 x i64> %183, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %185 = bitcast <8 x i64> %184 to <16 x i32>
  %186 = shufflevector <16 x i32> %185, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %187 = shufflevector <16 x i32> %186, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %188 = shl <16 x i32> %187, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %189 = bitcast <16 x i32> %188 to <8 x double>
  %190 = fmul <8 x double> %180, %189
  %191 = fmul <8 x double> %170, %179
  %192 = fmul <8 x double> %191, %189
  %193 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %194 = bitcast i8 %193 to <8 x i1>
  %195 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %190
  %196 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %192
  %197 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %195
  %198 = bitcast <8 x double> %195 to <8 x i64>
  %199 = and <8 x i64> %198, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %200 = bitcast <8 x i64> %199 to <8 x double>
  %201 = fsub <8 x double> %195, %200
  %202 = bitcast <8 x double> %197 to <8 x i64>
  %203 = and <8 x i64> %202, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %204 = bitcast <8 x i64> %203 to <8 x double>
  %205 = fsub <8 x double> %197, %204
  %206 = fmul <8 x double> %200, %204
  %207 = fmul <8 x double> %205, %200
  %208 = fmul <8 x double> %201, %204
  %209 = fmul <8 x double> %201, %205
  %210 = fmul <8 x double> %197, %196
  %211 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %206
  %212 = fsub <8 x double> %211, %207
  %213 = fsub <8 x double> %212, %208
  %214 = fsub <8 x double> %213, %209
  %215 = fsub <8 x double> %214, %210
  %216 = fmul <8 x double> %197, %215
  %217 = fsub <8 x double> %195, %197
  %218 = fsub <8 x double> %195, %217
  %219 = fsub <8 x double> %218, %197
  %220 = fadd <8 x double> %219, %196
  %221 = fsub <8 x double> %220, %216
  %222 = fadd <8 x double> %217, %221
  %223 = fmul <8 x double> %222, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %224 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02>, i32 30, i8 -1, i32 4) #7
  %225 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %223, <8 x double> %223, i32 4, i8 -1, i32 4) #7
  %226 = or i8 %225, %224
  %227 = bitcast i8 %226 to <8 x i1>
  %228 = bitcast <8 x double> %223 to <8 x i64>
  %229 = select <8 x i1> %227, <8 x i64> <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>, <8 x i64> %228
  %230 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %231 = xor <8 x i64> %229, %230
  %232 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %233 = bitcast i8 %232 to <8 x i1>
  %234 = bitcast <8 x i64> %231 to <8 x double>
  %235 = select <8 x i1> %233, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %234
  ret <8 x double> %235
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_coshd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fadd <8 x double> %4, zeroinitializer
  %6 = fmul <8 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %6, i32 8, <8 x double> %6, i8 -1, i32 4) #7
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = fmul <8 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <8 x double> %9, %4
  %11 = fsub <8 x double> %10, %4
  %12 = fsub <8 x double> %10, %11
  %13 = fsub <8 x double> %4, %12
  %14 = fsub <8 x double> %9, %11
  %15 = fadd <8 x double> %14, %13
  %16 = fadd <8 x double> %15, zeroinitializer
  %17 = fmul <8 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <8 x double> %17, %10
  %19 = fsub <8 x double> %18, %10
  %20 = fsub <8 x double> %18, %19
  %21 = fsub <8 x double> %10, %20
  %22 = fsub <8 x double> %17, %19
  %23 = fadd <8 x double> %22, %21
  %24 = fadd <8 x double> %23, %16
  %25 = bitcast <8 x double> %18 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %18, %27
  %29 = fmul <8 x double> %18, %18
  %30 = fmul <8 x double> %27, %27
  %31 = bitcast <8 x double> %29 to <8 x i64>
  %32 = xor <8 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fadd <8 x double> %27, %27
  %35 = fmul <8 x double> %34, %28
  %36 = fmul <8 x double> %28, %28
  %37 = fadd <8 x double> %24, %24
  %38 = fmul <8 x double> %18, %37
  %39 = fadd <8 x double> %30, %33
  %40 = fadd <8 x double> %39, %35
  %41 = fadd <8 x double> %36, %40
  %42 = fadd <8 x double> %38, %41
  %43 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <8 x i64> %43 to <8 x double>
  %45 = fsub <8 x double> %29, %44
  %46 = fmul <8 x double> %29, %29
  %47 = fmul <8 x double> %44, %44
  %48 = bitcast <8 x double> %46 to <8 x i64>
  %49 = xor <8 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fadd <8 x double> %44, %44
  %52 = fmul <8 x double> %51, %45
  %53 = fmul <8 x double> %45, %45
  %54 = fadd <8 x double> %42, %42
  %55 = fmul <8 x double> %29, %54
  %56 = fadd <8 x double> %47, %50
  %57 = fadd <8 x double> %56, %52
  %58 = fadd <8 x double> %53, %57
  %59 = fadd <8 x double> %58, %55
  %60 = fmul <8 x double> %46, %46
  %61 = fmul <8 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <8 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <8 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <8 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <8 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <8 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <8 x double> %29, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <8 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <8 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <8 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <8 x double> %29, %70
  %74 = fadd <8 x double> %72, %73
  %75 = fmul <8 x double> %46, %68
  %76 = fadd <8 x double> %74, %75
  %77 = fmul <8 x double> %62, %60
  %78 = fadd <8 x double> %77, %76
  %79 = fmul <8 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <8 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <8 x double> %79 to <8 x i64>
  %82 = xor <8 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <8 x i64> %82 to <8 x double>
  %84 = fmul <8 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <8 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <8 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <8 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <8 x double> %80, %83
  %89 = fadd <8 x double> %84, %88
  %90 = fadd <8 x double> %85, %89
  %91 = fadd <8 x double> %86, %90
  %92 = fadd <8 x double> %87, %91
  %93 = fadd <8 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <8 x double> %79, %94
  %96 = fadd <8 x double> %95, %92
  %97 = bitcast <8 x double> %93 to <8 x i64>
  %98 = and <8 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <8 x i64> %98 to <8 x double>
  %100 = fsub <8 x double> %93, %99
  %101 = fmul <8 x double> %18, %93
  %102 = fmul <8 x double> %27, %99
  %103 = bitcast <8 x double> %101 to <8 x i64>
  %104 = xor <8 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = fmul <8 x double> %100, %27
  %107 = fmul <8 x double> %28, %99
  %108 = fmul <8 x double> %28, %100
  %109 = fmul <8 x double> %93, %24
  %110 = fmul <8 x double> %18, %96
  %111 = fadd <8 x double> %102, %105
  %112 = fadd <8 x double> %106, %111
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %108, %113
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <8 x double> %101, %118
  %120 = fadd <8 x double> %119, %116
  %121 = bitcast <8 x double> %117 to <8 x i64>
  %122 = and <8 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <8 x i64> %122 to <8 x double>
  %124 = fsub <8 x double> %117, %123
  %125 = fmul <8 x double> %18, %117
  %126 = fmul <8 x double> %27, %123
  %127 = bitcast <8 x double> %125 to <8 x i64>
  %128 = xor <8 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <8 x i64> %128 to <8 x double>
  %130 = fmul <8 x double> %124, %27
  %131 = fmul <8 x double> %28, %123
  %132 = fmul <8 x double> %28, %124
  %133 = fmul <8 x double> %117, %24
  %134 = fmul <8 x double> %18, %120
  %135 = fadd <8 x double> %126, %129
  %136 = fadd <8 x double> %130, %135
  %137 = fadd <8 x double> %131, %136
  %138 = fadd <8 x double> %132, %137
  %139 = fadd <8 x double> %133, %138
  %140 = fadd <8 x double> %139, %134
  %141 = fadd <8 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <8 x double> %125, %142
  %144 = fadd <8 x double> %143, %140
  %145 = and <8 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fsub <8 x double> %46, %146
  %148 = bitcast <8 x double> %78 to <8 x i64>
  %149 = and <8 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <8 x i64> %149 to <8 x double>
  %151 = fsub <8 x double> %78, %150
  %152 = fmul <8 x double> %46, %78
  %153 = fmul <8 x double> %146, %150
  %154 = bitcast <8 x double> %152 to <8 x i64>
  %155 = xor <8 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <8 x i64> %155 to <8 x double>
  %157 = fmul <8 x double> %147, %150
  %158 = fmul <8 x double> %151, %146
  %159 = fmul <8 x double> %147, %151
  %160 = fmul <8 x double> %78, %59
  %161 = fadd <8 x double> %153, %156
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %158, %162
  %164 = fadd <8 x double> %159, %163
  %165 = fadd <8 x double> %160, %164
  %166 = fadd <8 x double> %141, %152
  %167 = fsub <8 x double> %141, %166
  %168 = fadd <8 x double> %152, %167
  %169 = fadd <8 x double> %168, %144
  %170 = fadd <8 x double> %165, %169
  %171 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <8 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = bitcast <8 x i32> %172 to <4 x i64>
  %174 = shufflevector <4 x i64> %173, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %175 = bitcast <8 x i64> %174 to <16 x i32>
  %176 = shufflevector <16 x i32> %175, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %177 = shufflevector <16 x i32> %176, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %178 = shl <16 x i32> %177, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <16 x i32> %178 to <8 x double>
  %180 = fmul <8 x double> %166, %179
  %181 = add <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %182 = sub <8 x i32> %181, %171
  %183 = bitcast <8 x i32> %182 to <4 x i64>
  %184 = shufflevector <4 x i64> %183, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %185 = bitcast <8 x i64> %184 to <16 x i32>
  %186 = shufflevector <16 x i32> %185, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %187 = shufflevector <16 x i32> %186, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %188 = shl <16 x i32> %187, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %189 = bitcast <16 x i32> %188 to <8 x double>
  %190 = fmul <8 x double> %180, %189
  %191 = fmul <8 x double> %170, %179
  %192 = fmul <8 x double> %191, %189
  %193 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %194 = bitcast i8 %193 to <8 x i1>
  %195 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %190
  %196 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %192
  %197 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %195
  %198 = bitcast <8 x double> %195 to <8 x i64>
  %199 = and <8 x i64> %198, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %200 = bitcast <8 x i64> %199 to <8 x double>
  %201 = fsub <8 x double> %195, %200
  %202 = bitcast <8 x double> %197 to <8 x i64>
  %203 = and <8 x i64> %202, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %204 = bitcast <8 x i64> %203 to <8 x double>
  %205 = fsub <8 x double> %197, %204
  %206 = fmul <8 x double> %200, %204
  %207 = fmul <8 x double> %205, %200
  %208 = fmul <8 x double> %201, %204
  %209 = fmul <8 x double> %201, %205
  %210 = fmul <8 x double> %197, %196
  %211 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %206
  %212 = fsub <8 x double> %211, %207
  %213 = fsub <8 x double> %212, %208
  %214 = fsub <8 x double> %213, %209
  %215 = fsub <8 x double> %214, %210
  %216 = fmul <8 x double> %197, %215
  %217 = fadd <8 x double> %195, %197
  %218 = fsub <8 x double> %195, %217
  %219 = fadd <8 x double> %197, %218
  %220 = fadd <8 x double> %219, %196
  %221 = fadd <8 x double> %220, %216
  %222 = fadd <8 x double> %217, %221
  %223 = fmul <8 x double> %222, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %224 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02, double 7.100000e+02>, i32 30, i8 -1, i32 4) #7
  %225 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %223, <8 x double> %223, i32 4, i8 -1, i32 4) #7
  %226 = or i8 %225, %224
  %227 = bitcast i8 %226 to <8 x i1>
  %228 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %229 = bitcast i8 %228 to <8 x i1>
  %230 = select <8 x i1> %227, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %223
  %231 = select <8 x i1> %229, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %230
  ret <8 x double> %231
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_tanhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fadd <8 x double> %4, zeroinitializer
  %6 = fmul <8 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %6, i32 8, <8 x double> %6, i8 -1, i32 4) #7
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = fmul <8 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <8 x double> %9, %4
  %11 = fsub <8 x double> %10, %4
  %12 = fsub <8 x double> %10, %11
  %13 = fsub <8 x double> %4, %12
  %14 = fsub <8 x double> %9, %11
  %15 = fadd <8 x double> %14, %13
  %16 = fadd <8 x double> %15, zeroinitializer
  %17 = fmul <8 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %18 = fadd <8 x double> %17, %10
  %19 = fsub <8 x double> %18, %10
  %20 = fsub <8 x double> %18, %19
  %21 = fsub <8 x double> %10, %20
  %22 = fsub <8 x double> %17, %19
  %23 = fadd <8 x double> %22, %21
  %24 = fadd <8 x double> %23, %16
  %25 = bitcast <8 x double> %18 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %18, %27
  %29 = fmul <8 x double> %18, %18
  %30 = fmul <8 x double> %27, %27
  %31 = bitcast <8 x double> %29 to <8 x i64>
  %32 = xor <8 x i64> %31, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fadd <8 x double> %27, %27
  %35 = fmul <8 x double> %34, %28
  %36 = fmul <8 x double> %28, %28
  %37 = fadd <8 x double> %24, %24
  %38 = fmul <8 x double> %18, %37
  %39 = fadd <8 x double> %30, %33
  %40 = fadd <8 x double> %39, %35
  %41 = fadd <8 x double> %36, %40
  %42 = fadd <8 x double> %38, %41
  %43 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %44 = bitcast <8 x i64> %43 to <8 x double>
  %45 = fsub <8 x double> %29, %44
  %46 = fmul <8 x double> %29, %29
  %47 = fmul <8 x double> %44, %44
  %48 = bitcast <8 x double> %46 to <8 x i64>
  %49 = xor <8 x i64> %48, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %50 = bitcast <8 x i64> %49 to <8 x double>
  %51 = fadd <8 x double> %44, %44
  %52 = fmul <8 x double> %51, %45
  %53 = fmul <8 x double> %45, %45
  %54 = fadd <8 x double> %42, %42
  %55 = fmul <8 x double> %29, %54
  %56 = fadd <8 x double> %47, %50
  %57 = fadd <8 x double> %56, %52
  %58 = fadd <8 x double> %53, %57
  %59 = fadd <8 x double> %58, %55
  %60 = fmul <8 x double> %46, %46
  %61 = fmul <8 x double> %18, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %62 = fadd <8 x double> %61, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %63 = fmul <8 x double> %18, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %64 = fadd <8 x double> %63, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %65 = fmul <8 x double> %18, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %66 = fadd <8 x double> %65, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %67 = fmul <8 x double> %29, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %18, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %70 = fadd <8 x double> %69, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %71 = fmul <8 x double> %18, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %72 = fadd <8 x double> %71, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %73 = fmul <8 x double> %29, %70
  %74 = fadd <8 x double> %72, %73
  %75 = fmul <8 x double> %46, %68
  %76 = fadd <8 x double> %74, %75
  %77 = fmul <8 x double> %62, %60
  %78 = fadd <8 x double> %77, %76
  %79 = fmul <8 x double> %18, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %80 = fmul <8 x double> %27, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %81 = bitcast <8 x double> %79 to <8 x i64>
  %82 = xor <8 x i64> %81, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %83 = bitcast <8 x i64> %82 to <8 x double>
  %84 = fmul <8 x double> %28, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %85 = fmul <8 x double> %27, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %86 = fmul <8 x double> %28, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %87 = fmul <8 x double> %24, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %88 = fadd <8 x double> %80, %83
  %89 = fadd <8 x double> %84, %88
  %90 = fadd <8 x double> %85, %89
  %91 = fadd <8 x double> %86, %90
  %92 = fadd <8 x double> %87, %91
  %93 = fadd <8 x double> %79, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %94 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %93
  %95 = fadd <8 x double> %79, %94
  %96 = fadd <8 x double> %95, %92
  %97 = bitcast <8 x double> %93 to <8 x i64>
  %98 = and <8 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %99 = bitcast <8 x i64> %98 to <8 x double>
  %100 = fsub <8 x double> %93, %99
  %101 = fmul <8 x double> %18, %93
  %102 = fmul <8 x double> %27, %99
  %103 = bitcast <8 x double> %101 to <8 x i64>
  %104 = xor <8 x i64> %103, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = fmul <8 x double> %100, %27
  %107 = fmul <8 x double> %28, %99
  %108 = fmul <8 x double> %28, %100
  %109 = fmul <8 x double> %93, %24
  %110 = fmul <8 x double> %18, %96
  %111 = fadd <8 x double> %102, %105
  %112 = fadd <8 x double> %106, %111
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %108, %113
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %101, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %118 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %117
  %119 = fadd <8 x double> %101, %118
  %120 = fadd <8 x double> %119, %116
  %121 = bitcast <8 x double> %117 to <8 x i64>
  %122 = and <8 x i64> %121, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %123 = bitcast <8 x i64> %122 to <8 x double>
  %124 = fsub <8 x double> %117, %123
  %125 = fmul <8 x double> %18, %117
  %126 = fmul <8 x double> %27, %123
  %127 = bitcast <8 x double> %125 to <8 x i64>
  %128 = xor <8 x i64> %127, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <8 x i64> %128 to <8 x double>
  %130 = fmul <8 x double> %124, %27
  %131 = fmul <8 x double> %28, %123
  %132 = fmul <8 x double> %28, %124
  %133 = fmul <8 x double> %117, %24
  %134 = fmul <8 x double> %18, %120
  %135 = fadd <8 x double> %126, %129
  %136 = fadd <8 x double> %130, %135
  %137 = fadd <8 x double> %131, %136
  %138 = fadd <8 x double> %132, %137
  %139 = fadd <8 x double> %133, %138
  %140 = fadd <8 x double> %139, %134
  %141 = fadd <8 x double> %125, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %142 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %141
  %143 = fadd <8 x double> %125, %142
  %144 = fadd <8 x double> %143, %140
  %145 = and <8 x i64> %48, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %146 = bitcast <8 x i64> %145 to <8 x double>
  %147 = fsub <8 x double> %46, %146
  %148 = bitcast <8 x double> %78 to <8 x i64>
  %149 = and <8 x i64> %148, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %150 = bitcast <8 x i64> %149 to <8 x double>
  %151 = fsub <8 x double> %78, %150
  %152 = fmul <8 x double> %46, %78
  %153 = fmul <8 x double> %146, %150
  %154 = bitcast <8 x double> %152 to <8 x i64>
  %155 = xor <8 x i64> %154, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %156 = bitcast <8 x i64> %155 to <8 x double>
  %157 = fmul <8 x double> %147, %150
  %158 = fmul <8 x double> %151, %146
  %159 = fmul <8 x double> %147, %151
  %160 = fmul <8 x double> %78, %59
  %161 = fadd <8 x double> %153, %156
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %158, %162
  %164 = fadd <8 x double> %159, %163
  %165 = fadd <8 x double> %160, %164
  %166 = fadd <8 x double> %141, %152
  %167 = fsub <8 x double> %141, %166
  %168 = fadd <8 x double> %152, %167
  %169 = fadd <8 x double> %168, %144
  %170 = fadd <8 x double> %165, %169
  %171 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <8 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = bitcast <8 x i32> %172 to <4 x i64>
  %174 = shufflevector <4 x i64> %173, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %175 = bitcast <8 x i64> %174 to <16 x i32>
  %176 = shufflevector <16 x i32> %175, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %177 = shufflevector <16 x i32> %176, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %178 = shl <16 x i32> %177, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <16 x i32> %178 to <8 x double>
  %180 = fmul <8 x double> %166, %179
  %181 = add <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %182 = sub <8 x i32> %181, %171
  %183 = bitcast <8 x i32> %182 to <4 x i64>
  %184 = shufflevector <4 x i64> %183, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %185 = bitcast <8 x i64> %184 to <16 x i32>
  %186 = shufflevector <16 x i32> %185, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %187 = shufflevector <16 x i32> %186, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %188 = shl <16 x i32> %187, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %189 = bitcast <16 x i32> %188 to <8 x double>
  %190 = fmul <8 x double> %180, %189
  %191 = fmul <8 x double> %170, %179
  %192 = fmul <8 x double> %191, %189
  %193 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %194 = bitcast i8 %193 to <8 x i1>
  %195 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %190
  %196 = select <8 x i1> %194, <8 x double> zeroinitializer, <8 x double> %192
  %197 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %195
  %198 = bitcast <8 x double> %195 to <8 x i64>
  %199 = and <8 x i64> %198, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %200 = bitcast <8 x i64> %199 to <8 x double>
  %201 = fsub <8 x double> %195, %200
  %202 = bitcast <8 x double> %197 to <8 x i64>
  %203 = and <8 x i64> %202, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %204 = bitcast <8 x i64> %203 to <8 x double>
  %205 = fsub <8 x double> %197, %204
  %206 = fmul <8 x double> %200, %204
  %207 = fmul <8 x double> %205, %200
  %208 = fmul <8 x double> %201, %204
  %209 = fmul <8 x double> %201, %205
  %210 = fmul <8 x double> %197, %196
  %211 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %206
  %212 = fsub <8 x double> %211, %207
  %213 = fsub <8 x double> %212, %208
  %214 = fsub <8 x double> %213, %209
  %215 = fsub <8 x double> %214, %210
  %216 = fmul <8 x double> %197, %215
  %217 = xor <8 x i64> %202, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %218 = bitcast <8 x double> %216 to <8 x i64>
  %219 = xor <8 x i64> %218, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %220 = bitcast <8 x i64> %217 to <8 x double>
  %221 = bitcast <8 x i64> %219 to <8 x double>
  %222 = fadd <8 x double> %195, %220
  %223 = fsub <8 x double> %222, %195
  %224 = fsub <8 x double> %222, %223
  %225 = fsub <8 x double> %195, %224
  %226 = fsub <8 x double> %220, %223
  %227 = fadd <8 x double> %226, %225
  %228 = fadd <8 x double> %196, %221
  %229 = fadd <8 x double> %227, %228
  %230 = fadd <8 x double> %195, %197
  %231 = fsub <8 x double> %230, %195
  %232 = fsub <8 x double> %230, %231
  %233 = fsub <8 x double> %195, %232
  %234 = fsub <8 x double> %197, %231
  %235 = fadd <8 x double> %234, %233
  %236 = fadd <8 x double> %196, %216
  %237 = fadd <8 x double> %235, %236
  %238 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %230
  %239 = bitcast <8 x double> %230 to <8 x i64>
  %240 = and <8 x i64> %239, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %241 = bitcast <8 x i64> %240 to <8 x double>
  %242 = fsub <8 x double> %230, %241
  %243 = bitcast <8 x double> %238 to <8 x i64>
  %244 = and <8 x i64> %243, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %245 = bitcast <8 x i64> %244 to <8 x double>
  %246 = fsub <8 x double> %238, %245
  %247 = bitcast <8 x double> %222 to <8 x i64>
  %248 = and <8 x i64> %247, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %249 = bitcast <8 x i64> %248 to <8 x double>
  %250 = fsub <8 x double> %222, %249
  %251 = fmul <8 x double> %238, %222
  %252 = fmul <8 x double> %245, %249
  %253 = fsub <8 x double> %252, %251
  %254 = fmul <8 x double> %246, %249
  %255 = fmul <8 x double> %250, %245
  %256 = fmul <8 x double> %246, %250
  %257 = fmul <8 x double> %241, %245
  %258 = fmul <8 x double> %246, %241
  %259 = fmul <8 x double> %242, %245
  %260 = fmul <8 x double> %242, %246
  %261 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %257
  %262 = fsub <8 x double> %261, %258
  %263 = fsub <8 x double> %262, %259
  %264 = fsub <8 x double> %263, %260
  %265 = fmul <8 x double> %251, %264
  %266 = fadd <8 x double> %254, %253
  %267 = fadd <8 x double> %255, %266
  %268 = fadd <8 x double> %256, %267
  %269 = fadd <8 x double> %265, %268
  %270 = fmul <8 x double> %251, %237
  %271 = fsub <8 x double> %229, %270
  %272 = fmul <8 x double> %238, %271
  %273 = fadd <8 x double> %269, %272
  %274 = fadd <8 x double> %251, %273
  %275 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i32 30, i8 -1, i32 4) #7
  %276 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %274, <8 x double> %274, i32 4, i8 -1, i32 4) #7
  %277 = or i8 %276, %275
  %278 = bitcast i8 %277 to <8 x i1>
  %279 = bitcast <8 x double> %274 to <8 x i64>
  %280 = select <8 x i1> %278, <8 x i64> <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>, <8 x i64> %279
  %281 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %282 = xor <8 x i64> %280, %281
  %283 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %284 = bitcast i8 %283 to <8 x i1>
  %285 = bitcast <8 x i64> %282 to <8 x double>
  %286 = select <8 x i1> %284, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %285
  ret <8 x double> %286
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sinhd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %5, i32 8, <8 x double> %5, i8 -1, i32 4) #7
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %8 = bitcast <8 x i32> %7 to <4 x i64>
  %9 = fmul <8 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <8 x double> %9, %4
  %11 = fmul <8 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %12 = fadd <8 x double> %11, %10
  %13 = fmul <8 x double> %12, %12
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %14, %14
  %16 = fmul <8 x double> %12, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %17 = fadd <8 x double> %16, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %18 = fmul <8 x double> %12, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %19 = fadd <8 x double> %18, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %20 = fmul <8 x double> %12, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %21 = fadd <8 x double> %20, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %22 = fmul <8 x double> %13, %19
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %12, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %25 = fadd <8 x double> %24, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %26 = fmul <8 x double> %12, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %27 = fadd <8 x double> %26, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %28 = fmul <8 x double> %13, %25
  %29 = fadd <8 x double> %27, %28
  %30 = fmul <8 x double> %14, %23
  %31 = fadd <8 x double> %29, %30
  %32 = fmul <8 x double> %17, %15
  %33 = fadd <8 x double> %32, %31
  %34 = fmul <8 x double> %12, %13
  %35 = fmul <8 x double> %34, %33
  %36 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %37 = fadd <8 x double> %36, %35
  %38 = fadd <8 x double> %12, %37
  %39 = shufflevector <4 x i64> %8, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <8 x i64> %39 to <16 x i32>
  %41 = icmp eq <16 x i32> %40, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = fadd <8 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %43 = ashr <8 x i32> %7, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %44 = add nsw <8 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %45 = bitcast <8 x i32> %44 to <4 x i64>
  %46 = shufflevector <4 x i64> %45, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %47 = bitcast <8 x i64> %46 to <16 x i32>
  %48 = shufflevector <16 x i32> %47, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %49 = shufflevector <16 x i32> %48, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %50 = shl <16 x i32> %49, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %51 = bitcast <16 x i32> %50 to <8 x double>
  %52 = fmul <8 x double> %42, %51
  %53 = add <8 x i32> %7, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %54 = sub <8 x i32> %53, %43
  %55 = bitcast <8 x i32> %54 to <4 x i64>
  %56 = shufflevector <4 x i64> %55, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <8 x i64> %56 to <16 x i32>
  %58 = shufflevector <16 x i32> %57, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %59 = shufflevector <16 x i32> %58, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %60 = shl <16 x i32> %59, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <16 x i32> %60 to <8 x double>
  %62 = fmul <8 x double> %52, %61
  %63 = fadd <8 x double> %62, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %64 = bitcast <16 x i1> %41 to <2 x i8>
  %65 = extractelement <2 x i8> %64, i32 0
  %66 = bitcast i8 %65 to <8 x i1>
  %67 = select <8 x i1> %66, <8 x double> %38, <8 x double> %63
  %68 = fadd <8 x double> %67, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %69 = fadd <8 x double> %67, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %70 = fdiv <8 x double> %68, %69
  %71 = fmul <8 x double> %67, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %72 = fmul <8 x double> %71, %70
  %73 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i32 30, i8 -1, i32 4) #7
  %74 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %72, <8 x double> %72, i32 4, i8 -1, i32 4) #7
  %75 = or i8 %74, %73
  %76 = bitcast i8 %75 to <8 x i1>
  %77 = bitcast <8 x double> %72 to <8 x i64>
  %78 = select <8 x i1> %76, <8 x i64> <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>, <8 x i64> %77
  %79 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = xor <8 x i64> %78, %79
  %81 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %82 = bitcast i8 %81 to <8 x i1>
  %83 = bitcast <8 x i64> %80 to <8 x double>
  %84 = select <8 x i1> %82, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %83
  ret <8 x double> %84
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_coshd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %5, i32 8, <8 x double> %5, i8 -1, i32 4) #7
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %8 = fmul <8 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <8 x double> %8, %4
  %10 = fmul <8 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <8 x double> %10, %9
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %12, %12
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <8 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <8 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <8 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <8 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <8 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <8 x double> %12, %18
  %22 = fadd <8 x double> %20, %21
  %23 = fmul <8 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <8 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <8 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <8 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <8 x double> %12, %24
  %28 = fadd <8 x double> %26, %27
  %29 = fmul <8 x double> %13, %22
  %30 = fadd <8 x double> %28, %29
  %31 = fmul <8 x double> %16, %14
  %32 = fadd <8 x double> %31, %30
  %33 = fmul <8 x double> %11, %32
  %34 = fadd <8 x double> %33, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %35 = fmul <8 x double> %12, %34
  %36 = fadd <8 x double> %11, %35
  %37 = fadd <8 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %38 = ashr <8 x i32> %7, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %39 = add nsw <8 x i32> %38, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %40 = bitcast <8 x i32> %39 to <4 x i64>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = bitcast <8 x i64> %41 to <16 x i32>
  %43 = shufflevector <16 x i32> %42, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %44 = shufflevector <16 x i32> %43, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %45 = shl <16 x i32> %44, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %46 = bitcast <16 x i32> %45 to <8 x double>
  %47 = fmul <8 x double> %37, %46
  %48 = add <8 x i32> %7, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %49 = sub <8 x i32> %48, %38
  %50 = bitcast <8 x i32> %49 to <4 x i64>
  %51 = shufflevector <4 x i64> %50, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <8 x i64> %51 to <16 x i32>
  %53 = shufflevector <16 x i32> %52, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %54 = shufflevector <16 x i32> %53, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %55 = shl <16 x i32> %54, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %56 = bitcast <16 x i32> %55 to <8 x double>
  %57 = fmul <8 x double> %47, %56
  %58 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i32 30, i8 -1, i32 4) #7
  %59 = bitcast i8 %58 to <8 x i1>
  %60 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %61 = bitcast i8 %60 to <8 x i1>
  %62 = select <8 x i1> %59, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %57
  %63 = select <8 x i1> %61, <8 x double> zeroinitializer, <8 x double> %62
  %64 = fdiv <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %63
  %65 = fmul <8 x double> %63, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %66 = fadd <8 x double> %65, %64
  %67 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i32 30, i8 -1, i32 4) #7
  %68 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %66, <8 x double> %66, i32 4, i8 -1, i32 4) #7
  %69 = or i8 %68, %67
  %70 = bitcast i8 %69 to <8 x i1>
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %72 = bitcast i8 %71 to <8 x i1>
  %73 = select <8 x i1> %70, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %66
  %74 = select <8 x i1> %72, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %73
  ret <8 x double> %74
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_tanhd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %6 = fmul <8 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %6, i32 8, <8 x double> %6, i8 -1, i32 4) #7
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = bitcast <8 x i32> %8 to <4 x i64>
  %10 = fmul <8 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %11 = fadd <8 x double> %5, %10
  %12 = fmul <8 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %13 = fadd <8 x double> %12, %11
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %14, %14
  %16 = fmul <8 x double> %15, %15
  %17 = fmul <8 x double> %13, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %18 = fadd <8 x double> %17, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %19 = fmul <8 x double> %13, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %20 = fadd <8 x double> %19, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %21 = fmul <8 x double> %13, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %22 = fadd <8 x double> %21, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %23 = fmul <8 x double> %14, %20
  %24 = fadd <8 x double> %22, %23
  %25 = fmul <8 x double> %13, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %26 = fadd <8 x double> %25, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %27 = fmul <8 x double> %13, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %28 = fadd <8 x double> %27, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %29 = fmul <8 x double> %14, %26
  %30 = fadd <8 x double> %28, %29
  %31 = fmul <8 x double> %15, %24
  %32 = fadd <8 x double> %30, %31
  %33 = fmul <8 x double> %18, %16
  %34 = fadd <8 x double> %33, %32
  %35 = fmul <8 x double> %13, %14
  %36 = fmul <8 x double> %35, %34
  %37 = fmul <8 x double> %14, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %38 = fadd <8 x double> %37, %36
  %39 = fadd <8 x double> %13, %38
  %40 = shufflevector <4 x i64> %9, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <8 x i64> %40 to <16 x i32>
  %42 = icmp eq <16 x i32> %41, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %43 = fadd <8 x double> %39, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %44 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %45 = add nsw <8 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = bitcast <8 x i32> %45 to <4 x i64>
  %47 = shufflevector <4 x i64> %46, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %48 = bitcast <8 x i64> %47 to <16 x i32>
  %49 = shufflevector <16 x i32> %48, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %50 = shufflevector <16 x i32> %49, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %51 = shl <16 x i32> %50, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %52 = bitcast <16 x i32> %51 to <8 x double>
  %53 = fmul <8 x double> %43, %52
  %54 = add <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = sub <8 x i32> %54, %44
  %56 = bitcast <8 x i32> %55 to <4 x i64>
  %57 = shufflevector <4 x i64> %56, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = bitcast <8 x i64> %57 to <16 x i32>
  %59 = shufflevector <16 x i32> %58, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %60 = shufflevector <16 x i32> %59, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %61 = shl <16 x i32> %60, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %62 = bitcast <16 x i32> %61 to <8 x double>
  %63 = fmul <8 x double> %53, %62
  %64 = fadd <8 x double> %63, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %65 = bitcast <16 x i1> %42 to <2 x i8>
  %66 = extractelement <2 x i8> %65, i32 0
  %67 = bitcast i8 %66 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x double> %39, <8 x double> %64
  %69 = fadd <8 x double> %68, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %70 = fdiv <8 x double> %68, %69
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i32 30, i8 -1, i32 4) #7
  %72 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %70, <8 x double> %70, i32 4, i8 -1, i32 4) #7
  %73 = or i8 %72, %71
  %74 = bitcast i8 %73 to <8 x i1>
  %75 = bitcast <8 x double> %70 to <8 x i64>
  %76 = select <8 x i1> %74, <8 x i64> <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>, <8 x i64> %75
  %77 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = xor <8 x i64> %76, %77
  %79 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %80 = bitcast i8 %79 to <8 x i1>
  %81 = bitcast <8 x i64> %78 to <8 x double>
  %82 = select <8 x i1> %80, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %81
  ret <8 x double> %82
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_asinhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 30, i8 -1, i32 4) #7
  %6 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %0
  %7 = and <8 x i64> %2, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = fsub <8 x double> %0, %8
  %10 = bitcast <8 x double> %6 to <8 x i64>
  %11 = and <8 x i64> %10, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %12 = bitcast <8 x i64> %11 to <8 x double>
  %13 = fsub <8 x double> %6, %12
  %14 = fmul <8 x double> %8, %12
  %15 = fmul <8 x double> %13, %8
  %16 = fmul <8 x double> %9, %12
  %17 = fmul <8 x double> %9, %13
  %18 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %19 = fsub <8 x double> %18, %15
  %20 = fsub <8 x double> %19, %16
  %21 = fsub <8 x double> %20, %17
  %22 = fmul <8 x double> %6, %21
  %23 = bitcast i8 %5 to <8 x i1>
  %24 = select <8 x i1> %23, <8 x double> %6, <8 x double> %4
  %25 = select <8 x i1> %23, <8 x double> %22, <8 x double> zeroinitializer
  %26 = bitcast <8 x double> %24 to <8 x i64>
  %27 = and <8 x i64> %26, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = fsub <8 x double> %24, %28
  %30 = fmul <8 x double> %24, %24
  %31 = fmul <8 x double> %28, %28
  %32 = bitcast <8 x double> %30 to <8 x i64>
  %33 = xor <8 x i64> %32, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %34 = bitcast <8 x i64> %33 to <8 x double>
  %35 = fadd <8 x double> %28, %28
  %36 = fmul <8 x double> %35, %29
  %37 = fmul <8 x double> %29, %29
  %38 = fadd <8 x double> %25, %25
  %39 = fmul <8 x double> %24, %38
  %40 = fadd <8 x double> %31, %34
  %41 = fadd <8 x double> %40, %36
  %42 = fadd <8 x double> %37, %41
  %43 = fadd <8 x double> %39, %42
  %44 = fadd <8 x double> %30, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %45 = fsub <8 x double> %44, %30
  %46 = fsub <8 x double> %44, %45
  %47 = fsub <8 x double> %30, %46
  %48 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %45
  %49 = fadd <8 x double> %48, %47
  %50 = fadd <8 x double> %49, %43
  %51 = fadd <8 x double> %44, %50
  %52 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %51, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %53 = bitcast <8 x double> %52 to <8 x i64>
  %54 = and <8 x i64> %53, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %55 = bitcast <8 x i64> %54 to <8 x double>
  %56 = fsub <8 x double> %52, %55
  %57 = fmul <8 x double> %52, %52
  %58 = fmul <8 x double> %55, %55
  %59 = bitcast <8 x double> %57 to <8 x i64>
  %60 = xor <8 x i64> %59, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %61 = bitcast <8 x i64> %60 to <8 x double>
  %62 = fmul <8 x double> %56, %55
  %63 = fmul <8 x double> %56, %56
  %64 = fadd <8 x double> %58, %61
  %65 = fadd <8 x double> %62, %64
  %66 = fadd <8 x double> %62, %65
  %67 = fadd <8 x double> %63, %66
  %68 = fadd <8 x double> %57, %44
  %69 = fsub <8 x double> %68, %44
  %70 = fsub <8 x double> %68, %69
  %71 = fsub <8 x double> %44, %70
  %72 = fsub <8 x double> %57, %69
  %73 = fadd <8 x double> %72, %71
  %74 = fadd <8 x double> %67, %50
  %75 = fadd <8 x double> %73, %74
  %76 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %52
  %77 = bitcast <8 x double> %76 to <8 x i64>
  %78 = and <8 x i64> %77, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fsub <8 x double> %76, %79
  %81 = fmul <8 x double> %55, %79
  %82 = fmul <8 x double> %80, %55
  %83 = fmul <8 x double> %56, %79
  %84 = fmul <8 x double> %56, %80
  %85 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %81
  %86 = fsub <8 x double> %85, %82
  %87 = fsub <8 x double> %86, %83
  %88 = fsub <8 x double> %87, %84
  %89 = fmul <8 x double> %76, %88
  %90 = bitcast <8 x double> %68 to <8 x i64>
  %91 = and <8 x i64> %90, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %92 = bitcast <8 x i64> %91 to <8 x double>
  %93 = fsub <8 x double> %68, %92
  %94 = fmul <8 x double> %76, %68
  %95 = fmul <8 x double> %79, %92
  %96 = bitcast <8 x double> %94 to <8 x i64>
  %97 = xor <8 x i64> %96, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %98 = bitcast <8 x i64> %97 to <8 x double>
  %99 = fmul <8 x double> %93, %79
  %100 = fmul <8 x double> %80, %92
  %101 = fmul <8 x double> %80, %93
  %102 = fmul <8 x double> %68, %89
  %103 = fmul <8 x double> %76, %75
  %104 = fadd <8 x double> %95, %98
  %105 = fadd <8 x double> %99, %104
  %106 = fadd <8 x double> %100, %105
  %107 = fadd <8 x double> %101, %106
  %108 = fadd <8 x double> %102, %107
  %109 = fadd <8 x double> %103, %108
  %110 = fmul <8 x double> %94, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %111 = fmul <8 x double> %109, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %112 = bitcast <8 x double> %110 to <8 x i64>
  %113 = and <8 x i64> %112, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %114 = bitcast <8 x i64> %113 to <8 x double>
  %115 = fsub <8 x double> %110, %114
  %116 = and <8 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %117 = bitcast <8 x i64> %116 to <8 x double>
  %118 = fsub <8 x double> %4, %117
  %119 = fmul <8 x double> %110, %4
  %120 = fmul <8 x double> %117, %114
  %121 = bitcast <8 x double> %119 to <8 x i64>
  %122 = xor <8 x i64> %121, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %123 = bitcast <8 x i64> %122 to <8 x double>
  %124 = fmul <8 x double> %115, %117
  %125 = fmul <8 x double> %118, %114
  %126 = fmul <8 x double> %118, %115
  %127 = fmul <8 x double> %111, %4
  %128 = fadd <8 x double> %120, %123
  %129 = fadd <8 x double> %124, %128
  %130 = fadd <8 x double> %125, %129
  %131 = fadd <8 x double> %126, %130
  %132 = fadd <8 x double> %131, %127
  %133 = select <8 x i1> %23, <8 x double> %119, <8 x double> %110
  %134 = select <8 x i1> %23, <8 x double> %132, <8 x double> %111
  %135 = fadd <8 x double> %133, %0
  %136 = fsub <8 x double> %135, %133
  %137 = fsub <8 x double> %135, %136
  %138 = fsub <8 x double> %133, %137
  %139 = fsub <8 x double> %0, %136
  %140 = fadd <8 x double> %139, %138
  %141 = fadd <8 x double> %140, %134
  %142 = fadd <8 x double> %135, %141
  %143 = fsub <8 x double> %135, %142
  %144 = fadd <8 x double> %141, %143
  %145 = fmul <8 x double> %142, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %146 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %145, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %147 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %146, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %148 = sub <8 x i32> zeroinitializer, %147
  %149 = ashr <8 x i32> %148, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %150 = add nsw <8 x i32> %149, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %151 = bitcast <8 x i32> %150 to <4 x i64>
  %152 = shufflevector <4 x i64> %151, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %153 = bitcast <8 x i64> %152 to <16 x i32>
  %154 = shufflevector <16 x i32> %153, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %155 = shufflevector <16 x i32> %154, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %156 = shl <16 x i32> %155, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %157 = bitcast <16 x i32> %156 to <8 x double>
  %158 = fmul <8 x double> %142, %157
  %159 = sub <8 x i32> <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>, %147
  %160 = sub <8 x i32> %159, %149
  %161 = bitcast <8 x i32> %160 to <4 x i64>
  %162 = shufflevector <4 x i64> %161, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %163 = bitcast <8 x i64> %162 to <16 x i32>
  %164 = shufflevector <16 x i32> %163, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %165 = shufflevector <16 x i32> %164, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %166 = shl <16 x i32> %165, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %167 = bitcast <16 x i32> %166 to <8 x double>
  %168 = fmul <8 x double> %158, %167
  %169 = fmul <8 x double> %144, %157
  %170 = fmul <8 x double> %169, %167
  %171 = fadd <8 x double> %168, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %172 = fsub <8 x double> %171, %168
  %173 = fsub <8 x double> %171, %172
  %174 = fsub <8 x double> %168, %173
  %175 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %172
  %176 = fadd <8 x double> %175, %174
  %177 = fadd <8 x double> %170, %176
  %178 = fadd <8 x double> %168, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %179 = fsub <8 x double> %178, %168
  %180 = fsub <8 x double> %178, %179
  %181 = fsub <8 x double> %168, %180
  %182 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %179
  %183 = fadd <8 x double> %182, %181
  %184 = fadd <8 x double> %170, %183
  %185 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %178
  %186 = bitcast <8 x double> %178 to <8 x i64>
  %187 = and <8 x i64> %186, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %188 = bitcast <8 x i64> %187 to <8 x double>
  %189 = fsub <8 x double> %178, %188
  %190 = bitcast <8 x double> %185 to <8 x i64>
  %191 = and <8 x i64> %190, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %192 = bitcast <8 x i64> %191 to <8 x double>
  %193 = fsub <8 x double> %185, %192
  %194 = bitcast <8 x double> %171 to <8 x i64>
  %195 = and <8 x i64> %194, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %196 = bitcast <8 x i64> %195 to <8 x double>
  %197 = fsub <8 x double> %171, %196
  %198 = fmul <8 x double> %171, %185
  %199 = fmul <8 x double> %196, %192
  %200 = fsub <8 x double> %199, %198
  %201 = fmul <8 x double> %193, %196
  %202 = fmul <8 x double> %197, %192
  %203 = fmul <8 x double> %197, %193
  %204 = fmul <8 x double> %188, %192
  %205 = fmul <8 x double> %193, %188
  %206 = fmul <8 x double> %189, %192
  %207 = fmul <8 x double> %189, %193
  %208 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %204
  %209 = fsub <8 x double> %208, %205
  %210 = fsub <8 x double> %209, %206
  %211 = fsub <8 x double> %210, %207
  %212 = fmul <8 x double> %198, %211
  %213 = fadd <8 x double> %200, %201
  %214 = fadd <8 x double> %202, %213
  %215 = fadd <8 x double> %203, %214
  %216 = fadd <8 x double> %215, %212
  %217 = fmul <8 x double> %198, %184
  %218 = fsub <8 x double> %177, %217
  %219 = fmul <8 x double> %185, %218
  %220 = fadd <8 x double> %219, %216
  %221 = bitcast <8 x double> %198 to <8 x i64>
  %222 = and <8 x i64> %221, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %223 = bitcast <8 x i64> %222 to <8 x double>
  %224 = fsub <8 x double> %198, %223
  %225 = fmul <8 x double> %198, %198
  %226 = fmul <8 x double> %223, %223
  %227 = bitcast <8 x double> %225 to <8 x i64>
  %228 = xor <8 x i64> %227, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %229 = bitcast <8 x i64> %228 to <8 x double>
  %230 = fadd <8 x double> %223, %223
  %231 = fmul <8 x double> %230, %224
  %232 = fmul <8 x double> %224, %224
  %233 = fadd <8 x double> %220, %220
  %234 = fmul <8 x double> %198, %233
  %235 = fadd <8 x double> %226, %229
  %236 = fadd <8 x double> %235, %231
  %237 = fadd <8 x double> %232, %236
  %238 = fadd <8 x double> %237, %234
  %239 = fmul <8 x double> %225, %225
  %240 = fmul <8 x double> %239, %239
  %241 = fmul <8 x double> %225, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %242 = fadd <8 x double> %241, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %243 = fmul <8 x double> %239, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %244 = fadd <8 x double> %243, %242
  %245 = fmul <8 x double> %225, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %246 = fadd <8 x double> %245, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %247 = fmul <8 x double> %225, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %248 = fadd <8 x double> %247, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %249 = fmul <8 x double> %239, %246
  %250 = fadd <8 x double> %248, %249
  %251 = fmul <8 x double> %240, %244
  %252 = fadd <8 x double> %251, %250
  %253 = fmul <8 x double> %225, %252
  %254 = fadd <8 x double> %253, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %255 = sitofp <8 x i32> %147 to <8 x double>
  %256 = bitcast <8 x double> %255 to <8 x i64>
  %257 = and <8 x i64> %256, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %258 = bitcast <8 x i64> %257 to <8 x double>
  %259 = fsub <8 x double> %255, %258
  %260 = fmul <8 x double> %255, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %261 = fmul <8 x double> %258, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %262 = bitcast <8 x double> %260 to <8 x i64>
  %263 = xor <8 x i64> %262, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %264 = bitcast <8 x i64> %263 to <8 x double>
  %265 = fmul <8 x double> %258, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %266 = fmul <8 x double> %259, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %267 = fmul <8 x double> %259, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %268 = fmul <8 x double> %255, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %269 = fadd <8 x double> %261, %264
  %270 = fadd <8 x double> %265, %269
  %271 = fadd <8 x double> %266, %270
  %272 = fadd <8 x double> %267, %271
  %273 = fadd <8 x double> %268, %272
  %274 = fmul <8 x double> %198, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %275 = fmul <8 x double> %220, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %276 = fadd <8 x double> %260, %274
  %277 = fsub <8 x double> %260, %276
  %278 = fadd <8 x double> %274, %277
  %279 = fadd <8 x double> %273, %278
  %280 = fadd <8 x double> %279, %275
  %281 = and <8 x i64> %227, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %282 = bitcast <8 x i64> %281 to <8 x double>
  %283 = fsub <8 x double> %225, %282
  %284 = fmul <8 x double> %198, %225
  %285 = fmul <8 x double> %223, %282
  %286 = bitcast <8 x double> %284 to <8 x i64>
  %287 = xor <8 x i64> %286, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %288 = bitcast <8 x i64> %287 to <8 x double>
  %289 = fmul <8 x double> %283, %223
  %290 = fmul <8 x double> %224, %282
  %291 = fmul <8 x double> %224, %283
  %292 = fmul <8 x double> %225, %220
  %293 = fmul <8 x double> %198, %238
  %294 = fadd <8 x double> %285, %288
  %295 = fadd <8 x double> %289, %294
  %296 = fadd <8 x double> %290, %295
  %297 = fadd <8 x double> %291, %296
  %298 = fadd <8 x double> %297, %292
  %299 = fadd <8 x double> %298, %293
  %300 = and <8 x i64> %286, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %301 = bitcast <8 x i64> %300 to <8 x double>
  %302 = fsub <8 x double> %284, %301
  %303 = bitcast <8 x double> %254 to <8 x i64>
  %304 = and <8 x i64> %303, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %305 = bitcast <8 x i64> %304 to <8 x double>
  %306 = fsub <8 x double> %254, %305
  %307 = fmul <8 x double> %284, %254
  %308 = fmul <8 x double> %301, %305
  %309 = bitcast <8 x double> %307 to <8 x i64>
  %310 = xor <8 x i64> %309, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %311 = bitcast <8 x i64> %310 to <8 x double>
  %312 = fmul <8 x double> %302, %305
  %313 = fmul <8 x double> %306, %301
  %314 = fmul <8 x double> %302, %306
  %315 = fmul <8 x double> %254, %299
  %316 = fadd <8 x double> %308, %311
  %317 = fadd <8 x double> %312, %316
  %318 = fadd <8 x double> %313, %317
  %319 = fadd <8 x double> %314, %318
  %320 = fadd <8 x double> %315, %319
  %321 = fadd <8 x double> %276, %307
  %322 = fsub <8 x double> %276, %321
  %323 = fadd <8 x double> %307, %322
  %324 = fadd <8 x double> %323, %280
  %325 = fadd <8 x double> %324, %320
  %326 = fadd <8 x double> %321, %325
  %327 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF>, i32 30, i8 -1, i32 4) #7
  %328 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %326, <8 x double> %326, i32 4, i8 -1, i32 4) #7
  %329 = or i8 %328, %327
  %330 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %331 = or <8 x i64> %330, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %332 = bitcast i8 %329 to <8 x i1>
  %333 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %334 = bitcast i8 %333 to <8 x i1>
  %335 = bitcast <8 x i64> %331 to <8 x double>
  %336 = select <8 x i1> %332, <8 x double> %335, <8 x double> %326
  %337 = select <8 x i1> %334, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %336
  %338 = icmp eq <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %339 = select <8 x i1> %338, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %337
  ret <8 x double> %339
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_acoshd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = fsub <8 x double> %2, %0
  %4 = fsub <8 x double> %2, %3
  %5 = fsub <8 x double> %0, %4
  %6 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %3
  %7 = fadd <8 x double> %6, %5
  %8 = fadd <8 x double> %2, %7
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %10 = bitcast <8 x double> %9 to <8 x i64>
  %11 = and <8 x i64> %10, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %12 = bitcast <8 x i64> %11 to <8 x double>
  %13 = fsub <8 x double> %9, %12
  %14 = fmul <8 x double> %9, %9
  %15 = fmul <8 x double> %12, %12
  %16 = bitcast <8 x double> %14 to <8 x i64>
  %17 = xor <8 x i64> %16, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %18 = bitcast <8 x i64> %17 to <8 x double>
  %19 = fmul <8 x double> %13, %12
  %20 = fmul <8 x double> %13, %13
  %21 = fadd <8 x double> %15, %18
  %22 = fadd <8 x double> %19, %21
  %23 = fadd <8 x double> %19, %22
  %24 = fadd <8 x double> %20, %23
  %25 = fadd <8 x double> %2, %14
  %26 = fsub <8 x double> %25, %2
  %27 = fsub <8 x double> %25, %26
  %28 = fsub <8 x double> %2, %27
  %29 = fsub <8 x double> %14, %26
  %30 = fadd <8 x double> %29, %28
  %31 = fadd <8 x double> %7, %24
  %32 = fadd <8 x double> %30, %31
  %33 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %9
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %33, %36
  %38 = fmul <8 x double> %12, %36
  %39 = fmul <8 x double> %37, %12
  %40 = fmul <8 x double> %13, %36
  %41 = fmul <8 x double> %13, %37
  %42 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %38
  %43 = fsub <8 x double> %42, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fmul <8 x double> %33, %45
  %47 = bitcast <8 x double> %25 to <8 x i64>
  %48 = and <8 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <8 x i64> %48 to <8 x double>
  %50 = fsub <8 x double> %25, %49
  %51 = fmul <8 x double> %33, %25
  %52 = fmul <8 x double> %36, %49
  %53 = bitcast <8 x double> %51 to <8 x i64>
  %54 = xor <8 x i64> %53, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %55 = bitcast <8 x i64> %54 to <8 x double>
  %56 = fmul <8 x double> %50, %36
  %57 = fmul <8 x double> %37, %49
  %58 = fmul <8 x double> %37, %50
  %59 = fmul <8 x double> %25, %46
  %60 = fmul <8 x double> %33, %32
  %61 = fadd <8 x double> %52, %55
  %62 = fadd <8 x double> %56, %61
  %63 = fadd <8 x double> %57, %62
  %64 = fadd <8 x double> %58, %63
  %65 = fadd <8 x double> %64, %59
  %66 = fadd <8 x double> %60, %65
  %67 = fmul <8 x double> %51, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %68 = fmul <8 x double> %66, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %69 = fadd <8 x double> %0, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %70 = fsub <8 x double> %69, %0
  %71 = fsub <8 x double> %69, %70
  %72 = fsub <8 x double> %0, %71
  %73 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %70
  %74 = fadd <8 x double> %73, %72
  %75 = fadd <8 x double> %69, %74
  %76 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %75, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %77 = bitcast <8 x double> %76 to <8 x i64>
  %78 = and <8 x i64> %77, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fsub <8 x double> %76, %79
  %81 = fmul <8 x double> %76, %76
  %82 = fmul <8 x double> %79, %79
  %83 = bitcast <8 x double> %81 to <8 x i64>
  %84 = xor <8 x i64> %83, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %85 = bitcast <8 x i64> %84 to <8 x double>
  %86 = fmul <8 x double> %80, %79
  %87 = fmul <8 x double> %80, %80
  %88 = fadd <8 x double> %82, %85
  %89 = fadd <8 x double> %86, %88
  %90 = fadd <8 x double> %86, %89
  %91 = fadd <8 x double> %87, %90
  %92 = fadd <8 x double> %69, %81
  %93 = fsub <8 x double> %92, %69
  %94 = fsub <8 x double> %92, %93
  %95 = fsub <8 x double> %69, %94
  %96 = fsub <8 x double> %81, %93
  %97 = fadd <8 x double> %96, %95
  %98 = fadd <8 x double> %74, %91
  %99 = fadd <8 x double> %97, %98
  %100 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %76
  %101 = bitcast <8 x double> %100 to <8 x i64>
  %102 = and <8 x i64> %101, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %103 = bitcast <8 x i64> %102 to <8 x double>
  %104 = fsub <8 x double> %100, %103
  %105 = fmul <8 x double> %79, %103
  %106 = fmul <8 x double> %104, %79
  %107 = fmul <8 x double> %80, %103
  %108 = fmul <8 x double> %80, %104
  %109 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %105
  %110 = fsub <8 x double> %109, %106
  %111 = fsub <8 x double> %110, %107
  %112 = fsub <8 x double> %111, %108
  %113 = fmul <8 x double> %100, %112
  %114 = bitcast <8 x double> %92 to <8 x i64>
  %115 = and <8 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <8 x i64> %115 to <8 x double>
  %117 = fsub <8 x double> %92, %116
  %118 = fmul <8 x double> %100, %92
  %119 = fmul <8 x double> %103, %116
  %120 = bitcast <8 x double> %118 to <8 x i64>
  %121 = xor <8 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <8 x i64> %121 to <8 x double>
  %123 = fmul <8 x double> %117, %103
  %124 = fmul <8 x double> %104, %116
  %125 = fmul <8 x double> %104, %117
  %126 = fmul <8 x double> %92, %113
  %127 = fmul <8 x double> %100, %99
  %128 = fadd <8 x double> %119, %122
  %129 = fadd <8 x double> %123, %128
  %130 = fadd <8 x double> %124, %129
  %131 = fadd <8 x double> %125, %130
  %132 = fadd <8 x double> %131, %126
  %133 = fadd <8 x double> %127, %132
  %134 = fmul <8 x double> %118, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %135 = fmul <8 x double> %133, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %136 = bitcast <8 x double> %67 to <8 x i64>
  %137 = and <8 x i64> %136, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %138 = bitcast <8 x i64> %137 to <8 x double>
  %139 = fsub <8 x double> %67, %138
  %140 = bitcast <8 x double> %134 to <8 x i64>
  %141 = and <8 x i64> %140, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %142 = bitcast <8 x i64> %141 to <8 x double>
  %143 = fsub <8 x double> %134, %142
  %144 = fmul <8 x double> %67, %134
  %145 = fmul <8 x double> %138, %142
  %146 = bitcast <8 x double> %144 to <8 x i64>
  %147 = xor <8 x i64> %146, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %148 = bitcast <8 x i64> %147 to <8 x double>
  %149 = fmul <8 x double> %139, %142
  %150 = fmul <8 x double> %143, %138
  %151 = fmul <8 x double> %139, %143
  %152 = fmul <8 x double> %67, %135
  %153 = fmul <8 x double> %134, %68
  %154 = fadd <8 x double> %145, %148
  %155 = fadd <8 x double> %149, %154
  %156 = fadd <8 x double> %150, %155
  %157 = fadd <8 x double> %151, %156
  %158 = fadd <8 x double> %157, %152
  %159 = fadd <8 x double> %153, %158
  %160 = fadd <8 x double> %144, %0
  %161 = fsub <8 x double> %160, %144
  %162 = fsub <8 x double> %160, %161
  %163 = fsub <8 x double> %144, %162
  %164 = fsub <8 x double> %0, %161
  %165 = fadd <8 x double> %164, %163
  %166 = fadd <8 x double> %165, %159
  %167 = fmul <8 x double> %160, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %168 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %167, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %169 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %168, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %170 = sub <8 x i32> zeroinitializer, %169
  %171 = ashr <8 x i32> %170, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %172 = add nsw <8 x i32> %171, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %173 = bitcast <8 x i32> %172 to <4 x i64>
  %174 = shufflevector <4 x i64> %173, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %175 = bitcast <8 x i64> %174 to <16 x i32>
  %176 = shufflevector <16 x i32> %175, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %177 = shufflevector <16 x i32> %176, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %178 = shl <16 x i32> %177, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %179 = bitcast <16 x i32> %178 to <8 x double>
  %180 = fmul <8 x double> %160, %179
  %181 = sub <8 x i32> <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>, %169
  %182 = sub <8 x i32> %181, %171
  %183 = bitcast <8 x i32> %182 to <4 x i64>
  %184 = shufflevector <4 x i64> %183, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %185 = bitcast <8 x i64> %184 to <16 x i32>
  %186 = shufflevector <16 x i32> %185, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %187 = shufflevector <16 x i32> %186, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %188 = shl <16 x i32> %187, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %189 = bitcast <16 x i32> %188 to <8 x double>
  %190 = fmul <8 x double> %180, %189
  %191 = fmul <8 x double> %166, %179
  %192 = fmul <8 x double> %191, %189
  %193 = fadd <8 x double> %190, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %194 = fsub <8 x double> %193, %190
  %195 = fsub <8 x double> %193, %194
  %196 = fsub <8 x double> %190, %195
  %197 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %194
  %198 = fadd <8 x double> %197, %196
  %199 = fadd <8 x double> %198, %192
  %200 = fadd <8 x double> %190, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %201 = fsub <8 x double> %200, %190
  %202 = fsub <8 x double> %200, %201
  %203 = fsub <8 x double> %190, %202
  %204 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %201
  %205 = fadd <8 x double> %204, %203
  %206 = fadd <8 x double> %205, %192
  %207 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %200
  %208 = bitcast <8 x double> %200 to <8 x i64>
  %209 = and <8 x i64> %208, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %210 = bitcast <8 x i64> %209 to <8 x double>
  %211 = fsub <8 x double> %200, %210
  %212 = bitcast <8 x double> %207 to <8 x i64>
  %213 = and <8 x i64> %212, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %214 = bitcast <8 x i64> %213 to <8 x double>
  %215 = fsub <8 x double> %207, %214
  %216 = bitcast <8 x double> %193 to <8 x i64>
  %217 = and <8 x i64> %216, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %218 = bitcast <8 x i64> %217 to <8 x double>
  %219 = fsub <8 x double> %193, %218
  %220 = fmul <8 x double> %193, %207
  %221 = fmul <8 x double> %218, %214
  %222 = fsub <8 x double> %221, %220
  %223 = fmul <8 x double> %215, %218
  %224 = fmul <8 x double> %219, %214
  %225 = fmul <8 x double> %219, %215
  %226 = fmul <8 x double> %210, %214
  %227 = fmul <8 x double> %215, %210
  %228 = fmul <8 x double> %211, %214
  %229 = fmul <8 x double> %211, %215
  %230 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %226
  %231 = fsub <8 x double> %230, %227
  %232 = fsub <8 x double> %231, %228
  %233 = fsub <8 x double> %232, %229
  %234 = fmul <8 x double> %220, %233
  %235 = fadd <8 x double> %222, %223
  %236 = fadd <8 x double> %224, %235
  %237 = fadd <8 x double> %225, %236
  %238 = fadd <8 x double> %237, %234
  %239 = fmul <8 x double> %220, %206
  %240 = fsub <8 x double> %199, %239
  %241 = fmul <8 x double> %207, %240
  %242 = fadd <8 x double> %241, %238
  %243 = bitcast <8 x double> %220 to <8 x i64>
  %244 = and <8 x i64> %243, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %245 = bitcast <8 x i64> %244 to <8 x double>
  %246 = fsub <8 x double> %220, %245
  %247 = fmul <8 x double> %220, %220
  %248 = fmul <8 x double> %245, %245
  %249 = bitcast <8 x double> %247 to <8 x i64>
  %250 = xor <8 x i64> %249, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %251 = bitcast <8 x i64> %250 to <8 x double>
  %252 = fadd <8 x double> %245, %245
  %253 = fmul <8 x double> %252, %246
  %254 = fmul <8 x double> %246, %246
  %255 = fadd <8 x double> %242, %242
  %256 = fmul <8 x double> %220, %255
  %257 = fadd <8 x double> %248, %251
  %258 = fadd <8 x double> %257, %253
  %259 = fadd <8 x double> %254, %258
  %260 = fadd <8 x double> %259, %256
  %261 = fmul <8 x double> %247, %247
  %262 = fmul <8 x double> %261, %261
  %263 = fmul <8 x double> %247, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %264 = fadd <8 x double> %263, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %265 = fmul <8 x double> %261, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %266 = fadd <8 x double> %265, %264
  %267 = fmul <8 x double> %247, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %268 = fadd <8 x double> %267, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %269 = fmul <8 x double> %247, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %270 = fadd <8 x double> %269, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %271 = fmul <8 x double> %261, %268
  %272 = fadd <8 x double> %270, %271
  %273 = fmul <8 x double> %262, %266
  %274 = fadd <8 x double> %273, %272
  %275 = fmul <8 x double> %247, %274
  %276 = fadd <8 x double> %275, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %277 = sitofp <8 x i32> %169 to <8 x double>
  %278 = bitcast <8 x double> %277 to <8 x i64>
  %279 = and <8 x i64> %278, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %280 = bitcast <8 x i64> %279 to <8 x double>
  %281 = fsub <8 x double> %277, %280
  %282 = fmul <8 x double> %277, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %283 = fmul <8 x double> %280, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %284 = bitcast <8 x double> %282 to <8 x i64>
  %285 = xor <8 x i64> %284, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %286 = bitcast <8 x i64> %285 to <8 x double>
  %287 = fmul <8 x double> %280, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %288 = fmul <8 x double> %281, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %289 = fmul <8 x double> %281, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %290 = fmul <8 x double> %277, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %291 = fadd <8 x double> %283, %286
  %292 = fadd <8 x double> %287, %291
  %293 = fadd <8 x double> %288, %292
  %294 = fadd <8 x double> %289, %293
  %295 = fadd <8 x double> %290, %294
  %296 = fmul <8 x double> %220, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %297 = fmul <8 x double> %242, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %298 = fadd <8 x double> %282, %296
  %299 = fsub <8 x double> %282, %298
  %300 = fadd <8 x double> %296, %299
  %301 = fadd <8 x double> %295, %300
  %302 = fadd <8 x double> %301, %297
  %303 = and <8 x i64> %249, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %304 = bitcast <8 x i64> %303 to <8 x double>
  %305 = fsub <8 x double> %247, %304
  %306 = fmul <8 x double> %220, %247
  %307 = fmul <8 x double> %245, %304
  %308 = bitcast <8 x double> %306 to <8 x i64>
  %309 = xor <8 x i64> %308, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %310 = bitcast <8 x i64> %309 to <8 x double>
  %311 = fmul <8 x double> %305, %245
  %312 = fmul <8 x double> %246, %304
  %313 = fmul <8 x double> %246, %305
  %314 = fmul <8 x double> %247, %242
  %315 = fmul <8 x double> %220, %260
  %316 = fadd <8 x double> %307, %310
  %317 = fadd <8 x double> %311, %316
  %318 = fadd <8 x double> %312, %317
  %319 = fadd <8 x double> %313, %318
  %320 = fadd <8 x double> %319, %314
  %321 = fadd <8 x double> %320, %315
  %322 = and <8 x i64> %308, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %323 = bitcast <8 x i64> %322 to <8 x double>
  %324 = fsub <8 x double> %306, %323
  %325 = bitcast <8 x double> %276 to <8 x i64>
  %326 = and <8 x i64> %325, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %327 = bitcast <8 x i64> %326 to <8 x double>
  %328 = fsub <8 x double> %276, %327
  %329 = fmul <8 x double> %306, %276
  %330 = fmul <8 x double> %323, %327
  %331 = bitcast <8 x double> %329 to <8 x i64>
  %332 = xor <8 x i64> %331, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %333 = bitcast <8 x i64> %332 to <8 x double>
  %334 = fmul <8 x double> %324, %327
  %335 = fmul <8 x double> %328, %323
  %336 = fmul <8 x double> %324, %328
  %337 = fmul <8 x double> %276, %321
  %338 = fadd <8 x double> %330, %333
  %339 = fadd <8 x double> %334, %338
  %340 = fadd <8 x double> %335, %339
  %341 = fadd <8 x double> %336, %340
  %342 = fadd <8 x double> %337, %341
  %343 = fadd <8 x double> %298, %329
  %344 = fsub <8 x double> %298, %343
  %345 = fadd <8 x double> %329, %344
  %346 = fadd <8 x double> %345, %302
  %347 = fadd <8 x double> %346, %342
  %348 = fadd <8 x double> %343, %347
  %349 = bitcast <8 x double> %0 to <8 x i64>
  %350 = and <8 x i64> %349, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %351 = bitcast <8 x i64> %350 to <8 x double>
  %352 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %351, <8 x double> <double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF, double 0x5FEFFFFFFFFFFFFF>, i32 30, i8 -1, i32 4) #7
  %353 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %348, <8 x double> %348, i32 4, i8 -1, i32 4) #7
  %354 = or i8 %353, %352
  %355 = bitcast i8 %354 to <8 x i1>
  %356 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %357 = bitcast i8 %356 to <8 x i1>
  %358 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 17, i8 -1, i32 4) #7
  %359 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %360 = or i8 %359, %358
  %361 = bitcast i8 %360 to <8 x i1>
  %362 = select <8 x i1> %355, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %348
  %363 = select <8 x i1> %357, <8 x double> zeroinitializer, <8 x double> %362
  %364 = select <8 x i1> %361, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %363
  ret <8 x double> %364
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_atanhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fadd <8 x double> %4, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %6 = fadd <8 x double> %5, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %7 = fsub <8 x double> %5, %6
  %8 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %7
  %9 = fsub <8 x double> %4, %6
  %10 = fadd <8 x double> %9, %8
  %11 = or <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %12 = bitcast <8 x i64> %11 to <8 x double>
  %13 = fadd <8 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = fadd <8 x double> %13, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %15 = fsub <8 x double> %13, %14
  %16 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %15
  %17 = fsub <8 x double> %12, %14
  %18 = fadd <8 x double> %17, %16
  %19 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %13
  %20 = bitcast <8 x double> %13 to <8 x i64>
  %21 = and <8 x i64> %20, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %22 = bitcast <8 x i64> %21 to <8 x double>
  %23 = fsub <8 x double> %13, %22
  %24 = bitcast <8 x double> %19 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = fsub <8 x double> %19, %26
  %28 = bitcast <8 x double> %5 to <8 x i64>
  %29 = and <8 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <8 x i64> %29 to <8 x double>
  %31 = fsub <8 x double> %5, %30
  %32 = fmul <8 x double> %5, %19
  %33 = fmul <8 x double> %30, %26
  %34 = fsub <8 x double> %33, %32
  %35 = fmul <8 x double> %27, %30
  %36 = fmul <8 x double> %31, %26
  %37 = fmul <8 x double> %31, %27
  %38 = fmul <8 x double> %22, %26
  %39 = fmul <8 x double> %27, %22
  %40 = fmul <8 x double> %23, %26
  %41 = fmul <8 x double> %23, %27
  %42 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %38
  %43 = fsub <8 x double> %42, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fmul <8 x double> %32, %45
  %47 = fadd <8 x double> %34, %35
  %48 = fadd <8 x double> %36, %47
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %49, %46
  %51 = fmul <8 x double> %32, %18
  %52 = fsub <8 x double> %10, %51
  %53 = fmul <8 x double> %19, %52
  %54 = fadd <8 x double> %53, %50
  %55 = fmul <8 x double> %32, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %56 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %55, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %57 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %56, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %58 = sub <8 x i32> zeroinitializer, %57
  %59 = ashr <8 x i32> %58, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %60 = add nsw <8 x i32> %59, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %61 = bitcast <8 x i32> %60 to <4 x i64>
  %62 = shufflevector <4 x i64> %61, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %63 = bitcast <8 x i64> %62 to <16 x i32>
  %64 = shufflevector <16 x i32> %63, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %65 = shufflevector <16 x i32> %64, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %66 = shl <16 x i32> %65, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %67 = bitcast <16 x i32> %66 to <8 x double>
  %68 = fmul <8 x double> %32, %67
  %69 = sub <8 x i32> <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>, %57
  %70 = sub <8 x i32> %69, %59
  %71 = bitcast <8 x i32> %70 to <4 x i64>
  %72 = shufflevector <4 x i64> %71, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %73 = bitcast <8 x i64> %72 to <16 x i32>
  %74 = shufflevector <16 x i32> %73, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %75 = shufflevector <16 x i32> %74, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %76 = shl <16 x i32> %75, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %77 = bitcast <16 x i32> %76 to <8 x double>
  %78 = fmul <8 x double> %68, %77
  %79 = fmul <8 x double> %54, %67
  %80 = fmul <8 x double> %79, %77
  %81 = fadd <8 x double> %78, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %82 = fsub <8 x double> %81, %78
  %83 = fsub <8 x double> %81, %82
  %84 = fsub <8 x double> %78, %83
  %85 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %82
  %86 = fadd <8 x double> %85, %84
  %87 = fadd <8 x double> %80, %86
  %88 = fadd <8 x double> %78, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %89 = fsub <8 x double> %88, %78
  %90 = fsub <8 x double> %88, %89
  %91 = fsub <8 x double> %78, %90
  %92 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %89
  %93 = fadd <8 x double> %92, %91
  %94 = fadd <8 x double> %80, %93
  %95 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %88
  %96 = bitcast <8 x double> %88 to <8 x i64>
  %97 = and <8 x i64> %96, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %98 = bitcast <8 x i64> %97 to <8 x double>
  %99 = fsub <8 x double> %88, %98
  %100 = bitcast <8 x double> %95 to <8 x i64>
  %101 = and <8 x i64> %100, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %102 = bitcast <8 x i64> %101 to <8 x double>
  %103 = fsub <8 x double> %95, %102
  %104 = bitcast <8 x double> %81 to <8 x i64>
  %105 = and <8 x i64> %104, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %106 = bitcast <8 x i64> %105 to <8 x double>
  %107 = fsub <8 x double> %81, %106
  %108 = fmul <8 x double> %81, %95
  %109 = fmul <8 x double> %106, %102
  %110 = fsub <8 x double> %109, %108
  %111 = fmul <8 x double> %103, %106
  %112 = fmul <8 x double> %107, %102
  %113 = fmul <8 x double> %107, %103
  %114 = fmul <8 x double> %98, %102
  %115 = fmul <8 x double> %103, %98
  %116 = fmul <8 x double> %99, %102
  %117 = fmul <8 x double> %99, %103
  %118 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %114
  %119 = fsub <8 x double> %118, %115
  %120 = fsub <8 x double> %119, %116
  %121 = fsub <8 x double> %120, %117
  %122 = fmul <8 x double> %108, %121
  %123 = fadd <8 x double> %110, %111
  %124 = fadd <8 x double> %112, %123
  %125 = fadd <8 x double> %113, %124
  %126 = fadd <8 x double> %125, %122
  %127 = fmul <8 x double> %108, %94
  %128 = fsub <8 x double> %87, %127
  %129 = fmul <8 x double> %95, %128
  %130 = fadd <8 x double> %129, %126
  %131 = bitcast <8 x double> %108 to <8 x i64>
  %132 = and <8 x i64> %131, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %133 = bitcast <8 x i64> %132 to <8 x double>
  %134 = fsub <8 x double> %108, %133
  %135 = fmul <8 x double> %108, %108
  %136 = fmul <8 x double> %133, %133
  %137 = bitcast <8 x double> %135 to <8 x i64>
  %138 = xor <8 x i64> %137, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %139 = bitcast <8 x i64> %138 to <8 x double>
  %140 = fadd <8 x double> %133, %133
  %141 = fmul <8 x double> %140, %134
  %142 = fmul <8 x double> %134, %134
  %143 = fadd <8 x double> %130, %130
  %144 = fmul <8 x double> %108, %143
  %145 = fadd <8 x double> %136, %139
  %146 = fadd <8 x double> %145, %141
  %147 = fadd <8 x double> %142, %146
  %148 = fadd <8 x double> %147, %144
  %149 = fmul <8 x double> %135, %135
  %150 = fmul <8 x double> %149, %149
  %151 = fmul <8 x double> %135, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %152 = fadd <8 x double> %151, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %153 = fmul <8 x double> %149, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %154 = fadd <8 x double> %153, %152
  %155 = fmul <8 x double> %135, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %156 = fadd <8 x double> %155, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %157 = fmul <8 x double> %135, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %158 = fadd <8 x double> %157, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %159 = fmul <8 x double> %149, %156
  %160 = fadd <8 x double> %158, %159
  %161 = fmul <8 x double> %150, %154
  %162 = fadd <8 x double> %161, %160
  %163 = fmul <8 x double> %135, %162
  %164 = fadd <8 x double> %163, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %165 = sitofp <8 x i32> %57 to <8 x double>
  %166 = bitcast <8 x double> %165 to <8 x i64>
  %167 = and <8 x i64> %166, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %168 = bitcast <8 x i64> %167 to <8 x double>
  %169 = fsub <8 x double> %165, %168
  %170 = fmul <8 x double> %165, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %171 = fmul <8 x double> %168, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %172 = bitcast <8 x double> %170 to <8 x i64>
  %173 = xor <8 x i64> %172, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %174 = bitcast <8 x i64> %173 to <8 x double>
  %175 = fmul <8 x double> %168, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %176 = fmul <8 x double> %169, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %177 = fmul <8 x double> %169, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %178 = fmul <8 x double> %165, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %179 = fadd <8 x double> %171, %174
  %180 = fadd <8 x double> %175, %179
  %181 = fadd <8 x double> %176, %180
  %182 = fadd <8 x double> %177, %181
  %183 = fadd <8 x double> %178, %182
  %184 = fmul <8 x double> %108, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %185 = fmul <8 x double> %130, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %186 = fadd <8 x double> %170, %184
  %187 = fsub <8 x double> %170, %186
  %188 = fadd <8 x double> %184, %187
  %189 = fadd <8 x double> %183, %188
  %190 = fadd <8 x double> %189, %185
  %191 = and <8 x i64> %137, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %192 = bitcast <8 x i64> %191 to <8 x double>
  %193 = fsub <8 x double> %135, %192
  %194 = fmul <8 x double> %108, %135
  %195 = fmul <8 x double> %133, %192
  %196 = bitcast <8 x double> %194 to <8 x i64>
  %197 = xor <8 x i64> %196, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %198 = bitcast <8 x i64> %197 to <8 x double>
  %199 = fmul <8 x double> %193, %133
  %200 = fmul <8 x double> %134, %192
  %201 = fmul <8 x double> %134, %193
  %202 = fmul <8 x double> %135, %130
  %203 = fmul <8 x double> %108, %148
  %204 = fadd <8 x double> %195, %198
  %205 = fadd <8 x double> %199, %204
  %206 = fadd <8 x double> %200, %205
  %207 = fadd <8 x double> %201, %206
  %208 = fadd <8 x double> %207, %202
  %209 = fadd <8 x double> %208, %203
  %210 = and <8 x i64> %196, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %211 = bitcast <8 x i64> %210 to <8 x double>
  %212 = fsub <8 x double> %194, %211
  %213 = bitcast <8 x double> %164 to <8 x i64>
  %214 = and <8 x i64> %213, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %215 = bitcast <8 x i64> %214 to <8 x double>
  %216 = fsub <8 x double> %164, %215
  %217 = fmul <8 x double> %194, %164
  %218 = fmul <8 x double> %211, %215
  %219 = bitcast <8 x double> %217 to <8 x i64>
  %220 = xor <8 x i64> %219, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %221 = bitcast <8 x i64> %220 to <8 x double>
  %222 = fmul <8 x double> %212, %215
  %223 = fmul <8 x double> %216, %211
  %224 = fmul <8 x double> %212, %216
  %225 = fmul <8 x double> %164, %209
  %226 = fadd <8 x double> %218, %221
  %227 = fadd <8 x double> %222, %226
  %228 = fadd <8 x double> %223, %227
  %229 = fadd <8 x double> %224, %228
  %230 = fadd <8 x double> %225, %229
  %231 = fadd <8 x double> %186, %217
  %232 = fsub <8 x double> %186, %231
  %233 = fadd <8 x double> %217, %232
  %234 = fadd <8 x double> %233, %190
  %235 = fadd <8 x double> %234, %230
  %236 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 30, i8 -1, i32 4) #7
  %237 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %238 = fadd <8 x double> %231, %235
  %239 = fmul <8 x double> %238, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %240 = bitcast i8 %237 to <8 x i1>
  %241 = bitcast <8 x double> %239 to <8 x i64>
  %242 = select <8 x i1> %240, <8 x i64> <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>, <8 x i64> %241
  %243 = bitcast i8 %236 to <8 x i1>
  %244 = select <8 x i1> %243, <8 x i64> <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1>, <8 x i64> %242
  %245 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %246 = xor <8 x i64> %244, %245
  %247 = bitcast <8 x i64> %246 to <8 x double>
  %248 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %249 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %247, <8 x double> %247, i32 4, i8 -1, i32 4) #7
  %250 = or i8 %249, %248
  %251 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %252 = or i8 %250, %251
  %253 = bitcast i8 %252 to <8 x i1>
  %254 = select <8 x i1> %253, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %247
  ret <8 x double> %254
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cbrtd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %4, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %6 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %5, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %7 = add <8 x i32> %6, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %8 = xor <8 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %10 = add nsw <8 x i32> %9, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %11 = bitcast <8 x i32> %10 to <4 x i64>
  %12 = shufflevector <4 x i64> %11, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <8 x i64> %12 to <16 x i32>
  %14 = shufflevector <16 x i32> %13, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %15 = shufflevector <16 x i32> %14, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %16 = shl <16 x i32> %15, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %17 = bitcast <16 x i32> %16 to <8 x double>
  %18 = fmul <8 x double> %17, %0
  %19 = sub <8 x i32> <i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022>, %6
  %20 = sub <8 x i32> %19, %9
  %21 = bitcast <8 x i32> %20 to <4 x i64>
  %22 = shufflevector <4 x i64> %21, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast <8 x i64> %22 to <16 x i32>
  %24 = shufflevector <16 x i32> %23, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %25 = shufflevector <16 x i32> %24, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %26 = shl <16 x i32> %25, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %27 = bitcast <16 x i32> %26 to <8 x double>
  %28 = fmul <8 x double> %18, %27
  %29 = sitofp <8 x i32> %7 to <8 x double>
  %30 = fadd <8 x double> %29, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %31 = fmul <8 x double> %30, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %32 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %31, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %33 = sitofp <8 x i32> %32 to <8 x double>
  %34 = fmul <8 x double> %33, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %35 = fsub <8 x double> %30, %34
  %36 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %35, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %37 = bitcast <8 x i32> %36 to <4 x i64>
  %38 = shufflevector <4 x i64> %37, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %39 = bitcast <8 x i64> %38 to <16 x i32>
  %40 = icmp eq <16 x i32> %39, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <16 x i1> %40 to <2 x i8>
  %42 = extractelement <2 x i8> %41, i32 0
  %43 = bitcast i8 %42 to <8 x i1>
  %44 = select <8 x i1> %43, <8 x double> <double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %45 = icmp eq <16 x i32> %39, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %46 = bitcast <16 x i1> %45 to <2 x i8>
  %47 = extractelement <2 x i8> %46, i32 0
  %48 = bitcast i8 %47 to <8 x i1>
  %49 = select <8 x i1> %48, <8 x double> <double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D>, <8 x double> %44
  %50 = add <8 x i32> %32, <i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %51 = ashr <8 x i32> %50, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %52 = add nsw <8 x i32> %51, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %53 = bitcast <8 x i32> %52 to <4 x i64>
  %54 = shufflevector <4 x i64> %53, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %55 = bitcast <8 x i64> %54 to <16 x i32>
  %56 = shufflevector <16 x i32> %55, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %57 = shufflevector <16 x i32> %56, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %58 = shl <16 x i32> %57, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %59 = bitcast <16 x i32> %58 to <8 x double>
  %60 = fmul <8 x double> %49, %59
  %61 = add <8 x i32> %32, <i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025>
  %62 = sub <8 x i32> %61, %51
  %63 = bitcast <8 x i32> %62 to <4 x i64>
  %64 = shufflevector <4 x i64> %63, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <8 x i64> %64 to <16 x i32>
  %66 = shufflevector <16 x i32> %65, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %67 = shufflevector <16 x i32> %66, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %68 = shl <16 x i32> %67, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %69 = bitcast <16 x i32> %68 to <8 x double>
  %70 = fmul <8 x double> %60, %69
  %71 = bitcast <8 x double> %70 to <8 x i64>
  %72 = bitcast <8 x double> %28 to <8 x i64>
  %73 = and <8 x i64> %72, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %74 = xor <8 x i64> %73, %71
  %75 = bitcast <8 x i64> %74 to <8 x double>
  %76 = and <8 x i64> %72, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %77 = bitcast <8 x i64> %76 to <8 x double>
  %78 = fmul <8 x double> %77, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %79 = fadd <8 x double> %78, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %80 = fmul <8 x double> %79, %77
  %81 = fadd <8 x double> %80, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %82 = fmul <8 x double> %81, %77
  %83 = fadd <8 x double> %82, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %84 = fmul <8 x double> %83, %77
  %85 = fadd <8 x double> %84, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %86 = fmul <8 x double> %85, %77
  %87 = fadd <8 x double> %86, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %88 = fmul <8 x double> %87, %87
  %89 = fmul <8 x double> %88, %88
  %90 = fmul <8 x double> %89, %77
  %91 = fsub <8 x double> %90, %87
  %92 = fmul <8 x double> %91, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %93 = fsub <8 x double> %87, %92
  %94 = fmul <8 x double> %93, %77
  %95 = fmul <8 x double> %93, %94
  %96 = fmul <8 x double> %95, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %97 = fmul <8 x double> %93, %95
  %98 = fadd <8 x double> %97, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %99 = fmul <8 x double> %96, %98
  %100 = fsub <8 x double> %95, %99
  %101 = fmul <8 x double> %100, %75
  %102 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %103 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %104 = or <8 x i64> %103, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = bitcast i8 %102 to <8 x i1>
  %107 = select <8 x i1> %106, <8 x double> %105, <8 x double> %101
  %108 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %109 = bitcast <8 x i64> %103 to <8 x double>
  %110 = bitcast i8 %108 to <8 x i1>
  %111 = select <8 x i1> %110, <8 x double> %109, <8 x double> %107
  ret <8 x double> %111
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cbrtd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %4, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %6 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %5, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %7 = add <8 x i32> %6, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %8 = xor <8 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %10 = add nsw <8 x i32> %9, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %11 = bitcast <8 x i32> %10 to <4 x i64>
  %12 = shufflevector <4 x i64> %11, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <8 x i64> %12 to <16 x i32>
  %14 = shufflevector <16 x i32> %13, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %15 = shufflevector <16 x i32> %14, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %16 = shl <16 x i32> %15, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %17 = bitcast <16 x i32> %16 to <8 x double>
  %18 = fmul <8 x double> %17, %0
  %19 = sub <8 x i32> <i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022>, %6
  %20 = sub <8 x i32> %19, %9
  %21 = bitcast <8 x i32> %20 to <4 x i64>
  %22 = shufflevector <4 x i64> %21, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast <8 x i64> %22 to <16 x i32>
  %24 = shufflevector <16 x i32> %23, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %25 = shufflevector <16 x i32> %24, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %26 = shl <16 x i32> %25, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %27 = bitcast <16 x i32> %26 to <8 x double>
  %28 = fmul <8 x double> %18, %27
  %29 = sitofp <8 x i32> %7 to <8 x double>
  %30 = fadd <8 x double> %29, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %31 = fmul <8 x double> %30, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %32 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %31, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %33 = sitofp <8 x i32> %32 to <8 x double>
  %34 = fmul <8 x double> %33, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %35 = fsub <8 x double> %30, %34
  %36 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %35, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %37 = bitcast <8 x i32> %36 to <4 x i64>
  %38 = shufflevector <4 x i64> %37, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %39 = bitcast <8 x i64> %38 to <16 x i32>
  %40 = icmp eq <16 x i32> %39, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <16 x i1> %40 to <2 x i8>
  %42 = extractelement <2 x i8> %41, i32 0
  %43 = bitcast i8 %42 to <8 x i1>
  %44 = icmp eq <16 x i32> %39, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %45 = bitcast <16 x i1> %44 to <2 x i8>
  %46 = extractelement <2 x i8> %45, i32 0
  %47 = bitcast i8 %46 to <8 x i1>
  %48 = select <8 x i1> %43, <8 x i64> <i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707, i64 4608352999143469707>, <8 x i64> <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %49 = select <8 x i1> %47, <8 x i64> <i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429, i64 4609827837958778429>, <8 x i64> %48
  %50 = bitcast <8 x double> %28 to <8 x i64>
  %51 = and <8 x i64> %50, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %52 = or <8 x i64> %51, %49
  %53 = bitcast <8 x i64> %52 to <8 x double>
  %54 = select <8 x i1> %43, <8 x i64> <i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594, i64 -4864489982484634594>, <8 x i64> zeroinitializer
  %55 = select <8 x i1> %47, <8 x i64> <i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015, i64 -4855069610512929015>, <8 x i64> %54
  %56 = xor <8 x i64> %51, %55
  %57 = bitcast <8 x i64> %56 to <8 x double>
  %58 = and <8 x i64> %50, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %59 = bitcast <8 x i64> %58 to <8 x double>
  %60 = fmul <8 x double> %59, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %61 = fadd <8 x double> %60, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %62 = fmul <8 x double> %61, %59
  %63 = fadd <8 x double> %62, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %64 = fmul <8 x double> %63, %59
  %65 = fadd <8 x double> %64, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %66 = fmul <8 x double> %65, %59
  %67 = fadd <8 x double> %66, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %68 = fmul <8 x double> %67, %59
  %69 = fadd <8 x double> %68, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %70 = fmul <8 x double> %69, %69
  %71 = fmul <8 x double> %70, %70
  %72 = fmul <8 x double> %71, %59
  %73 = fsub <8 x double> %72, %69
  %74 = fmul <8 x double> %73, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %75 = fsub <8 x double> %69, %74
  %76 = bitcast <8 x double> %75 to <8 x i64>
  %77 = and <8 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fsub <8 x double> %75, %78
  %80 = fmul <8 x double> %75, %75
  %81 = fmul <8 x double> %78, %78
  %82 = bitcast <8 x double> %80 to <8 x i64>
  %83 = xor <8 x i64> %82, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %84 = bitcast <8 x i64> %83 to <8 x double>
  %85 = fmul <8 x double> %79, %78
  %86 = fmul <8 x double> %79, %79
  %87 = fadd <8 x double> %81, %84
  %88 = fadd <8 x double> %85, %87
  %89 = fadd <8 x double> %85, %88
  %90 = fadd <8 x double> %86, %89
  %91 = and <8 x i64> %82, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %92 = bitcast <8 x i64> %91 to <8 x double>
  %93 = fsub <8 x double> %80, %92
  %94 = fmul <8 x double> %80, %80
  %95 = fmul <8 x double> %92, %92
  %96 = bitcast <8 x double> %94 to <8 x i64>
  %97 = xor <8 x i64> %96, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %98 = bitcast <8 x i64> %97 to <8 x double>
  %99 = fmul <8 x double> %93, %92
  %100 = fmul <8 x double> %93, %93
  %101 = fmul <8 x double> %80, %90
  %102 = fadd <8 x double> %95, %98
  %103 = fadd <8 x double> %99, %102
  %104 = fadd <8 x double> %99, %103
  %105 = fadd <8 x double> %100, %104
  %106 = fadd <8 x double> %101, %105
  %107 = fadd <8 x double> %101, %106
  %108 = and <8 x i64> %96, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %109 = bitcast <8 x i64> %108 to <8 x double>
  %110 = fsub <8 x double> %94, %109
  %111 = and <8 x i64> %50, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %112 = bitcast <8 x i64> %111 to <8 x double>
  %113 = fsub <8 x double> %59, %112
  %114 = fmul <8 x double> %94, %59
  %115 = fmul <8 x double> %112, %109
  %116 = bitcast <8 x double> %114 to <8 x i64>
  %117 = xor <8 x i64> %116, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %118 = bitcast <8 x i64> %117 to <8 x double>
  %119 = fmul <8 x double> %110, %112
  %120 = fmul <8 x double> %113, %109
  %121 = fmul <8 x double> %113, %110
  %122 = fmul <8 x double> %107, %59
  %123 = fadd <8 x double> %115, %118
  %124 = fadd <8 x double> %119, %123
  %125 = fadd <8 x double> %120, %124
  %126 = fadd <8 x double> %121, %125
  %127 = fadd <8 x double> %126, %122
  %128 = xor <8 x i64> %76, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %129 = bitcast <8 x i64> %128 to <8 x double>
  %130 = fadd <8 x double> %114, %129
  %131 = fsub <8 x double> %130, %114
  %132 = fsub <8 x double> %130, %131
  %133 = fsub <8 x double> %114, %132
  %134 = fsub <8 x double> %129, %131
  %135 = fadd <8 x double> %134, %133
  %136 = fadd <8 x double> %135, %127
  %137 = fadd <8 x double> %130, %136
  %138 = fmul <8 x double> %137, <double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555, double 0xBFE5555555555555>
  %139 = fmul <8 x double> %75, %138
  %140 = fadd <8 x double> %80, %139
  %141 = fsub <8 x double> %140, %80
  %142 = fsub <8 x double> %140, %141
  %143 = fsub <8 x double> %80, %142
  %144 = fsub <8 x double> %139, %141
  %145 = fadd <8 x double> %144, %143
  %146 = fadd <8 x double> %90, %145
  %147 = bitcast <8 x double> %140 to <8 x i64>
  %148 = and <8 x i64> %147, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <8 x i64> %148 to <8 x double>
  %150 = fsub <8 x double> %140, %149
  %151 = fmul <8 x double> %140, %59
  %152 = fmul <8 x double> %112, %149
  %153 = bitcast <8 x double> %151 to <8 x i64>
  %154 = xor <8 x i64> %153, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %155 = bitcast <8 x i64> %154 to <8 x double>
  %156 = fmul <8 x double> %150, %112
  %157 = fmul <8 x double> %113, %149
  %158 = fmul <8 x double> %113, %150
  %159 = fmul <8 x double> %146, %59
  %160 = fadd <8 x double> %152, %155
  %161 = fadd <8 x double> %156, %160
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %158, %162
  %164 = fadd <8 x double> %159, %163
  %165 = and <8 x i64> %153, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %166 = bitcast <8 x i64> %165 to <8 x double>
  %167 = fsub <8 x double> %151, %166
  %168 = and <8 x i64> %52, <i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536, i64 -4612409501507649536>
  %169 = bitcast <8 x i64> %168 to <8 x double>
  %170 = fsub <8 x double> %53, %169
  %171 = fmul <8 x double> %151, %53
  %172 = fmul <8 x double> %169, %166
  %173 = bitcast <8 x double> %171 to <8 x i64>
  %174 = xor <8 x i64> %173, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %175 = bitcast <8 x i64> %174 to <8 x double>
  %176 = fmul <8 x double> %167, %169
  %177 = fmul <8 x double> %170, %166
  %178 = fmul <8 x double> %170, %167
  %179 = fmul <8 x double> %151, %57
  %180 = fmul <8 x double> %164, %53
  %181 = fadd <8 x double> %172, %175
  %182 = fadd <8 x double> %176, %181
  %183 = fadd <8 x double> %177, %182
  %184 = fadd <8 x double> %178, %183
  %185 = fadd <8 x double> %179, %184
  %186 = fadd <8 x double> %180, %185
  %187 = fadd <8 x double> %171, %186
  %188 = add <8 x i32> %32, <i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %189 = ashr <8 x i32> %188, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %190 = add nsw <8 x i32> %189, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %191 = bitcast <8 x i32> %190 to <4 x i64>
  %192 = shufflevector <4 x i64> %191, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %193 = bitcast <8 x i64> %192 to <16 x i32>
  %194 = shufflevector <16 x i32> %193, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %195 = shufflevector <16 x i32> %194, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %196 = shl <16 x i32> %195, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %197 = bitcast <16 x i32> %196 to <8 x double>
  %198 = fmul <8 x double> %187, %197
  %199 = add <8 x i32> %32, <i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025>
  %200 = sub <8 x i32> %199, %189
  %201 = bitcast <8 x i32> %200 to <4 x i64>
  %202 = shufflevector <4 x i64> %201, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %203 = bitcast <8 x i64> %202 to <16 x i32>
  %204 = shufflevector <16 x i32> %203, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %205 = shufflevector <16 x i32> %204, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %206 = shl <16 x i32> %205, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %207 = bitcast <16 x i32> %206 to <8 x double>
  %208 = fmul <8 x double> %198, %207
  %209 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %210 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %211 = or <8 x i64> %210, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %212 = bitcast <8 x i64> %211 to <8 x double>
  %213 = bitcast i8 %209 to <8 x i1>
  %214 = select <8 x i1> %213, <8 x double> %212, <8 x double> %208
  %215 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %216 = bitcast <8 x i64> %210 to <8 x double>
  %217 = bitcast i8 %215 to <8 x i1>
  %218 = select <8 x i1> %217, <8 x double> %216, <8 x double> %214
  ret <8 x double> %218
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_exp2d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 8, <8 x double> %0, i8 -1, i32 4) #7
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %4 = fsub <8 x double> %0, %2
  %5 = fmul <8 x double> %4, %4
  %6 = fmul <8 x double> %5, %5
  %7 = fmul <8 x double> %6, %6
  %8 = fmul <8 x double> %4, <double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150>
  %9 = fadd <8 x double> %8, <double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17>
  %10 = fmul <8 x double> %4, <double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979>
  %11 = fadd <8 x double> %10, <double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81>
  %12 = fmul <8 x double> %4, <double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80>
  %13 = fadd <8 x double> %12, <double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC>
  %14 = fmul <8 x double> %5, %11
  %15 = fadd <8 x double> %13, %14
  %16 = fmul <8 x double> %4, <double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960>
  %17 = fadd <8 x double> %16, <double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0>
  %18 = fmul <8 x double> %4, <double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F>
  %19 = fadd <8 x double> %18, <double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1>
  %20 = fmul <8 x double> %5, %17
  %21 = fadd <8 x double> %19, %20
  %22 = fmul <8 x double> %6, %15
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %9, %7
  %25 = fadd <8 x double> %24, %23
  %26 = fmul <8 x double> %4, %25
  %27 = fadd <8 x double> %26, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %28 = bitcast <8 x double> %27 to <8 x i64>
  %29 = and <8 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <8 x i64> %29 to <8 x double>
  %31 = fsub <8 x double> %27, %30
  %32 = bitcast <8 x double> %4 to <8 x i64>
  %33 = and <8 x i64> %32, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %34 = bitcast <8 x i64> %33 to <8 x double>
  %35 = fsub <8 x double> %4, %34
  %36 = fmul <8 x double> %4, %27
  %37 = fmul <8 x double> %34, %30
  %38 = bitcast <8 x double> %36 to <8 x i64>
  %39 = xor <8 x i64> %38, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %40 = bitcast <8 x i64> %39 to <8 x double>
  %41 = fmul <8 x double> %31, %34
  %42 = fmul <8 x double> %35, %30
  %43 = fmul <8 x double> %35, %31
  %44 = fadd <8 x double> %37, %40
  %45 = fadd <8 x double> %41, %44
  %46 = fadd <8 x double> %42, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %49 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %48
  %50 = fadd <8 x double> %36, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fadd <8 x double> %48, %51
  %53 = ashr <8 x i32> %3, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %54 = add nsw <8 x i32> %53, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = bitcast <8 x i32> %54 to <4 x i64>
  %56 = shufflevector <4 x i64> %55, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <8 x i64> %56 to <16 x i32>
  %58 = shufflevector <16 x i32> %57, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %59 = shufflevector <16 x i32> %58, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %60 = shl <16 x i32> %59, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <16 x i32> %60 to <8 x double>
  %62 = fmul <8 x double> %52, %61
  %63 = add <8 x i32> %3, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %64 = sub <8 x i32> %63, %53
  %65 = bitcast <8 x i32> %64 to <4 x i64>
  %66 = shufflevector <4 x i64> %65, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %67 = bitcast <8 x i64> %66 to <16 x i32>
  %68 = shufflevector <16 x i32> %67, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %69 = shufflevector <16 x i32> %68, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %70 = shl <16 x i32> %69, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %71 = bitcast <16 x i32> %70 to <8 x double>
  %72 = fmul <8 x double> %62, %71
  %73 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, i32 29, i8 -1, i32 4) #7
  %74 = bitcast i8 %73 to <8 x i1>
  %75 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03>, i32 17, i8 -1, i32 4) #7
  %76 = bitcast i8 %75 to <8 x i1>
  %77 = select <8 x i1> %74, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %72
  %78 = select <8 x i1> %76, <8 x double> zeroinitializer, <8 x double> %77
  ret <8 x double> %78
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_exp2d8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 8, <8 x double> %0, i8 -1, i32 4) #7
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %4 = fsub <8 x double> %0, %2
  %5 = fmul <8 x double> %4, %4
  %6 = fmul <8 x double> %5, %5
  %7 = fmul <8 x double> %6, %6
  %8 = fmul <8 x double> %4, <double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150, double 0x3DFE7901CA95E150>
  %9 = fadd <8 x double> %8, <double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17, double 0x3E3E6106D72C1C17>
  %10 = fmul <8 x double> %4, <double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979, double 0x3E7B5266946BF979>
  %11 = fadd <8 x double> %10, <double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81, double 0x3EB62BFCDABCBB81>
  %12 = fmul <8 x double> %4, <double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80, double 0x3EEFFCBFBC12CC80>
  %13 = fadd <8 x double> %12, <double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC, double 0x3F24309130CB34EC>
  %14 = fmul <8 x double> %5, %11
  %15 = fadd <8 x double> %13, %14
  %16 = fmul <8 x double> %4, <double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960, double 0x3F55D87FE78C5960>
  %17 = fadd <8 x double> %16, <double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0, double 0x3F83B2AB6FBA08F0>
  %18 = fmul <8 x double> %4, <double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F, double 0x3FAC6B08D704A01F>
  %19 = fadd <8 x double> %18, <double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1, double 0x3FCEBFBDFF82C5A1>
  %20 = fmul <8 x double> %5, %17
  %21 = fadd <8 x double> %19, %20
  %22 = fmul <8 x double> %6, %15
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %9, %7
  %25 = fadd <8 x double> %24, %23
  %26 = fmul <8 x double> %4, %25
  %27 = fadd <8 x double> %26, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %28 = fmul <8 x double> %4, %27
  %29 = fadd <8 x double> %28, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %30 = ashr <8 x i32> %3, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %31 = add nsw <8 x i32> %30, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %32 = bitcast <8 x i32> %31 to <4 x i64>
  %33 = shufflevector <4 x i64> %32, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %34 = bitcast <8 x i64> %33 to <16 x i32>
  %35 = shufflevector <16 x i32> %34, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %36 = shufflevector <16 x i32> %35, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %37 = shl <16 x i32> %36, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %38 = bitcast <16 x i32> %37 to <8 x double>
  %39 = fmul <8 x double> %29, %38
  %40 = add <8 x i32> %3, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %41 = sub <8 x i32> %40, %30
  %42 = bitcast <8 x i32> %41 to <4 x i64>
  %43 = shufflevector <4 x i64> %42, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %44 = bitcast <8 x i64> %43 to <16 x i32>
  %45 = shufflevector <16 x i32> %44, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %46 = shufflevector <16 x i32> %45, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %47 = shl <16 x i32> %46, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %48 = bitcast <16 x i32> %47 to <8 x double>
  %49 = fmul <8 x double> %39, %48
  %50 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, i32 29, i8 -1, i32 4) #7
  %51 = bitcast i8 %50 to <8 x i1>
  %52 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03, double -2.000000e+03>, i32 17, i8 -1, i32 4) #7
  %53 = bitcast i8 %52 to <8 x i1>
  %54 = select <8 x i1> %51, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %49
  %55 = select <8 x i1> %53, <8 x double> zeroinitializer, <8 x double> %54
  ret <8 x double> %55
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_exp10d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %2, i32 8, <8 x double> %2, i8 -1, i32 4) #7
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %5 = fmul <8 x double> %3, <double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000>
  %6 = fadd <8 x double> %5, %0
  %7 = fmul <8 x double> %3, <double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B>
  %8 = fadd <8 x double> %7, %6
  %9 = fmul <8 x double> %8, <double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F>
  %10 = fadd <8 x double> %9, <double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A>
  %11 = fmul <8 x double> %8, %10
  %12 = fadd <8 x double> %11, <double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706>
  %13 = fmul <8 x double> %8, %12
  %14 = fadd <8 x double> %13, <double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154>
  %15 = fmul <8 x double> %8, %14
  %16 = fadd <8 x double> %15, <double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37>
  %17 = fmul <8 x double> %8, %16
  %18 = fadd <8 x double> %17, <double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E>
  %19 = fmul <8 x double> %8, %18
  %20 = fadd <8 x double> %19, <double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2>
  %21 = fmul <8 x double> %8, %20
  %22 = fadd <8 x double> %21, <double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B>
  %23 = fmul <8 x double> %8, %22
  %24 = fadd <8 x double> %23, <double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43>
  %25 = fmul <8 x double> %8, %24
  %26 = fadd <8 x double> %25, <double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78>
  %27 = fmul <8 x double> %8, %26
  %28 = fadd <8 x double> %27, <double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516>
  %29 = bitcast <8 x double> %28 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %28, %31
  %33 = bitcast <8 x double> %8 to <8 x i64>
  %34 = and <8 x i64> %33, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %35 = bitcast <8 x i64> %34 to <8 x double>
  %36 = fsub <8 x double> %8, %35
  %37 = fmul <8 x double> %8, %28
  %38 = fmul <8 x double> %35, %31
  %39 = bitcast <8 x double> %37 to <8 x i64>
  %40 = xor <8 x i64> %39, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %41 = bitcast <8 x i64> %40 to <8 x double>
  %42 = fmul <8 x double> %32, %35
  %43 = fmul <8 x double> %36, %31
  %44 = fmul <8 x double> %36, %32
  %45 = fadd <8 x double> %38, %41
  %46 = fadd <8 x double> %42, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %44, %47
  %49 = fadd <8 x double> %37, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %50 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %49
  %51 = fadd <8 x double> %37, %50
  %52 = fadd <8 x double> %51, %48
  %53 = fadd <8 x double> %49, %52
  %54 = ashr <8 x i32> %4, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %55 = add nsw <8 x i32> %54, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %56 = bitcast <8 x i32> %55 to <4 x i64>
  %57 = shufflevector <4 x i64> %56, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = bitcast <8 x i64> %57 to <16 x i32>
  %59 = shufflevector <16 x i32> %58, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %60 = shufflevector <16 x i32> %59, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %61 = shl <16 x i32> %60, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %62 = bitcast <16 x i32> %61 to <8 x double>
  %63 = fmul <8 x double> %53, %62
  %64 = add <8 x i32> %4, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %65 = sub <8 x i32> %64, %54
  %66 = bitcast <8 x i32> %65 to <4 x i64>
  %67 = shufflevector <4 x i64> %66, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %68 = bitcast <8 x i64> %67 to <16 x i32>
  %69 = shufflevector <16 x i32> %68, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %70 = shufflevector <16 x i32> %69, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %71 = shl <16 x i32> %70, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %72 = bitcast <16 x i32> %71 to <8 x double>
  %73 = fmul <8 x double> %63, %72
  %74 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE>, i32 30, i8 -1, i32 4) #7
  %75 = bitcast i8 %74 to <8 x i1>
  %76 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02>, i32 17, i8 -1, i32 4) #7
  %77 = bitcast i8 %76 to <8 x i1>
  %78 = select <8 x i1> %75, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %73
  %79 = select <8 x i1> %77, <8 x double> zeroinitializer, <8 x double> %78
  ret <8 x double> %79
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_exp10d8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371, double 0x400A934F0979A371>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %2, i32 8, <8 x double> %2, i8 -1, i32 4) #7
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %5 = fmul <8 x double> %3, <double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000, double 0xBFD34413509F7000>
  %6 = fadd <8 x double> %5, %0
  %7 = fmul <8 x double> %3, <double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B, double 0xBD43FDE623E2566B>
  %8 = fadd <8 x double> %7, %6
  %9 = fmul <8 x double> %8, %8
  %10 = fmul <8 x double> %9, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %8, <double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A, double 0x3F52F6DBB8E3072A>
  %13 = fadd <8 x double> %12, <double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706, double 0x3F748988CFF14706>
  %14 = fmul <8 x double> %9, <double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F, double 0x3F2F9B875F46726F>
  %15 = fadd <8 x double> %14, %13
  %16 = fmul <8 x double> %8, <double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154, double 0x3F9411663B046154>
  %17 = fadd <8 x double> %16, <double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37, double 0x3FB16E4DF78FCA37>
  %18 = fmul <8 x double> %8, <double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E, double 0x3FCA7ED709F2107E>
  %19 = fadd <8 x double> %18, <double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2, double 0x3FE1429FFD1EB6E2>
  %20 = fmul <8 x double> %9, %17
  %21 = fadd <8 x double> %19, %20
  %22 = fmul <8 x double> %8, <double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B, double 0x3FF2BD7609FD573B>
  %23 = fadd <8 x double> %22, <double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43, double 0x4000470591DE2C43>
  %24 = fmul <8 x double> %8, <double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78, double 0x40053524C73CEA78>
  %25 = fadd <8 x double> %24, <double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516, double 0x40026BB1BBB55516>
  %26 = fmul <8 x double> %9, %23
  %27 = fadd <8 x double> %25, %26
  %28 = fmul <8 x double> %10, %21
  %29 = fadd <8 x double> %27, %28
  %30 = fmul <8 x double> %11, %15
  %31 = fadd <8 x double> %30, %29
  %32 = fmul <8 x double> %8, %31
  %33 = fadd <8 x double> %32, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %34 = ashr <8 x i32> %4, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %35 = add nsw <8 x i32> %34, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %36 = bitcast <8 x i32> %35 to <4 x i64>
  %37 = shufflevector <4 x i64> %36, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %38 = bitcast <8 x i64> %37 to <16 x i32>
  %39 = shufflevector <16 x i32> %38, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %40 = shufflevector <16 x i32> %39, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %41 = shl <16 x i32> %40, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %42 = bitcast <16 x i32> %41 to <8 x double>
  %43 = fmul <8 x double> %33, %42
  %44 = add <8 x i32> %4, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %45 = sub <8 x i32> %44, %34
  %46 = bitcast <8 x i32> %45 to <4 x i64>
  %47 = shufflevector <4 x i64> %46, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %48 = bitcast <8 x i64> %47 to <16 x i32>
  %49 = shufflevector <16 x i32> %48, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %50 = shufflevector <16 x i32> %49, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %51 = shl <16 x i32> %50, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %52 = bitcast <16 x i32> %51 to <8 x double>
  %53 = fmul <8 x double> %43, %52
  %54 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE, double 0x40734413509F79FE>, i32 30, i8 -1, i32 4) #7
  %55 = bitcast i8 %54 to <8 x i1>
  %56 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02, double -3.500000e+02>, i32 17, i8 -1, i32 4) #7
  %57 = bitcast i8 %56 to <8 x i1>
  %58 = select <8 x i1> %55, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %53
  %59 = select <8 x i1> %57, <8 x double> zeroinitializer, <8 x double> %58
  ret <8 x double> %59
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_expm1d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, zeroinitializer
  %3 = fmul <8 x double> %2, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %3, i32 8, <8 x double> %3, i8 -1, i32 4) #7
  %5 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %4, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %6 = fmul <8 x double> %4, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %7 = fadd <8 x double> %6, %0
  %8 = fsub <8 x double> %7, %0
  %9 = fsub <8 x double> %7, %8
  %10 = fsub <8 x double> %0, %9
  %11 = fsub <8 x double> %6, %8
  %12 = fadd <8 x double> %11, %10
  %13 = fadd <8 x double> %12, zeroinitializer
  %14 = fmul <8 x double> %4, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %15 = fadd <8 x double> %14, %7
  %16 = fsub <8 x double> %15, %7
  %17 = fsub <8 x double> %15, %16
  %18 = fsub <8 x double> %7, %17
  %19 = fsub <8 x double> %14, %16
  %20 = fadd <8 x double> %19, %18
  %21 = fadd <8 x double> %20, %13
  %22 = bitcast <8 x double> %15 to <8 x i64>
  %23 = and <8 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %24 = bitcast <8 x i64> %23 to <8 x double>
  %25 = fsub <8 x double> %15, %24
  %26 = fmul <8 x double> %15, %15
  %27 = fmul <8 x double> %24, %24
  %28 = bitcast <8 x double> %26 to <8 x i64>
  %29 = xor <8 x i64> %28, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %30 = bitcast <8 x i64> %29 to <8 x double>
  %31 = fadd <8 x double> %24, %24
  %32 = fmul <8 x double> %31, %25
  %33 = fmul <8 x double> %25, %25
  %34 = fadd <8 x double> %21, %21
  %35 = fmul <8 x double> %15, %34
  %36 = fadd <8 x double> %27, %30
  %37 = fadd <8 x double> %36, %32
  %38 = fadd <8 x double> %33, %37
  %39 = fadd <8 x double> %35, %38
  %40 = and <8 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %41 = bitcast <8 x i64> %40 to <8 x double>
  %42 = fsub <8 x double> %26, %41
  %43 = fmul <8 x double> %26, %26
  %44 = fmul <8 x double> %41, %41
  %45 = bitcast <8 x double> %43 to <8 x i64>
  %46 = xor <8 x i64> %45, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %47 = bitcast <8 x i64> %46 to <8 x double>
  %48 = fadd <8 x double> %41, %41
  %49 = fmul <8 x double> %48, %42
  %50 = fmul <8 x double> %42, %42
  %51 = fadd <8 x double> %39, %39
  %52 = fmul <8 x double> %26, %51
  %53 = fadd <8 x double> %44, %47
  %54 = fadd <8 x double> %53, %49
  %55 = fadd <8 x double> %50, %54
  %56 = fadd <8 x double> %55, %52
  %57 = fmul <8 x double> %43, %43
  %58 = fmul <8 x double> %15, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %59 = fadd <8 x double> %58, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %60 = fmul <8 x double> %15, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %61 = fadd <8 x double> %60, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %62 = fmul <8 x double> %15, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %63 = fadd <8 x double> %62, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %64 = fmul <8 x double> %26, %61
  %65 = fadd <8 x double> %63, %64
  %66 = fmul <8 x double> %15, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %67 = fadd <8 x double> %66, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %68 = fmul <8 x double> %15, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %69 = fadd <8 x double> %68, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %70 = fmul <8 x double> %26, %67
  %71 = fadd <8 x double> %69, %70
  %72 = fmul <8 x double> %43, %65
  %73 = fadd <8 x double> %71, %72
  %74 = fmul <8 x double> %59, %57
  %75 = fadd <8 x double> %74, %73
  %76 = fmul <8 x double> %15, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %77 = fmul <8 x double> %24, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %78 = bitcast <8 x double> %76 to <8 x i64>
  %79 = xor <8 x i64> %78, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = bitcast <8 x i64> %79 to <8 x double>
  %81 = fmul <8 x double> %25, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %82 = fmul <8 x double> %24, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %83 = fmul <8 x double> %25, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %84 = fmul <8 x double> %21, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %85 = fadd <8 x double> %77, %80
  %86 = fadd <8 x double> %81, %85
  %87 = fadd <8 x double> %82, %86
  %88 = fadd <8 x double> %83, %87
  %89 = fadd <8 x double> %84, %88
  %90 = fadd <8 x double> %76, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %91 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %90
  %92 = fadd <8 x double> %76, %91
  %93 = fadd <8 x double> %92, %89
  %94 = bitcast <8 x double> %90 to <8 x i64>
  %95 = and <8 x i64> %94, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = fsub <8 x double> %90, %96
  %98 = fmul <8 x double> %15, %90
  %99 = fmul <8 x double> %24, %96
  %100 = bitcast <8 x double> %98 to <8 x i64>
  %101 = xor <8 x i64> %100, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %102 = bitcast <8 x i64> %101 to <8 x double>
  %103 = fmul <8 x double> %97, %24
  %104 = fmul <8 x double> %25, %96
  %105 = fmul <8 x double> %25, %97
  %106 = fmul <8 x double> %90, %21
  %107 = fmul <8 x double> %15, %93
  %108 = fadd <8 x double> %99, %102
  %109 = fadd <8 x double> %103, %108
  %110 = fadd <8 x double> %104, %109
  %111 = fadd <8 x double> %105, %110
  %112 = fadd <8 x double> %106, %111
  %113 = fadd <8 x double> %107, %112
  %114 = fadd <8 x double> %98, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %115 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %114
  %116 = fadd <8 x double> %98, %115
  %117 = fadd <8 x double> %116, %113
  %118 = bitcast <8 x double> %114 to <8 x i64>
  %119 = and <8 x i64> %118, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %120 = bitcast <8 x i64> %119 to <8 x double>
  %121 = fsub <8 x double> %114, %120
  %122 = fmul <8 x double> %15, %114
  %123 = fmul <8 x double> %24, %120
  %124 = bitcast <8 x double> %122 to <8 x i64>
  %125 = xor <8 x i64> %124, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %126 = bitcast <8 x i64> %125 to <8 x double>
  %127 = fmul <8 x double> %121, %24
  %128 = fmul <8 x double> %25, %120
  %129 = fmul <8 x double> %25, %121
  %130 = fmul <8 x double> %114, %21
  %131 = fmul <8 x double> %15, %117
  %132 = fadd <8 x double> %123, %126
  %133 = fadd <8 x double> %127, %132
  %134 = fadd <8 x double> %128, %133
  %135 = fadd <8 x double> %129, %134
  %136 = fadd <8 x double> %130, %135
  %137 = fadd <8 x double> %136, %131
  %138 = fadd <8 x double> %122, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %139 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %138
  %140 = fadd <8 x double> %122, %139
  %141 = fadd <8 x double> %140, %137
  %142 = and <8 x i64> %45, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %143 = bitcast <8 x i64> %142 to <8 x double>
  %144 = fsub <8 x double> %43, %143
  %145 = bitcast <8 x double> %75 to <8 x i64>
  %146 = and <8 x i64> %145, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %147 = bitcast <8 x i64> %146 to <8 x double>
  %148 = fsub <8 x double> %75, %147
  %149 = fmul <8 x double> %43, %75
  %150 = fmul <8 x double> %143, %147
  %151 = bitcast <8 x double> %149 to <8 x i64>
  %152 = xor <8 x i64> %151, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %153 = bitcast <8 x i64> %152 to <8 x double>
  %154 = fmul <8 x double> %144, %147
  %155 = fmul <8 x double> %148, %143
  %156 = fmul <8 x double> %144, %148
  %157 = fmul <8 x double> %75, %56
  %158 = fadd <8 x double> %150, %153
  %159 = fadd <8 x double> %154, %158
  %160 = fadd <8 x double> %155, %159
  %161 = fadd <8 x double> %156, %160
  %162 = fadd <8 x double> %157, %161
  %163 = fadd <8 x double> %138, %149
  %164 = fsub <8 x double> %138, %163
  %165 = fadd <8 x double> %149, %164
  %166 = fadd <8 x double> %165, %141
  %167 = fadd <8 x double> %162, %166
  %168 = ashr <8 x i32> %5, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %169 = add nsw <8 x i32> %168, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %170 = bitcast <8 x i32> %169 to <4 x i64>
  %171 = shufflevector <4 x i64> %170, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %172 = bitcast <8 x i64> %171 to <16 x i32>
  %173 = shufflevector <16 x i32> %172, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %174 = shufflevector <16 x i32> %173, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %175 = shl <16 x i32> %174, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %176 = bitcast <16 x i32> %175 to <8 x double>
  %177 = fmul <8 x double> %163, %176
  %178 = add <8 x i32> %5, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %179 = sub <8 x i32> %178, %168
  %180 = bitcast <8 x i32> %179 to <4 x i64>
  %181 = shufflevector <4 x i64> %180, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %182 = bitcast <8 x i64> %181 to <16 x i32>
  %183 = shufflevector <16 x i32> %182, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %184 = shufflevector <16 x i32> %183, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %185 = shl <16 x i32> %184, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %186 = bitcast <16 x i32> %185 to <8 x double>
  %187 = fmul <8 x double> %177, %186
  %188 = fmul <8 x double> %167, %176
  %189 = fmul <8 x double> %188, %186
  %190 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %191 = bitcast i8 %190 to <8 x i1>
  %192 = select <8 x i1> %191, <8 x double> zeroinitializer, <8 x double> %187
  %193 = select <8 x i1> %191, <8 x double> zeroinitializer, <8 x double> %189
  %194 = fadd <8 x double> %192, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %195 = fsub <8 x double> %194, %192
  %196 = fsub <8 x double> %194, %195
  %197 = fsub <8 x double> %192, %196
  %198 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %195
  %199 = fadd <8 x double> %198, %197
  %200 = fadd <8 x double> %199, %193
  %201 = fadd <8 x double> %194, %200
  %202 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF>, i32 30, i8 -1, i32 4) #7
  %203 = bitcast i8 %202 to <8 x i1>
  %204 = select <8 x i1> %203, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %201
  %205 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA, double 0xC0425E4F7B2737FA>, i32 17, i8 -1, i32 4) #7
  %206 = bitcast i8 %205 to <8 x i1>
  %207 = select <8 x i1> %206, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <8 x double> %204
  %208 = bitcast <8 x double> %0 to <8 x i64>
  %209 = icmp eq <8 x i64> %208, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %210 = select <8 x i1> %209, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %207
  ret <8 x double> %210
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_log10d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192>
  %60 = fadd <8 x double> %59, <double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48>
  %61 = fmul <8 x double> %57, <double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74>
  %64 = fadd <8 x double> %63, <double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821>
  %65 = fmul <8 x double> %56, <double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88>
  %66 = fadd <8 x double> %65, <double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %6 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %6, %73
  %75 = fmul <8 x double> %6, <double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF>
  %76 = fmul <8 x double> %73, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %73, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %81 = fmul <8 x double> %74, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %82 = fmul <8 x double> %74, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %83 = fmul <8 x double> %6, <double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21>
  %84 = fadd <8 x double> %76, %79
  %85 = fadd <8 x double> %80, %84
  %86 = fadd <8 x double> %81, %85
  %87 = fadd <8 x double> %82, %86
  %88 = fadd <8 x double> %83, %87
  %89 = bitcast <8 x double> %33 to <8 x i64>
  %90 = and <8 x i64> %89, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %91 = bitcast <8 x i64> %90 to <8 x double>
  %92 = fsub <8 x double> %33, %91
  %93 = fmul <8 x double> %33, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %94 = fmul <8 x double> %91, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %95 = bitcast <8 x double> %93 to <8 x i64>
  %96 = xor <8 x i64> %95, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %97 = bitcast <8 x i64> %96 to <8 x double>
  %98 = fmul <8 x double> %92, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %99 = fmul <8 x double> %91, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %100 = fmul <8 x double> %92, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %101 = fmul <8 x double> %33, <double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F>
  %102 = fmul <8 x double> %55, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %103 = fadd <8 x double> %94, %97
  %104 = fadd <8 x double> %98, %103
  %105 = fadd <8 x double> %99, %104
  %106 = fadd <8 x double> %100, %105
  %107 = fadd <8 x double> %101, %106
  %108 = fadd <8 x double> %107, %102
  %109 = fadd <8 x double> %75, %93
  %110 = fsub <8 x double> %75, %109
  %111 = fadd <8 x double> %93, %110
  %112 = fadd <8 x double> %111, %88
  %113 = fadd <8 x double> %112, %108
  %114 = fmul <8 x double> %33, %56
  %115 = fmul <8 x double> %114, %70
  %116 = fadd <8 x double> %109, %115
  %117 = fsub <8 x double> %109, %116
  %118 = fadd <8 x double> %115, %117
  %119 = fadd <8 x double> %118, %113
  %120 = fadd <8 x double> %116, %119
  %121 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %120, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4)
  ret <8 x double> %121
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_log2d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %60 = fadd <8 x double> %59, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %61 = fmul <8 x double> %57, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %64 = fadd <8 x double> %63, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %65 = fmul <8 x double> %56, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %66 = fadd <8 x double> %65, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %33 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %33, %73
  %75 = fmul <8 x double> %33, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %76 = fmul <8 x double> %73, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %74, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %81 = fmul <8 x double> %73, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %82 = fmul <8 x double> %74, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %83 = fmul <8 x double> %33, <double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1>
  %84 = fmul <8 x double> %55, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %85 = fadd <8 x double> %76, %79
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %82, %87
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %89, %84
  %91 = fadd <8 x double> %6, %75
  %92 = fsub <8 x double> %91, %6
  %93 = fsub <8 x double> %91, %92
  %94 = fsub <8 x double> %6, %93
  %95 = fsub <8 x double> %75, %92
  %96 = fadd <8 x double> %95, %94
  %97 = fadd <8 x double> %96, %90
  %98 = fmul <8 x double> %33, %56
  %99 = fmul <8 x double> %98, %70
  %100 = fadd <8 x double> %91, %99
  %101 = fsub <8 x double> %100, %91
  %102 = fsub <8 x double> %100, %101
  %103 = fsub <8 x double> %91, %102
  %104 = fsub <8 x double> %99, %101
  %105 = fadd <8 x double> %104, %103
  %106 = fadd <8 x double> %105, %97
  %107 = fadd <8 x double> %100, %106
  %108 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %107, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4)
  ret <8 x double> %108
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_log2d8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fdiv <8 x double> %8, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %11, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %13 = fadd <8 x double> %12, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %14 = fmul <8 x double> %11, %13
  %15 = fadd <8 x double> %14, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %16 = fmul <8 x double> %11, %15
  %17 = fadd <8 x double> %16, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %18 = fmul <8 x double> %11, %17
  %19 = fadd <8 x double> %18, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %20 = fmul <8 x double> %11, %19
  %21 = fadd <8 x double> %20, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %22 = fmul <8 x double> %11, %21
  %23 = fadd <8 x double> %22, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %24 = bitcast <8 x double> %10 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = fsub <8 x double> %10, %26
  %28 = fmul <8 x double> %10, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %29 = fmul <8 x double> %26, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %30 = bitcast <8 x double> %28 to <8 x i64>
  %31 = xor <8 x i64> %30, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %32 = bitcast <8 x i64> %31 to <8 x double>
  %33 = fmul <8 x double> %27, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %34 = fmul <8 x double> %26, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %35 = fmul <8 x double> %27, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %36 = fadd <8 x double> %29, %32
  %37 = fadd <8 x double> %33, %36
  %38 = fadd <8 x double> %34, %37
  %39 = fadd <8 x double> %35, %38
  %40 = fadd <8 x double> %6, %28
  %41 = fsub <8 x double> %6, %40
  %42 = fadd <8 x double> %28, %41
  %43 = fadd <8 x double> %42, %39
  %44 = fmul <8 x double> %10, %11
  %45 = fadd <8 x double> %40, %43
  %46 = fmul <8 x double> %44, %23
  %47 = fadd <8 x double> %45, %46
  %48 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %47, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4)
  ret <8 x double> %48
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_log1pd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = fmul <8 x double> %2, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %3, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %6 = bitcast i8 %5 to <8 x i1>
  %7 = select <8 x i1> %6, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %4
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = sub <8 x i32> zeroinitializer, %8
  %10 = bitcast <8 x i32> %9 to <4 x i64>
  %11 = shufflevector <4 x i64> %10, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = bitcast <8 x i64> %11 to <16 x i32>
  %13 = shufflevector <16 x i32> %12, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %14 = shufflevector <16 x i32> %13, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %15 = shl <16 x i32> %14, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %16 = add <16 x i32> %15, <i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248>
  %17 = bitcast <16 x i32> %16 to <8 x double>
  %18 = fadd <8 x double> %17, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %19 = fmul <8 x double> %17, %0
  %20 = fadd <8 x double> %19, %18
  %21 = bitcast <8 x double> %7 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %7, %23
  %25 = fmul <8 x double> %7, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %26 = fmul <8 x double> %23, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %27 = bitcast <8 x double> %25 to <8 x i64>
  %28 = xor <8 x i64> %27, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %29 = bitcast <8 x i64> %28 to <8 x double>
  %30 = fmul <8 x double> %23, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %31 = fmul <8 x double> %24, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %32 = fmul <8 x double> %24, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %33 = fmul <8 x double> %7, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %34 = fadd <8 x double> %26, %29
  %35 = fadd <8 x double> %30, %34
  %36 = fadd <8 x double> %31, %35
  %37 = fadd <8 x double> %32, %36
  %38 = fadd <8 x double> %33, %37
  %39 = fadd <8 x double> %20, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %40 = fsub <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %39
  %41 = fadd <8 x double> %20, %40
  %42 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %43 = bitcast <8 x double> %39 to <8 x i64>
  %44 = and <8 x i64> %43, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %45 = bitcast <8 x i64> %44 to <8 x double>
  %46 = fsub <8 x double> %39, %45
  %47 = bitcast <8 x double> %42 to <8 x i64>
  %48 = and <8 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <8 x i64> %48 to <8 x double>
  %50 = fsub <8 x double> %42, %49
  %51 = bitcast <8 x double> %20 to <8 x i64>
  %52 = and <8 x i64> %51, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %53 = bitcast <8 x i64> %52 to <8 x double>
  %54 = fsub <8 x double> %20, %53
  %55 = fmul <8 x double> %20, %42
  %56 = fmul <8 x double> %53, %49
  %57 = fsub <8 x double> %56, %55
  %58 = fmul <8 x double> %50, %53
  %59 = fmul <8 x double> %54, %49
  %60 = fmul <8 x double> %54, %50
  %61 = fmul <8 x double> %45, %49
  %62 = fmul <8 x double> %50, %45
  %63 = fmul <8 x double> %46, %49
  %64 = fmul <8 x double> %46, %50
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %55, %68
  %70 = fadd <8 x double> %57, %58
  %71 = fadd <8 x double> %59, %70
  %72 = fadd <8 x double> %60, %71
  %73 = fadd <8 x double> %72, %69
  %74 = fmul <8 x double> %55, %41
  %75 = fsub <8 x double> zeroinitializer, %74
  %76 = fmul <8 x double> %42, %75
  %77 = fadd <8 x double> %76, %73
  %78 = fmul <8 x double> %55, %55
  %79 = fmul <8 x double> %78, %78
  %80 = fmul <8 x double> %79, %79
  %81 = fmul <8 x double> %78, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %82 = fadd <8 x double> %81, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %83 = fmul <8 x double> %79, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %84 = fadd <8 x double> %83, %82
  %85 = fmul <8 x double> %78, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %86 = fadd <8 x double> %85, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %87 = fmul <8 x double> %78, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %88 = fadd <8 x double> %87, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %89 = fmul <8 x double> %79, %86
  %90 = fadd <8 x double> %88, %89
  %91 = fmul <8 x double> %80, %84
  %92 = fadd <8 x double> %91, %90
  %93 = fmul <8 x double> %55, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %94 = fmul <8 x double> %77, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %95 = fadd <8 x double> %25, %93
  %96 = fsub <8 x double> %25, %95
  %97 = fadd <8 x double> %93, %96
  %98 = fadd <8 x double> %38, %97
  %99 = fadd <8 x double> %98, %94
  %100 = fmul <8 x double> %55, %78
  %101 = fmul <8 x double> %100, %92
  %102 = fadd <8 x double> %95, %101
  %103 = fsub <8 x double> %95, %102
  %104 = fadd <8 x double> %101, %103
  %105 = fadd <8 x double> %104, %99
  %106 = fadd <8 x double> %102, %105
  %107 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433>, i32 30, i8 -1, i32 4) #7
  %108 = bitcast i8 %107 to <8 x i1>
  %109 = select <8 x i1> %108, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %106
  %110 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i32 17, i8 -1, i32 4) #7
  %111 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %112 = or i8 %111, %110
  %113 = bitcast i8 %112 to <8 x i1>
  %114 = select <8 x i1> %113, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %109
  %115 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %116 = bitcast i8 %115 to <8 x i1>
  %117 = select <8 x i1> %116, <8 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <8 x double> %114
  %118 = bitcast <8 x double> %0 to <8 x i64>
  %119 = icmp eq <8 x i64> %118, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %120 = select <8 x i1> %119, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %117
  ret <8 x double> %120
}

; Function Attrs: norecurse nounwind readnone uwtable
define <8 x double> @Sleef_fabsd8_avx512fnofma(<8 x double>) local_unnamed_addr #0 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  ret <8 x double> %4
}

; Function Attrs: norecurse nounwind readnone uwtable
define <8 x double> @Sleef_copysignd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #0 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x double> %1 to <8 x i64>
  %6 = and <8 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = or <8 x i64> %6, %4
  %8 = bitcast <8 x i64> %7 to <8 x double>
  ret <8 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_fmaxd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %0, <8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = bitcast i8 %3 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> %0, <8 x double> %4
  ret <8 x double> %6
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_fmind8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %0, <8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = bitcast i8 %3 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> %0, <8 x double> %4
  ret <8 x double> %6
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_fdimd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = fsub <8 x double> %0, %1
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %1, i32 0, i8 -1, i32 4) #7
  %6 = or i8 %5, %4
  %7 = bitcast i8 %6 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> zeroinitializer, <8 x double> %3
  ret <8 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_truncd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 11, <8 x double> %0, i8 -1, i32 4) #7
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_floord8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = sitofp <8 x i32> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <8 x double> %0, %5
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %8 = sitofp <8 x i32> %7 to <8 x double>
  %9 = fsub <8 x double> %6, %8
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %11 = fadd <8 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %9
  %14 = bitcast <8 x double> %0 to <8 x i64>
  %15 = and <8 x i64> %14, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %16 = bitcast <8 x i64> %15 to <8 x double>
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %19 = or i8 %18, %17
  %20 = fsub <8 x double> %0, %13
  %21 = bitcast <8 x double> %20 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = and <8 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %24 = or <8 x i64> %22, %23
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = bitcast i8 %19 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %0, <8 x double> %25
  ret <8 x double> %27
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_ceild8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = sitofp <8 x i32> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <8 x double> %0, %5
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %8 = sitofp <8 x i32> %7 to <8 x double>
  %9 = fsub <8 x double> %6, %8
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 18, i8 -1, i32 4) #7
  %11 = fadd <8 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %9, <8 x double> %11
  %14 = bitcast <8 x double> %0 to <8 x i64>
  %15 = and <8 x i64> %14, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %16 = bitcast <8 x i64> %15 to <8 x double>
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %19 = or i8 %18, %17
  %20 = fsub <8 x double> %0, %13
  %21 = bitcast <8 x double> %20 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = and <8 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %24 = or <8 x i64> %22, %23
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = bitcast i8 %19 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %0, <8 x double> %25
  ret <8 x double> %27
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_roundd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %3 = fmul <8 x double> %2, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = sitofp <8 x i32> %4 to <8 x double>
  %6 = fmul <8 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <8 x double> %2, %6
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %9 = sitofp <8 x i32> %8 to <8 x double>
  %10 = fsub <8 x double> %7, %9
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i32 18, i8 -1, i32 4) #7
  %12 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %13 = and i8 %12, %11
  %14 = fadd <8 x double> %2, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %15 = bitcast i8 %13 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> %14, <8 x double> %2
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %18 = fadd <8 x double> %10, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %19 = bitcast i8 %17 to <8 x i1>
  %20 = select <8 x i1> %19, <8 x double> %18, <8 x double> %10
  %21 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF>, i32 0, i8 -1, i32 4) #7
  %22 = bitcast i8 %21 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x double> zeroinitializer, <8 x double> %16
  %24 = bitcast <8 x double> %0 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %26, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %28 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %26, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %29 = or i8 %28, %27
  %30 = fsub <8 x double> %23, %20
  %31 = bitcast <8 x double> %30 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %33 = and <8 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %34 = or <8 x i64> %32, %33
  %35 = bitcast <8 x i64> %34 to <8 x double>
  %36 = bitcast i8 %29 to <8 x i1>
  %37 = select <8 x i1> %36, <8 x double> %0, <8 x double> %35
  ret <8 x double> %37
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_rintd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 8, <8 x double> %0, i8 -1, i32 4) #7
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_nextafterd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %4 = bitcast <8 x double> %1 to <8 x i64>
  %5 = and <8 x i64> %4, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %6 = bitcast <8 x i64> %5 to <8 x double>
  %7 = bitcast i8 %3 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = icmp slt <8 x i64> %9, zeroinitializer
  %11 = bitcast <8 x i1> %10 to i8
  %12 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %8, i32 29, i8 -1, i32 4) #7
  %13 = xor i8 %12, %11
  %14 = bitcast <8 x double> %8 to <16 x i32>
  %15 = xor <16 x i32> %14, <i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %16 = add <16 x i32> %15, <i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0>
  %17 = icmp eq <16 x i32> %16, <i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1>
  %18 = sext <16 x i1> %17 to <16 x i32>
  %19 = bitcast <16 x i32> %18 to <8 x i64>
  %20 = and <8 x i64> %19, <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>
  %21 = bitcast <8 x i64> %20 to <16 x float>
  %22 = shufflevector <16 x float> %21, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %23 = bitcast <16 x float> %22 to <16 x i32>
  %24 = add <16 x i32> %16, %23
  %25 = bitcast <16 x i32> %24 to <8 x double>
  %26 = bitcast i8 %13 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %25, <8 x double> %8
  %28 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %29 = bitcast i8 %28 to <8 x i1>
  %30 = zext <8 x i1> %29 to <8 x i64>
  %31 = bitcast <8 x double> %27 to <16 x i32>
  %32 = bitcast <8 x i64> %30 to <16 x i32>
  %33 = sub <16 x i32> %31, %32
  %34 = icmp eq <16 x i32> %33, <i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0>
  %35 = sext <16 x i1> %34 to <16 x i32>
  %36 = bitcast <16 x i32> %35 to <8 x i64>
  %37 = and <8 x i64> %36, <i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295>
  %38 = bitcast <8 x i64> %37 to <16 x float>
  %39 = shufflevector <16 x float> %38, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %40 = bitcast <16 x float> %39 to <16 x i32>
  %41 = add <16 x i32> %33, %40
  %42 = bitcast <16 x i32> %41 to <8 x double>
  %43 = bitcast <16 x i32> %33 to <8 x double>
  %44 = select <8 x i1> %29, <8 x double> %42, <8 x double> %43
  %45 = bitcast <8 x double> %44 to <16 x i32>
  %46 = xor <16 x i32> %45, <i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %47 = add <16 x i32> %46, <i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0>
  %48 = icmp eq <16 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1>
  %49 = sext <16 x i1> %48 to <16 x i32>
  %50 = bitcast <16 x i32> %49 to <8 x i64>
  %51 = and <8 x i64> %50, <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>
  %52 = bitcast <8 x i64> %51 to <16 x float>
  %53 = shufflevector <16 x float> %52, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %54 = bitcast <16 x float> %53 to <16 x i32>
  %55 = add <16 x i32> %47, %54
  %56 = bitcast <16 x i32> %55 to <8 x double>
  %57 = select <8 x i1> %26, <8 x double> %56, <8 x double> %44
  %58 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %57, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %59 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 4, i8 -1, i32 4) #7
  %60 = and i8 %59, %58
  %61 = and <8 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = bitcast i8 %60 to <8 x i1>
  %64 = select <8 x i1> %63, <8 x double> %62, <8 x double> %57
  %65 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %66 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %67 = and i8 %66, %65
  %68 = bitcast i8 %67 to <8 x i1>
  %69 = select <8 x i1> %68, <8 x double> %1, <8 x double> %64
  %70 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %72 = or i8 %71, %70
  %73 = bitcast i8 %72 to <8 x i1>
  %74 = select <8 x i1> %73, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %69
  ret <8 x double> %74
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_frfrexpd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = and <8 x i64> %9, <i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313>
  %11 = or <8 x i64> %10, <i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912>
  %12 = and <8 x i64> %9, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <8 x i64> %12 to <8 x double>
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %15 = and <8 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %16 = or <8 x i64> %15, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %17 = bitcast i8 %14 to <8 x i1>
  %18 = select <8 x i1> %17, <8 x i64> %16, <8 x i64> %11
  %19 = bitcast <8 x i64> %18 to <8 x double>
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %21 = bitcast i8 %20 to <8 x i1>
  %22 = select <8 x i1> %21, <8 x double> %8, <8 x double> %19
  ret <8 x double> %22
}

; Function Attrs: nounwind readnone uwtable
define <4 x i64> @Sleef_expfrexpd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = bitcast <8 x double> %8 to <16 x i32>
  %11 = shufflevector <16 x i32> %10, <16 x i32> undef, <16 x i32> <i32 1, i32 3, i32 5, i32 7, i32 9, i32 11, i32 13, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = bitcast <16 x i32> %11 to <8 x i64>
  %13 = shufflevector <8 x i64> %12, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %14 = bitcast <4 x i64> %13 to <8 x i32>
  %15 = lshr <8 x i32> %14, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %16 = and <8 x i32> %15, <i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047>
  %17 = add nsw <8 x i32> %16, <i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022>
  %18 = bitcast <8 x i32> %17 to <4 x i64>
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %21 = or i8 %20, %19
  %22 = and <8 x i64> %9, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %25 = or i8 %21, %24
  %26 = zext i8 %25 to i16
  %27 = shufflevector <4 x i64> %18, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <8 x i64> %27 to <16 x i32>
  %29 = bitcast i16 %26 to <16 x i1>
  %30 = select <16 x i1> %29, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> %28
  %31 = bitcast <16 x i32> %30 to <8 x i64>
  %32 = shufflevector <8 x i64> %31, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  ret <4 x i64> %32
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_fmad8_avx512fnofma(<8 x double>, <8 x double>, <8 x double>) local_unnamed_addr #1 {
  %4 = fmul <8 x double> %0, %1
  %5 = fadd <8 x double> %4, %2
  %6 = bitcast <8 x double> %5 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %0, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %0
  %13 = fmul <8 x double> %1, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %1
  %15 = fmul <8 x double> %2, <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>
  %16 = select <8 x i1> %11, <8 x double> %15, <8 x double> %2
  %17 = select <8 x i1> %11, <8 x double> <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300>, i32 30, i8 -1, i32 4) #7
  %19 = fmul <8 x double> %12, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %20 = bitcast i8 %18 to <8 x i1>
  %21 = select <8 x i1> %20, <8 x double> %19, <8 x double> %12
  %22 = fmul <8 x double> %14, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %23 = select <8 x i1> %20, <8 x double> %22, <8 x double> %14
  %24 = fmul <8 x double> %16, <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>
  %25 = select <8 x i1> %20, <8 x double> %24, <8 x double> %16
  %26 = select <8 x i1> %20, <8 x double> <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>, <8 x double> %17
  %27 = bitcast <8 x double> %21 to <8 x i64>
  %28 = and <8 x i64> %27, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %29 = bitcast <8 x i64> %28 to <8 x double>
  %30 = fsub <8 x double> %21, %29
  %31 = bitcast <8 x double> %23 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fsub <8 x double> %23, %33
  %35 = fmul <8 x double> %21, %23
  %36 = fmul <8 x double> %29, %33
  %37 = bitcast <8 x double> %35 to <8 x i64>
  %38 = xor <8 x i64> %37, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %39 = bitcast <8 x i64> %38 to <8 x double>
  %40 = fmul <8 x double> %30, %33
  %41 = fmul <8 x double> %34, %29
  %42 = fmul <8 x double> %30, %34
  %43 = fadd <8 x double> %36, %39
  %44 = fadd <8 x double> %40, %43
  %45 = fadd <8 x double> %41, %44
  %46 = fadd <8 x double> %42, %45
  %47 = fadd <8 x double> %25, %35
  %48 = fsub <8 x double> %47, %35
  %49 = fsub <8 x double> %47, %48
  %50 = fsub <8 x double> %35, %49
  %51 = fsub <8 x double> %25, %48
  %52 = fadd <8 x double> %51, %50
  %53 = fadd <8 x double> %52, %46
  %54 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %21, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %55 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %56 = or i8 %55, %54
  %57 = fadd <8 x double> %47, %53
  %58 = bitcast i8 %56 to <8 x i1>
  %59 = select <8 x i1> %58, <8 x double> %25, <8 x double> %57
  %60 = bitcast <8 x double> %25 to <8 x i64>
  %61 = and <8 x i64> %60, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %62, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %64 = zext i8 %63 to i16
  %65 = and <8 x i64> %27, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %66 = bitcast <8 x i64> %65 to <8 x double>
  %67 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %66, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %68 = zext i8 %67 to i16
  %69 = bitcast i16 %68 to <16 x i1>
  %70 = bitcast i16 %64 to <16 x i1>
  %71 = xor <16 x i1> %69, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %72 = and <16 x i1> %71, %70
  %73 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %21, <8 x double> %21, i32 4, i8 -1, i32 4) #7
  %74 = zext i8 %73 to i16
  %75 = bitcast i16 %74 to <16 x i1>
  %76 = xor <16 x i1> %75, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %77 = and <16 x i1> %72, %76
  %78 = and <8 x i64> %31, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %79, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %81 = zext i8 %80 to i16
  %82 = bitcast i16 %81 to <16 x i1>
  %83 = xor <16 x i1> %82, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %84 = and <16 x i1> %77, %83
  %85 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> %23, i32 4, i8 -1, i32 4) #7
  %86 = zext i8 %85 to i16
  %87 = bitcast i16 %86 to <16 x i1>
  %88 = xor <16 x i1> %87, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %89 = and <16 x i1> %84, %88
  %90 = bitcast <16 x i1> %89 to <2 x i8>
  %91 = extractelement <2 x i8> %90, i32 0
  %92 = bitcast i8 %91 to <8 x i1>
  %93 = select <8 x i1> %92, <8 x double> %25, <8 x double> %5
  %94 = bitcast <8 x double> %93 to <8 x i64>
  %95 = and <8 x i64> %94, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %96, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %98 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %93, <8 x double> %93, i32 4, i8 -1, i32 4) #7
  %99 = or i8 %98, %97
  %100 = fmul <8 x double> %26, %59
  %101 = bitcast i8 %99 to <8 x i1>
  %102 = select <8 x i1> %101, <8 x double> %93, <8 x double> %100
  ret <8 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sqrtd8_u05avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %3 = bitcast i8 %2 to <8 x i1>
  %4 = select <8 x i1> %3, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %4, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %4
  %9 = select <8 x i1> %7, <8 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i32 30, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %8, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %8
  %14 = select <8 x i1> %12, <8 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <8 x double> %9
  %15 = fadd <8 x double> %13, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %16 = bitcast <8 x double> %15 to <16 x i32>
  %17 = lshr <16 x i32> %16, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %18 = sub nsw <16 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %19 = bitcast <16 x i32> %18 to <8 x double>
  %20 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = fmul <8 x double> %20, %19
  %22 = fmul <8 x double> %21, %19
  %23 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %22
  %24 = fmul <8 x double> %23, %19
  %25 = fmul <8 x double> %20, %24
  %26 = fmul <8 x double> %24, %25
  %27 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %26
  %28 = fmul <8 x double> %24, %27
  %29 = fmul <8 x double> %20, %28
  %30 = fmul <8 x double> %28, %29
  %31 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <8 x double> %28, %31
  %33 = fmul <8 x double> %13, %32
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %33, %36
  %38 = fmul <8 x double> %33, %33
  %39 = fmul <8 x double> %36, %36
  %40 = bitcast <8 x double> %38 to <8 x i64>
  %41 = xor <8 x i64> %40, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <8 x i64> %41 to <8 x double>
  %43 = fmul <8 x double> %37, %36
  %44 = fmul <8 x double> %37, %37
  %45 = fadd <8 x double> %39, %42
  %46 = fadd <8 x double> %43, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %44, %47
  %49 = fadd <8 x double> %13, %38
  %50 = fsub <8 x double> %49, %13
  %51 = fsub <8 x double> %49, %50
  %52 = fsub <8 x double> %13, %51
  %53 = fsub <8 x double> %38, %50
  %54 = fadd <8 x double> %53, %52
  %55 = fadd <8 x double> %54, %48
  %56 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %33
  %57 = bitcast <8 x double> %56 to <8 x i64>
  %58 = and <8 x i64> %57, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %59 = bitcast <8 x i64> %58 to <8 x double>
  %60 = fsub <8 x double> %56, %59
  %61 = fmul <8 x double> %36, %59
  %62 = fmul <8 x double> %60, %36
  %63 = fmul <8 x double> %37, %59
  %64 = fmul <8 x double> %37, %60
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %56, %68
  %70 = bitcast <8 x double> %49 to <8 x i64>
  %71 = and <8 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <8 x i64> %71 to <8 x double>
  %73 = fsub <8 x double> %49, %72
  %74 = fmul <8 x double> %56, %49
  %75 = fmul <8 x double> %59, %72
  %76 = bitcast <8 x double> %74 to <8 x i64>
  %77 = xor <8 x i64> %76, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fmul <8 x double> %73, %59
  %80 = fmul <8 x double> %60, %72
  %81 = fmul <8 x double> %60, %73
  %82 = fmul <8 x double> %49, %69
  %83 = fmul <8 x double> %56, %55
  %84 = fadd <8 x double> %75, %78
  %85 = fadd <8 x double> %79, %84
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %87, %82
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %74, %89
  %91 = fmul <8 x double> %14, %90
  %92 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %93 = bitcast i8 %92 to <8 x i1>
  %94 = select <8 x i1> %93, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %91
  %95 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %96 = bitcast i8 %95 to <8 x i1>
  %97 = select <8 x i1> %96, <8 x double> %13, <8 x double> %94
  ret <8 x double> %97
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sqrtd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_sqrtd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %3 = bitcast i8 %2 to <8 x i1>
  %4 = select <8 x i1> %3, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %4, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %4
  %9 = select <8 x i1> %7, <8 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i32 30, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %8, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %8
  %14 = select <8 x i1> %12, <8 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <8 x double> %9
  %15 = fadd <8 x double> %13, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %16 = bitcast <8 x double> %15 to <16 x i32>
  %17 = lshr <16 x i32> %16, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %18 = sub nsw <16 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %19 = bitcast <16 x i32> %18 to <8 x double>
  %20 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = fmul <8 x double> %20, %19
  %22 = fmul <8 x double> %21, %19
  %23 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %22
  %24 = fmul <8 x double> %23, %19
  %25 = fmul <8 x double> %20, %24
  %26 = fmul <8 x double> %24, %25
  %27 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %26
  %28 = fmul <8 x double> %24, %27
  %29 = fmul <8 x double> %20, %28
  %30 = fmul <8 x double> %28, %29
  %31 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <8 x double> %28, %31
  %33 = fmul <8 x double> %13, %32
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %33, %36
  %38 = fmul <8 x double> %33, %33
  %39 = fmul <8 x double> %36, %36
  %40 = bitcast <8 x double> %38 to <8 x i64>
  %41 = xor <8 x i64> %40, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <8 x i64> %41 to <8 x double>
  %43 = fmul <8 x double> %37, %36
  %44 = fmul <8 x double> %37, %37
  %45 = fadd <8 x double> %39, %42
  %46 = fadd <8 x double> %43, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %44, %47
  %49 = fadd <8 x double> %13, %38
  %50 = fsub <8 x double> %49, %13
  %51 = fsub <8 x double> %49, %50
  %52 = fsub <8 x double> %13, %51
  %53 = fsub <8 x double> %38, %50
  %54 = fadd <8 x double> %53, %52
  %55 = fadd <8 x double> %54, %48
  %56 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %33
  %57 = bitcast <8 x double> %56 to <8 x i64>
  %58 = and <8 x i64> %57, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %59 = bitcast <8 x i64> %58 to <8 x double>
  %60 = fsub <8 x double> %56, %59
  %61 = fmul <8 x double> %36, %59
  %62 = fmul <8 x double> %60, %36
  %63 = fmul <8 x double> %37, %59
  %64 = fmul <8 x double> %37, %60
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %56, %68
  %70 = bitcast <8 x double> %49 to <8 x i64>
  %71 = and <8 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <8 x i64> %71 to <8 x double>
  %73 = fsub <8 x double> %49, %72
  %74 = fmul <8 x double> %56, %49
  %75 = fmul <8 x double> %59, %72
  %76 = bitcast <8 x double> %74 to <8 x i64>
  %77 = xor <8 x i64> %76, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fmul <8 x double> %73, %59
  %80 = fmul <8 x double> %60, %72
  %81 = fmul <8 x double> %60, %73
  %82 = fmul <8 x double> %49, %69
  %83 = fmul <8 x double> %56, %55
  %84 = fadd <8 x double> %75, %78
  %85 = fadd <8 x double> %79, %84
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %87, %82
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %74, %89
  %91 = fmul <8 x double> %14, %90
  %92 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %93 = bitcast i8 %92 to <8 x i1>
  %94 = select <8 x i1> %93, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %91
  %95 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %96 = bitcast i8 %95 to <8 x i1>
  %97 = select <8 x i1> %96, <8 x double> %13, <8 x double> %94
  ret <8 x double> %97
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_hypotd8_u05avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %12 = fmul <8 x double> %9, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = bitcast i8 %11 to <8 x i1>
  %14 = select <8 x i1> %13, <8 x double> %12, <8 x double> %9
  %15 = fmul <8 x double> %10, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %16 = select <8 x i1> %13, <8 x double> %15, <8 x double> %10
  %17 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = bitcast <8 x double> %16 to <8 x i64>
  %19 = and <8 x i64> %18, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %20 = bitcast <8 x i64> %19 to <8 x double>
  %21 = fsub <8 x double> %16, %20
  %22 = bitcast <8 x double> %17 to <8 x i64>
  %23 = and <8 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %24 = bitcast <8 x i64> %23 to <8 x double>
  %25 = fsub <8 x double> %17, %24
  %26 = bitcast <8 x double> %14 to <8 x i64>
  %27 = and <8 x i64> %26, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = fsub <8 x double> %14, %28
  %30 = fmul <8 x double> %14, %17
  %31 = fmul <8 x double> %28, %24
  %32 = fsub <8 x double> %31, %30
  %33 = fmul <8 x double> %25, %28
  %34 = fmul <8 x double> %29, %24
  %35 = fmul <8 x double> %29, %25
  %36 = fmul <8 x double> %20, %24
  %37 = fmul <8 x double> %25, %20
  %38 = fmul <8 x double> %21, %24
  %39 = fmul <8 x double> %21, %25
  %40 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %36
  %41 = fsub <8 x double> %40, %37
  %42 = fsub <8 x double> %41, %38
  %43 = fsub <8 x double> %42, %39
  %44 = fmul <8 x double> %30, %43
  %45 = fadd <8 x double> %32, %33
  %46 = fadd <8 x double> %34, %45
  %47 = fadd <8 x double> %35, %46
  %48 = fadd <8 x double> %47, %44
  %49 = fmul <8 x double> %30, zeroinitializer
  %50 = fsub <8 x double> zeroinitializer, %49
  %51 = fmul <8 x double> %17, %50
  %52 = fadd <8 x double> %51, %48
  %53 = bitcast <8 x double> %30 to <8 x i64>
  %54 = and <8 x i64> %53, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %55 = bitcast <8 x i64> %54 to <8 x double>
  %56 = fsub <8 x double> %30, %55
  %57 = fmul <8 x double> %30, %30
  %58 = fmul <8 x double> %55, %55
  %59 = bitcast <8 x double> %57 to <8 x i64>
  %60 = xor <8 x i64> %59, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %61 = bitcast <8 x i64> %60 to <8 x double>
  %62 = fadd <8 x double> %55, %55
  %63 = fmul <8 x double> %62, %56
  %64 = fmul <8 x double> %56, %56
  %65 = fadd <8 x double> %52, %52
  %66 = fmul <8 x double> %30, %65
  %67 = fadd <8 x double> %58, %61
  %68 = fadd <8 x double> %67, %63
  %69 = fadd <8 x double> %64, %68
  %70 = fadd <8 x double> %69, %66
  %71 = fadd <8 x double> %57, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %72 = fsub <8 x double> %71, %57
  %73 = fsub <8 x double> %71, %72
  %74 = fsub <8 x double> %57, %73
  %75 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %72
  %76 = fadd <8 x double> %75, %74
  %77 = fadd <8 x double> %76, %70
  %78 = fadd <8 x double> %71, %77
  %79 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %78, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %80 = bitcast <8 x double> %79 to <8 x i64>
  %81 = and <8 x i64> %80, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %82 = bitcast <8 x i64> %81 to <8 x double>
  %83 = fsub <8 x double> %79, %82
  %84 = fmul <8 x double> %79, %79
  %85 = fmul <8 x double> %82, %82
  %86 = bitcast <8 x double> %84 to <8 x i64>
  %87 = xor <8 x i64> %86, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %88 = bitcast <8 x i64> %87 to <8 x double>
  %89 = fmul <8 x double> %83, %82
  %90 = fmul <8 x double> %83, %83
  %91 = fadd <8 x double> %85, %88
  %92 = fadd <8 x double> %89, %91
  %93 = fadd <8 x double> %89, %92
  %94 = fadd <8 x double> %90, %93
  %95 = fadd <8 x double> %84, %71
  %96 = fsub <8 x double> %95, %71
  %97 = fsub <8 x double> %95, %96
  %98 = fsub <8 x double> %71, %97
  %99 = fsub <8 x double> %84, %96
  %100 = fadd <8 x double> %99, %98
  %101 = fadd <8 x double> %94, %77
  %102 = fadd <8 x double> %100, %101
  %103 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %79
  %104 = bitcast <8 x double> %103 to <8 x i64>
  %105 = and <8 x i64> %104, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %106 = bitcast <8 x i64> %105 to <8 x double>
  %107 = fsub <8 x double> %103, %106
  %108 = fmul <8 x double> %82, %106
  %109 = fmul <8 x double> %107, %82
  %110 = fmul <8 x double> %83, %106
  %111 = fmul <8 x double> %83, %107
  %112 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %108
  %113 = fsub <8 x double> %112, %109
  %114 = fsub <8 x double> %113, %110
  %115 = fsub <8 x double> %114, %111
  %116 = fmul <8 x double> %103, %115
  %117 = bitcast <8 x double> %95 to <8 x i64>
  %118 = and <8 x i64> %117, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %119 = bitcast <8 x i64> %118 to <8 x double>
  %120 = fsub <8 x double> %95, %119
  %121 = fmul <8 x double> %103, %95
  %122 = fmul <8 x double> %106, %119
  %123 = bitcast <8 x double> %121 to <8 x i64>
  %124 = xor <8 x i64> %123, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %125 = bitcast <8 x i64> %124 to <8 x double>
  %126 = fmul <8 x double> %120, %106
  %127 = fmul <8 x double> %107, %119
  %128 = fmul <8 x double> %107, %120
  %129 = fmul <8 x double> %95, %116
  %130 = fmul <8 x double> %103, %102
  %131 = fadd <8 x double> %122, %125
  %132 = fadd <8 x double> %126, %131
  %133 = fadd <8 x double> %127, %132
  %134 = fadd <8 x double> %128, %133
  %135 = fadd <8 x double> %129, %134
  %136 = fadd <8 x double> %135, %130
  %137 = fmul <8 x double> %121, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %138 = fmul <8 x double> %136, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %139 = bitcast <8 x double> %137 to <8 x i64>
  %140 = and <8 x i64> %139, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %141 = bitcast <8 x i64> %140 to <8 x double>
  %142 = fsub <8 x double> %137, %141
  %143 = bitcast <8 x double> %10 to <8 x i64>
  %144 = and <8 x i64> %143, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = fsub <8 x double> %10, %145
  %147 = fmul <8 x double> %10, %137
  %148 = fmul <8 x double> %145, %141
  %149 = bitcast <8 x double> %147 to <8 x i64>
  %150 = xor <8 x i64> %149, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %151 = bitcast <8 x i64> %150 to <8 x double>
  %152 = fmul <8 x double> %142, %145
  %153 = fmul <8 x double> %146, %141
  %154 = fmul <8 x double> %146, %142
  %155 = fmul <8 x double> %10, %138
  %156 = fadd <8 x double> %148, %151
  %157 = fadd <8 x double> %152, %156
  %158 = fadd <8 x double> %153, %157
  %159 = fadd <8 x double> %154, %158
  %160 = fadd <8 x double> %159, %155
  %161 = fadd <8 x double> %147, %160
  %162 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %161, <8 x double> %161, i32 4, i8 -1, i32 4) #7
  %163 = bitcast i8 %162 to <8 x i1>
  %164 = select <8 x i1> %163, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %161
  %165 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %166 = bitcast i8 %165 to <8 x i1>
  %167 = select <8 x i1> %166, <8 x double> %10, <8 x double> %164
  %168 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> %5, i32 4, i8 -1, i32 4) #7
  %169 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %170 = or i8 %169, %168
  %171 = bitcast i8 %170 to <8 x i1>
  %172 = select <8 x i1> %171, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %167
  %173 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %174 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %175 = or i8 %174, %173
  %176 = bitcast i8 %175 to <8 x i1>
  %177 = select <8 x i1> %176, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %172
  ret <8 x double> %177
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_hypotd8_u35avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %11 = fdiv <8 x double> %9, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fadd <8 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %15 = fmul <8 x double> %10, %14
  %16 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %17 = bitcast i8 %16 to <8 x i1>
  %18 = select <8 x i1> %17, <8 x double> %10, <8 x double> %15
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> %5, i32 4, i8 -1, i32 4) #7
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %21 = or i8 %20, %19
  %22 = bitcast i8 %21 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %18
  %24 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %25 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %26 = or i8 %25, %24
  %27 = bitcast i8 %26 to <8 x i1>
  %28 = select <8 x i1> %27, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %23
  ret <8 x double> %28
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_fmodd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %5
  %13 = fmul <8 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %8
  %15 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %16 = bitcast <8 x double> %15 to <8 x i64>
  %17 = add <8 x i64> %16, <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1>
  %18 = bitcast <8 x i64> %17 to <8 x double>
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %15, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %20 = bitcast i8 %19 to <8 x i1>
  %21 = select <8 x i1> %20, <8 x double> zeroinitializer, <8 x double> %18
  %22 = fmul <8 x double> %14, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %23 = fadd <8 x double> %14, %14
  %24 = bitcast <8 x double> %14 to <8 x i64>
  %25 = xor <8 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = fsub <8 x double> %26, %28
  br label %30

; <label>:30:                                     ; preds = %30, %2
  %31 = phi i32 [ 0, %2 ], [ %83, %30 ]
  %32 = phi <8 x double> [ zeroinitializer, %2 ], [ %80, %30 ]
  %33 = phi <8 x double> [ %12, %2 ], [ %78, %30 ]
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = add <8 x i64> %34, <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %33, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %38 = bitcast i8 %37 to <8 x i1>
  %39 = select <8 x i1> %38, <8 x double> zeroinitializer, <8 x double> %36
  %40 = fmul <8 x double> %21, %39
  %41 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %40, i32 11, <8 x double> %40, i8 -1, i32 4) #7
  %42 = bitcast <8 x double> %41 to <8 x i64>
  %43 = and <8 x i64> %42, <i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2>
  %44 = bitcast <8 x i64> %43 to <8 x double>
  %45 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %22, <8 x double> %33, i32 30, i8 -1, i32 4) #7
  %46 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %33, <8 x double> %14, i32 29, i8 -1, i32 4) #7
  %47 = and i8 %46, %45
  %48 = bitcast i8 %47 to <8 x i1>
  %49 = select <8 x i1> %48, <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, <8 x double> %44
  %50 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> %33, i32 30, i8 -1, i32 4) #7
  %51 = and i8 %50, %46
  %52 = bitcast i8 %51 to <8 x i1>
  %53 = select <8 x i1> %52, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %49
  %54 = bitcast <8 x double> %53 to <8 x i64>
  %55 = and <8 x i64> %54, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %56 = bitcast <8 x i64> %55 to <8 x double>
  %57 = fsub <8 x double> %53, %56
  %58 = fmul <8 x double> %53, %26
  %59 = fmul <8 x double> %28, %56
  %60 = bitcast <8 x double> %58 to <8 x i64>
  %61 = xor <8 x i64> %60, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = fmul <8 x double> %57, %28
  %64 = fmul <8 x double> %29, %56
  %65 = fmul <8 x double> %29, %57
  %66 = fadd <8 x double> %59, %62
  %67 = fadd <8 x double> %63, %66
  %68 = fadd <8 x double> %64, %67
  %69 = fadd <8 x double> %65, %68
  %70 = fadd <8 x double> %33, %58
  %71 = fsub <8 x double> %70, %33
  %72 = fsub <8 x double> %70, %71
  %73 = fsub <8 x double> %33, %72
  %74 = fsub <8 x double> %58, %71
  %75 = fadd <8 x double> %74, %73
  %76 = fadd <8 x double> %32, %69
  %77 = fadd <8 x double> %75, %76
  %78 = fadd <8 x double> %70, %77
  %79 = fsub <8 x double> %70, %78
  %80 = fadd <8 x double> %77, %79
  %81 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %78, <8 x double> %14, i32 17, i8 -1, i32 4) #7
  %82 = icmp ne i8 %81, -1
  %83 = add nuw nsw i32 %31, 1
  %84 = icmp ult i32 %83, 21
  %85 = and i1 %82, %84
  br i1 %85, label %30, label %86

; <label>:86:                                     ; preds = %30
  %87 = select <8 x i1> %11, <8 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %88 = fmul <8 x double> %87, %78
  %89 = fadd <8 x double> %78, %80
  %90 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %89, <8 x double> %14, i32 0, i8 -1, i32 4) #7
  %91 = bitcast i8 %90 to <8 x i1>
  %92 = bitcast <8 x double> %88 to <8 x i64>
  %93 = select <8 x i1> %91, <8 x i64> zeroinitializer, <8 x i64> %92
  %94 = and <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %95 = xor <8 x i64> %93, %94
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %12, <8 x double> %14, i32 17, i8 -1, i32 4) #7
  %98 = bitcast i8 %97 to <8 x i1>
  %99 = select <8 x i1> %98, <8 x double> %0, <8 x double> %96
  %100 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %14, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %101 = bitcast i8 %100 to <8 x i1>
  %102 = select <8 x i1> %101, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %99
  ret <8 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_remainderd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %5
  %13 = fmul <8 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %8
  %15 = select <8 x i1> %11, <8 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %16 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> zeroinitializer, <8 x double> zeroinitializer, i32 4, i8 -1, i32 4) #7
  %18 = zext i8 %17 to i16
  %19 = fmul <8 x double> %14, <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>
  %20 = fmul <8 x double> %14, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = xor <8 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = and <8 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = fsub <8 x double> %23, %25
  br label %27

; <label>:27:                                     ; preds = %2, %57
  %28 = phi i32 [ 0, %2 ], [ %101, %57 ]
  %29 = phi i16 [ %18, %2 ], [ %73, %57 ]
  %30 = phi <8 x double> [ zeroinitializer, %2 ], [ %100, %57 ]
  %31 = phi <8 x double> [ %12, %2 ], [ %98, %57 ]
  %32 = fmul <8 x double> %16, %31
  %33 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %32, i32 8, <8 x double> %32, i8 -1, i32 4) #7
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = bitcast <8 x double> %31 to <8 x i64>
  %38 = and <8 x i64> %37, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %39 = bitcast <8 x i64> %38 to <8 x double>
  %40 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %19, i32 17, i8 -1, i32 4) #7
  %41 = bitcast i8 %40 to <8 x i1>
  %42 = select <8 x i1> %41, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %36
  %43 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %20, i32 17, i8 -1, i32 4) #7
  %44 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %20, i32 0, i8 -1, i32 4) #7
  %45 = zext i8 %44 to i16
  %46 = bitcast i16 %29 to <16 x i1>
  %47 = bitcast i16 %45 to <16 x i1>
  %48 = xor <16 x i1> %46, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %49 = and <16 x i1> %48, %47
  %50 = bitcast <16 x i1> %49 to <2 x i8>
  %51 = extractelement <2 x i8> %50, i32 0
  %52 = or i8 %51, %43
  %53 = bitcast i8 %52 to <8 x i1>
  %54 = select <8 x i1> %53, <8 x double> zeroinitializer, <8 x double> %42
  %55 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %54, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %56 = icmp eq i8 %55, -1
  br i1 %56, label %103, label %57

; <label>:57:                                     ; preds = %27
  %58 = fmul <8 x double> %54, %23
  %59 = bitcast <8 x double> %58 to <8 x i64>
  %60 = and <8 x i64> %59, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %61 = bitcast <8 x i64> %60 to <8 x double>
  %62 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %61, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %63 = and <8 x i64> %37, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %64 = xor <8 x i64> %63, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %65 = bitcast <8 x i64> %64 to <8 x double>
  %66 = fadd <8 x double> %54, %65
  %67 = bitcast i8 %62 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x double> %66, <8 x double> %54
  %69 = fmul <8 x double> %68, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %70 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %69, i32 11, <8 x double> %69, i8 -1, i32 4) #7
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %70, <8 x double> %69, i32 4, i8 -1, i32 4) #7
  %72 = zext i8 %71 to i16
  %73 = xor i16 %29, %72
  %74 = bitcast <8 x double> %68 to <8 x i64>
  %75 = and <8 x i64> %74, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %76 = bitcast <8 x i64> %75 to <8 x double>
  %77 = fsub <8 x double> %68, %76
  %78 = fmul <8 x double> %68, %23
  %79 = fmul <8 x double> %25, %76
  %80 = bitcast <8 x double> %78 to <8 x i64>
  %81 = xor <8 x i64> %80, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %82 = bitcast <8 x i64> %81 to <8 x double>
  %83 = fmul <8 x double> %77, %25
  %84 = fmul <8 x double> %26, %76
  %85 = fmul <8 x double> %26, %77
  %86 = fadd <8 x double> %79, %82
  %87 = fadd <8 x double> %83, %86
  %88 = fadd <8 x double> %84, %87
  %89 = fadd <8 x double> %85, %88
  %90 = fadd <8 x double> %31, %78
  %91 = fsub <8 x double> %90, %31
  %92 = fsub <8 x double> %90, %91
  %93 = fsub <8 x double> %31, %92
  %94 = fsub <8 x double> %78, %91
  %95 = fadd <8 x double> %94, %93
  %96 = fadd <8 x double> %30, %89
  %97 = fadd <8 x double> %95, %96
  %98 = fadd <8 x double> %90, %97
  %99 = fsub <8 x double> %90, %98
  %100 = fadd <8 x double> %97, %99
  %101 = add nuw nsw i32 %28, 1
  %102 = icmp ult i32 %101, 21
  br i1 %102, label %27, label %103

; <label>:103:                                    ; preds = %27, %57
  %104 = phi <8 x double> [ %31, %27 ], [ %98, %57 ]
  %105 = fmul <8 x double> %15, %104
  %106 = bitcast <8 x double> %105 to <8 x i64>
  %107 = and <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %108 = xor <8 x i64> %107, %106
  %109 = bitcast <8 x i64> %108 to <8 x double>
  %110 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %111 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %112 = bitcast i8 %111 to <8 x i1>
  %113 = select <8 x i1> %112, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %114 = bitcast i8 %110 to <8 x i1>
  %115 = select <8 x i1> %114, <8 x double> %113, <8 x double> %109
  %116 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %14, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %117 = bitcast i8 %116 to <8 x i1>
  %118 = select <8 x i1> %117, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %115
  ret <8 x double> %118
}

; Function Attrs: nounwind uwtable
define <8 x double> @Sleef_tgammad8_u10avx512fnofma(<8 x double>) local_unnamed_addr #3 {
  %2 = alloca %struct.dd2, align 64
  %3 = bitcast %struct.dd2* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %3) #7
  call fastcc void @gammak(%struct.dd2* noalias nonnull %2, <8 x double> %0)
  %4 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 0
  %5 = load <8 x double>, <8 x double>* %4, align 64
  %6 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 1
  %7 = load <8 x double>, <8 x double>* %6, align 64
  %8 = fadd <8 x double> %5, %7
  %9 = fmul <8 x double> %8, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %9, i32 8, <8 x double> %9, i8 -1, i32 4) #7
  %11 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %10, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %12 = fmul <8 x double> %10, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %13 = fadd <8 x double> %5, %12
  %14 = fsub <8 x double> %13, %5
  %15 = fsub <8 x double> %13, %14
  %16 = fsub <8 x double> %5, %15
  %17 = fsub <8 x double> %12, %14
  %18 = fadd <8 x double> %17, %16
  %19 = fadd <8 x double> %7, %18
  %20 = fmul <8 x double> %10, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %21 = fadd <8 x double> %20, %13
  %22 = fsub <8 x double> %21, %13
  %23 = fsub <8 x double> %21, %22
  %24 = fsub <8 x double> %13, %23
  %25 = fsub <8 x double> %20, %22
  %26 = fadd <8 x double> %25, %24
  %27 = fadd <8 x double> %26, %19
  %28 = bitcast <8 x double> %21 to <8 x i64>
  %29 = and <8 x i64> %28, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %30 = bitcast <8 x i64> %29 to <8 x double>
  %31 = fsub <8 x double> %21, %30
  %32 = fmul <8 x double> %21, %21
  %33 = fmul <8 x double> %30, %30
  %34 = bitcast <8 x double> %32 to <8 x i64>
  %35 = xor <8 x i64> %34, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fadd <8 x double> %30, %30
  %38 = fmul <8 x double> %37, %31
  %39 = fmul <8 x double> %31, %31
  %40 = fadd <8 x double> %27, %27
  %41 = fmul <8 x double> %21, %40
  %42 = fadd <8 x double> %33, %36
  %43 = fadd <8 x double> %42, %38
  %44 = fadd <8 x double> %39, %43
  %45 = fadd <8 x double> %41, %44
  %46 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %47 = bitcast <8 x i64> %46 to <8 x double>
  %48 = fsub <8 x double> %32, %47
  %49 = fmul <8 x double> %32, %32
  %50 = fmul <8 x double> %47, %47
  %51 = bitcast <8 x double> %49 to <8 x i64>
  %52 = xor <8 x i64> %51, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %53 = bitcast <8 x i64> %52 to <8 x double>
  %54 = fadd <8 x double> %47, %47
  %55 = fmul <8 x double> %54, %48
  %56 = fmul <8 x double> %48, %48
  %57 = fadd <8 x double> %45, %45
  %58 = fmul <8 x double> %32, %57
  %59 = fadd <8 x double> %50, %53
  %60 = fadd <8 x double> %59, %55
  %61 = fadd <8 x double> %56, %60
  %62 = fadd <8 x double> %61, %58
  %63 = fmul <8 x double> %49, %49
  %64 = fmul <8 x double> %21, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %65 = fadd <8 x double> %64, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %66 = fmul <8 x double> %21, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %67 = fadd <8 x double> %66, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %68 = fmul <8 x double> %21, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %69 = fadd <8 x double> %68, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %70 = fmul <8 x double> %32, %67
  %71 = fadd <8 x double> %69, %70
  %72 = fmul <8 x double> %21, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %73 = fadd <8 x double> %72, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %74 = fmul <8 x double> %21, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %75 = fadd <8 x double> %74, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %76 = fmul <8 x double> %32, %73
  %77 = fadd <8 x double> %75, %76
  %78 = fmul <8 x double> %49, %71
  %79 = fadd <8 x double> %77, %78
  %80 = fmul <8 x double> %65, %63
  %81 = fadd <8 x double> %80, %79
  %82 = fmul <8 x double> %21, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %83 = fmul <8 x double> %30, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %84 = bitcast <8 x double> %82 to <8 x i64>
  %85 = xor <8 x i64> %84, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %86 = bitcast <8 x i64> %85 to <8 x double>
  %87 = fmul <8 x double> %31, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %88 = fmul <8 x double> %30, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %89 = fmul <8 x double> %31, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %90 = fmul <8 x double> %27, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %91 = fadd <8 x double> %83, %86
  %92 = fadd <8 x double> %87, %91
  %93 = fadd <8 x double> %88, %92
  %94 = fadd <8 x double> %89, %93
  %95 = fadd <8 x double> %90, %94
  %96 = fadd <8 x double> %82, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %97 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %96
  %98 = fadd <8 x double> %82, %97
  %99 = fadd <8 x double> %98, %95
  %100 = bitcast <8 x double> %96 to <8 x i64>
  %101 = and <8 x i64> %100, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %102 = bitcast <8 x i64> %101 to <8 x double>
  %103 = fsub <8 x double> %96, %102
  %104 = fmul <8 x double> %21, %96
  %105 = fmul <8 x double> %30, %102
  %106 = bitcast <8 x double> %104 to <8 x i64>
  %107 = xor <8 x i64> %106, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %108 = bitcast <8 x i64> %107 to <8 x double>
  %109 = fmul <8 x double> %103, %30
  %110 = fmul <8 x double> %31, %102
  %111 = fmul <8 x double> %31, %103
  %112 = fmul <8 x double> %96, %27
  %113 = fmul <8 x double> %21, %99
  %114 = fadd <8 x double> %105, %108
  %115 = fadd <8 x double> %109, %114
  %116 = fadd <8 x double> %110, %115
  %117 = fadd <8 x double> %111, %116
  %118 = fadd <8 x double> %112, %117
  %119 = fadd <8 x double> %113, %118
  %120 = fadd <8 x double> %104, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %121 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %120
  %122 = fadd <8 x double> %104, %121
  %123 = fadd <8 x double> %122, %119
  %124 = bitcast <8 x double> %120 to <8 x i64>
  %125 = and <8 x i64> %124, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %126 = bitcast <8 x i64> %125 to <8 x double>
  %127 = fsub <8 x double> %120, %126
  %128 = fmul <8 x double> %21, %120
  %129 = fmul <8 x double> %30, %126
  %130 = bitcast <8 x double> %128 to <8 x i64>
  %131 = xor <8 x i64> %130, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %132 = bitcast <8 x i64> %131 to <8 x double>
  %133 = fmul <8 x double> %127, %30
  %134 = fmul <8 x double> %31, %126
  %135 = fmul <8 x double> %31, %127
  %136 = fmul <8 x double> %120, %27
  %137 = fmul <8 x double> %21, %123
  %138 = fadd <8 x double> %129, %132
  %139 = fadd <8 x double> %133, %138
  %140 = fadd <8 x double> %134, %139
  %141 = fadd <8 x double> %135, %140
  %142 = fadd <8 x double> %136, %141
  %143 = fadd <8 x double> %142, %137
  %144 = fadd <8 x double> %128, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %145 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %144
  %146 = fadd <8 x double> %128, %145
  %147 = fadd <8 x double> %146, %143
  %148 = and <8 x i64> %51, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %149 = bitcast <8 x i64> %148 to <8 x double>
  %150 = fsub <8 x double> %49, %149
  %151 = bitcast <8 x double> %81 to <8 x i64>
  %152 = and <8 x i64> %151, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %153 = bitcast <8 x i64> %152 to <8 x double>
  %154 = fsub <8 x double> %81, %153
  %155 = fmul <8 x double> %49, %81
  %156 = fmul <8 x double> %149, %153
  %157 = bitcast <8 x double> %155 to <8 x i64>
  %158 = xor <8 x i64> %157, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %159 = bitcast <8 x i64> %158 to <8 x double>
  %160 = fmul <8 x double> %150, %153
  %161 = fmul <8 x double> %154, %149
  %162 = fmul <8 x double> %150, %154
  %163 = fmul <8 x double> %81, %62
  %164 = fadd <8 x double> %156, %159
  %165 = fadd <8 x double> %160, %164
  %166 = fadd <8 x double> %161, %165
  %167 = fadd <8 x double> %162, %166
  %168 = fadd <8 x double> %163, %167
  %169 = fadd <8 x double> %144, %155
  %170 = fsub <8 x double> %144, %169
  %171 = fadd <8 x double> %155, %170
  %172 = fadd <8 x double> %171, %147
  %173 = fadd <8 x double> %168, %172
  %174 = ashr <8 x i32> %11, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %175 = add nsw <8 x i32> %174, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %176 = bitcast <8 x i32> %175 to <4 x i64>
  %177 = shufflevector <4 x i64> %176, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %178 = bitcast <8 x i64> %177 to <16 x i32>
  %179 = shufflevector <16 x i32> %178, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %180 = shufflevector <16 x i32> %179, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %181 = shl <16 x i32> %180, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %182 = bitcast <16 x i32> %181 to <8 x double>
  %183 = fmul <8 x double> %169, %182
  %184 = add <8 x i32> %11, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %185 = sub <8 x i32> %184, %174
  %186 = bitcast <8 x i32> %185 to <4 x i64>
  %187 = shufflevector <4 x i64> %186, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %188 = bitcast <8 x i64> %187 to <16 x i32>
  %189 = shufflevector <16 x i32> %188, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %190 = shufflevector <16 x i32> %189, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %191 = shl <16 x i32> %190, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %192 = bitcast <16 x i32> %191 to <8 x double>
  %193 = fmul <8 x double> %183, %192
  %194 = fmul <8 x double> %173, %182
  %195 = fmul <8 x double> %194, %192
  %196 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %197 = bitcast i8 %196 to <8 x i1>
  %198 = select <8 x i1> %197, <8 x double> zeroinitializer, <8 x double> %193
  %199 = select <8 x i1> %197, <8 x double> zeroinitializer, <8 x double> %195
  %200 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 0
  %201 = load <8 x double>, <8 x double>* %200, align 64
  %202 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 1
  %203 = load <8 x double>, <8 x double>* %202, align 64
  %204 = bitcast <8 x double> %198 to <8 x i64>
  %205 = and <8 x i64> %204, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %206 = bitcast <8 x i64> %205 to <8 x double>
  %207 = fsub <8 x double> %198, %206
  %208 = bitcast <8 x double> %201 to <8 x i64>
  %209 = and <8 x i64> %208, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %210 = bitcast <8 x i64> %209 to <8 x double>
  %211 = fsub <8 x double> %201, %210
  %212 = fmul <8 x double> %201, %198
  %213 = fmul <8 x double> %210, %206
  %214 = bitcast <8 x double> %212 to <8 x i64>
  %215 = xor <8 x i64> %214, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %216 = bitcast <8 x i64> %215 to <8 x double>
  %217 = fmul <8 x double> %207, %210
  %218 = fmul <8 x double> %211, %206
  %219 = fmul <8 x double> %211, %207
  %220 = fmul <8 x double> %203, %198
  %221 = fmul <8 x double> %201, %199
  %222 = fadd <8 x double> %213, %216
  %223 = fadd <8 x double> %217, %222
  %224 = fadd <8 x double> %218, %223
  %225 = fadd <8 x double> %219, %224
  %226 = fadd <8 x double> %220, %225
  %227 = fadd <8 x double> %226, %221
  %228 = fadd <8 x double> %212, %227
  %229 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, i32 0, i8 -1, i32 4) #7
  %230 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %231 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 11, <8 x double> %0, i8 -1, i32 4) #7
  %232 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %231, <8 x double> %0, i32 0, i8 -1, i32 4) #7
  %233 = and i8 %232, %230
  %234 = or i8 %233, %229
  %235 = bitcast <8 x double> %0 to <8 x i64>
  %236 = and <8 x i64> %235, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %237 = bitcast <8 x i64> %236 to <8 x double>
  %238 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %237, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %239 = zext i8 %238 to i16
  %240 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 0, i8 -1, i32 4) #7
  %241 = zext i8 %240 to i16
  %242 = bitcast i16 %239 to <16 x i1>
  %243 = bitcast i16 %241 to <16 x i1>
  %244 = xor <16 x i1> %242, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %245 = and <16 x i1> %244, %243
  %246 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %228, <8 x double> %228, i32 4, i8 -1, i32 4) #7
  %247 = bitcast <16 x i1> %245 to <2 x i8>
  %248 = extractelement <2 x i8> %247, i32 0
  %249 = and i8 %246, %230
  %250 = and i8 %249, %248
  %251 = or i8 %234, %250
  %252 = bitcast i8 %251 to <8 x i1>
  %253 = select <8 x i1> %252, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %228
  %254 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %255 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000, double 0x8010000000000000>, i32 29, i8 -1, i32 4) #7
  %256 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %257 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02, double 2.000000e+02>, i32 30, i8 -1, i32 4) #7
  %258 = or i8 %257, %256
  %259 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %253, <8 x double> %253, i32 4, i8 -1, i32 4) #7
  %260 = or i8 %258, %259
  %261 = and <8 x i64> %235, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %262 = or <8 x i64> %261, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %263 = bitcast <8 x i64> %262 to <8 x double>
  %264 = or i8 %254, %248
  %265 = and i8 %264, %255
  %266 = and i8 %265, %260
  %267 = bitcast i8 %266 to <8 x i1>
  %268 = select <8 x i1> %267, <8 x double> %263, <8 x double> %253
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %3) #7
  ret <8 x double> %268
}

; Function Attrs: nounwind uwtable
define internal fastcc void @gammak(%struct.dd2* noalias nocapture, <8 x double>) unnamed_addr #3 {
  %3 = bitcast <8 x double> %1 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306, double 1.000000e-306>, i32 17, i8 -1, i32 4) #7
  %7 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, i32 17, i8 -1, i32 4) #7
  %8 = xor <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %9 = bitcast <8 x i64> %8 to <8 x double>
  %10 = fadd <8 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %11 = fadd <8 x double> %10, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %12 = fsub <8 x double> %10, %11
  %13 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %12
  %14 = fsub <8 x double> %9, %11
  %15 = fadd <8 x double> %14, %13
  %16 = bitcast i8 %7 to <8 x i1>
  %17 = select <8 x i1> %16, <8 x double> %10, <8 x double> %1
  %18 = select <8 x i1> %16, <8 x double> %15, <8 x double> zeroinitializer
  %19 = bitcast i8 %6 to <8 x i1>
  %20 = select <8 x i1> %19, <8 x double> zeroinitializer, <8 x double> %17
  %21 = select <8 x i1> %19, <8 x double> zeroinitializer, <8 x double> %18
  %22 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, <8 x double> %20, i32 18, i8 -1, i32 4) #7
  %23 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %20, <8 x double> <double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00, double 1.100000e+00>, i32 18, i8 -1, i32 4) #7
  %24 = and i8 %23, %22
  %25 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> <double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00, double 2.300000e+00>, <8 x double> %20, i32 18, i8 -1, i32 4) #7
  %26 = fadd <8 x double> %20, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %27 = fsub <8 x double> %26, %20
  %28 = fsub <8 x double> %26, %27
  %29 = fsub <8 x double> %20, %28
  %30 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %27
  %31 = fadd <8 x double> %30, %29
  %32 = fadd <8 x double> %21, %31
  %33 = bitcast <8 x double> %26 to <8 x i64>
  %34 = and <8 x i64> %33, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %35 = bitcast <8 x i64> %34 to <8 x double>
  %36 = fsub <8 x double> %26, %35
  %37 = bitcast <8 x double> %20 to <8 x i64>
  %38 = and <8 x i64> %37, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %39 = bitcast <8 x i64> %38 to <8 x double>
  %40 = fsub <8 x double> %20, %39
  %41 = fmul <8 x double> %20, %26
  %42 = fmul <8 x double> %39, %35
  %43 = bitcast <8 x double> %41 to <8 x i64>
  %44 = xor <8 x i64> %43, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %45 = bitcast <8 x i64> %44 to <8 x double>
  %46 = fmul <8 x double> %36, %39
  %47 = fmul <8 x double> %40, %35
  %48 = fmul <8 x double> %40, %36
  %49 = fmul <8 x double> %21, %26
  %50 = fmul <8 x double> %20, %32
  %51 = fadd <8 x double> %42, %45
  %52 = fadd <8 x double> %46, %51
  %53 = fadd <8 x double> %47, %52
  %54 = fadd <8 x double> %48, %53
  %55 = fadd <8 x double> %49, %54
  %56 = fadd <8 x double> %50, %55
  %57 = fadd <8 x double> %41, %56
  %58 = fsub <8 x double> %41, %57
  %59 = fadd <8 x double> %56, %58
  %60 = fadd <8 x double> %20, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %61 = fsub <8 x double> %60, %20
  %62 = fsub <8 x double> %60, %61
  %63 = fsub <8 x double> %20, %62
  %64 = fsub <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %61
  %65 = fadd <8 x double> %64, %63
  %66 = fadd <8 x double> %21, %65
  %67 = bitcast <8 x double> %60 to <8 x i64>
  %68 = and <8 x i64> %67, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %69 = bitcast <8 x i64> %68 to <8 x double>
  %70 = fsub <8 x double> %60, %69
  %71 = bitcast <8 x double> %57 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %57, %73
  %75 = fmul <8 x double> %60, %57
  %76 = fmul <8 x double> %69, %73
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %70, %73
  %81 = fmul <8 x double> %74, %69
  %82 = fmul <8 x double> %70, %74
  %83 = fmul <8 x double> %60, %59
  %84 = fmul <8 x double> %66, %57
  %85 = fadd <8 x double> %76, %79
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %82, %87
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %84, %89
  %91 = fadd <8 x double> %75, %90
  %92 = fsub <8 x double> %75, %91
  %93 = fadd <8 x double> %90, %92
  %94 = fadd <8 x double> %20, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %95 = fsub <8 x double> %94, %20
  %96 = fsub <8 x double> %94, %95
  %97 = fsub <8 x double> %20, %96
  %98 = fsub <8 x double> <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>, %95
  %99 = fadd <8 x double> %98, %97
  %100 = fadd <8 x double> %21, %99
  %101 = bitcast <8 x double> %94 to <8 x i64>
  %102 = and <8 x i64> %101, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %103 = bitcast <8 x i64> %102 to <8 x double>
  %104 = fsub <8 x double> %94, %103
  %105 = bitcast <8 x double> %91 to <8 x i64>
  %106 = and <8 x i64> %105, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %107 = bitcast <8 x i64> %106 to <8 x double>
  %108 = fsub <8 x double> %91, %107
  %109 = fmul <8 x double> %94, %91
  %110 = fmul <8 x double> %103, %107
  %111 = bitcast <8 x double> %109 to <8 x i64>
  %112 = xor <8 x i64> %111, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %113 = bitcast <8 x i64> %112 to <8 x double>
  %114 = fmul <8 x double> %104, %107
  %115 = fmul <8 x double> %108, %103
  %116 = fmul <8 x double> %104, %108
  %117 = fmul <8 x double> %94, %93
  %118 = fmul <8 x double> %100, %91
  %119 = fadd <8 x double> %110, %113
  %120 = fadd <8 x double> %114, %119
  %121 = fadd <8 x double> %115, %120
  %122 = fadd <8 x double> %116, %121
  %123 = fadd <8 x double> %117, %122
  %124 = fadd <8 x double> %118, %123
  %125 = fadd <8 x double> %109, %124
  %126 = fsub <8 x double> %109, %125
  %127 = fadd <8 x double> %124, %126
  %128 = fadd <8 x double> %20, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %129 = fsub <8 x double> %128, %20
  %130 = fsub <8 x double> %128, %129
  %131 = fsub <8 x double> %20, %130
  %132 = fsub <8 x double> <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>, %129
  %133 = fadd <8 x double> %132, %131
  %134 = fadd <8 x double> %21, %133
  %135 = bitcast <8 x double> %128 to <8 x i64>
  %136 = and <8 x i64> %135, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %137 = bitcast <8 x i64> %136 to <8 x double>
  %138 = fsub <8 x double> %128, %137
  %139 = bitcast <8 x double> %125 to <8 x i64>
  %140 = and <8 x i64> %139, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %141 = bitcast <8 x i64> %140 to <8 x double>
  %142 = fsub <8 x double> %125, %141
  %143 = fmul <8 x double> %128, %125
  %144 = fmul <8 x double> %137, %141
  %145 = bitcast <8 x double> %143 to <8 x i64>
  %146 = xor <8 x i64> %145, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %147 = bitcast <8 x i64> %146 to <8 x double>
  %148 = fmul <8 x double> %138, %141
  %149 = fmul <8 x double> %142, %137
  %150 = fmul <8 x double> %138, %142
  %151 = fmul <8 x double> %128, %127
  %152 = fmul <8 x double> %134, %125
  %153 = fadd <8 x double> %144, %147
  %154 = fadd <8 x double> %148, %153
  %155 = fadd <8 x double> %149, %154
  %156 = fadd <8 x double> %150, %155
  %157 = fadd <8 x double> %151, %156
  %158 = fadd <8 x double> %152, %157
  %159 = fadd <8 x double> %143, %158
  %160 = fsub <8 x double> %143, %159
  %161 = fadd <8 x double> %158, %160
  %162 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %20, <8 x double> <double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00, double 7.000000e+00>, i32 18, i8 -1, i32 4) #7
  %163 = and i8 %162, %25
  %164 = bitcast i8 %163 to <8 x i1>
  %165 = select <8 x i1> %164, <8 x double> %159, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %166 = select <8 x i1> %164, <8 x double> %161, <8 x double> zeroinitializer
  %167 = fadd <8 x double> %20, <double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00>
  %168 = fsub <8 x double> %167, %20
  %169 = fsub <8 x double> %167, %168
  %170 = fsub <8 x double> %20, %169
  %171 = fsub <8 x double> <double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00, double 5.000000e+00>, %168
  %172 = fadd <8 x double> %171, %170
  %173 = fadd <8 x double> %21, %172
  %174 = select <8 x i1> %164, <8 x double> %167, <8 x double> %20
  %175 = select <8 x i1> %164, <8 x double> %173, <8 x double> %21
  %176 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %174
  %177 = bitcast i8 %24 to <8 x i1>
  %178 = select <8 x i1> %177, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, <8 x double> <double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00, double -2.000000e+00>
  %179 = fadd <8 x double> %178, %174
  %180 = fsub <8 x double> %179, %174
  %181 = fsub <8 x double> %179, %180
  %182 = fsub <8 x double> %174, %181
  %183 = fsub <8 x double> %178, %180
  %184 = fadd <8 x double> %183, %182
  %185 = fadd <8 x double> %175, %184
  %186 = fadd <8 x double> %179, %185
  %187 = bitcast i8 %25 to <8 x i1>
  %188 = select <8 x i1> %187, <8 x double> %176, <8 x double> %186
  %189 = select <8 x i1> %177, <8 x i64> <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>, <8 x i64> <i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3>
  %190 = select <8 x i1> %187, <8 x i64> zeroinitializer, <8 x i64> %189
  %191 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xC06399A52C414C0D, double 0x403D7AAABC7A3EA1, double 0x3E72FDC6CB0D558F, double 0x3E72FDC6CB0D558F, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %192 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FF1EED0A9756022, double 0x406004ABC79048B9, double 0x3E9AE7D44E1AB8F6, double 0x3E9AE7D44E1AB8F6, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %193 = fmul <8 x double> %191, %188
  %194 = fadd <8 x double> %192, %193
  %195 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x402ACBC4BFE43E00, double 0x40705C120870277A, double 0x3EB1734224875A66, double 0x3EB1734224875A66, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %196 = fmul <8 x double> %188, %194
  %197 = fadd <8 x double> %195, %196
  %198 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBFBDD5FA0E771B94, double 0x40748B3C8FCAD7FF, double 0x3EB94E4F6E12FEE0, double 0x3EB94E4F6E12FEE0, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %199 = fmul <8 x double> %188, %197
  %200 = fadd <8 x double> %198, %199
  %201 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBFF644D13921C967, double 0x40719D088C23DF05, double 0x3EB59C884A045AF0, double 0x3EB59C884A045AF0, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %202 = fmul <8 x double> %188, %200
  %203 = fadd <8 x double> %201, %202
  %204 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F8ED5BD48E4F389, double 0x40659BBECDBF523B, double 0x3E9FD66B0AC39DFF, double 0x3E9FD66B0AC39DFF, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %205 = fmul <8 x double> %188, %203
  %206 = fadd <8 x double> %204, %205
  %207 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FC6FB2BA98C8BC4, double 0x40535F30DE19A3FA, double 0xBE71986F7AC19AC9, double 0xBE71986F7AC19AC9, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %208 = fmul <8 x double> %188, %206
  %209 = fadd <8 x double> %207, %208
  %210 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF645497F334CD1D, double 0x403920E9BAC7B07E, double 0xBE956718120CF4B7, double 0xBE956718120CF4B7, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %211 = fmul <8 x double> %188, %209
  %212 = fadd <8 x double> %210, %211
  %213 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF9E3C8E8BED86BB, double 0x40171131F32ACF74, double 0x3E823D16D999C674, double 0x3E823D16D999C674, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %214 = fmul <8 x double> %188, %212
  %215 = fadd <8 x double> %213, %214
  %216 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F41B33B019B3E6F, double 0x3FE743CF466BEB1B, double 0xBE9D26D12E073976, double 0xBE9D26D12E073976, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %217 = fmul <8 x double> %188, %215
  %218 = fadd <8 x double> %216, %217
  %219 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F7A3A699F4A401B, double 0x3FB57EDE06D746AF, double 0x3EB050C384661C46, double 0x3EB050C384661C46, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %220 = fmul <8 x double> %188, %218
  %221 = fadd <8 x double> %219, %220
  %222 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF254D241144693F, double 0xBFB50586EF5B83AC, double 0xBEC1162DF3C28D5A, double 0xBEC1162DF3C28D5A, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %223 = fmul <8 x double> %188, %221
  %224 = fadd <8 x double> %222, %223
  %225 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF5F5DBCAF756CDE, double 0x3FB17B57DDB9E32F, double 0x3ED257DCE81F6BB4, double 0x3ED257DCE81F6BB4, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %226 = fmul <8 x double> %188, %224
  %227 = fadd <8 x double> %225, %226
  %228 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F12E31F9B7913EA, double 0xBFB3BE73A742EECE, double 0xBEE3CC0905ECA8BE, double 0xBEE3CC0905ECA8BE, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %229 = fmul <8 x double> %188, %227
  %230 = fadd <8 x double> %228, %229
  %231 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F4B8239C670E690, double 0x3FB5580F0BB1F8CA, double 0x3EF580E0E2726AC9, double 0x3EF580E0E2726AC9, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %232 = fmul <8 x double> %188, %230
  %233 = fadd <8 x double> %231, %232
  %234 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF0B1D75D3346711, double 0xBFB74879E96382CA, double 0xBF078DE48A7816D9, double 0xBF078DE48A7816D9, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %235 = fmul <8 x double> %188, %233
  %236 = fadd <8 x double> %234, %235
  %237 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF436773BDB97B48, double 0x3FB9A0212305C3B9, double 0x3F1A127B0D3DBB7D, double 0x3F1A127B0D3DBB7D, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %238 = fmul <8 x double> %188, %236
  %239 = fadd <8 x double> %237, %238
  %240 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F1247604839C038, double 0xBFBC80675DF4ED19, double 0xBF2D3FD4CA9D6B1F, double 0xBF2D3FD4CA9D6B1F, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %241 = fmul <8 x double> %188, %239
  %242 = fadd <8 x double> %240, %241
  %243 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F49B0FF6874F2C4, double 0x3FC010B3663D08D8, double 0x3F40B36AF85EF785, double 0x3F40B36AF85EF785, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %244 = fmul <8 x double> %188, %242
  %245 = fadd <8 x double> %243, %244
  %246 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF2E13CE465FA859, double 0xBFC2703A1DD72363, double 0xBF538AC5C2BD10CA, double 0xBF538AC5C2BD10CA, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %247 = fmul <8 x double> %188, %245
  %248 = fadd <8 x double> %246, %247
  %249 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF65F7268EDAB4C8, double 0x3FC5B40CB1047E2E, double 0x3F67ADD6EADB7260, double 0x3F67ADD6EADB7260, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %250 = fmul <8 x double> %188, %248
  %251 = fadd <8 x double> %249, %250
  %252 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F6C71C71C71C71C, double 0xBFCA8B9C17AA3C08, double 0xBF7E404FC218F817, double 0xBF7E404FC218F817, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %253 = fmul <8 x double> %188, %251
  %254 = fadd <8 x double> %252, %253
  %255 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FB5555555555555, double 0x3FD151322AC7D813, double 0x3F951322AC7D8485, double 0x3F951322AC7D8485, double undef, double undef, double undef, double undef>, <8 x i64> %190, <8 x double> zeroinitializer, i8 -1) #7
  %256 = fmul <8 x double> %188, %254
  %257 = fadd <8 x double> %255, %256
  %258 = fadd <8 x double> %174, <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>
  %259 = fsub <8 x double> %258, %174
  %260 = fsub <8 x double> %258, %259
  %261 = fsub <8 x double> %174, %260
  %262 = fsub <8 x double> <double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01, double -5.000000e-01>, %259
  %263 = fadd <8 x double> %262, %261
  %264 = fadd <8 x double> %175, %263
  %265 = fmul <8 x double> %174, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %266 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %265, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %267 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %266, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %268 = sub <8 x i32> zeroinitializer, %267
  %269 = ashr <8 x i32> %268, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %270 = add nsw <8 x i32> %269, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %271 = bitcast <8 x i32> %270 to <4 x i64>
  %272 = shufflevector <4 x i64> %271, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %273 = bitcast <8 x i64> %272 to <16 x i32>
  %274 = shufflevector <16 x i32> %273, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %275 = shufflevector <16 x i32> %274, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %276 = shl <16 x i32> %275, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %277 = bitcast <16 x i32> %276 to <8 x double>
  %278 = fmul <8 x double> %174, %277
  %279 = sub <8 x i32> <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>, %267
  %280 = sub <8 x i32> %279, %269
  %281 = bitcast <8 x i32> %280 to <4 x i64>
  %282 = shufflevector <4 x i64> %281, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %283 = bitcast <8 x i64> %282 to <16 x i32>
  %284 = shufflevector <16 x i32> %283, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %285 = shufflevector <16 x i32> %284, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %286 = shl <16 x i32> %285, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %287 = bitcast <16 x i32> %286 to <8 x double>
  %288 = fmul <8 x double> %278, %287
  %289 = fmul <8 x double> %175, %277
  %290 = fmul <8 x double> %289, %287
  %291 = fadd <8 x double> %288, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %292 = fsub <8 x double> %291, %288
  %293 = fsub <8 x double> %291, %292
  %294 = fsub <8 x double> %288, %293
  %295 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %292
  %296 = fadd <8 x double> %295, %294
  %297 = fadd <8 x double> %290, %296
  %298 = fadd <8 x double> %288, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %299 = fsub <8 x double> %298, %288
  %300 = fsub <8 x double> %298, %299
  %301 = fsub <8 x double> %288, %300
  %302 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %299
  %303 = fadd <8 x double> %302, %301
  %304 = fadd <8 x double> %290, %303
  %305 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %298
  %306 = bitcast <8 x double> %298 to <8 x i64>
  %307 = and <8 x i64> %306, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %308 = bitcast <8 x i64> %307 to <8 x double>
  %309 = fsub <8 x double> %298, %308
  %310 = bitcast <8 x double> %305 to <8 x i64>
  %311 = and <8 x i64> %310, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %312 = bitcast <8 x i64> %311 to <8 x double>
  %313 = fsub <8 x double> %305, %312
  %314 = bitcast <8 x double> %291 to <8 x i64>
  %315 = and <8 x i64> %314, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %316 = bitcast <8 x i64> %315 to <8 x double>
  %317 = fsub <8 x double> %291, %316
  %318 = fmul <8 x double> %291, %305
  %319 = fmul <8 x double> %316, %312
  %320 = fsub <8 x double> %319, %318
  %321 = fmul <8 x double> %313, %316
  %322 = fmul <8 x double> %317, %312
  %323 = fmul <8 x double> %317, %313
  %324 = fmul <8 x double> %308, %312
  %325 = fmul <8 x double> %313, %308
  %326 = fmul <8 x double> %309, %312
  %327 = fmul <8 x double> %309, %313
  %328 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %324
  %329 = fsub <8 x double> %328, %325
  %330 = fsub <8 x double> %329, %326
  %331 = fsub <8 x double> %330, %327
  %332 = fmul <8 x double> %318, %331
  %333 = fadd <8 x double> %320, %321
  %334 = fadd <8 x double> %322, %333
  %335 = fadd <8 x double> %323, %334
  %336 = fadd <8 x double> %335, %332
  %337 = fmul <8 x double> %318, %304
  %338 = fsub <8 x double> %297, %337
  %339 = fmul <8 x double> %305, %338
  %340 = fadd <8 x double> %339, %336
  %341 = bitcast <8 x double> %318 to <8 x i64>
  %342 = and <8 x i64> %341, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %343 = bitcast <8 x i64> %342 to <8 x double>
  %344 = fsub <8 x double> %318, %343
  %345 = fmul <8 x double> %318, %318
  %346 = fmul <8 x double> %343, %343
  %347 = bitcast <8 x double> %345 to <8 x i64>
  %348 = xor <8 x i64> %347, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %349 = bitcast <8 x i64> %348 to <8 x double>
  %350 = fadd <8 x double> %343, %343
  %351 = fmul <8 x double> %350, %344
  %352 = fmul <8 x double> %344, %344
  %353 = fadd <8 x double> %340, %340
  %354 = fmul <8 x double> %318, %353
  %355 = fadd <8 x double> %346, %349
  %356 = fadd <8 x double> %355, %351
  %357 = fadd <8 x double> %352, %356
  %358 = fadd <8 x double> %357, %354
  %359 = fmul <8 x double> %345, %345
  %360 = fmul <8 x double> %359, %359
  %361 = fmul <8 x double> %345, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %362 = fadd <8 x double> %361, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %363 = fmul <8 x double> %359, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %364 = fadd <8 x double> %363, %362
  %365 = fmul <8 x double> %345, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %366 = fadd <8 x double> %365, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %367 = fmul <8 x double> %345, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %368 = fadd <8 x double> %367, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %369 = fmul <8 x double> %359, %366
  %370 = fadd <8 x double> %368, %369
  %371 = fmul <8 x double> %360, %364
  %372 = fadd <8 x double> %371, %370
  %373 = fmul <8 x double> %345, %372
  %374 = fadd <8 x double> %373, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %375 = sitofp <8 x i32> %267 to <8 x double>
  %376 = bitcast <8 x double> %375 to <8 x i64>
  %377 = and <8 x i64> %376, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %378 = bitcast <8 x i64> %377 to <8 x double>
  %379 = fsub <8 x double> %375, %378
  %380 = fmul <8 x double> %375, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %381 = fmul <8 x double> %378, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %382 = bitcast <8 x double> %380 to <8 x i64>
  %383 = xor <8 x i64> %382, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %384 = bitcast <8 x i64> %383 to <8 x double>
  %385 = fmul <8 x double> %378, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %386 = fmul <8 x double> %379, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %387 = fmul <8 x double> %379, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %388 = fmul <8 x double> %375, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %389 = fadd <8 x double> %381, %384
  %390 = fadd <8 x double> %385, %389
  %391 = fadd <8 x double> %386, %390
  %392 = fadd <8 x double> %387, %391
  %393 = fadd <8 x double> %388, %392
  %394 = fmul <8 x double> %318, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %395 = fmul <8 x double> %340, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %396 = fadd <8 x double> %380, %394
  %397 = fsub <8 x double> %380, %396
  %398 = fadd <8 x double> %394, %397
  %399 = fadd <8 x double> %393, %398
  %400 = fadd <8 x double> %399, %395
  %401 = and <8 x i64> %347, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %402 = bitcast <8 x i64> %401 to <8 x double>
  %403 = fsub <8 x double> %345, %402
  %404 = fmul <8 x double> %318, %345
  %405 = fmul <8 x double> %343, %402
  %406 = bitcast <8 x double> %404 to <8 x i64>
  %407 = xor <8 x i64> %406, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %408 = bitcast <8 x i64> %407 to <8 x double>
  %409 = fmul <8 x double> %403, %343
  %410 = fmul <8 x double> %344, %402
  %411 = fmul <8 x double> %344, %403
  %412 = fmul <8 x double> %345, %340
  %413 = fmul <8 x double> %318, %358
  %414 = fadd <8 x double> %405, %408
  %415 = fadd <8 x double> %409, %414
  %416 = fadd <8 x double> %410, %415
  %417 = fadd <8 x double> %411, %416
  %418 = fadd <8 x double> %417, %412
  %419 = fadd <8 x double> %418, %413
  %420 = and <8 x i64> %406, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %421 = bitcast <8 x i64> %420 to <8 x double>
  %422 = fsub <8 x double> %404, %421
  %423 = bitcast <8 x double> %374 to <8 x i64>
  %424 = and <8 x i64> %423, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %425 = bitcast <8 x i64> %424 to <8 x double>
  %426 = fsub <8 x double> %374, %425
  %427 = fmul <8 x double> %404, %374
  %428 = fmul <8 x double> %421, %425
  %429 = bitcast <8 x double> %427 to <8 x i64>
  %430 = xor <8 x i64> %429, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %431 = bitcast <8 x i64> %430 to <8 x double>
  %432 = fmul <8 x double> %422, %425
  %433 = fmul <8 x double> %426, %421
  %434 = fmul <8 x double> %422, %426
  %435 = fmul <8 x double> %374, %419
  %436 = fadd <8 x double> %428, %431
  %437 = fadd <8 x double> %432, %436
  %438 = fadd <8 x double> %433, %437
  %439 = fadd <8 x double> %434, %438
  %440 = fadd <8 x double> %435, %439
  %441 = fadd <8 x double> %396, %427
  %442 = fsub <8 x double> %396, %441
  %443 = fadd <8 x double> %427, %442
  %444 = fadd <8 x double> %443, %400
  %445 = fadd <8 x double> %444, %440
  %446 = bitcast <8 x double> %258 to <8 x i64>
  %447 = and <8 x i64> %446, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %448 = bitcast <8 x i64> %447 to <8 x double>
  %449 = fsub <8 x double> %258, %448
  %450 = bitcast <8 x double> %441 to <8 x i64>
  %451 = and <8 x i64> %450, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %452 = bitcast <8 x i64> %451 to <8 x double>
  %453 = fsub <8 x double> %441, %452
  %454 = fmul <8 x double> %258, %441
  %455 = fmul <8 x double> %448, %452
  %456 = bitcast <8 x double> %454 to <8 x i64>
  %457 = xor <8 x i64> %456, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %458 = bitcast <8 x i64> %457 to <8 x double>
  %459 = fmul <8 x double> %449, %452
  %460 = fmul <8 x double> %453, %448
  %461 = fmul <8 x double> %449, %453
  %462 = fmul <8 x double> %258, %445
  %463 = fmul <8 x double> %264, %441
  %464 = fadd <8 x double> %455, %458
  %465 = fadd <8 x double> %459, %464
  %466 = fadd <8 x double> %460, %465
  %467 = fadd <8 x double> %461, %466
  %468 = fadd <8 x double> %467, %462
  %469 = fadd <8 x double> %463, %468
  %470 = bitcast <8 x double> %174 to <8 x i64>
  %471 = xor <8 x i64> %470, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %472 = bitcast <8 x double> %175 to <8 x i64>
  %473 = xor <8 x i64> %472, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %474 = bitcast <8 x i64> %471 to <8 x double>
  %475 = bitcast <8 x i64> %473 to <8 x double>
  %476 = fadd <8 x double> %454, %474
  %477 = fsub <8 x double> %476, %454
  %478 = fsub <8 x double> %476, %477
  %479 = fsub <8 x double> %454, %478
  %480 = fsub <8 x double> %474, %477
  %481 = fadd <8 x double> %480, %479
  %482 = fadd <8 x double> %469, %475
  %483 = fadd <8 x double> %481, %482
  %484 = fadd <8 x double> %476, <double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5>
  %485 = fsub <8 x double> %484, %476
  %486 = fsub <8 x double> %484, %485
  %487 = fsub <8 x double> %476, %486
  %488 = fsub <8 x double> <double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5, double 0x3FED67F1C864BEB5>, %485
  %489 = fadd <8 x double> %488, %487
  %490 = fadd <8 x double> %483, <double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF, double 0xBC865B5A1B7FF5DF>
  %491 = fadd <8 x double> %489, %490
  %492 = bitcast <8 x double> %257 to <8 x i64>
  %493 = and <8 x i64> %492, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %494 = bitcast <8 x i64> %493 to <8 x double>
  %495 = fsub <8 x double> %257, %494
  %496 = bitcast <8 x double> %188 to <8 x i64>
  %497 = and <8 x i64> %496, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %498 = bitcast <8 x i64> %497 to <8 x double>
  %499 = fsub <8 x double> %188, %498
  %500 = fmul <8 x double> %188, %257
  %501 = fmul <8 x double> %498, %494
  %502 = bitcast <8 x double> %500 to <8 x i64>
  %503 = xor <8 x i64> %502, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %504 = bitcast <8 x i64> %503 to <8 x double>
  %505 = fmul <8 x double> %495, %498
  %506 = fmul <8 x double> %499, %494
  %507 = fmul <8 x double> %499, %495
  %508 = fadd <8 x double> %501, %504
  %509 = fadd <8 x double> %505, %508
  %510 = fadd <8 x double> %506, %509
  %511 = fadd <8 x double> %507, %510
  %512 = select <8 x i1> %177, <8 x double> <double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8, double 0xBFD9A4D55BEAB2D8>, <8 x double> <double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607, double 0xBFB13E001A557607>
  %513 = fadd <8 x double> %512, %500
  %514 = fsub <8 x double> %513, %500
  %515 = fsub <8 x double> %513, %514
  %516 = fsub <8 x double> %500, %515
  %517 = fsub <8 x double> %512, %514
  %518 = fadd <8 x double> %517, %516
  %519 = fadd <8 x double> %518, %511
  %520 = bitcast <8 x double> %513 to <8 x i64>
  %521 = and <8 x i64> %520, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %522 = bitcast <8 x i64> %521 to <8 x double>
  %523 = fsub <8 x double> %513, %522
  %524 = fmul <8 x double> %188, %513
  %525 = fmul <8 x double> %498, %522
  %526 = bitcast <8 x double> %524 to <8 x i64>
  %527 = xor <8 x i64> %526, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %528 = bitcast <8 x i64> %527 to <8 x double>
  %529 = fmul <8 x double> %523, %498
  %530 = fmul <8 x double> %499, %522
  %531 = fmul <8 x double> %499, %523
  %532 = fmul <8 x double> %188, %519
  %533 = fadd <8 x double> %525, %528
  %534 = fadd <8 x double> %529, %533
  %535 = fadd <8 x double> %530, %534
  %536 = fadd <8 x double> %531, %535
  %537 = fadd <8 x double> %532, %536
  %538 = select <8 x i1> %177, <8 x double> <double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3, double 0x3FEA51A6625307D3>, <8 x double> <double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6, double 0x3FD4A34CC4A60FA6>
  %539 = fadd <8 x double> %538, %524
  %540 = fsub <8 x double> %539, %524
  %541 = fsub <8 x double> %539, %540
  %542 = fsub <8 x double> %524, %541
  %543 = fsub <8 x double> %538, %540
  %544 = fadd <8 x double> %543, %542
  %545 = fadd <8 x double> %544, %537
  %546 = bitcast <8 x double> %539 to <8 x i64>
  %547 = and <8 x i64> %546, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %548 = bitcast <8 x i64> %547 to <8 x double>
  %549 = fsub <8 x double> %539, %548
  %550 = fmul <8 x double> %188, %539
  %551 = fmul <8 x double> %498, %548
  %552 = bitcast <8 x double> %550 to <8 x i64>
  %553 = xor <8 x i64> %552, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %554 = bitcast <8 x i64> %553 to <8 x double>
  %555 = fmul <8 x double> %549, %498
  %556 = fmul <8 x double> %499, %548
  %557 = fmul <8 x double> %499, %549
  %558 = fmul <8 x double> %188, %545
  %559 = fadd <8 x double> %551, %554
  %560 = fadd <8 x double> %555, %559
  %561 = fadd <8 x double> %556, %560
  %562 = fadd <8 x double> %557, %561
  %563 = fadd <8 x double> %562, %558
  %564 = select <8 x i1> %177, <8 x double> <double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619, double 0xBFE2788CFC6FB619>, <8 x double> <double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE, double 0x3FDB0EE6072093CE>
  %565 = fadd <8 x double> %564, %550
  %566 = fsub <8 x double> %565, %550
  %567 = fsub <8 x double> %565, %566
  %568 = fsub <8 x double> %550, %567
  %569 = fsub <8 x double> %564, %566
  %570 = fadd <8 x double> %569, %568
  %571 = fadd <8 x double> %570, %563
  %572 = bitcast <8 x double> %565 to <8 x i64>
  %573 = and <8 x i64> %572, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %574 = bitcast <8 x i64> %573 to <8 x double>
  %575 = fsub <8 x double> %565, %574
  %576 = fmul <8 x double> %188, %565
  %577 = fmul <8 x double> %498, %574
  %578 = bitcast <8 x double> %576 to <8 x i64>
  %579 = xor <8 x i64> %578, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %580 = bitcast <8 x i64> %579 to <8 x double>
  %581 = fmul <8 x double> %575, %498
  %582 = fmul <8 x double> %499, %574
  %583 = fmul <8 x double> %499, %575
  %584 = fmul <8 x double> %188, %571
  %585 = fadd <8 x double> %577, %580
  %586 = fadd <8 x double> %581, %585
  %587 = fadd <8 x double> %582, %586
  %588 = fadd <8 x double> %583, %587
  %589 = fadd <8 x double> %588, %584
  %590 = select <8 x i1> %187, <8 x double> %484, <8 x double> %576
  %591 = select <8 x i1> %187, <8 x double> %491, <8 x double> %589
  %592 = fadd <8 x double> %500, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %593 = fsub <8 x double> %592, %500
  %594 = fsub <8 x double> %592, %593
  %595 = fsub <8 x double> %500, %594
  %596 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %593
  %597 = fadd <8 x double> %596, %595
  %598 = fadd <8 x double> %597, %511
  %599 = select <8 x i1> %187, <8 x double> %592, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %600 = select <8 x i1> %187, <8 x double> %598, <8 x double> zeroinitializer
  %601 = bitcast <8 x double> %590 to <8 x i64>
  %602 = xor <8 x i64> %601, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %603 = bitcast <8 x double> %591 to <8 x i64>
  %604 = xor <8 x i64> %603, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %605 = bitcast <8 x i64> %602 to <8 x double>
  %606 = bitcast <8 x i64> %604 to <8 x double>
  %607 = fadd <8 x double> %605, <double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD>
  %608 = fadd <8 x double> %607, <double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD, double 0xBFF250D048E7A1BD>
  %609 = fsub <8 x double> %607, %608
  %610 = fsub <8 x double> <double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD, double 0x3FF250D048E7A1BD>, %609
  %611 = fsub <8 x double> %605, %608
  %612 = fadd <8 x double> %611, %610
  %613 = fadd <8 x double> %606, <double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088, double 0x3C67ABF2AD8D5088>
  %614 = fadd <8 x double> %612, %613
  %615 = select <8 x i1> %16, <8 x double> %607, <8 x double> %590
  %616 = select <8 x i1> %16, <8 x double> %614, <8 x double> %591
  %617 = select <8 x i1> %19, <8 x double> <double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650, double 0x4054CB5ECF0A9650>, <8 x double> %615
  %618 = select <8 x i1> %19, <8 x double> <double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E, double 0x3CF0886A2BC2F41E>, <8 x double> %616
  %619 = select <8 x i1> %16, <8 x double> %165, <8 x double> %599
  %620 = select <8 x i1> %16, <8 x double> %166, <8 x double> %600
  %621 = select <8 x i1> %19, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %619
  %622 = select <8 x i1> %19, <8 x double> zeroinitializer, <8 x double> %620
  %623 = icmp eq i8 %7, 0
  br i1 %623, label %792, label %624

; <label>:624:                                    ; preds = %2
  %625 = fmul <8 x double> %1, <double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000, double 0x3E30000000000000>
  %626 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %625, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %627 = sitofp <8 x i32> %626 to <8 x double>
  %628 = fmul <8 x double> %627, <double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000, double 0x41B0000000000000>
  %629 = fsub <8 x double> %1, %628
  %630 = fmul <8 x double> %629, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %631 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %630, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %632 = lshr <8 x i32> %631, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %633 = xor <8 x i32> %632, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %634 = add <8 x i32> %633, %631
  %635 = bitcast <8 x i32> %634 to <4 x i64>
  %636 = and <4 x i64> %635, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %637 = shufflevector <4 x i64> %636, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %638 = bitcast <8 x i64> %637 to <16 x i32>
  %639 = icmp eq <16 x i32> %638, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %640 = and <8 x i32> %634, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %641 = sitofp <8 x i32> %640 to <8 x double>
  %642 = fsub <8 x double> %630, %641
  %643 = fmul <8 x double> %642, %642
  %644 = bitcast <8 x double> %642 to <8 x i64>
  %645 = and <8 x i64> %644, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %646 = bitcast <8 x i64> %645 to <8 x double>
  %647 = fsub <8 x double> %642, %646
  %648 = fmul <8 x double> %646, %646
  %649 = bitcast <8 x double> %643 to <8 x i64>
  %650 = xor <8 x i64> %649, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %651 = bitcast <8 x i64> %650 to <8 x double>
  %652 = fmul <8 x double> %647, %646
  %653 = fmul <8 x double> %647, %647
  %654 = fadd <8 x double> %648, %651
  %655 = fadd <8 x double> %652, %654
  %656 = fadd <8 x double> %652, %655
  %657 = fadd <8 x double> %653, %656
  %658 = bitcast <16 x i1> %639 to <2 x i8>
  %659 = extractelement <2 x i8> %658, i32 0
  %660 = bitcast i8 %659 to <8 x i1>
  %661 = select <8 x i1> %660, <8 x double> <double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B, double 0x3CD1EA3B366CF50B>, <8 x double> <double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115, double 0xBD16CB8B645A2115>
  %662 = select <8 x i1> %660, <8 x double> <double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480, double 0xBD5B6DF1CE46F480>, <8 x double> <double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38, double 0x3D9E8EFF936BEB38>
  %663 = fmul <8 x double> %643, %661
  %664 = fadd <8 x double> %662, %663
  %665 = select <8 x i1> %660, <8 x double> <double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12, double 0x3DDF9D387B282B12>, <8 x double> <double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020, double 0xBE1E3074CBC7E020>
  %666 = fmul <8 x double> %643, %664
  %667 = fadd <8 x double> %665, %666
  %668 = select <8 x i1> %660, <8 x double> <double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D, double 0xBE5A6D1F2A0E516D>, <8 x double> <double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8, double 0x3E950783486A74C8>
  %669 = fmul <8 x double> %643, %667
  %670 = fadd <8 x double> %668, %669
  %671 = select <8 x i1> %660, <8 x double> <double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB, double 0x3ECE1F506891B1AB>, <8 x double> <double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479, double 0xBF032D2CCE62B479>
  %672 = fmul <8 x double> %643, %670
  %673 = fadd <8 x double> %671, %672
  %674 = select <8 x i1> %660, <8 x double> <double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8, double 0xBF355D3C7E3CBFF8>, <8 x double> <double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE, double 0x3F6466BC6775AADE>
  %675 = fmul <8 x double> %643, %673
  %676 = fadd <8 x double> %674, %675
  %677 = fmul <8 x double> %643, %676
  %678 = select <8 x i1> %660, <8 x double> <double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4, double 0x3F903C1F081B5AC4>, <8 x double> <double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53, double 0xBFB4ABBCE625BE53>
  %679 = select <8 x i1> %660, <8 x double> <double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000, double 0xBC33500000000000>, <8 x double> <double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000, double 0x3C50B00000000000>
  %680 = fadd <8 x double> %678, %677
  %681 = fsub <8 x double> %680, %677
  %682 = fsub <8 x double> %680, %681
  %683 = fsub <8 x double> %677, %682
  %684 = fsub <8 x double> %678, %681
  %685 = fadd <8 x double> %684, %683
  %686 = fadd <8 x double> %679, %685
  %687 = and <8 x i64> %649, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %688 = bitcast <8 x i64> %687 to <8 x double>
  %689 = fsub <8 x double> %643, %688
  %690 = bitcast <8 x double> %680 to <8 x i64>
  %691 = and <8 x i64> %690, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %692 = bitcast <8 x i64> %691 to <8 x double>
  %693 = fsub <8 x double> %680, %692
  %694 = fmul <8 x double> %643, %680
  %695 = fmul <8 x double> %688, %692
  %696 = bitcast <8 x double> %694 to <8 x i64>
  %697 = xor <8 x i64> %696, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %698 = bitcast <8 x i64> %697 to <8 x double>
  %699 = fmul <8 x double> %689, %692
  %700 = fmul <8 x double> %693, %688
  %701 = fmul <8 x double> %689, %693
  %702 = fmul <8 x double> %643, %686
  %703 = fmul <8 x double> %657, %680
  %704 = fadd <8 x double> %695, %698
  %705 = fadd <8 x double> %699, %704
  %706 = fadd <8 x double> %700, %705
  %707 = fadd <8 x double> %701, %706
  %708 = fadd <8 x double> %702, %707
  %709 = fadd <8 x double> %703, %708
  %710 = select <8 x i1> %660, <8 x double> <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>, <8 x double> <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %711 = select <8 x i1> %660, <8 x double> <double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000, double 0xBC76900000000000>, <8 x double> <double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000, double 0x3C81A80000000000>
  %712 = fadd <8 x double> %710, %694
  %713 = fsub <8 x double> %712, %694
  %714 = fsub <8 x double> %712, %713
  %715 = fsub <8 x double> %694, %714
  %716 = fsub <8 x double> %710, %713
  %717 = fadd <8 x double> %716, %715
  %718 = fadd <8 x double> %711, %709
  %719 = fadd <8 x double> %717, %718
  %720 = select <8 x i1> %660, <8 x double> %643, <8 x double> %642
  %721 = select <8 x i1> %660, <8 x double> %657, <8 x double> zeroinitializer
  %722 = bitcast <8 x double> %712 to <8 x i64>
  %723 = and <8 x i64> %722, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %724 = bitcast <8 x i64> %723 to <8 x double>
  %725 = fsub <8 x double> %712, %724
  %726 = bitcast <8 x double> %720 to <8 x i64>
  %727 = and <8 x i64> %726, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %728 = bitcast <8 x i64> %727 to <8 x double>
  %729 = fsub <8 x double> %720, %728
  %730 = fmul <8 x double> %720, %712
  %731 = fmul <8 x double> %728, %724
  %732 = bitcast <8 x double> %730 to <8 x i64>
  %733 = xor <8 x i64> %732, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %734 = bitcast <8 x i64> %733 to <8 x double>
  %735 = fmul <8 x double> %725, %728
  %736 = fmul <8 x double> %729, %724
  %737 = fmul <8 x double> %729, %725
  %738 = fmul <8 x double> %721, %712
  %739 = fmul <8 x double> %720, %719
  %740 = fadd <8 x double> %731, %734
  %741 = fadd <8 x double> %735, %740
  %742 = fadd <8 x double> %736, %741
  %743 = fadd <8 x double> %737, %742
  %744 = fadd <8 x double> %738, %743
  %745 = fadd <8 x double> %744, %739
  %746 = fadd <8 x double> %730, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %747 = fsub <8 x double> %746, %730
  %748 = fsub <8 x double> %746, %747
  %749 = fsub <8 x double> %730, %748
  %750 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %747
  %751 = fadd <8 x double> %750, %749
  %752 = fadd <8 x double> %751, %745
  %753 = select <8 x i1> %660, <8 x double> %746, <8 x double> %730
  %754 = select <8 x i1> %660, <8 x double> %752, <8 x double> %745
  %755 = and <4 x i64> %635, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %756 = shufflevector <4 x i64> %755, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %757 = bitcast <8 x i64> %756 to <16 x i32>
  %758 = icmp eq <16 x i32> %757, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %759 = bitcast <16 x i1> %758 to <2 x i8>
  %760 = extractelement <2 x i8> %759, i32 0
  %761 = bitcast i8 %760 to <8 x i1>
  %762 = select <8 x i1> %761, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %763 = bitcast <8 x double> %753 to <8 x i64>
  %764 = xor <8 x i64> %762, %763
  %765 = bitcast <8 x double> %754 to <8 x i64>
  %766 = xor <8 x i64> %762, %765
  %767 = bitcast <8 x i64> %764 to <8 x double>
  %768 = bitcast <8 x i64> %766 to <8 x double>
  %769 = bitcast <8 x double> %599 to <8 x i64>
  %770 = and <8 x i64> %769, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %771 = bitcast <8 x i64> %770 to <8 x double>
  %772 = fsub <8 x double> %599, %771
  %773 = and <8 x i64> %764, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %774 = bitcast <8 x i64> %773 to <8 x double>
  %775 = fsub <8 x double> %767, %774
  %776 = fmul <8 x double> %599, %767
  %777 = fmul <8 x double> %771, %774
  %778 = bitcast <8 x double> %776 to <8 x i64>
  %779 = xor <8 x i64> %778, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %780 = bitcast <8 x i64> %779 to <8 x double>
  %781 = fmul <8 x double> %772, %774
  %782 = fmul <8 x double> %775, %771
  %783 = fmul <8 x double> %772, %775
  %784 = fmul <8 x double> %599, %768
  %785 = fmul <8 x double> %600, %767
  %786 = fadd <8 x double> %777, %780
  %787 = fadd <8 x double> %781, %786
  %788 = fadd <8 x double> %782, %787
  %789 = fadd <8 x double> %783, %788
  %790 = fadd <8 x double> %789, %784
  %791 = fadd <8 x double> %785, %790
  br label %792

; <label>:792:                                    ; preds = %2, %624
  %793 = phi <8 x double> [ %776, %624 ], [ %174, %2 ]
  %794 = phi <8 x double> [ %791, %624 ], [ %175, %2 ]
  %795 = fmul <8 x double> %1, <double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000, double 0x4770000000000000>
  %796 = select <8 x i1> %16, <8 x double> %793, <8 x double> %165
  %797 = select <8 x i1> %16, <8 x double> %794, <8 x double> %166
  %798 = select <8 x i1> %19, <8 x double> %795, <8 x double> %796
  %799 = select <8 x i1> %19, <8 x double> zeroinitializer, <8 x double> %797
  %800 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %798
  %801 = bitcast <8 x double> %798 to <8 x i64>
  %802 = and <8 x i64> %801, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %803 = bitcast <8 x i64> %802 to <8 x double>
  %804 = fsub <8 x double> %798, %803
  %805 = bitcast <8 x double> %800 to <8 x i64>
  %806 = and <8 x i64> %805, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %807 = bitcast <8 x i64> %806 to <8 x double>
  %808 = fsub <8 x double> %800, %807
  %809 = bitcast <8 x double> %621 to <8 x i64>
  %810 = and <8 x i64> %809, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %811 = bitcast <8 x i64> %810 to <8 x double>
  %812 = fsub <8 x double> %621, %811
  %813 = fmul <8 x double> %621, %800
  %814 = fmul <8 x double> %811, %807
  %815 = fsub <8 x double> %814, %813
  %816 = fmul <8 x double> %808, %811
  %817 = fmul <8 x double> %812, %807
  %818 = fmul <8 x double> %812, %808
  %819 = fmul <8 x double> %803, %807
  %820 = fmul <8 x double> %808, %803
  %821 = fmul <8 x double> %804, %807
  %822 = fmul <8 x double> %804, %808
  %823 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %819
  %824 = fsub <8 x double> %823, %820
  %825 = fsub <8 x double> %824, %821
  %826 = fsub <8 x double> %825, %822
  %827 = fmul <8 x double> %813, %826
  %828 = fadd <8 x double> %815, %816
  %829 = fadd <8 x double> %817, %828
  %830 = fadd <8 x double> %818, %829
  %831 = fadd <8 x double> %830, %827
  %832 = fmul <8 x double> %799, %813
  %833 = fsub <8 x double> %622, %832
  %834 = fmul <8 x double> %800, %833
  %835 = fadd <8 x double> %834, %831
  %836 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 0, i32 0
  store <8 x double> %617, <8 x double>* %836, align 64
  %837 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 0, i32 1
  store <8 x double> %618, <8 x double>* %837, align 64
  %838 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 1, i32 0
  store <8 x double> %813, <8 x double>* %838, align 64
  %839 = getelementptr inbounds %struct.dd2, %struct.dd2* %0, i64 0, i32 1, i32 1
  store <8 x double> %835, <8 x double>* %839, align 64
  ret void
}

; Function Attrs: nounwind uwtable
define <8 x double> @Sleef_lgammad8_u10avx512fnofma(<8 x double>) local_unnamed_addr #3 {
  %2 = alloca %struct.dd2, align 64
  %3 = bitcast %struct.dd2* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %3) #7
  call fastcc void @gammak(%struct.dd2* noalias nonnull %2, <8 x double> %0)
  %4 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1
  %5 = bitcast %struct.vdouble2* %4 to <8 x i64>*
  %6 = load <8 x i64>, <8 x i64>* %5, align 64
  %7 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 1, i32 1
  %8 = bitcast <8 x double>* %7 to <8 x i64>*
  %9 = load <8 x i64>, <8 x i64>* %8, align 64
  %10 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %11 = and <8 x i64> %6, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %12 = xor <8 x i64> %11, %9
  %13 = bitcast <8 x i64> %10 to <8 x double>
  %14 = bitcast <8 x i64> %12 to <8 x double>
  %15 = fmul <8 x double> %13, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %16 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %15, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %17 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %16, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %18 = sub <8 x i32> zeroinitializer, %17
  %19 = ashr <8 x i32> %18, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %20 = add nsw <8 x i32> %19, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %21 = bitcast <8 x i32> %20 to <4 x i64>
  %22 = shufflevector <4 x i64> %21, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast <8 x i64> %22 to <16 x i32>
  %24 = shufflevector <16 x i32> %23, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %25 = shufflevector <16 x i32> %24, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %26 = shl <16 x i32> %25, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %27 = bitcast <16 x i32> %26 to <8 x double>
  %28 = fmul <8 x double> %13, %27
  %29 = sub <8 x i32> <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>, %17
  %30 = sub <8 x i32> %29, %19
  %31 = bitcast <8 x i32> %30 to <4 x i64>
  %32 = shufflevector <4 x i64> %31, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %33 = bitcast <8 x i64> %32 to <16 x i32>
  %34 = shufflevector <16 x i32> %33, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %35 = shufflevector <16 x i32> %34, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %36 = shl <16 x i32> %35, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %37 = bitcast <16 x i32> %36 to <8 x double>
  %38 = fmul <8 x double> %28, %37
  %39 = fmul <8 x double> %14, %27
  %40 = fmul <8 x double> %39, %37
  %41 = fadd <8 x double> %38, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %42 = fsub <8 x double> %41, %38
  %43 = fsub <8 x double> %41, %42
  %44 = fsub <8 x double> %38, %43
  %45 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %42
  %46 = fadd <8 x double> %45, %44
  %47 = fadd <8 x double> %40, %46
  %48 = fadd <8 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %49 = fsub <8 x double> %48, %38
  %50 = fsub <8 x double> %48, %49
  %51 = fsub <8 x double> %38, %50
  %52 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %49
  %53 = fadd <8 x double> %52, %51
  %54 = fadd <8 x double> %40, %53
  %55 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %48
  %56 = bitcast <8 x double> %48 to <8 x i64>
  %57 = and <8 x i64> %56, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %58 = bitcast <8 x i64> %57 to <8 x double>
  %59 = fsub <8 x double> %48, %58
  %60 = bitcast <8 x double> %55 to <8 x i64>
  %61 = and <8 x i64> %60, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = fsub <8 x double> %55, %62
  %64 = bitcast <8 x double> %41 to <8 x i64>
  %65 = and <8 x i64> %64, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %66 = bitcast <8 x i64> %65 to <8 x double>
  %67 = fsub <8 x double> %41, %66
  %68 = fmul <8 x double> %41, %55
  %69 = fmul <8 x double> %66, %62
  %70 = fsub <8 x double> %69, %68
  %71 = fmul <8 x double> %63, %66
  %72 = fmul <8 x double> %67, %62
  %73 = fmul <8 x double> %67, %63
  %74 = fmul <8 x double> %58, %62
  %75 = fmul <8 x double> %63, %58
  %76 = fmul <8 x double> %59, %62
  %77 = fmul <8 x double> %59, %63
  %78 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %74
  %79 = fsub <8 x double> %78, %75
  %80 = fsub <8 x double> %79, %76
  %81 = fsub <8 x double> %80, %77
  %82 = fmul <8 x double> %68, %81
  %83 = fadd <8 x double> %70, %71
  %84 = fadd <8 x double> %72, %83
  %85 = fadd <8 x double> %73, %84
  %86 = fadd <8 x double> %85, %82
  %87 = fmul <8 x double> %68, %54
  %88 = fsub <8 x double> %47, %87
  %89 = fmul <8 x double> %55, %88
  %90 = fadd <8 x double> %89, %86
  %91 = bitcast <8 x double> %68 to <8 x i64>
  %92 = and <8 x i64> %91, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %93 = bitcast <8 x i64> %92 to <8 x double>
  %94 = fsub <8 x double> %68, %93
  %95 = fmul <8 x double> %68, %68
  %96 = fmul <8 x double> %93, %93
  %97 = bitcast <8 x double> %95 to <8 x i64>
  %98 = xor <8 x i64> %97, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %99 = bitcast <8 x i64> %98 to <8 x double>
  %100 = fadd <8 x double> %93, %93
  %101 = fmul <8 x double> %100, %94
  %102 = fmul <8 x double> %94, %94
  %103 = fadd <8 x double> %90, %90
  %104 = fmul <8 x double> %68, %103
  %105 = fadd <8 x double> %96, %99
  %106 = fadd <8 x double> %105, %101
  %107 = fadd <8 x double> %102, %106
  %108 = fadd <8 x double> %107, %104
  %109 = fmul <8 x double> %95, %95
  %110 = fmul <8 x double> %109, %109
  %111 = fmul <8 x double> %95, <double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B, double 0x3FC0DB8A525B4A6B>
  %112 = fadd <8 x double> %111, <double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971, double 0x3FC3B3759FB81971>
  %113 = fmul <8 x double> %109, <double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760, double 0x3FC1BDC9AD06D760>
  %114 = fadd <8 x double> %113, %112
  %115 = fmul <8 x double> %95, <double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A, double 0x3FC745C38C19C82A>
  %116 = fadd <8 x double> %115, <double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90, double 0x3FCC71C750354F90>
  %117 = fmul <8 x double> %95, <double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C, double 0x3FD2492492114D0C>
  %118 = fadd <8 x double> %117, <double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB, double 0x3FD999999999D9EB>
  %119 = fmul <8 x double> %109, %116
  %120 = fadd <8 x double> %118, %119
  %121 = fmul <8 x double> %110, %114
  %122 = fadd <8 x double> %121, %120
  %123 = fmul <8 x double> %95, %122
  %124 = fadd <8 x double> %123, <double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545, double 0x3FE5555555555545>
  %125 = sitofp <8 x i32> %17 to <8 x double>
  %126 = bitcast <8 x double> %125 to <8 x i64>
  %127 = and <8 x i64> %126, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %128 = bitcast <8 x i64> %127 to <8 x double>
  %129 = fsub <8 x double> %125, %128
  %130 = fmul <8 x double> %125, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %131 = fmul <8 x double> %128, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %132 = bitcast <8 x double> %130 to <8 x i64>
  %133 = xor <8 x i64> %132, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %134 = bitcast <8 x i64> %133 to <8 x double>
  %135 = fmul <8 x double> %128, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %136 = fmul <8 x double> %129, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %137 = fmul <8 x double> %129, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %138 = fmul <8 x double> %125, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %139 = fadd <8 x double> %131, %134
  %140 = fadd <8 x double> %135, %139
  %141 = fadd <8 x double> %136, %140
  %142 = fadd <8 x double> %137, %141
  %143 = fadd <8 x double> %138, %142
  %144 = fmul <8 x double> %68, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %145 = fmul <8 x double> %90, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %146 = fadd <8 x double> %130, %144
  %147 = fsub <8 x double> %130, %146
  %148 = fadd <8 x double> %144, %147
  %149 = fadd <8 x double> %143, %148
  %150 = fadd <8 x double> %149, %145
  %151 = and <8 x i64> %97, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %152 = bitcast <8 x i64> %151 to <8 x double>
  %153 = fsub <8 x double> %95, %152
  %154 = fmul <8 x double> %68, %95
  %155 = fmul <8 x double> %93, %152
  %156 = bitcast <8 x double> %154 to <8 x i64>
  %157 = xor <8 x i64> %156, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %158 = bitcast <8 x i64> %157 to <8 x double>
  %159 = fmul <8 x double> %153, %93
  %160 = fmul <8 x double> %94, %152
  %161 = fmul <8 x double> %94, %153
  %162 = fmul <8 x double> %95, %90
  %163 = fmul <8 x double> %68, %108
  %164 = fadd <8 x double> %155, %158
  %165 = fadd <8 x double> %159, %164
  %166 = fadd <8 x double> %160, %165
  %167 = fadd <8 x double> %161, %166
  %168 = fadd <8 x double> %167, %162
  %169 = fadd <8 x double> %168, %163
  %170 = and <8 x i64> %156, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %171 = bitcast <8 x i64> %170 to <8 x double>
  %172 = fsub <8 x double> %154, %171
  %173 = bitcast <8 x double> %124 to <8 x i64>
  %174 = and <8 x i64> %173, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %175 = bitcast <8 x i64> %174 to <8 x double>
  %176 = fsub <8 x double> %124, %175
  %177 = fmul <8 x double> %154, %124
  %178 = fmul <8 x double> %171, %175
  %179 = bitcast <8 x double> %177 to <8 x i64>
  %180 = xor <8 x i64> %179, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %181 = bitcast <8 x i64> %180 to <8 x double>
  %182 = fmul <8 x double> %172, %175
  %183 = fmul <8 x double> %176, %171
  %184 = fmul <8 x double> %172, %176
  %185 = fmul <8 x double> %124, %169
  %186 = fadd <8 x double> %178, %181
  %187 = fadd <8 x double> %182, %186
  %188 = fadd <8 x double> %183, %187
  %189 = fadd <8 x double> %184, %188
  %190 = fadd <8 x double> %185, %189
  %191 = fadd <8 x double> %146, %177
  %192 = fsub <8 x double> %146, %191
  %193 = fadd <8 x double> %177, %192
  %194 = fadd <8 x double> %193, %150
  %195 = fadd <8 x double> %194, %190
  %196 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 0
  %197 = load <8 x double>, <8 x double>* %196, align 64
  %198 = getelementptr inbounds %struct.dd2, %struct.dd2* %2, i64 0, i32 0, i32 1
  %199 = load <8 x double>, <8 x double>* %198, align 64
  %200 = fadd <8 x double> %197, %191
  %201 = fsub <8 x double> %200, %197
  %202 = fsub <8 x double> %200, %201
  %203 = fsub <8 x double> %197, %202
  %204 = fsub <8 x double> %191, %201
  %205 = fadd <8 x double> %204, %203
  %206 = fadd <8 x double> %199, %195
  %207 = fadd <8 x double> %205, %206
  %208 = fadd <8 x double> %200, %207
  %209 = bitcast <8 x double> %0 to <8 x i64>
  %210 = and <8 x i64> %209, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %211 = bitcast <8 x i64> %210 to <8 x double>
  %212 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %211, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %213 = zext i8 %212 to i16
  %214 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 18, i8 -1, i32 4) #7
  %215 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 11, <8 x double> %0, i8 -1, i32 4) #7
  %216 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %215, <8 x double> %0, i32 0, i8 -1, i32 4) #7
  %217 = and i8 %216, %214
  %218 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 0, i8 -1, i32 4) #7
  %219 = zext i8 %218 to i16
  %220 = bitcast i16 %213 to <16 x i1>
  %221 = bitcast i16 %219 to <16 x i1>
  %222 = xor <16 x i1> %220, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %223 = and <16 x i1> %222, %221
  %224 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %208, <8 x double> %208, i32 4, i8 -1, i32 4) #7
  %225 = bitcast <16 x i1> %223 to <2 x i8>
  %226 = extractelement <2 x i8> %225, i32 0
  %227 = and i8 %226, %224
  %228 = or i8 %217, %212
  %229 = or i8 %228, %227
  %230 = bitcast i8 %229 to <8 x i1>
  %231 = select <8 x i1> %230, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %208
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %3) #7
  ret <8 x double> %231
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_erfd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 17, i8 -1, i32 4) #7
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00, double 3.700000e+00>, i32 17, i8 -1, i32 4) #7
  %7 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00, double 6.000000e+00>, i32 17, i8 -1, i32 4) #7
  %8 = fmul <8 x double> %4, %4
  %9 = bitcast i8 %5 to <8 x i1>
  %10 = select <8 x i1> %9, <8 x double> %8, <8 x double> %4
  %11 = bitcast i8 %6 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x i64> <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>, <8 x i64> <i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3>
  %13 = select <8 x i1> %9, <8 x i64> zeroinitializer, <8 x i64> %12
  %14 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3BC00EFEFABE989B, double 0x3D1FDFABBDFC43F1, double 0xBC5AF69FE192740F, double 0xBC5AF69FE192740F, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %15 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBC0FE6EC06B043F5, double 0xBD7A8E25B9CCCB64, double 0x3CC5E4C21B562709, double 0x3CC5E4C21B562709, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %16 = fmul <8 x double> %10, %14
  %17 = fadd <8 x double> %16, %15
  %18 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3C55A7F67BDE0C17, double 0x3DC50B3AE48C7164, double 0xBD20EE4A859274F9, double 0xBD20EE4A859274F9, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %19 = fmul <8 x double> %10, %17
  %20 = fadd <8 x double> %18, %19
  %21 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBC9A15164BF4F36C, double 0xBE0518912B895660, double 0x3D7095F3964F9BBA, double 0x3D7095F3964F9BBA, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %22 = fmul <8 x double> %10, %20
  %23 = fadd <8 x double> %21, %22
  %24 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3CDD6F95068FEEA8, double 0x3E3E0083E7FD4B05, double 0xBDB7174964833400, double 0xBDB7174964833400, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %25 = fmul <8 x double> %10, %23
  %26 = fadd <8 x double> %24, %25
  %27 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBD1F56D9FF51275A, double 0xBE70131398DAE973, double 0x3DF84A341FC35F63, double 0x3DF84A341FC35F63, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %28 = fmul <8 x double> %10, %26
  %29 = fadd <8 x double> %27, %28
  %30 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3D5F6839841402FB, double 0x3E9AE1C4F259778D, double 0xBE34092FAEC3CB81, double 0xBE34092FAEC3CB81, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %31 = fmul <8 x double> %10, %29
  %32 = fadd <8 x double> %30, %31
  %33 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBD9D8453B9E7FD7B, double 0xBEC1E2D7E8039AC0, double 0x3E6A8ABD2DF8AA98, double 0x3E6A8ABD2DF8AA98, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %34 = fmul <8 x double> %10, %32
  %35 = fadd <8 x double> %33, %34
  %36 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3DD9E6AD5DAB7034, double 0x3EE3117A5DB988BA, double 0xBE9CA9DF1E6D3F55, double 0xBE9CA9DF1E6D3F55, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %37 = fmul <8 x double> %10, %35
  %38 = fadd <8 x double> %36, %37
  %39 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBE151D7181C08B9D, double 0xBF0024D0F7EE3723, double 0x3EC9739C586B056B, double 0x3EC9739C586B056B, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %40 = fmul <8 x double> %10, %38
  %41 = fadd <8 x double> %39, %40
  %42 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3E4FCC5720620921, double 0x3F14E58666D1B46F, double 0xBEF2A034D3F36A50, double 0xBEF2A034D3F36A50, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %43 = fmul <8 x double> %10, %41
  %44 = fadd <8 x double> %42, %43
  %45 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBE85F742EC43E5C7, double 0xBF2230DCD58EAD99, double 0x3F1658BA21A7397E, double 0x3F1658BA21A7397E, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %46 = fmul <8 x double> %10, %44
  %47 = fadd <8 x double> %45, %46
  %48 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3EBB9E6C9DC6519C, double 0x3F10F5BA38B6A6E5, double 0xBF3590AE9D03C290, double 0xBF3590AE9D03C290, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %49 = fmul <8 x double> %10, %47
  %50 = fadd <8 x double> %48, %49
  %51 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBEEF4D25C3E0C2EA, double 0x3F405F7D6748381E, double 0x3F4FC6679B56D25A, double 0x3F4FC6679B56D25A, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %52 = fmul <8 x double> %10, %50
  %53 = fadd <8 x double> %51, %52
  %54 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F1F9A326F9B89B8, double 0xBF5A9686E5DE05F7, double 0xBF5DB24AB8ACFC8B, double 0xBF5DB24AB8ACFC8B, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %55 = fmul <8 x double> %10, %53
  %56 = fadd <8 x double> %54, %55
  %57 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF4C02DB40040B84, double 0x3F252C1DCB0324BA, double 0xBF3EF7EC1133F0A8, double 0xBF3EF7EC1133F0A8, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %58 = fmul <8 x double> %10, %56
  %59 = fadd <8 x double> %57, %58
  %60 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F7565BCD0E6A540, double 0x3F939CBECA106F66, double 0x3F9567A2F00CE3E5, double 0x3F9567A2F00CE3E5, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %61 = fmul <8 x double> %10, %59
  %62 = fadd <8 x double> %60, %61
  %63 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF9B82CE31288B52, double 0xBFBA4FE8F5D2A23C, double 0xBFBAEEA974D564EF, double 0xBFBAEEA974D564EF, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %64 = fmul <8 x double> %10, %62
  %65 = fadd <8 x double> %63, %64
  %66 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FBCE2F21A042BE3, double 0xBFE45F2B34C61AC0, double 0xBFE44E1CB940DA9C, double 0xBFE44E1CB940DA9C, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %67 = fmul <8 x double> %10, %65
  %68 = fadd <8 x double> %66, %67
  %69 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBFD812746B0379E7, double 0xBFF20DD7C1F4F99A, double 0xBFF21232BFB32B5A, double 0xBFF21232BFB32B5A, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %70 = fmul <8 x double> %10, %68
  %71 = fadd <8 x double> %69, %70
  %72 = bitcast <8 x double> %71 to <8 x i64>
  %73 = and <8 x i64> %72, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %74 = bitcast <8 x i64> %73 to <8 x double>
  %75 = fsub <8 x double> %71, %74
  %76 = bitcast <8 x double> %10 to <8 x i64>
  %77 = and <8 x i64> %76, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fsub <8 x double> %10, %78
  %80 = fmul <8 x double> %10, %71
  %81 = fmul <8 x double> %78, %74
  %82 = bitcast <8 x double> %80 to <8 x i64>
  %83 = xor <8 x i64> %82, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %84 = bitcast <8 x i64> %83 to <8 x double>
  %85 = fmul <8 x double> %75, %78
  %86 = fmul <8 x double> %79, %74
  %87 = fmul <8 x double> %79, %75
  %88 = fadd <8 x double> %81, %84
  %89 = fadd <8 x double> %85, %88
  %90 = fadd <8 x double> %86, %89
  %91 = fadd <8 x double> %87, %90
  %92 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FF20DD750429B6D, double 0x3E6250219DD8BAD1, double 0x3F305C1A38102E9A, double 0x3F305C1A38102E9A, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %93 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3C71AE3A914FED6D, double 0xBB080EE9AD757828, double 0xBBB9AC0AFE024E87, double 0xBBB9AC0AFE024E87, double undef, double undef, double undef, double undef>, <8 x i64> %13, <8 x double> zeroinitializer, i8 -1) #7
  %94 = fadd <8 x double> %92, %80
  %95 = fsub <8 x double> %94, %80
  %96 = fsub <8 x double> %94, %95
  %97 = fsub <8 x double> %80, %96
  %98 = fsub <8 x double> %92, %95
  %99 = fadd <8 x double> %98, %97
  %100 = fadd <8 x double> %93, %91
  %101 = fadd <8 x double> %99, %100
  %102 = bitcast <8 x double> %94 to <8 x i64>
  %103 = and <8 x i64> %102, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %104 = bitcast <8 x i64> %103 to <8 x double>
  %105 = fsub <8 x double> %94, %104
  %106 = and <8 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %107 = bitcast <8 x i64> %106 to <8 x double>
  %108 = fsub <8 x double> %4, %107
  %109 = fmul <8 x double> %94, %4
  %110 = fmul <8 x double> %107, %104
  %111 = bitcast <8 x double> %109 to <8 x i64>
  %112 = xor <8 x i64> %111, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %113 = bitcast <8 x i64> %112 to <8 x double>
  %114 = fmul <8 x double> %105, %107
  %115 = fmul <8 x double> %108, %104
  %116 = fmul <8 x double> %108, %105
  %117 = fmul <8 x double> %101, %4
  %118 = fadd <8 x double> %110, %113
  %119 = fadd <8 x double> %114, %118
  %120 = fadd <8 x double> %115, %119
  %121 = fadd <8 x double> %116, %120
  %122 = fadd <8 x double> %121, %117
  %123 = fadd <8 x double> %94, %101
  %124 = fmul <8 x double> %123, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %125 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %124, i32 8, <8 x double> %124, i8 -1, i32 4) #7
  %126 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %125, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %127 = fmul <8 x double> %125, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %128 = fadd <8 x double> %127, %94
  %129 = fsub <8 x double> %128, %94
  %130 = fsub <8 x double> %128, %129
  %131 = fsub <8 x double> %94, %130
  %132 = fsub <8 x double> %127, %129
  %133 = fadd <8 x double> %132, %131
  %134 = fadd <8 x double> %133, %101
  %135 = fmul <8 x double> %125, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %136 = fadd <8 x double> %135, %128
  %137 = fsub <8 x double> %136, %128
  %138 = fsub <8 x double> %136, %137
  %139 = fsub <8 x double> %128, %138
  %140 = fsub <8 x double> %135, %137
  %141 = fadd <8 x double> %140, %139
  %142 = fadd <8 x double> %141, %134
  %143 = bitcast <8 x double> %136 to <8 x i64>
  %144 = and <8 x i64> %143, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = fsub <8 x double> %136, %145
  %147 = fmul <8 x double> %136, %136
  %148 = fmul <8 x double> %145, %145
  %149 = bitcast <8 x double> %147 to <8 x i64>
  %150 = xor <8 x i64> %149, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %151 = bitcast <8 x i64> %150 to <8 x double>
  %152 = fadd <8 x double> %145, %145
  %153 = fmul <8 x double> %152, %146
  %154 = fmul <8 x double> %146, %146
  %155 = fadd <8 x double> %142, %142
  %156 = fmul <8 x double> %136, %155
  %157 = fadd <8 x double> %148, %151
  %158 = fadd <8 x double> %157, %153
  %159 = fadd <8 x double> %154, %158
  %160 = fadd <8 x double> %159, %156
  %161 = and <8 x i64> %149, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %162 = bitcast <8 x i64> %161 to <8 x double>
  %163 = fsub <8 x double> %147, %162
  %164 = fmul <8 x double> %147, %147
  %165 = fmul <8 x double> %162, %162
  %166 = bitcast <8 x double> %164 to <8 x i64>
  %167 = xor <8 x i64> %166, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %168 = bitcast <8 x i64> %167 to <8 x double>
  %169 = fadd <8 x double> %162, %162
  %170 = fmul <8 x double> %169, %163
  %171 = fmul <8 x double> %163, %163
  %172 = fadd <8 x double> %160, %160
  %173 = fmul <8 x double> %147, %172
  %174 = fadd <8 x double> %165, %168
  %175 = fadd <8 x double> %174, %170
  %176 = fadd <8 x double> %171, %175
  %177 = fadd <8 x double> %176, %173
  %178 = fmul <8 x double> %164, %164
  %179 = fmul <8 x double> %136, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %180 = fadd <8 x double> %179, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %181 = fmul <8 x double> %136, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %182 = fadd <8 x double> %181, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %183 = fmul <8 x double> %136, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %184 = fadd <8 x double> %183, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %185 = fmul <8 x double> %147, %182
  %186 = fadd <8 x double> %184, %185
  %187 = fmul <8 x double> %136, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %188 = fadd <8 x double> %187, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %189 = fmul <8 x double> %136, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %190 = fadd <8 x double> %189, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %191 = fmul <8 x double> %147, %188
  %192 = fadd <8 x double> %190, %191
  %193 = fmul <8 x double> %164, %186
  %194 = fadd <8 x double> %192, %193
  %195 = fmul <8 x double> %180, %178
  %196 = fadd <8 x double> %195, %194
  %197 = fmul <8 x double> %136, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %198 = fmul <8 x double> %145, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %199 = bitcast <8 x double> %197 to <8 x i64>
  %200 = xor <8 x i64> %199, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %201 = bitcast <8 x i64> %200 to <8 x double>
  %202 = fmul <8 x double> %146, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %203 = fmul <8 x double> %145, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %204 = fmul <8 x double> %146, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %205 = fmul <8 x double> %142, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %206 = fadd <8 x double> %198, %201
  %207 = fadd <8 x double> %202, %206
  %208 = fadd <8 x double> %203, %207
  %209 = fadd <8 x double> %204, %208
  %210 = fadd <8 x double> %209, %205
  %211 = fadd <8 x double> %197, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %212 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %211
  %213 = fadd <8 x double> %197, %212
  %214 = fadd <8 x double> %213, %210
  %215 = bitcast <8 x double> %211 to <8 x i64>
  %216 = and <8 x i64> %215, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %217 = bitcast <8 x i64> %216 to <8 x double>
  %218 = fsub <8 x double> %211, %217
  %219 = fmul <8 x double> %136, %211
  %220 = fmul <8 x double> %145, %217
  %221 = bitcast <8 x double> %219 to <8 x i64>
  %222 = xor <8 x i64> %221, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %223 = bitcast <8 x i64> %222 to <8 x double>
  %224 = fmul <8 x double> %218, %145
  %225 = fmul <8 x double> %146, %217
  %226 = fmul <8 x double> %146, %218
  %227 = fmul <8 x double> %211, %142
  %228 = fmul <8 x double> %136, %214
  %229 = fadd <8 x double> %220, %223
  %230 = fadd <8 x double> %224, %229
  %231 = fadd <8 x double> %225, %230
  %232 = fadd <8 x double> %226, %231
  %233 = fadd <8 x double> %227, %232
  %234 = fadd <8 x double> %233, %228
  %235 = fadd <8 x double> %219, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %236 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %235
  %237 = fadd <8 x double> %219, %236
  %238 = fadd <8 x double> %237, %234
  %239 = bitcast <8 x double> %235 to <8 x i64>
  %240 = and <8 x i64> %239, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %241 = bitcast <8 x i64> %240 to <8 x double>
  %242 = fsub <8 x double> %235, %241
  %243 = fmul <8 x double> %136, %235
  %244 = fmul <8 x double> %145, %241
  %245 = bitcast <8 x double> %243 to <8 x i64>
  %246 = xor <8 x i64> %245, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %247 = bitcast <8 x i64> %246 to <8 x double>
  %248 = fmul <8 x double> %242, %145
  %249 = fmul <8 x double> %146, %241
  %250 = fmul <8 x double> %146, %242
  %251 = fmul <8 x double> %235, %142
  %252 = fmul <8 x double> %136, %238
  %253 = fadd <8 x double> %244, %247
  %254 = fadd <8 x double> %248, %253
  %255 = fadd <8 x double> %249, %254
  %256 = fadd <8 x double> %250, %255
  %257 = fadd <8 x double> %251, %256
  %258 = fadd <8 x double> %257, %252
  %259 = fadd <8 x double> %243, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %260 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %259
  %261 = fadd <8 x double> %243, %260
  %262 = fadd <8 x double> %261, %258
  %263 = and <8 x i64> %166, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %264 = bitcast <8 x i64> %263 to <8 x double>
  %265 = fsub <8 x double> %164, %264
  %266 = bitcast <8 x double> %196 to <8 x i64>
  %267 = and <8 x i64> %266, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %268 = bitcast <8 x i64> %267 to <8 x double>
  %269 = fsub <8 x double> %196, %268
  %270 = fmul <8 x double> %164, %196
  %271 = fmul <8 x double> %264, %268
  %272 = bitcast <8 x double> %270 to <8 x i64>
  %273 = xor <8 x i64> %272, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %274 = bitcast <8 x i64> %273 to <8 x double>
  %275 = fmul <8 x double> %265, %268
  %276 = fmul <8 x double> %269, %264
  %277 = fmul <8 x double> %265, %269
  %278 = fmul <8 x double> %196, %177
  %279 = fadd <8 x double> %271, %274
  %280 = fadd <8 x double> %275, %279
  %281 = fadd <8 x double> %276, %280
  %282 = fadd <8 x double> %277, %281
  %283 = fadd <8 x double> %278, %282
  %284 = fadd <8 x double> %259, %270
  %285 = fsub <8 x double> %259, %284
  %286 = fadd <8 x double> %270, %285
  %287 = fadd <8 x double> %286, %262
  %288 = fadd <8 x double> %283, %287
  %289 = ashr <8 x i32> %126, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %290 = add nsw <8 x i32> %289, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %291 = bitcast <8 x i32> %290 to <4 x i64>
  %292 = shufflevector <4 x i64> %291, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %293 = bitcast <8 x i64> %292 to <16 x i32>
  %294 = shufflevector <16 x i32> %293, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %295 = shufflevector <16 x i32> %294, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %296 = shl <16 x i32> %295, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %297 = bitcast <16 x i32> %296 to <8 x double>
  %298 = fmul <8 x double> %284, %297
  %299 = add <8 x i32> %126, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %300 = sub <8 x i32> %299, %289
  %301 = bitcast <8 x i32> %300 to <4 x i64>
  %302 = shufflevector <4 x i64> %301, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %303 = bitcast <8 x i64> %302 to <16 x i32>
  %304 = shufflevector <16 x i32> %303, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %305 = shufflevector <16 x i32> %304, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %306 = shl <16 x i32> %305, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %307 = bitcast <16 x i32> %306 to <8 x double>
  %308 = fmul <8 x double> %298, %307
  %309 = fmul <8 x double> %288, %297
  %310 = fmul <8 x double> %309, %307
  %311 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %94, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %312 = bitcast i8 %311 to <8 x i1>
  %313 = bitcast <8 x double> %308 to <8 x i64>
  %314 = xor <8 x i64> %313, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %315 = bitcast <8 x double> %310 to <8 x i64>
  %316 = xor <8 x i64> %315, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %317 = bitcast <8 x i64> %314 to <8 x double>
  %318 = select <8 x i1> %312, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %317
  %319 = bitcast <8 x i64> %316 to <8 x double>
  %320 = select <8 x i1> %312, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %319
  %321 = fadd <8 x double> %318, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %322 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %321
  %323 = fadd <8 x double> %318, %322
  %324 = fadd <8 x double> %323, %320
  %325 = select <8 x i1> %9, <8 x double> %109, <8 x double> %321
  %326 = select <8 x i1> %9, <8 x double> %122, <8 x double> %324
  %327 = fadd <8 x double> %325, %326
  %328 = bitcast i8 %7 to <8 x i1>
  %329 = bitcast <8 x double> %327 to <8 x i64>
  %330 = select <8 x i1> %328, <8 x i64> %329, <8 x i64> <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>
  %331 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %332 = xor <8 x i64> %330, %331
  %333 = bitcast <8 x i64> %332 to <8 x double>
  %334 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> %4, i32 4, i8 -1, i32 4) #7
  %335 = bitcast i8 %334 to <8 x i1>
  %336 = select <8 x i1> %335, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %333
  ret <8 x double> %336
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_erfcd8_u15avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, i32 17, i8 -1, i32 4) #7
  %6 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00, double 2.200000e+00>, i32 17, i8 -1, i32 4) #7
  %7 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00, double 4.200000e+00>, i32 17, i8 -1, i32 4) #7
  %8 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01, double 2.730000e+01>, i32 17, i8 -1, i32 4) #7
  %9 = and <8 x i64> %2, <i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080, i64 9223372036720558080>
  %10 = bitcast <8 x i64> %9 to <8 x double>
  %11 = fsub <8 x double> %4, %10
  %12 = fmul <8 x double> %4, %4
  %13 = fmul <8 x double> %10, %10
  %14 = bitcast <8 x double> %12 to <8 x i64>
  %15 = xor <8 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %16 = bitcast <8 x i64> %15 to <8 x double>
  %17 = fmul <8 x double> %11, %10
  %18 = fmul <8 x double> %11, %11
  %19 = fadd <8 x double> %13, %16
  %20 = fadd <8 x double> %17, %19
  %21 = fadd <8 x double> %17, %20
  %22 = fadd <8 x double> %18, %21
  %23 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %4
  %24 = bitcast <8 x double> %23 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = fsub <8 x double> %23, %26
  %28 = fsub <8 x double> %26, %23
  %29 = fmul <8 x double> %26, zeroinitializer
  %30 = fmul <8 x double> %27, zeroinitializer
  %31 = fmul <8 x double> %10, %26
  %32 = fmul <8 x double> %27, %10
  %33 = fmul <8 x double> %11, %26
  %34 = fmul <8 x double> %11, %27
  %35 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %31
  %36 = fsub <8 x double> %35, %32
  %37 = fsub <8 x double> %36, %33
  %38 = fsub <8 x double> %37, %34
  %39 = fmul <8 x double> %23, %38
  %40 = fadd <8 x double> %28, %27
  %41 = fadd <8 x double> %29, %40
  %42 = fadd <8 x double> %30, %41
  %43 = fadd <8 x double> %42, %39
  %44 = fmul <8 x double> %23, zeroinitializer
  %45 = fsub <8 x double> zeroinitializer, %44
  %46 = fmul <8 x double> %23, %45
  %47 = fadd <8 x double> %46, %43
  %48 = bitcast i8 %6 to <8 x i1>
  %49 = select <8 x i1> %48, <8 x double> %4, <8 x double> %23
  %50 = select <8 x i1> %48, <8 x double> zeroinitializer, <8 x double> %47
  %51 = bitcast i8 %5 to <8 x i1>
  %52 = select <8 x i1> %51, <8 x double> %12, <8 x double> %49
  %53 = select <8 x i1> %51, <8 x double> %22, <8 x double> %50
  %54 = bitcast i8 %7 to <8 x i1>
  %55 = select <8 x i1> %54, <8 x i64> <i64 2, i64 2, i64 2, i64 2, i64 2, i64 2, i64 2, i64 2>, <8 x i64> <i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3>
  %56 = select <8 x i1> %48, <8 x i64> <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>, <8 x i64> %55
  %57 = select <8 x i1> %51, <8 x i64> zeroinitializer, <8 x i64> %56
  %58 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3BC00EFEFABE9897, double 0x3D58315E6C186224, double 0xC04CCA024E41FBF2, double 0x40D6CB9FD3B439A9, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %59 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBC0FE6EC06B043F2, double 0xBDAB33CF696F6246, double 0x407D2EDD0AE020CC, double 0xC0E6ED9388CD091B, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %60 = fmul <8 x double> %58, %52
  %61 = fadd <8 x double> %60, %59
  %62 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3C55A7F67BDE0C13, double 0x3DED1C000C3FE200, double 0xC09C1151CBEBE895, double 0x40DEFD81FD565E63, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %63 = fmul <8 x double> %52, %61
  %64 = fadd <8 x double> %62, %63
  %65 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBC9A15164BF4F369, double 0xBE23ACFF2B1B8BEC, double 0x40B103E466CE6960, double 0x40A955F72FDA349C, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %66 = fmul <8 x double> %52, %64
  %67 = fadd <8 x double> %65, %66
  %68 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3CDD6F95068FEEA4, double 0x3E52C76D37FDB57D, double 0xC0BD20424648FD63, double 0xC0D3ACCB8514AB13, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %69 = fmul <8 x double> %52, %67
  %70 = fadd <8 x double> %68, %69
  %71 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBD1F56D9FF51274F, double 0xBE7ABA200DE4015C, double 0x40C2A8FD1A1289EB, double 0x40CE5A08EC3F1AF9, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %72 = fmul <8 x double> %52, %70
  %73 = fadd <8 x double> %71, %72
  %74 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3D5F683984140301, double 0x3E9D0EE6A4A80D73, double 0xC0C27F028C42F7FD, double 0xC0B806DFCAF3E8F0, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %75 = fmul <8 x double> %52, %73
  %76 = fadd <8 x double> %74, %75
  %77 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBD9D8453B9E7FD78, double 0xBEB8137ED27E2624, double 0x40BCDB58257A0C6D, double 0x40936030E9797DA0, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %78 = fmul <8 x double> %52, %76
  %79 = fadd <8 x double> %77, %78
  %80 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3DD9E6AD5DAB7037, double 0x3ECD0697CBB9A376, double 0xC0B1CDB68AB7C4E4, double 0xC054869BB9D7AF08, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %81 = fmul <8 x double> %52, %79
  %82 = fadd <8 x double> %80, %81
  %83 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBE151D7181C08BA0, double 0xBED4ECCCA37D22C1, double 0x40A13FBBE32520BC, double 0x4040365402C89D37, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %84 = fmul <8 x double> %52, %82
  %85 = fadd <8 x double> %83, %84
  %86 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3E4FCC572062092A, double 0xBEB5F5266774B791, double 0xC089AE616A35F399, double 0xC03D3BF3C95EBAA1, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %87 = fmul <8 x double> %52, %85
  %88 = fadd <8 x double> %86, %87
  %89 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBE85F742EC43E5BC, double 0x3EFD9F88B02EA0EC, double 0x406C5BB5D950D59F, double 0x3FD620B48EBD7FD2, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %90 = fmul <8 x double> %52, %88
  %91 = fadd <8 x double> %89, %90
  %92 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3EBB9E6C9DC6519D, double 0xBF10C2E202FB0D80, double 0xC0472AB3D15A1B99, double 0x4015F57BD26EB8D7, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %93 = fmul <8 x double> %52, %91
  %94 = fadd <8 x double> %92, %93
  %95 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBEEF4D25C3E0C2E2, double 0xBEFAE939BE608207, double 0x40231D60ED75C166, double 0x3F598ED6853E65C9, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %96 = fmul <8 x double> %52, %94
  %97 = fadd <8 x double> %95, %96
  %98 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F1F9A326F9B89C2, double 0x3F4351BFC5997AEF, double 0xC007AADCFF61A9EE, double 0xBFF8AAF93486CD89, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %99 = fmul <8 x double> %52, %97
  %100 = fadd <8 x double> %98, %99
  %101 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF4C02DB40040B83, double 0xBF5BC858BD2C3DEE, double 0x3FC56155F28A44A2, double 0x3EC7AEAC5A2C6C34, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %102 = fmul <8 x double> %52, %100
  %103 = fadd <8 x double> %101, %102
  %104 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3F7565BCD0E6A53F, double 0x3F2B61E95A64E1B4, double 0x3FE38258FA079AD9, double 0x3FE3FFFFD433AA8A, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %105 = fmul <8 x double> %52, %103
  %106 = fadd <8 x double> %104, %105
  %107 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBF9B82CE31288B51, double 0x3F93966FE5D12A2E, double 0x3F515AA8B364E28B, double 0x3E1DEC4B817418DD, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %108 = fmul <8 x double> %52, %106
  %109 = fadd <8 x double> %107, %108
  %110 = bitcast <8 x double> %52 to <8 x i64>
  %111 = and <8 x i64> %110, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %112 = bitcast <8 x i64> %111 to <8 x double>
  %113 = fsub <8 x double> %52, %112
  %114 = bitcast <8 x double> %109 to <8 x i64>
  %115 = and <8 x i64> %114, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %116 = bitcast <8 x i64> %115 to <8 x double>
  %117 = fsub <8 x double> %109, %116
  %118 = fmul <8 x double> %52, %109
  %119 = fmul <8 x double> %112, %116
  %120 = bitcast <8 x double> %118 to <8 x i64>
  %121 = xor <8 x i64> %120, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %122 = bitcast <8 x i64> %121 to <8 x double>
  %123 = fmul <8 x double> %113, %116
  %124 = fmul <8 x double> %117, %112
  %125 = fmul <8 x double> %113, %117
  %126 = fmul <8 x double> %53, %109
  %127 = fadd <8 x double> %119, %122
  %128 = fadd <8 x double> %123, %127
  %129 = fadd <8 x double> %124, %128
  %130 = fadd <8 x double> %125, %129
  %131 = fadd <8 x double> %126, %130
  %132 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FBCE2F21A042BE2, double 0xBFBA4F4EAB8311A0, double 0xBFE0006CA4753FC8, double 0xBFE0000000038D52, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %133 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBC52871BC5EF8ED7, double 0xBC5CBFA8068241AE, double 0x3C7E64BB064EBF0B, double 0xBC8719E29ACB2723, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %134 = fadd <8 x double> %132, %118
  %135 = fsub <8 x double> %134, %118
  %136 = fsub <8 x double> %134, %135
  %137 = fsub <8 x double> %118, %136
  %138 = fsub <8 x double> %132, %135
  %139 = fadd <8 x double> %138, %137
  %140 = fadd <8 x double> %133, %131
  %141 = fadd <8 x double> %139, %140
  %142 = bitcast <8 x double> %134 to <8 x i64>
  %143 = and <8 x i64> %142, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %144 = bitcast <8 x i64> %143 to <8 x double>
  %145 = fsub <8 x double> %134, %144
  %146 = fmul <8 x double> %52, %134
  %147 = fmul <8 x double> %112, %144
  %148 = bitcast <8 x double> %146 to <8 x i64>
  %149 = xor <8 x i64> %148, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %150 = bitcast <8 x i64> %149 to <8 x double>
  %151 = fmul <8 x double> %145, %112
  %152 = fmul <8 x double> %113, %144
  %153 = fmul <8 x double> %113, %145
  %154 = fmul <8 x double> %53, %134
  %155 = fmul <8 x double> %52, %141
  %156 = fadd <8 x double> %147, %150
  %157 = fadd <8 x double> %151, %156
  %158 = fadd <8 x double> %152, %157
  %159 = fadd <8 x double> %153, %158
  %160 = fadd <8 x double> %154, %159
  %161 = fadd <8 x double> %160, %155
  %162 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0xBFD812746B0379E7, double 0xBFE45F306B230D62, double 0x3EBADCB2F72A1080, double 0x3D50B89397C75A64, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %163 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3C6EE12E49CAD52E, double 0x3C619932A20CE10B, double 0x3B2CF38C548C5245, double 0xB9ED96501FDC09B6, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %164 = fadd <8 x double> %162, %146
  %165 = fsub <8 x double> %164, %146
  %166 = fsub <8 x double> %164, %165
  %167 = fsub <8 x double> %146, %166
  %168 = fsub <8 x double> %162, %165
  %169 = fadd <8 x double> %168, %167
  %170 = fadd <8 x double> %163, %161
  %171 = fadd <8 x double> %169, %170
  %172 = bitcast <8 x double> %164 to <8 x i64>
  %173 = and <8 x i64> %172, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %174 = bitcast <8 x i64> %173 to <8 x double>
  %175 = fsub <8 x double> %164, %174
  %176 = fmul <8 x double> %52, %164
  %177 = fmul <8 x double> %112, %174
  %178 = bitcast <8 x double> %176 to <8 x i64>
  %179 = xor <8 x i64> %178, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %180 = bitcast <8 x i64> %179 to <8 x double>
  %181 = fmul <8 x double> %175, %112
  %182 = fmul <8 x double> %113, %174
  %183 = fmul <8 x double> %113, %175
  %184 = fmul <8 x double> %53, %164
  %185 = fmul <8 x double> %52, %171
  %186 = fadd <8 x double> %177, %180
  %187 = fadd <8 x double> %181, %186
  %188 = fadd <8 x double> %182, %187
  %189 = fadd <8 x double> %183, %188
  %190 = fadd <8 x double> %184, %189
  %191 = fadd <8 x double> %190, %185
  %192 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3FF20DD750429B6D, double 0xBFF20DD7505C75E8, double 0xBFE250D055891FD0, double 0xBFE250D048E7A1C6, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %193 = tail call <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double> <double 0x3C71AE3A914FED6D, double 0x3C9751223FE9154D, double 0x3C81B3313996DEA7, double 0xBC7BA6EE6A6AB496, double undef, double undef, double undef, double undef>, <8 x i64> %57, <8 x double> zeroinitializer, i8 -1) #7
  %194 = fadd <8 x double> %192, %176
  %195 = fsub <8 x double> %194, %176
  %196 = fsub <8 x double> %194, %195
  %197 = fsub <8 x double> %176, %196
  %198 = fsub <8 x double> %192, %195
  %199 = fadd <8 x double> %198, %197
  %200 = fadd <8 x double> %193, %191
  %201 = fadd <8 x double> %199, %200
  %202 = or <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %203 = bitcast <8 x i64> %202 to <8 x double>
  %204 = select <8 x i1> %48, <8 x double> %194, <8 x double> %203
  %205 = select <8 x i1> %48, <8 x double> %201, <8 x double> zeroinitializer
  %206 = bitcast <8 x double> %204 to <8 x i64>
  %207 = and <8 x i64> %206, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %208 = bitcast <8 x i64> %207 to <8 x double>
  %209 = fsub <8 x double> %204, %208
  %210 = fmul <8 x double> %204, %4
  %211 = fmul <8 x double> %10, %208
  %212 = bitcast <8 x double> %210 to <8 x i64>
  %213 = xor <8 x i64> %212, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %214 = bitcast <8 x i64> %213 to <8 x double>
  %215 = fmul <8 x double> %209, %10
  %216 = fmul <8 x double> %11, %208
  %217 = fmul <8 x double> %11, %209
  %218 = fmul <8 x double> %205, %4
  %219 = fadd <8 x double> %211, %214
  %220 = fadd <8 x double> %215, %219
  %221 = fadd <8 x double> %216, %220
  %222 = fadd <8 x double> %217, %221
  %223 = fadd <8 x double> %222, %218
  %224 = fadd <8 x double> %194, %210
  %225 = fsub <8 x double> %224, %210
  %226 = fsub <8 x double> %224, %225
  %227 = fsub <8 x double> %210, %226
  %228 = fsub <8 x double> %194, %225
  %229 = fadd <8 x double> %228, %227
  %230 = fadd <8 x double> %201, %223
  %231 = fadd <8 x double> %229, %230
  %232 = select <8 x i1> %48, <8 x double> %210, <8 x double> %224
  %233 = select <8 x i1> %48, <8 x double> %223, <8 x double> %231
  %234 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %232
  %235 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %234
  %236 = fsub <8 x double> %235, %232
  %237 = fadd <8 x double> %236, zeroinitializer
  %238 = fsub <8 x double> %237, %233
  %239 = fadd <8 x double> %232, %233
  %240 = fmul <8 x double> %239, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %241 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %240, i32 8, <8 x double> %240, i8 -1, i32 4) #7
  %242 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %241, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %243 = fmul <8 x double> %241, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %244 = fadd <8 x double> %243, %232
  %245 = fsub <8 x double> %244, %232
  %246 = fsub <8 x double> %244, %245
  %247 = fsub <8 x double> %232, %246
  %248 = fsub <8 x double> %243, %245
  %249 = fadd <8 x double> %248, %247
  %250 = fadd <8 x double> %249, %233
  %251 = fmul <8 x double> %241, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %252 = fadd <8 x double> %251, %244
  %253 = fsub <8 x double> %252, %244
  %254 = fsub <8 x double> %252, %253
  %255 = fsub <8 x double> %244, %254
  %256 = fsub <8 x double> %251, %253
  %257 = fadd <8 x double> %256, %255
  %258 = fadd <8 x double> %257, %250
  %259 = bitcast <8 x double> %252 to <8 x i64>
  %260 = and <8 x i64> %259, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %261 = bitcast <8 x i64> %260 to <8 x double>
  %262 = fsub <8 x double> %252, %261
  %263 = fmul <8 x double> %252, %252
  %264 = fmul <8 x double> %261, %261
  %265 = bitcast <8 x double> %263 to <8 x i64>
  %266 = xor <8 x i64> %265, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %267 = bitcast <8 x i64> %266 to <8 x double>
  %268 = fadd <8 x double> %261, %261
  %269 = fmul <8 x double> %268, %262
  %270 = fmul <8 x double> %262, %262
  %271 = fadd <8 x double> %258, %258
  %272 = fmul <8 x double> %252, %271
  %273 = fadd <8 x double> %264, %267
  %274 = fadd <8 x double> %273, %269
  %275 = fadd <8 x double> %270, %274
  %276 = fadd <8 x double> %275, %272
  %277 = and <8 x i64> %265, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %278 = bitcast <8 x i64> %277 to <8 x double>
  %279 = fsub <8 x double> %263, %278
  %280 = fmul <8 x double> %263, %263
  %281 = fmul <8 x double> %278, %278
  %282 = bitcast <8 x double> %280 to <8 x i64>
  %283 = xor <8 x i64> %282, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %284 = bitcast <8 x i64> %283 to <8 x double>
  %285 = fadd <8 x double> %278, %278
  %286 = fmul <8 x double> %285, %279
  %287 = fmul <8 x double> %279, %279
  %288 = fadd <8 x double> %276, %276
  %289 = fmul <8 x double> %263, %288
  %290 = fadd <8 x double> %281, %284
  %291 = fadd <8 x double> %290, %286
  %292 = fadd <8 x double> %287, %291
  %293 = fadd <8 x double> %292, %289
  %294 = fmul <8 x double> %280, %280
  %295 = fmul <8 x double> %252, <double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C, double 0x3DE60632A887194C>
  %296 = fadd <8 x double> %295, <double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC, double 0x3E21F8EAF54829DC>
  %297 = fmul <8 x double> %252, <double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6, double 0x3E5AE652E8103AB6>
  %298 = fadd <8 x double> %297, <double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C, double 0x3E927E4C95A9765C>
  %299 = fmul <8 x double> %252, <double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656, double 0x3EC71DE3A11D7656>
  %300 = fadd <8 x double> %299, <double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7, double 0x3EFA01A01AF6F0B7>
  %301 = fmul <8 x double> %263, %298
  %302 = fadd <8 x double> %300, %301
  %303 = fmul <8 x double> %252, <double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002, double 0x3F2A01A01A02D002>
  %304 = fadd <8 x double> %303, <double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC, double 0x3F56C16C16C145CC>
  %305 = fmul <8 x double> %252, <double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119, double 0x3F81111111111119>
  %306 = fadd <8 x double> %305, <double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A, double 0x3FA555555555555A>
  %307 = fmul <8 x double> %263, %304
  %308 = fadd <8 x double> %306, %307
  %309 = fmul <8 x double> %280, %302
  %310 = fadd <8 x double> %308, %309
  %311 = fmul <8 x double> %296, %294
  %312 = fadd <8 x double> %311, %310
  %313 = fmul <8 x double> %252, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %314 = fmul <8 x double> %261, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %315 = bitcast <8 x double> %313 to <8 x i64>
  %316 = xor <8 x i64> %315, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %317 = bitcast <8 x i64> %316 to <8 x double>
  %318 = fmul <8 x double> %262, <double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000, double 0x3FC5555550000000>
  %319 = fmul <8 x double> %261, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %320 = fmul <8 x double> %262, <double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000, double 0x3E25555554000000>
  %321 = fmul <8 x double> %258, <double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555, double 0x3FC5555555555555>
  %322 = fadd <8 x double> %314, %317
  %323 = fadd <8 x double> %318, %322
  %324 = fadd <8 x double> %319, %323
  %325 = fadd <8 x double> %320, %324
  %326 = fadd <8 x double> %325, %321
  %327 = fadd <8 x double> %313, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %328 = fsub <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %327
  %329 = fadd <8 x double> %313, %328
  %330 = fadd <8 x double> %329, %326
  %331 = bitcast <8 x double> %327 to <8 x i64>
  %332 = and <8 x i64> %331, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %333 = bitcast <8 x i64> %332 to <8 x double>
  %334 = fsub <8 x double> %327, %333
  %335 = fmul <8 x double> %252, %327
  %336 = fmul <8 x double> %261, %333
  %337 = bitcast <8 x double> %335 to <8 x i64>
  %338 = xor <8 x i64> %337, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %339 = bitcast <8 x i64> %338 to <8 x double>
  %340 = fmul <8 x double> %334, %261
  %341 = fmul <8 x double> %262, %333
  %342 = fmul <8 x double> %262, %334
  %343 = fmul <8 x double> %327, %258
  %344 = fmul <8 x double> %252, %330
  %345 = fadd <8 x double> %336, %339
  %346 = fadd <8 x double> %340, %345
  %347 = fadd <8 x double> %341, %346
  %348 = fadd <8 x double> %342, %347
  %349 = fadd <8 x double> %348, %343
  %350 = fadd <8 x double> %349, %344
  %351 = fadd <8 x double> %335, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %352 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %351
  %353 = fadd <8 x double> %335, %352
  %354 = fadd <8 x double> %353, %350
  %355 = bitcast <8 x double> %351 to <8 x i64>
  %356 = and <8 x i64> %355, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %357 = bitcast <8 x i64> %356 to <8 x double>
  %358 = fsub <8 x double> %351, %357
  %359 = fmul <8 x double> %252, %351
  %360 = fmul <8 x double> %261, %357
  %361 = bitcast <8 x double> %359 to <8 x i64>
  %362 = xor <8 x i64> %361, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %363 = bitcast <8 x i64> %362 to <8 x double>
  %364 = fmul <8 x double> %358, %261
  %365 = fmul <8 x double> %262, %357
  %366 = fmul <8 x double> %262, %358
  %367 = fmul <8 x double> %351, %258
  %368 = fmul <8 x double> %252, %354
  %369 = fadd <8 x double> %360, %363
  %370 = fadd <8 x double> %364, %369
  %371 = fadd <8 x double> %365, %370
  %372 = fadd <8 x double> %366, %371
  %373 = fadd <8 x double> %372, %367
  %374 = fadd <8 x double> %373, %368
  %375 = fadd <8 x double> %359, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %376 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %375
  %377 = fadd <8 x double> %359, %376
  %378 = fadd <8 x double> %377, %374
  %379 = and <8 x i64> %282, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %380 = bitcast <8 x i64> %379 to <8 x double>
  %381 = fsub <8 x double> %280, %380
  %382 = bitcast <8 x double> %312 to <8 x i64>
  %383 = and <8 x i64> %382, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %384 = bitcast <8 x i64> %383 to <8 x double>
  %385 = fsub <8 x double> %312, %384
  %386 = fmul <8 x double> %280, %312
  %387 = fmul <8 x double> %380, %384
  %388 = bitcast <8 x double> %386 to <8 x i64>
  %389 = xor <8 x i64> %388, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %390 = bitcast <8 x i64> %389 to <8 x double>
  %391 = fmul <8 x double> %381, %384
  %392 = fmul <8 x double> %385, %380
  %393 = fmul <8 x double> %381, %385
  %394 = fmul <8 x double> %312, %293
  %395 = fadd <8 x double> %387, %390
  %396 = fadd <8 x double> %391, %395
  %397 = fadd <8 x double> %392, %396
  %398 = fadd <8 x double> %393, %397
  %399 = fadd <8 x double> %398, %394
  %400 = fadd <8 x double> %375, %386
  %401 = fsub <8 x double> %375, %400
  %402 = fadd <8 x double> %386, %401
  %403 = fadd <8 x double> %402, %378
  %404 = fadd <8 x double> %399, %403
  %405 = ashr <8 x i32> %242, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %406 = add nsw <8 x i32> %405, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %407 = bitcast <8 x i32> %406 to <4 x i64>
  %408 = shufflevector <4 x i64> %407, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %409 = bitcast <8 x i64> %408 to <16 x i32>
  %410 = shufflevector <16 x i32> %409, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %411 = shufflevector <16 x i32> %410, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %412 = shl <16 x i32> %411, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %413 = bitcast <16 x i32> %412 to <8 x double>
  %414 = fmul <8 x double> %400, %413
  %415 = add <8 x i32> %242, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %416 = sub <8 x i32> %415, %405
  %417 = bitcast <8 x i32> %416 to <4 x i64>
  %418 = shufflevector <4 x i64> %417, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %419 = bitcast <8 x i64> %418 to <16 x i32>
  %420 = shufflevector <16 x i32> %419, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %421 = shufflevector <16 x i32> %420, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %422 = shl <16 x i32> %421, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %423 = bitcast <16 x i32> %422 to <8 x double>
  %424 = fmul <8 x double> %414, %423
  %425 = fmul <8 x double> %404, %413
  %426 = fmul <8 x double> %425, %423
  %427 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %232, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %428 = bitcast i8 %427 to <8 x i1>
  %429 = select <8 x i1> %428, <8 x double> zeroinitializer, <8 x double> %424
  %430 = select <8 x i1> %428, <8 x double> zeroinitializer, <8 x double> %426
  %431 = select <8 x i1> %51, <8 x double> %234, <8 x double> %429
  %432 = select <8 x i1> %51, <8 x double> %238, <8 x double> %430
  %433 = bitcast <8 x double> %431 to <8 x i64>
  %434 = and <8 x i64> %433, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %435 = bitcast <8 x i64> %434 to <8 x double>
  %436 = fsub <8 x double> %431, %435
  %437 = fmul <8 x double> %52, %431
  %438 = fmul <8 x double> %112, %435
  %439 = bitcast <8 x double> %437 to <8 x i64>
  %440 = xor <8 x i64> %439, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %441 = bitcast <8 x i64> %440 to <8 x double>
  %442 = fmul <8 x double> %436, %112
  %443 = fmul <8 x double> %113, %435
  %444 = fmul <8 x double> %113, %436
  %445 = fmul <8 x double> %53, %431
  %446 = fmul <8 x double> %52, %432
  %447 = fadd <8 x double> %438, %441
  %448 = fadd <8 x double> %442, %447
  %449 = fadd <8 x double> %443, %448
  %450 = fadd <8 x double> %444, %449
  %451 = fadd <8 x double> %445, %450
  %452 = fadd <8 x double> %451, %446
  %453 = select <8 x i1> %48, <8 x double> %431, <8 x double> %437
  %454 = select <8 x i1> %48, <8 x double> %432, <8 x double> %452
  %455 = fadd <8 x double> %453, %454
  %456 = bitcast i8 %8 to <8 x i1>
  %457 = select <8 x i1> %456, <8 x double> %455, <8 x double> zeroinitializer
  %458 = icmp slt <8 x i64> %2, zeroinitializer
  %459 = fsub <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %457
  %460 = select <8 x i1> %458, <8 x double> %459, <8 x double> %457
  %461 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %462 = bitcast i8 %461 to <8 x i1>
  %463 = select <8 x i1> %462, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %460
  ret <8 x double> %463
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_sincospid8_u05avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  tail call void @Sleef_sincospid8_u05avx512fnofma(%struct.vdouble2* sret %0, <8 x double> %1)
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_sincospid8_u35avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = fmul <8 x double> %1, <double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00, double 4.000000e+00>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = lshr <8 x i32> %4, <i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31, i32 31>
  %6 = xor <8 x i32> %5, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %7 = add <8 x i32> %6, %4
  %8 = bitcast <8 x i32> %7 to <4 x i64>
  %9 = and <8 x i32> %7, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %10 = sitofp <8 x i32> %9 to <8 x double>
  %11 = fsub <8 x double> %3, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %12, <double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C, double 0x3D9E42E923057D6C>
  %14 = fadd <8 x double> %13, <double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5, double 0xBE1E3011CA3F21B5>
  %15 = fmul <8 x double> %12, %14
  %16 = fadd <8 x double> %15, <double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C, double 0x3E9507830918116C>
  %17 = fmul <8 x double> %12, %16
  %18 = fadd <8 x double> %17, <double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE, double 0xBF032D2CCE398CAE>
  %19 = fmul <8 x double> %12, %18
  %20 = fadd <8 x double> %19, <double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5, double 0x3F6466BC677591C5>
  %21 = fmul <8 x double> %12, %20
  %22 = fadd <8 x double> %21, <double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43, double 0xBFB4ABBCE625BE43>
  %23 = fmul <8 x double> %12, %22
  %24 = fadd <8 x double> %23, <double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18, double 0x3FE921FB54442D18>
  %25 = fmul <8 x double> %11, %24
  %26 = fmul <8 x double> %12, <double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3, double 0xBD5B29CFED2A85B3>
  %27 = fadd <8 x double> %26, <double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD, double 0x3DDF9CD01C42C7CD>
  %28 = fmul <8 x double> %12, %27
  %29 = fadd <8 x double> %28, <double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707, double 0xBE5A6D1ED7B66707>
  %30 = fmul <8 x double> %12, %29
  %31 = fadd <8 x double> %30, <double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332, double 0x3ECE1F50684AD332>
  %32 = fmul <8 x double> %12, %31
  %33 = fadd <8 x double> %32, <double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF, double 0xBF355D3C7E3C9FCF>
  %34 = fmul <8 x double> %12, %33
  %35 = fadd <8 x double> %34, <double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA, double 0x3F903C1F081B5AAA>
  %36 = fmul <8 x double> %12, %35
  %37 = fadd <8 x double> %36, <double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE, double 0xBFD3BD3CC9BE45DE>
  %38 = fmul <8 x double> %12, %37
  %39 = fadd <8 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %40 = and <4 x i64> %8, <i64 8589934594, i64 8589934594, i64 8589934594, i64 8589934594>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = bitcast <8 x i64> %41 to <16 x i32>
  %43 = icmp eq <16 x i32> %42, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %44 = bitcast <16 x i1> %43 to <2 x i8>
  %45 = extractelement <2 x i8> %44, i32 0
  %46 = bitcast i8 %45 to <8 x i1>
  %47 = select <8 x i1> %46, <8 x double> %25, <8 x double> %39
  %48 = select <8 x i1> %46, <8 x double> %39, <8 x double> %25
  %49 = and <4 x i64> %8, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %50 = shufflevector <4 x i64> %49, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %51 = bitcast <8 x i64> %50 to <16 x i32>
  %52 = icmp eq <16 x i32> %51, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %53 = bitcast <16 x i1> %52 to <2 x i8>
  %54 = extractelement <2 x i8> %53, i32 0
  %55 = bitcast i8 %54 to <8 x i1>
  %56 = select <8 x i1> %55, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %57 = bitcast <8 x double> %47 to <8 x i64>
  %58 = xor <8 x i64> %56, %57
  %59 = add <8 x i32> %9, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2>
  %60 = bitcast <8 x i32> %59 to <4 x i64>
  %61 = and <4 x i64> %60, <i64 17179869188, i64 17179869188, i64 17179869188, i64 17179869188>
  %62 = shufflevector <4 x i64> %61, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %63 = bitcast <8 x i64> %62 to <16 x i32>
  %64 = icmp eq <16 x i32> %63, <i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 4, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <16 x i1> %64 to <2 x i8>
  %66 = extractelement <2 x i8> %65, i32 0
  %67 = bitcast i8 %66 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x i64> <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>, <8 x i64> zeroinitializer
  %69 = bitcast <8 x double> %48 to <8 x i64>
  %70 = xor <8 x i64> %68, %69
  %71 = bitcast <8 x double> %1 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %73, <8 x double> <double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08, double 2.500000e+08>, i32 30, i8 -1, i32 4) #7
  %75 = bitcast i8 %74 to <8 x i1>
  %76 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %73, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %77 = bitcast i8 %76 to <8 x i1>
  %78 = bitcast <8 x i64> %58 to <8 x double>
  %79 = select <8 x i1> %75, <8 x double> zeroinitializer, <8 x double> %78
  %80 = select <8 x i1> %77, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %79
  %81 = bitcast <8 x i64> %70 to <8 x double>
  %82 = select <8 x i1> %75, <8 x double> zeroinitializer, <8 x double> %81
  %83 = select <8 x i1> %77, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %82
  %84 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 0
  store <8 x double> %80, <8 x double>* %84, align 64, !alias.scope !27
  %85 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  store <8 x double> %83, <8 x double>* %85, align 64, !alias.scope !27
  ret void
}

; Function Attrs: nounwind uwtable
define void @Sleef_cinz_modfd8_avx512fnofma(%struct.vdouble2* noalias nocapture sret, <8 x double>) local_unnamed_addr #3 {
  %3 = fmul <8 x double> %1, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = sitofp <8 x i32> %4 to <8 x double>
  %6 = fmul <8 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <8 x double> %1, %6
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %9 = sitofp <8 x i32> %8 to <8 x double>
  %10 = fsub <8 x double> %7, %9
  %11 = bitcast <8 x double> %1 to <8 x i64>
  %12 = and <8 x i64> %11, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <8 x i64> %12 to <8 x double>
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 30, i8 -1, i32 4) #7
  %15 = bitcast i8 %14 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> zeroinitializer, <8 x double> %10
  %17 = bitcast <8 x double> %16 to <8 x i64>
  %18 = and <8 x i64> %17, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %19 = and <8 x i64> %11, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %20 = or <8 x i64> %18, %19
  %21 = fsub <8 x double> %1, %16
  %22 = bitcast <8 x double> %21 to <8 x i64>
  %23 = and <8 x i64> %22, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %24 = or <8 x i64> %23, %19
  %25 = bitcast %struct.vdouble2* %0 to <8 x i64>*
  store <8 x i64> %20, <8 x i64>* %25, align 64, !alias.scope !30
  %26 = getelementptr inbounds %struct.vdouble2, %struct.vdouble2* %0, i64 0, i32 1
  %27 = bitcast <8 x double>* %26 to <8 x i64>*
  store <8 x i64> %24, <8 x i64>* %27, align 64, !alias.scope !30
  ret void
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_logd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %7 = fadd <8 x double> %6, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %8 = fadd <8 x double> %6, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %9 = fdiv <8 x double> %7, %8
  %10 = fmul <8 x double> %9, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %9, %10
  %14 = fmul <8 x double> %10, <double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D, double 0x3FC385C5CBC3F50D>
  %15 = fadd <8 x double> %14, <double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F, double 0x3FC7474BA672B05F>
  %16 = fmul <8 x double> %11, <double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39, double 0x3FC3A5791D95DB39>
  %17 = fadd <8 x double> %16, %15
  %18 = fmul <8 x double> %10, <double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419, double 0x3FCC71BFEED5D419>
  %19 = fadd <8 x double> %18, <double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987, double 0x3FD249249BFBE987>
  %20 = fmul <8 x double> %10, <double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E, double 0x3FD99999998C136E>
  %21 = fadd <8 x double> %20, <double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F, double 0x3FE555555555593F>
  %22 = fmul <8 x double> %11, %19
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %12, %17
  %25 = fadd <8 x double> %24, %23
  %26 = fmul <8 x double> %3, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %27 = select <8 x i1> %5, <8 x double> <double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF, double 0x40862E42FEFA39EF>, <8 x double> %26
  %28 = fmul <8 x double> %9, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %29 = fadd <8 x double> %27, %28
  %30 = fmul <8 x double> %13, %25
  %31 = fadd <8 x double> %29, %30
  %32 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %31, <8 x double> %0, <8 x i64> <i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360, i64 22517998142095360>, i32 0, i8 -1, i32 4) #7
  ret <8 x double> %32
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_logd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %60 = fadd <8 x double> %59, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %61 = fmul <8 x double> %57, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %64 = fadd <8 x double> %63, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %65 = fmul <8 x double> %56, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %66 = fadd <8 x double> %65, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %6 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %6, %73
  %75 = fmul <8 x double> %6, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %76 = fmul <8 x double> %73, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %73, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %81 = fmul <8 x double> %74, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %82 = fmul <8 x double> %74, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %83 = fmul <8 x double> %6, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %84 = fadd <8 x double> %76, %79
  %85 = fadd <8 x double> %80, %84
  %86 = fadd <8 x double> %81, %85
  %87 = fadd <8 x double> %82, %86
  %88 = fadd <8 x double> %83, %87
  %89 = fmul <8 x double> %33, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %90 = fmul <8 x double> %55, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %91 = fadd <8 x double> %75, %89
  %92 = fsub <8 x double> %75, %91
  %93 = fadd <8 x double> %89, %92
  %94 = fadd <8 x double> %93, %88
  %95 = fadd <8 x double> %94, %90
  %96 = fmul <8 x double> %33, %56
  %97 = fmul <8 x double> %96, %70
  %98 = fadd <8 x double> %91, %97
  %99 = fsub <8 x double> %91, %98
  %100 = fadd <8 x double> %97, %99
  %101 = fadd <8 x double> %100, %95
  %102 = fadd <8 x double> %98, %101
  %103 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %102, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4) #7
  ret <8 x double> %103
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_powd8_u10avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call <8 x double> @Sleef_powd8_u10avx512fnofma(<8 x double> %0, <8 x double> %1)
  ret <8 x double> %3
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_sinhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_sinhd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_coshd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_coshd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_tanhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_tanhd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_sinhd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %5, i32 8, <8 x double> %5, i8 -1, i32 4) #7
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %8 = bitcast <8 x i32> %7 to <4 x i64>
  %9 = fmul <8 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %10 = fadd <8 x double> %9, %4
  %11 = fmul <8 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %12 = fadd <8 x double> %11, %10
  %13 = fmul <8 x double> %12, %12
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %14, %14
  %16 = fmul <8 x double> %12, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %17 = fadd <8 x double> %16, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %18 = fmul <8 x double> %12, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %19 = fadd <8 x double> %18, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %20 = fmul <8 x double> %12, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %21 = fadd <8 x double> %20, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %22 = fmul <8 x double> %13, %19
  %23 = fadd <8 x double> %21, %22
  %24 = fmul <8 x double> %12, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %25 = fadd <8 x double> %24, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %26 = fmul <8 x double> %12, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %27 = fadd <8 x double> %26, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %28 = fmul <8 x double> %13, %25
  %29 = fadd <8 x double> %27, %28
  %30 = fmul <8 x double> %14, %23
  %31 = fadd <8 x double> %29, %30
  %32 = fmul <8 x double> %17, %15
  %33 = fadd <8 x double> %32, %31
  %34 = fmul <8 x double> %12, %13
  %35 = fmul <8 x double> %34, %33
  %36 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %37 = fadd <8 x double> %36, %35
  %38 = fadd <8 x double> %12, %37
  %39 = shufflevector <4 x i64> %8, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %40 = bitcast <8 x i64> %39 to <16 x i32>
  %41 = icmp eq <16 x i32> %40, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = fadd <8 x double> %38, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %43 = ashr <8 x i32> %7, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %44 = add nsw <8 x i32> %43, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %45 = bitcast <8 x i32> %44 to <4 x i64>
  %46 = shufflevector <4 x i64> %45, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %47 = bitcast <8 x i64> %46 to <16 x i32>
  %48 = shufflevector <16 x i32> %47, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %49 = shufflevector <16 x i32> %48, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %50 = shl <16 x i32> %49, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %51 = bitcast <16 x i32> %50 to <8 x double>
  %52 = fmul <8 x double> %42, %51
  %53 = add <8 x i32> %7, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %54 = sub <8 x i32> %53, %43
  %55 = bitcast <8 x i32> %54 to <4 x i64>
  %56 = shufflevector <4 x i64> %55, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %57 = bitcast <8 x i64> %56 to <16 x i32>
  %58 = shufflevector <16 x i32> %57, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %59 = shufflevector <16 x i32> %58, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %60 = shl <16 x i32> %59, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %61 = bitcast <16 x i32> %60 to <8 x double>
  %62 = fmul <8 x double> %52, %61
  %63 = fadd <8 x double> %62, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %64 = bitcast <16 x i1> %41 to <2 x i8>
  %65 = extractelement <2 x i8> %64, i32 0
  %66 = bitcast i8 %65 to <8 x i1>
  %67 = select <8 x i1> %66, <8 x double> %38, <8 x double> %63
  %68 = fadd <8 x double> %67, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %69 = fadd <8 x double> %67, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %70 = fdiv <8 x double> %68, %69
  %71 = fmul <8 x double> %67, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %72 = fmul <8 x double> %71, %70
  %73 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i32 30, i8 -1, i32 4) #7
  %74 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %72, <8 x double> %72, i32 4, i8 -1, i32 4) #7
  %75 = or i8 %74, %73
  %76 = bitcast i8 %75 to <8 x i1>
  %77 = bitcast <8 x double> %72 to <8 x i64>
  %78 = select <8 x i1> %76, <8 x i64> <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>, <8 x i64> %77
  %79 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %80 = xor <8 x i64> %78, %79
  %81 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %82 = bitcast i8 %81 to <8 x i1>
  %83 = bitcast <8 x i64> %80 to <8 x double>
  %84 = select <8 x i1> %82, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %83
  ret <8 x double> %84
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_coshd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %6 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %5, i32 8, <8 x double> %5, i8 -1, i32 4) #7
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %8 = fmul <8 x double> %6, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %9 = fadd <8 x double> %8, %4
  %10 = fmul <8 x double> %6, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %11 = fadd <8 x double> %10, %9
  %12 = fmul <8 x double> %11, %11
  %13 = fmul <8 x double> %12, %12
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %11, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %16 = fadd <8 x double> %15, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %17 = fmul <8 x double> %11, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %18 = fadd <8 x double> %17, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %19 = fmul <8 x double> %11, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %20 = fadd <8 x double> %19, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %21 = fmul <8 x double> %12, %18
  %22 = fadd <8 x double> %20, %21
  %23 = fmul <8 x double> %11, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %24 = fadd <8 x double> %23, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %25 = fmul <8 x double> %11, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %26 = fadd <8 x double> %25, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %27 = fmul <8 x double> %12, %24
  %28 = fadd <8 x double> %26, %27
  %29 = fmul <8 x double> %13, %22
  %30 = fadd <8 x double> %28, %29
  %31 = fmul <8 x double> %16, %14
  %32 = fadd <8 x double> %31, %30
  %33 = fmul <8 x double> %11, %32
  %34 = fadd <8 x double> %33, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %35 = fmul <8 x double> %12, %34
  %36 = fadd <8 x double> %11, %35
  %37 = fadd <8 x double> %36, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %38 = ashr <8 x i32> %7, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %39 = add nsw <8 x i32> %38, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %40 = bitcast <8 x i32> %39 to <4 x i64>
  %41 = shufflevector <4 x i64> %40, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %42 = bitcast <8 x i64> %41 to <16 x i32>
  %43 = shufflevector <16 x i32> %42, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %44 = shufflevector <16 x i32> %43, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %45 = shl <16 x i32> %44, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %46 = bitcast <16 x i32> %45 to <8 x double>
  %47 = fmul <8 x double> %37, %46
  %48 = add <8 x i32> %7, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %49 = sub <8 x i32> %48, %38
  %50 = bitcast <8 x i32> %49 to <4 x i64>
  %51 = shufflevector <4 x i64> %50, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %52 = bitcast <8 x i64> %51 to <16 x i32>
  %53 = shufflevector <16 x i32> %52, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %54 = shufflevector <16 x i32> %53, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %55 = shl <16 x i32> %54, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %56 = bitcast <16 x i32> %55 to <8 x double>
  %57 = fmul <8 x double> %47, %56
  %58 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83, double 0x40862E42FE102C83>, i32 30, i8 -1, i32 4) #7
  %59 = bitcast i8 %58 to <8 x i1>
  %60 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03, double -1.000000e+03>, i32 17, i8 -1, i32 4) #7
  %61 = bitcast i8 %60 to <8 x i1>
  %62 = select <8 x i1> %59, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %57
  %63 = select <8 x i1> %61, <8 x double> zeroinitializer, <8 x double> %62
  %64 = fdiv <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>, %63
  %65 = fmul <8 x double> %63, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %66 = fadd <8 x double> %65, %64
  %67 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02, double 7.090000e+02>, i32 30, i8 -1, i32 4) #7
  %68 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %66, <8 x double> %66, i32 4, i8 -1, i32 4) #7
  %69 = or i8 %68, %67
  %70 = bitcast i8 %69 to <8 x i1>
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %72 = bitcast i8 %71 to <8 x i1>
  %73 = select <8 x i1> %70, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %66
  %74 = select <8 x i1> %72, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %73
  ret <8 x double> %74
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_tanhd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %6 = fmul <8 x double> %5, <double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE, double 0x3FF71547652B82FE>
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %6, i32 8, <8 x double> %6, i8 -1, i32 4) #7
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = bitcast <8 x i32> %8 to <4 x i64>
  %10 = fmul <8 x double> %7, <double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000, double 0xBFE62E42FEFA3000>
  %11 = fadd <8 x double> %5, %10
  %12 = fmul <8 x double> %7, <double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6, double 0xBD53DE6AF278ECE6>
  %13 = fadd <8 x double> %12, %11
  %14 = fmul <8 x double> %13, %13
  %15 = fmul <8 x double> %14, %14
  %16 = fmul <8 x double> %15, %15
  %17 = fmul <8 x double> %13, <double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775, double 0x3E21F0E4C4ECD775>
  %18 = fadd <8 x double> %17, <double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A, double 0x3E5AF68A28CC800A>
  %19 = fmul <8 x double> %13, <double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573, double 0x3E927E52E0FCD573>
  %20 = fadd <8 x double> %19, <double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE, double 0x3EC71DDF1629E6CE>
  %21 = fmul <8 x double> %13, <double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E, double 0x3EFA01A01780879E>
  %22 = fadd <8 x double> %21, <double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5, double 0x3F2A01A01B3603F5>
  %23 = fmul <8 x double> %14, %20
  %24 = fadd <8 x double> %22, %23
  %25 = fmul <8 x double> %13, <double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0, double 0x3F56C16C16C20BA0>
  %26 = fadd <8 x double> %25, <double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39, double 0x3F8111111110EB39>
  %27 = fmul <8 x double> %13, <double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E, double 0x3FA555555555553E>
  %28 = fadd <8 x double> %27, <double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C, double 0x3FC555555555555C>
  %29 = fmul <8 x double> %14, %26
  %30 = fadd <8 x double> %28, %29
  %31 = fmul <8 x double> %15, %24
  %32 = fadd <8 x double> %30, %31
  %33 = fmul <8 x double> %18, %16
  %34 = fadd <8 x double> %33, %32
  %35 = fmul <8 x double> %13, %14
  %36 = fmul <8 x double> %35, %34
  %37 = fmul <8 x double> %14, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %38 = fadd <8 x double> %37, %36
  %39 = fadd <8 x double> %13, %38
  %40 = shufflevector <4 x i64> %9, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <8 x i64> %40 to <16 x i32>
  %42 = icmp eq <16 x i32> %41, <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %43 = fadd <8 x double> %39, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %44 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %45 = add nsw <8 x i32> %44, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %46 = bitcast <8 x i32> %45 to <4 x i64>
  %47 = shufflevector <4 x i64> %46, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %48 = bitcast <8 x i64> %47 to <16 x i32>
  %49 = shufflevector <16 x i32> %48, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %50 = shufflevector <16 x i32> %49, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %51 = shl <16 x i32> %50, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %52 = bitcast <16 x i32> %51 to <8 x double>
  %53 = fmul <8 x double> %43, %52
  %54 = add <8 x i32> %8, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %55 = sub <8 x i32> %54, %44
  %56 = bitcast <8 x i32> %55 to <4 x i64>
  %57 = shufflevector <4 x i64> %56, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %58 = bitcast <8 x i64> %57 to <16 x i32>
  %59 = shufflevector <16 x i32> %58, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %60 = shufflevector <16 x i32> %59, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %61 = shl <16 x i32> %60, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %62 = bitcast <16 x i32> %61 to <8 x double>
  %63 = fmul <8 x double> %53, %62
  %64 = fadd <8 x double> %63, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %65 = bitcast <16 x i1> %42 to <2 x i8>
  %66 = extractelement <2 x i8> %65, i32 0
  %67 = bitcast i8 %66 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x double> %39, <8 x double> %64
  %69 = fadd <8 x double> %68, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %70 = fdiv <8 x double> %68, %69
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90, double 0x4032B70887229E90>, i32 30, i8 -1, i32 4) #7
  %72 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %70, <8 x double> %70, i32 4, i8 -1, i32 4) #7
  %73 = or i8 %72, %71
  %74 = bitcast i8 %73 to <8 x i1>
  %75 = bitcast <8 x double> %70 to <8 x i64>
  %76 = select <8 x i1> %74, <8 x i64> <i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408, i64 4607182418800017408>, <8 x i64> %75
  %77 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = xor <8 x i64> %76, %77
  %79 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %80 = bitcast i8 %79 to <8 x i1>
  %81 = bitcast <8 x i64> %78 to <8 x double>
  %82 = select <8 x i1> %80, <8 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, <8 x double> %81
  ret <8 x double> %82
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_asinhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_asinhd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_acoshd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_acoshd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_atanhd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_atanhd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_cbrtd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %4, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %6 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %5, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %7 = add <8 x i32> %6, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %8 = xor <8 x i32> %6, <i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2, i32 -2>
  %9 = ashr <8 x i32> %8, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %10 = add nsw <8 x i32> %9, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %11 = bitcast <8 x i32> %10 to <4 x i64>
  %12 = shufflevector <4 x i64> %11, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %13 = bitcast <8 x i64> %12 to <16 x i32>
  %14 = shufflevector <16 x i32> %13, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %15 = shufflevector <16 x i32> %14, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %16 = shl <16 x i32> %15, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %17 = bitcast <16 x i32> %16 to <8 x double>
  %18 = fmul <8 x double> %17, %0
  %19 = sub <8 x i32> <i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022, i32 1022>, %6
  %20 = sub <8 x i32> %19, %9
  %21 = bitcast <8 x i32> %20 to <4 x i64>
  %22 = shufflevector <4 x i64> %21, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %23 = bitcast <8 x i64> %22 to <16 x i32>
  %24 = shufflevector <16 x i32> %23, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %25 = shufflevector <16 x i32> %24, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %26 = shl <16 x i32> %25, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %27 = bitcast <16 x i32> %26 to <8 x double>
  %28 = fmul <8 x double> %18, %27
  %29 = sitofp <8 x i32> %7 to <8 x double>
  %30 = fadd <8 x double> %29, <double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03, double 6.144000e+03>
  %31 = fmul <8 x double> %30, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %32 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %31, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %33 = sitofp <8 x i32> %32 to <8 x double>
  %34 = fmul <8 x double> %33, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %35 = fsub <8 x double> %30, %34
  %36 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %35, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %37 = bitcast <8 x i32> %36 to <4 x i64>
  %38 = shufflevector <4 x i64> %37, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %39 = bitcast <8 x i64> %38 to <16 x i32>
  %40 = icmp eq <16 x i32> %39, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %41 = bitcast <16 x i1> %40 to <2 x i8>
  %42 = extractelement <2 x i8> %41, i32 0
  %43 = bitcast i8 %42 to <8 x i1>
  %44 = select <8 x i1> %43, <8 x double> <double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B, double 0x3FF428A2F98D728B>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %45 = icmp eq <16 x i32> %39, <i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 2, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %46 = bitcast <16 x i1> %45 to <2 x i8>
  %47 = extractelement <2 x i8> %46, i32 0
  %48 = bitcast i8 %47 to <8 x i1>
  %49 = select <8 x i1> %48, <8 x double> <double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D, double 0x3FF965FEA53D6E3D>, <8 x double> %44
  %50 = add <8 x i32> %32, <i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048, i32 -2048>
  %51 = ashr <8 x i32> %50, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %52 = add nsw <8 x i32> %51, <i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023, i32 1023>
  %53 = bitcast <8 x i32> %52 to <4 x i64>
  %54 = shufflevector <4 x i64> %53, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %55 = bitcast <8 x i64> %54 to <16 x i32>
  %56 = shufflevector <16 x i32> %55, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %57 = shufflevector <16 x i32> %56, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %58 = shl <16 x i32> %57, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %59 = bitcast <16 x i32> %58 to <8 x double>
  %60 = fmul <8 x double> %49, %59
  %61 = add <8 x i32> %32, <i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025, i32 -1025>
  %62 = sub <8 x i32> %61, %51
  %63 = bitcast <8 x i32> %62 to <4 x i64>
  %64 = shufflevector <4 x i64> %63, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %65 = bitcast <8 x i64> %64 to <16 x i32>
  %66 = shufflevector <16 x i32> %65, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %67 = shufflevector <16 x i32> %66, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %68 = shl <16 x i32> %67, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %69 = bitcast <16 x i32> %68 to <8 x double>
  %70 = fmul <8 x double> %60, %69
  %71 = bitcast <8 x double> %70 to <8 x i64>
  %72 = bitcast <8 x double> %28 to <8 x i64>
  %73 = and <8 x i64> %72, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %74 = xor <8 x i64> %73, %71
  %75 = bitcast <8 x i64> %74 to <8 x double>
  %76 = and <8 x i64> %72, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %77 = bitcast <8 x i64> %76 to <8 x double>
  %78 = fmul <8 x double> %77, <double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42, double 0xBFE47CE4F76BED42>
  %79 = fadd <8 x double> %78, <double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C, double 0x4007B141AAA12A9C>
  %80 = fmul <8 x double> %79, %77
  %81 = fadd <8 x double> %80, <double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3, double 0xC016EF22A5E505B3>
  %82 = fmul <8 x double> %81, %77
  %83 = fadd <8 x double> %82, <double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911, double 0x401828DC834C5911>
  %84 = fmul <8 x double> %83, %77
  %85 = fadd <8 x double> %84, <double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B, double 0xC00EDE0AF7836A8B>
  %86 = fmul <8 x double> %85, %77
  %87 = fadd <8 x double> %86, <double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54, double 0x4001D887ACE5AC54>
  %88 = fmul <8 x double> %87, %87
  %89 = fmul <8 x double> %88, %88
  %90 = fmul <8 x double> %89, %77
  %91 = fsub <8 x double> %90, %87
  %92 = fmul <8 x double> %91, <double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555, double 0x3FD5555555555555>
  %93 = fsub <8 x double> %87, %92
  %94 = fmul <8 x double> %93, %77
  %95 = fmul <8 x double> %93, %94
  %96 = fmul <8 x double> %95, <double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555, double 0x3FE5555555555555>
  %97 = fmul <8 x double> %93, %95
  %98 = fadd <8 x double> %97, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %99 = fmul <8 x double> %96, %98
  %100 = fsub <8 x double> %95, %99
  %101 = fmul <8 x double> %100, %75
  %102 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %103 = and <8 x i64> %2, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %104 = or <8 x i64> %103, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %105 = bitcast <8 x i64> %104 to <8 x double>
  %106 = bitcast i8 %102 to <8 x i1>
  %107 = select <8 x i1> %106, <8 x double> %105, <8 x double> %101
  %108 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %109 = bitcast <8 x i64> %103 to <8 x double>
  %110 = bitcast i8 %108 to <8 x i1>
  %111 = select <8 x i1> %110, <8 x double> %109, <8 x double> %107
  ret <8 x double> %111
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_cbrtd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_cbrtd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_expm1d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_expm1d8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_log10d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192, double 0x3FB0F63BD2A55192>
  %60 = fadd <8 x double> %59, <double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48, double 0x3FB4381A2BF55D48>
  %61 = fmul <8 x double> %57, <double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496, double 0x3FB10895F3EA9496>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74, double 0x3FB8B4D992891F74>
  %64 = fadd <8 x double> %63, <double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821, double 0x3FBFC3FA6F6D7821>
  %65 = fmul <8 x double> %56, <double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88, double 0x3FC63C6277499B88>
  %66 = fadd <8 x double> %65, <double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570, double 0x3FD287A7636F4570>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %6 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %6, %73
  %75 = fmul <8 x double> %6, <double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF, double 0x3FD34413509F79FF>
  %76 = fmul <8 x double> %73, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %73, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %81 = fmul <8 x double> %74, <double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000, double 0x3FD3441350000000>
  %82 = fmul <8 x double> %74, <double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000, double 0x3E03EF3FE0000000>
  %83 = fmul <8 x double> %6, <double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21, double 0xBC49DC1DA994FD21>
  %84 = fadd <8 x double> %76, %79
  %85 = fadd <8 x double> %80, %84
  %86 = fadd <8 x double> %81, %85
  %87 = fadd <8 x double> %82, %86
  %88 = fadd <8 x double> %83, %87
  %89 = bitcast <8 x double> %33 to <8 x i64>
  %90 = and <8 x i64> %89, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %91 = bitcast <8 x i64> %90 to <8 x double>
  %92 = fsub <8 x double> %33, %91
  %93 = fmul <8 x double> %33, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %94 = fmul <8 x double> %91, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %95 = bitcast <8 x double> %93 to <8 x i64>
  %96 = xor <8 x i64> %95, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %97 = bitcast <8 x i64> %96 to <8 x double>
  %98 = fmul <8 x double> %92, <double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000, double 0x3FEBCB7B10000000>
  %99 = fmul <8 x double> %91, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %100 = fmul <8 x double> %92, <double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000, double 0x3E449B9438000000>
  %101 = fmul <8 x double> %33, <double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F, double 0x3C6A5B1DC915F38F>
  %102 = fmul <8 x double> %55, <double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E, double 0x3FEBCB7B1526E50E>
  %103 = fadd <8 x double> %94, %97
  %104 = fadd <8 x double> %98, %103
  %105 = fadd <8 x double> %99, %104
  %106 = fadd <8 x double> %100, %105
  %107 = fadd <8 x double> %101, %106
  %108 = fadd <8 x double> %107, %102
  %109 = fadd <8 x double> %75, %93
  %110 = fsub <8 x double> %75, %109
  %111 = fadd <8 x double> %93, %110
  %112 = fadd <8 x double> %111, %88
  %113 = fadd <8 x double> %112, %108
  %114 = fmul <8 x double> %33, %56
  %115 = fmul <8 x double> %114, %70
  %116 = fadd <8 x double> %109, %115
  %117 = fsub <8 x double> %109, %116
  %118 = fadd <8 x double> %115, %117
  %119 = fadd <8 x double> %118, %113
  %120 = fadd <8 x double> %116, %119
  %121 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %120, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4) #7
  ret <8 x double> %121
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_log2d8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %8, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fsub <8 x double> %8, %9
  %11 = fsub <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, %10
  %12 = fsub <8 x double> %7, %9
  %13 = fadd <8 x double> %12, %11
  %14 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %15 = fadd <8 x double> %14, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %16 = fsub <8 x double> %14, %15
  %17 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = fsub <8 x double> %7, %15
  %19 = fadd <8 x double> %18, %17
  %20 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %14, %23
  %25 = bitcast <8 x double> %20 to <8 x i64>
  %26 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %27 = bitcast <8 x i64> %26 to <8 x double>
  %28 = fsub <8 x double> %20, %27
  %29 = bitcast <8 x double> %8 to <8 x i64>
  %30 = and <8 x i64> %29, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %31 = bitcast <8 x i64> %30 to <8 x double>
  %32 = fsub <8 x double> %8, %31
  %33 = fmul <8 x double> %8, %20
  %34 = fmul <8 x double> %31, %27
  %35 = fsub <8 x double> %34, %33
  %36 = fmul <8 x double> %28, %31
  %37 = fmul <8 x double> %32, %27
  %38 = fmul <8 x double> %32, %28
  %39 = fmul <8 x double> %23, %27
  %40 = fmul <8 x double> %28, %23
  %41 = fmul <8 x double> %24, %27
  %42 = fmul <8 x double> %24, %28
  %43 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %44 = fsub <8 x double> %43, %40
  %45 = fsub <8 x double> %44, %41
  %46 = fsub <8 x double> %45, %42
  %47 = fmul <8 x double> %33, %46
  %48 = fadd <8 x double> %35, %36
  %49 = fadd <8 x double> %37, %48
  %50 = fadd <8 x double> %38, %49
  %51 = fadd <8 x double> %50, %47
  %52 = fmul <8 x double> %33, %19
  %53 = fsub <8 x double> %13, %52
  %54 = fmul <8 x double> %20, %53
  %55 = fadd <8 x double> %54, %51
  %56 = fmul <8 x double> %33, %33
  %57 = fmul <8 x double> %56, %56
  %58 = fmul <8 x double> %57, %57
  %59 = fmul <8 x double> %56, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %60 = fadd <8 x double> %59, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %61 = fmul <8 x double> %57, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %62 = fadd <8 x double> %61, %60
  %63 = fmul <8 x double> %56, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %64 = fadd <8 x double> %63, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %65 = fmul <8 x double> %56, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %66 = fadd <8 x double> %65, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %67 = fmul <8 x double> %57, %64
  %68 = fadd <8 x double> %66, %67
  %69 = fmul <8 x double> %58, %62
  %70 = fadd <8 x double> %69, %68
  %71 = bitcast <8 x double> %33 to <8 x i64>
  %72 = and <8 x i64> %71, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %73 = bitcast <8 x i64> %72 to <8 x double>
  %74 = fsub <8 x double> %33, %73
  %75 = fmul <8 x double> %33, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %76 = fmul <8 x double> %73, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %77 = bitcast <8 x double> %75 to <8 x i64>
  %78 = xor <8 x i64> %77, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = fmul <8 x double> %74, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %81 = fmul <8 x double> %73, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %82 = fmul <8 x double> %74, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %83 = fmul <8 x double> %33, <double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1, double 0x3C5BEDDA32EBBCB1>
  %84 = fmul <8 x double> %55, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %85 = fadd <8 x double> %76, %79
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %82, %87
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %89, %84
  %91 = fadd <8 x double> %6, %75
  %92 = fsub <8 x double> %91, %6
  %93 = fsub <8 x double> %91, %92
  %94 = fsub <8 x double> %6, %93
  %95 = fsub <8 x double> %75, %92
  %96 = fadd <8 x double> %95, %94
  %97 = fadd <8 x double> %96, %90
  %98 = fmul <8 x double> %33, %56
  %99 = fmul <8 x double> %98, %70
  %100 = fadd <8 x double> %91, %99
  %101 = fsub <8 x double> %100, %91
  %102 = fsub <8 x double> %100, %101
  %103 = fsub <8 x double> %91, %102
  %104 = fsub <8 x double> %99, %101
  %105 = fadd <8 x double> %104, %103
  %106 = fadd <8 x double> %105, %97
  %107 = fadd <8 x double> %100, %106
  %108 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %107, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4) #7
  ret <8 x double> %108
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_log2d8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %3 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %5 = bitcast i8 %4 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %3
  %7 = tail call <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double> %0, i32 11, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %8 = fadd <8 x double> %7, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %9 = fadd <8 x double> %7, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %10 = fdiv <8 x double> %8, %9
  %11 = fmul <8 x double> %10, %10
  %12 = fmul <8 x double> %11, <double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9, double 0x3FCC501739F17BA9>
  %13 = fadd <8 x double> %12, <double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9, double 0x3FCC2B7A962850E9>
  %14 = fmul <8 x double> %11, %13
  %15 = fadd <8 x double> %14, <double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481, double 0x3FD0CAAEEB877481>
  %16 = fmul <8 x double> %11, %15
  %17 = fadd <8 x double> %16, <double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD, double 0x3FD484AC6A7CB2DD>
  %18 = fmul <8 x double> %11, %17
  %19 = fadd <8 x double> %18, <double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254, double 0x3FDA617636C2C254>
  %20 = fmul <8 x double> %11, %19
  %21 = fadd <8 x double> %20, <double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9, double 0x3FE2776C50E7EDE9>
  %22 = fmul <8 x double> %11, %21
  %23 = fadd <8 x double> %22, <double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2, double 0x3FEEC709DC3A07B2>
  %24 = bitcast <8 x double> %10 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = fsub <8 x double> %10, %26
  %28 = fmul <8 x double> %10, <double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE, double 0x40071547652B82FE>
  %29 = fmul <8 x double> %26, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %30 = bitcast <8 x double> %28 to <8 x i64>
  %31 = xor <8 x i64> %30, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %32 = bitcast <8 x i64> %31 to <8 x double>
  %33 = fmul <8 x double> %27, <double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000, double 0x4007154760000000>
  %34 = fmul <8 x double> %26, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %35 = fmul <8 x double> %27, <double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000, double 0x3E64AE0BF8000000>
  %36 = fadd <8 x double> %29, %32
  %37 = fadd <8 x double> %33, %36
  %38 = fadd <8 x double> %34, %37
  %39 = fadd <8 x double> %35, %38
  %40 = fadd <8 x double> %6, %28
  %41 = fsub <8 x double> %6, %40
  %42 = fadd <8 x double> %28, %41
  %43 = fadd <8 x double> %42, %39
  %44 = fmul <8 x double> %10, %11
  %45 = fadd <8 x double> %40, %43
  %46 = fmul <8 x double> %44, %23
  %47 = fadd <8 x double> %45, %46
  %48 = tail call <8 x double> @llvm.x86.avx512.mask.fixupimm.pd.512(<8 x double> %47, <8 x double> %0, <8 x i64> <i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368, i64 167482009228346368>, i32 0, i8 -1, i32 4) #7
  ret <8 x double> %48
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_log1pd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %3 = fmul <8 x double> %2, <double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555, double 0x3FF5555555555555>
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double> %3, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %6 = bitcast i8 %5 to <8 x i1>
  %7 = select <8 x i1> %6, <8 x double> <double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03, double 1.024000e+03>, <8 x double> %4
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 8) #7
  %9 = sub <8 x i32> zeroinitializer, %8
  %10 = bitcast <8 x i32> %9 to <4 x i64>
  %11 = shufflevector <4 x i64> %10, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = bitcast <8 x i64> %11 to <16 x i32>
  %13 = shufflevector <16 x i32> %12, <16 x i32> undef, <16 x i32> <i32 undef, i32 0, i32 undef, i32 1, i32 undef, i32 2, i32 undef, i32 3, i32 undef, i32 4, i32 undef, i32 5, i32 undef, i32 6, i32 undef, i32 7>
  %14 = shufflevector <16 x i32> %13, <16 x i32> <i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef, i32 0, i32 undef>, <16 x i32> <i32 16, i32 1, i32 18, i32 3, i32 20, i32 5, i32 22, i32 7, i32 24, i32 9, i32 26, i32 11, i32 28, i32 13, i32 30, i32 15>
  %15 = shl <16 x i32> %14, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %16 = add <16 x i32> %15, <i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248, i32 0, i32 1072693248>
  %17 = bitcast <16 x i32> %16 to <8 x double>
  %18 = fadd <8 x double> %17, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %19 = fmul <8 x double> %17, %0
  %20 = fadd <8 x double> %19, %18
  %21 = bitcast <8 x double> %7 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = fsub <8 x double> %7, %23
  %25 = fmul <8 x double> %7, <double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF, double 0x3FE62E42FEFA39EF>
  %26 = fmul <8 x double> %23, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %27 = bitcast <8 x double> %25 to <8 x i64>
  %28 = xor <8 x i64> %27, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %29 = bitcast <8 x i64> %28 to <8 x double>
  %30 = fmul <8 x double> %23, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %31 = fmul <8 x double> %24, <double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000, double 0x3FE62E42F8000000>
  %32 = fmul <8 x double> %24, <double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000, double 0x3E4BE8E7BC000000>
  %33 = fmul <8 x double> %7, <double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F, double 0x3C7ABC9E3B39803F>
  %34 = fadd <8 x double> %26, %29
  %35 = fadd <8 x double> %30, %34
  %36 = fadd <8 x double> %31, %35
  %37 = fadd <8 x double> %32, %36
  %38 = fadd <8 x double> %33, %37
  %39 = fadd <8 x double> %20, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %40 = fsub <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, %39
  %41 = fadd <8 x double> %20, %40
  %42 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %39
  %43 = bitcast <8 x double> %39 to <8 x i64>
  %44 = and <8 x i64> %43, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %45 = bitcast <8 x i64> %44 to <8 x double>
  %46 = fsub <8 x double> %39, %45
  %47 = bitcast <8 x double> %42 to <8 x i64>
  %48 = and <8 x i64> %47, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %49 = bitcast <8 x i64> %48 to <8 x double>
  %50 = fsub <8 x double> %42, %49
  %51 = bitcast <8 x double> %20 to <8 x i64>
  %52 = and <8 x i64> %51, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %53 = bitcast <8 x i64> %52 to <8 x double>
  %54 = fsub <8 x double> %20, %53
  %55 = fmul <8 x double> %20, %42
  %56 = fmul <8 x double> %53, %49
  %57 = fsub <8 x double> %56, %55
  %58 = fmul <8 x double> %50, %53
  %59 = fmul <8 x double> %54, %49
  %60 = fmul <8 x double> %54, %50
  %61 = fmul <8 x double> %45, %49
  %62 = fmul <8 x double> %50, %45
  %63 = fmul <8 x double> %46, %49
  %64 = fmul <8 x double> %46, %50
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %55, %68
  %70 = fadd <8 x double> %57, %58
  %71 = fadd <8 x double> %59, %70
  %72 = fadd <8 x double> %60, %71
  %73 = fadd <8 x double> %72, %69
  %74 = fmul <8 x double> %55, %41
  %75 = fsub <8 x double> zeroinitializer, %74
  %76 = fmul <8 x double> %42, %75
  %77 = fadd <8 x double> %76, %73
  %78 = fmul <8 x double> %55, %55
  %79 = fmul <8 x double> %78, %78
  %80 = fmul <8 x double> %79, %79
  %81 = fmul <8 x double> %78, <double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84, double 0x3FC3872E67FE8E84>
  %82 = fadd <8 x double> %81, <double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035, double 0x3FC747353A506035>
  %83 = fmul <8 x double> %79, <double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E, double 0x3FC39C4F5407567E>
  %84 = fadd <8 x double> %83, %82
  %85 = fmul <8 x double> %78, <double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E, double 0x3FCC71C0A65ECD8E>
  %86 = fadd <8 x double> %85, <double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245, double 0x3FD249249A68A245>
  %87 = fmul <8 x double> %78, <double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA, double 0x3FD99999998F92EA>
  %88 = fadd <8 x double> %87, <double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE, double 0x3FE55555555557AE>
  %89 = fmul <8 x double> %79, %86
  %90 = fadd <8 x double> %88, %89
  %91 = fmul <8 x double> %80, %84
  %92 = fadd <8 x double> %91, %90
  %93 = fmul <8 x double> %55, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %94 = fmul <8 x double> %77, <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>
  %95 = fadd <8 x double> %25, %93
  %96 = fsub <8 x double> %25, %95
  %97 = fadd <8 x double> %93, %96
  %98 = fadd <8 x double> %38, %97
  %99 = fadd <8 x double> %98, %94
  %100 = fmul <8 x double> %55, %78
  %101 = fmul <8 x double> %100, %92
  %102 = fadd <8 x double> %95, %101
  %103 = fsub <8 x double> %95, %102
  %104 = fadd <8 x double> %101, %103
  %105 = fadd <8 x double> %104, %99
  %106 = fadd <8 x double> %102, %105
  %107 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433, double 0x7FAC7B1F3CAC7433>, i32 30, i8 -1, i32 4) #7
  %108 = bitcast i8 %107 to <8 x i1>
  %109 = select <8 x i1> %108, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %106
  %110 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i32 17, i8 -1, i32 4) #7
  %111 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %0, i32 4, i8 -1, i32 4) #7
  %112 = or i8 %111, %110
  %113 = bitcast i8 %112 to <8 x i1>
  %114 = select <8 x i1> %113, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %109
  %115 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>, i32 0, i8 -1, i32 4) #7
  %116 = bitcast i8 %115 to <8 x i1>
  %117 = select <8 x i1> %116, <8 x double> <double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000, double 0xFFF0000000000000>, <8 x double> %114
  %118 = bitcast <8 x double> %0 to <8 x i64>
  %119 = icmp eq <8 x i64> %118, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %120 = select <8 x i1> %119, <8 x double> <double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00, double -0.000000e+00>, <8 x double> %117
  ret <8 x double> %120
}

; Function Attrs: norecurse nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fabsd8_avx512fnofma(<8 x double>) local_unnamed_addr #0 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  ret <8 x double> %4
}

; Function Attrs: norecurse nounwind readnone uwtable
define <8 x double> @Sleef_cinz_copysignd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #0 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x double> %1 to <8 x i64>
  %6 = and <8 x i64> %5, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %7 = or <8 x i64> %6, %4
  %8 = bitcast <8 x i64> %7 to <8 x double>
  ret <8 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fmaxd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %0, <8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = bitcast i8 %3 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> %0, <8 x double> %4
  ret <8 x double> %6
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fmind8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %4 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %0, <8 x double> %1, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %5 = bitcast i8 %3 to <8 x i1>
  %6 = select <8 x i1> %5, <8 x double> %0, <8 x double> %4
  ret <8 x double> %6
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fdimd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = fsub <8 x double> %0, %1
  %4 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %3, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> %1, i32 0, i8 -1, i32 4) #7
  %6 = or i8 %5, %4
  %7 = bitcast i8 %6 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> zeroinitializer, <8 x double> %3
  ret <8 x double> %8
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_truncd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 11, <8 x double> %0, i8 -1, i32 4) #7
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_floord8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = sitofp <8 x i32> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <8 x double> %0, %5
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %8 = sitofp <8 x i32> %7 to <8 x double>
  %9 = fsub <8 x double> %6, %8
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %11 = fadd <8 x double> %9, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %9
  %14 = bitcast <8 x double> %0 to <8 x i64>
  %15 = and <8 x i64> %14, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %16 = bitcast <8 x i64> %15 to <8 x double>
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %19 = or i8 %18, %17
  %20 = fsub <8 x double> %0, %13
  %21 = bitcast <8 x double> %20 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = and <8 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %24 = or <8 x i64> %22, %23
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = bitcast i8 %19 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %0, <8 x double> %25
  ret <8 x double> %27
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_ceild8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fmul <8 x double> %0, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %3 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %2, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %4 = sitofp <8 x i32> %3 to <8 x double>
  %5 = fmul <8 x double> %4, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %6 = fsub <8 x double> %0, %5
  %7 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %6, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %8 = sitofp <8 x i32> %7 to <8 x double>
  %9 = fsub <8 x double> %6, %8
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 18, i8 -1, i32 4) #7
  %11 = fadd <8 x double> %9, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %9, <8 x double> %11
  %14 = bitcast <8 x double> %0 to <8 x i64>
  %15 = and <8 x i64> %14, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %16 = bitcast <8 x i64> %15 to <8 x double>
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %16, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %19 = or i8 %18, %17
  %20 = fsub <8 x double> %0, %13
  %21 = bitcast <8 x double> %20 to <8 x i64>
  %22 = and <8 x i64> %21, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = and <8 x i64> %14, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %24 = or <8 x i64> %22, %23
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = bitcast i8 %19 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %0, <8 x double> %25
  ret <8 x double> %27
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_roundd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = fadd <8 x double> %0, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %3 = fmul <8 x double> %2, <double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000, double 0x3E00000000000000>
  %4 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %3, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %5 = sitofp <8 x i32> %4 to <8 x double>
  %6 = fmul <8 x double> %5, <double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000, double 0x41E0000000000000>
  %7 = fsub <8 x double> %2, %6
  %8 = tail call <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double> %7, <8 x i32> zeroinitializer, i8 -1, i32 11) #7
  %9 = sitofp <8 x i32> %8 to <8 x double>
  %10 = fsub <8 x double> %7, %9
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %2, <8 x double> zeroinitializer, i32 18, i8 -1, i32 4) #7
  %12 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %13 = and i8 %12, %11
  %14 = fadd <8 x double> %2, <double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00, double -1.000000e+00>
  %15 = bitcast i8 %13 to <8 x i1>
  %16 = select <8 x i1> %15, <8 x double> %14, <8 x double> %2
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %18 = fadd <8 x double> %10, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %19 = bitcast i8 %17 to <8 x i1>
  %20 = select <8 x i1> %19, <8 x double> %18, <8 x double> %10
  %21 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> <double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF, double 0x3FDFFFFFFFFFFFFF>, i32 0, i8 -1, i32 4) #7
  %22 = bitcast i8 %21 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x double> zeroinitializer, <8 x double> %16
  %24 = bitcast <8 x double> %0 to <8 x i64>
  %25 = and <8 x i64> %24, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %26, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %28 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %26, <8 x double> <double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000, double 0x4330000000000000>, i32 29, i8 -1, i32 4) #7
  %29 = or i8 %28, %27
  %30 = fsub <8 x double> %23, %20
  %31 = bitcast <8 x double> %30 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %33 = and <8 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %34 = or <8 x i64> %32, %33
  %35 = bitcast <8 x i64> %34 to <8 x double>
  %36 = bitcast i8 %29 to <8 x i1>
  %37 = select <8 x i1> %36, <8 x double> %0, <8 x double> %35
  ret <8 x double> %37
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_rintd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %0, i32 8, <8 x double> %0, i8 -1, i32 4) #7
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_nextafterd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %4 = bitcast <8 x double> %1 to <8 x i64>
  %5 = and <8 x i64> %4, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %6 = bitcast <8 x i64> %5 to <8 x double>
  %7 = bitcast i8 %3 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = icmp slt <8 x i64> %9, zeroinitializer
  %11 = bitcast <8 x i1> %10 to i8
  %12 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %8, i32 29, i8 -1, i32 4) #7
  %13 = xor i8 %12, %11
  %14 = bitcast <8 x double> %8 to <16 x i32>
  %15 = xor <16 x i32> %14, <i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %16 = add <16 x i32> %15, <i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0>
  %17 = icmp eq <16 x i32> %16, <i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1>
  %18 = sext <16 x i1> %17 to <16 x i32>
  %19 = bitcast <16 x i32> %18 to <8 x i64>
  %20 = and <8 x i64> %19, <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>
  %21 = bitcast <8 x i64> %20 to <16 x float>
  %22 = shufflevector <16 x float> %21, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %23 = bitcast <16 x float> %22 to <16 x i32>
  %24 = add <16 x i32> %16, %23
  %25 = bitcast <16 x i32> %24 to <8 x double>
  %26 = bitcast i8 %13 to <8 x i1>
  %27 = select <8 x i1> %26, <8 x double> %25, <8 x double> %8
  %28 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %29 = bitcast i8 %28 to <8 x i1>
  %30 = zext <8 x i1> %29 to <8 x i64>
  %31 = bitcast <8 x double> %27 to <16 x i32>
  %32 = bitcast <8 x i64> %30 to <16 x i32>
  %33 = sub <16 x i32> %31, %32
  %34 = icmp eq <16 x i32> %33, <i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0>
  %35 = sext <16 x i1> %34 to <16 x i32>
  %36 = bitcast <16 x i32> %35 to <8 x i64>
  %37 = and <8 x i64> %36, <i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295, i64 4294967295>
  %38 = bitcast <8 x i64> %37 to <16 x float>
  %39 = shufflevector <16 x float> %38, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %40 = bitcast <16 x float> %39 to <16 x i32>
  %41 = add <16 x i32> %33, %40
  %42 = bitcast <16 x i32> %41 to <8 x double>
  %43 = bitcast <16 x i32> %33 to <8 x double>
  %44 = select <8 x i1> %29, <8 x double> %42, <8 x double> %43
  %45 = bitcast <8 x double> %44 to <16 x i32>
  %46 = xor <16 x i32> %45, <i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647, i32 -1, i32 2147483647>
  %47 = add <16 x i32> %46, <i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0>
  %48 = icmp eq <16 x i32> %47, <i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1, i32 0, i32 -1>
  %49 = sext <16 x i1> %48 to <16 x i32>
  %50 = bitcast <16 x i32> %49 to <8 x i64>
  %51 = and <8 x i64> %50, <i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1, i64 1>
  %52 = bitcast <8 x i64> %51 to <16 x float>
  %53 = shufflevector <16 x float> %52, <16 x float> undef, <16 x i32> <i32 1, i32 0, i32 3, i32 2, i32 5, i32 4, i32 7, i32 6, i32 9, i32 8, i32 11, i32 10, i32 13, i32 12, i32 15, i32 14>
  %54 = bitcast <16 x float> %53 to <16 x i32>
  %55 = add <16 x i32> %47, %54
  %56 = bitcast <16 x i32> %55 to <8 x double>
  %57 = select <8 x i1> %26, <8 x double> %56, <8 x double> %44
  %58 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %57, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %59 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 4, i8 -1, i32 4) #7
  %60 = and i8 %59, %58
  %61 = and <8 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = bitcast i8 %60 to <8 x i1>
  %64 = select <8 x i1> %63, <8 x double> %62, <8 x double> %57
  %65 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %66 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %67 = and i8 %66, %65
  %68 = bitcast i8 %67 to <8 x i1>
  %69 = select <8 x i1> %68, <8 x double> %1, <8 x double> %64
  %70 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %1, <8 x double> %1, i32 4, i8 -1, i32 4) #7
  %72 = or i8 %71, %70
  %73 = bitcast i8 %72 to <8 x i1>
  %74 = select <8 x i1> %73, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %69
  ret <8 x double> %74
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_frfrexpd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = and <8 x i64> %9, <i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313, i64 -9218868437227405313>
  %11 = or <8 x i64> %10, <i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912, i64 4602678819172646912>
  %12 = and <8 x i64> %9, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %13 = bitcast <8 x i64> %12 to <8 x double>
  %14 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %15 = and <8 x i64> %9, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %16 = or <8 x i64> %15, <i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312, i64 9218868437227405312>
  %17 = bitcast i8 %14 to <8 x i1>
  %18 = select <8 x i1> %17, <8 x i64> %16, <8 x i64> %11
  %19 = bitcast <8 x i64> %18 to <8 x double>
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %21 = bitcast i8 %20 to <8 x i1>
  %22 = select <8 x i1> %21, <8 x double> %8, <8 x double> %19
  ret <8 x double> %22
}

; Function Attrs: nounwind readnone uwtable
define <4 x i64> @Sleef_cinz_expfrexpd8_avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = bitcast <8 x double> %0 to <8 x i64>
  %3 = and <8 x i64> %2, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %4 = bitcast <8 x i64> %3 to <8 x double>
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %0, <double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000, double 0x43E0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %0
  %9 = bitcast <8 x double> %8 to <8 x i64>
  %10 = bitcast <8 x double> %8 to <16 x i32>
  %11 = shufflevector <16 x i32> %10, <16 x i32> undef, <16 x i32> <i32 1, i32 3, i32 5, i32 7, i32 9, i32 11, i32 13, i32 15, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %12 = bitcast <16 x i32> %11 to <8 x i64>
  %13 = shufflevector <8 x i64> %12, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %14 = bitcast <4 x i64> %13 to <8 x i32>
  %15 = lshr <8 x i32> %14, <i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20, i32 20>
  %16 = and <8 x i32> %15, <i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047, i32 2047>
  %17 = add nsw <8 x i32> %16, <i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022, i32 -1022>
  %18 = bitcast <8 x i32> %17 to <4 x i64>
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %21 = or i8 %20, %19
  %22 = and <8 x i64> %9, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %25 = or i8 %21, %24
  %26 = zext i8 %25 to i16
  %27 = shufflevector <4 x i64> %18, <4 x i64> undef, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef>
  %28 = bitcast <8 x i64> %27 to <16 x i32>
  %29 = bitcast i16 %26 to <16 x i1>
  %30 = select <16 x i1> %29, <16 x i32> <i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>, <16 x i32> %28
  %31 = bitcast <16 x i32> %30 to <8 x i64>
  %32 = shufflevector <8 x i64> %31, <8 x i64> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  ret <4 x i64> %32
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fmad8_avx512fnofma(<8 x double>, <8 x double>, <8 x double>) local_unnamed_addr #1 {
  %4 = fmul <8 x double> %0, %1
  %5 = fadd <8 x double> %4, %2
  %6 = bitcast <8 x double> %5 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300, double 1.000000e-300>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %0, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %0
  %13 = fmul <8 x double> %1, <double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000, double 0x46B0000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %1
  %15 = fmul <8 x double> %2, <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>
  %16 = select <8 x i1> %11, <8 x double> %15, <8 x double> %2
  %17 = select <8 x i1> %11, <8 x double> <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %18 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300, double 1.000000e+300>, i32 30, i8 -1, i32 4) #7
  %19 = fmul <8 x double> %12, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %20 = bitcast i8 %18 to <8 x i1>
  %21 = select <8 x i1> %20, <8 x double> %19, <8 x double> %12
  %22 = fmul <8 x double> %14, <double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000, double 0x3930000000000000>
  %23 = select <8 x i1> %20, <8 x double> %22, <8 x double> %14
  %24 = fmul <8 x double> %16, <double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000, double 0x3270000000000000>
  %25 = select <8 x i1> %20, <8 x double> %24, <8 x double> %16
  %26 = select <8 x i1> %20, <8 x double> <double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000, double 0x4D70000000000000>, <8 x double> %17
  %27 = bitcast <8 x double> %21 to <8 x i64>
  %28 = and <8 x i64> %27, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %29 = bitcast <8 x i64> %28 to <8 x double>
  %30 = fsub <8 x double> %21, %29
  %31 = bitcast <8 x double> %23 to <8 x i64>
  %32 = and <8 x i64> %31, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %33 = bitcast <8 x i64> %32 to <8 x double>
  %34 = fsub <8 x double> %23, %33
  %35 = fmul <8 x double> %21, %23
  %36 = fmul <8 x double> %29, %33
  %37 = bitcast <8 x double> %35 to <8 x i64>
  %38 = xor <8 x i64> %37, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %39 = bitcast <8 x i64> %38 to <8 x double>
  %40 = fmul <8 x double> %30, %33
  %41 = fmul <8 x double> %34, %29
  %42 = fmul <8 x double> %30, %34
  %43 = fadd <8 x double> %36, %39
  %44 = fadd <8 x double> %40, %43
  %45 = fadd <8 x double> %41, %44
  %46 = fadd <8 x double> %42, %45
  %47 = fadd <8 x double> %25, %35
  %48 = fsub <8 x double> %47, %35
  %49 = fsub <8 x double> %47, %48
  %50 = fsub <8 x double> %35, %49
  %51 = fsub <8 x double> %25, %48
  %52 = fadd <8 x double> %51, %50
  %53 = fadd <8 x double> %52, %46
  %54 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %21, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %55 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %56 = or i8 %55, %54
  %57 = fadd <8 x double> %47, %53
  %58 = bitcast i8 %56 to <8 x i1>
  %59 = select <8 x i1> %58, <8 x double> %25, <8 x double> %57
  %60 = bitcast <8 x double> %25 to <8 x i64>
  %61 = and <8 x i64> %60, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %62, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %64 = zext i8 %63 to i16
  %65 = and <8 x i64> %27, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %66 = bitcast <8 x i64> %65 to <8 x double>
  %67 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %66, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %68 = zext i8 %67 to i16
  %69 = bitcast i16 %68 to <16 x i1>
  %70 = bitcast i16 %64 to <16 x i1>
  %71 = xor <16 x i1> %69, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %72 = and <16 x i1> %71, %70
  %73 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %21, <8 x double> %21, i32 4, i8 -1, i32 4) #7
  %74 = zext i8 %73 to i16
  %75 = bitcast i16 %74 to <16 x i1>
  %76 = xor <16 x i1> %75, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %77 = and <16 x i1> %72, %76
  %78 = and <8 x i64> %31, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %79 = bitcast <8 x i64> %78 to <8 x double>
  %80 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %79, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %81 = zext i8 %80 to i16
  %82 = bitcast i16 %81 to <16 x i1>
  %83 = xor <16 x i1> %82, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %84 = and <16 x i1> %77, %83
  %85 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> %23, i32 4, i8 -1, i32 4) #7
  %86 = zext i8 %85 to i16
  %87 = bitcast i16 %86 to <16 x i1>
  %88 = xor <16 x i1> %87, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %89 = and <16 x i1> %84, %88
  %90 = bitcast <16 x i1> %89 to <2 x i8>
  %91 = extractelement <2 x i8> %90, i32 0
  %92 = bitcast i8 %91 to <8 x i1>
  %93 = select <8 x i1> %92, <8 x double> %25, <8 x double> %5
  %94 = bitcast <8 x double> %93 to <8 x i64>
  %95 = and <8 x i64> %94, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %96, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %98 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %93, <8 x double> %93, i32 4, i8 -1, i32 4) #7
  %99 = or i8 %98, %97
  %100 = fmul <8 x double> %26, %59
  %101 = bitcast i8 %99 to <8 x i1>
  %102 = select <8 x i1> %101, <8 x double> %93, <8 x double> %100
  ret <8 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_sqrtd8_u05avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %3 = bitcast i8 %2 to <8 x i1>
  %4 = select <8 x i1> %3, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %4, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %4
  %9 = select <8 x i1> %7, <8 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i32 30, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %8, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %8
  %14 = select <8 x i1> %12, <8 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <8 x double> %9
  %15 = fadd <8 x double> %13, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %16 = bitcast <8 x double> %15 to <16 x i32>
  %17 = lshr <16 x i32> %16, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %18 = sub nsw <16 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %19 = bitcast <16 x i32> %18 to <8 x double>
  %20 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = fmul <8 x double> %20, %19
  %22 = fmul <8 x double> %21, %19
  %23 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %22
  %24 = fmul <8 x double> %23, %19
  %25 = fmul <8 x double> %20, %24
  %26 = fmul <8 x double> %24, %25
  %27 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %26
  %28 = fmul <8 x double> %24, %27
  %29 = fmul <8 x double> %20, %28
  %30 = fmul <8 x double> %28, %29
  %31 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <8 x double> %28, %31
  %33 = fmul <8 x double> %13, %32
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %33, %36
  %38 = fmul <8 x double> %33, %33
  %39 = fmul <8 x double> %36, %36
  %40 = bitcast <8 x double> %38 to <8 x i64>
  %41 = xor <8 x i64> %40, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <8 x i64> %41 to <8 x double>
  %43 = fmul <8 x double> %37, %36
  %44 = fmul <8 x double> %37, %37
  %45 = fadd <8 x double> %39, %42
  %46 = fadd <8 x double> %43, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %44, %47
  %49 = fadd <8 x double> %13, %38
  %50 = fsub <8 x double> %49, %13
  %51 = fsub <8 x double> %49, %50
  %52 = fsub <8 x double> %13, %51
  %53 = fsub <8 x double> %38, %50
  %54 = fadd <8 x double> %53, %52
  %55 = fadd <8 x double> %54, %48
  %56 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %33
  %57 = bitcast <8 x double> %56 to <8 x i64>
  %58 = and <8 x i64> %57, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %59 = bitcast <8 x i64> %58 to <8 x double>
  %60 = fsub <8 x double> %56, %59
  %61 = fmul <8 x double> %36, %59
  %62 = fmul <8 x double> %60, %36
  %63 = fmul <8 x double> %37, %59
  %64 = fmul <8 x double> %37, %60
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %56, %68
  %70 = bitcast <8 x double> %49 to <8 x i64>
  %71 = and <8 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <8 x i64> %71 to <8 x double>
  %73 = fsub <8 x double> %49, %72
  %74 = fmul <8 x double> %56, %49
  %75 = fmul <8 x double> %59, %72
  %76 = bitcast <8 x double> %74 to <8 x i64>
  %77 = xor <8 x i64> %76, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fmul <8 x double> %73, %59
  %80 = fmul <8 x double> %60, %72
  %81 = fmul <8 x double> %60, %73
  %82 = fmul <8 x double> %49, %69
  %83 = fmul <8 x double> %56, %55
  %84 = fadd <8 x double> %75, %78
  %85 = fadd <8 x double> %79, %84
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %87, %82
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %74, %89
  %91 = fmul <8 x double> %14, %90
  %92 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %93 = bitcast i8 %92 to <8 x i1>
  %94 = select <8 x i1> %93, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %91
  %95 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %96 = bitcast i8 %95 to <8 x i1>
  %97 = select <8 x i1> %96, <8 x double> %13, <8 x double> %94
  ret <8 x double> %97
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_sqrtd8_u35avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %0, <8 x double> zeroinitializer, i32 17, i8 -1, i32 4) #7
  %3 = bitcast i8 %2 to <8 x i1>
  %4 = select <8 x i1> %3, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %5 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %4, <8 x double> <double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000, double 0x2FF0000000000000>, i32 17, i8 -1, i32 4) #7
  %6 = fmul <8 x double> %4, <double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000, double 0x4FF0000000000000>
  %7 = bitcast i8 %5 to <8 x i1>
  %8 = select <8 x i1> %7, <8 x double> %6, <8 x double> %4
  %9 = select <8 x i1> %7, <8 x double> <double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000, double 0x37E0000000000000>, <8 x double> <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %10 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000, double 0x5FF0000000000000>, i32 30, i8 -1, i32 4) #7
  %11 = fmul <8 x double> %8, <double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000, double 0x1FF0000000000000>
  %12 = bitcast i8 %10 to <8 x i1>
  %13 = select <8 x i1> %12, <8 x double> %11, <8 x double> %8
  %14 = select <8 x i1> %12, <8 x double> <double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000, double 0x4FE0000000000000>, <8 x double> %9
  %15 = fadd <8 x double> %13, <double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321, double 9.999880e-321>
  %16 = bitcast <8 x double> %15 to <16 x i32>
  %17 = lshr <16 x i32> %16, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %18 = sub nsw <16 x i32> <i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350, i32 0, i32 1608969350>, %17
  %19 = bitcast <16 x i32> %18 to <8 x double>
  %20 = fmul <8 x double> %13, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = fmul <8 x double> %20, %19
  %22 = fmul <8 x double> %21, %19
  %23 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %22
  %24 = fmul <8 x double> %23, %19
  %25 = fmul <8 x double> %20, %24
  %26 = fmul <8 x double> %24, %25
  %27 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %26
  %28 = fmul <8 x double> %24, %27
  %29 = fmul <8 x double> %20, %28
  %30 = fmul <8 x double> %28, %29
  %31 = fsub <8 x double> <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>, %30
  %32 = fmul <8 x double> %28, %31
  %33 = fmul <8 x double> %13, %32
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = fsub <8 x double> %33, %36
  %38 = fmul <8 x double> %33, %33
  %39 = fmul <8 x double> %36, %36
  %40 = bitcast <8 x double> %38 to <8 x i64>
  %41 = xor <8 x i64> %40, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %42 = bitcast <8 x i64> %41 to <8 x double>
  %43 = fmul <8 x double> %37, %36
  %44 = fmul <8 x double> %37, %37
  %45 = fadd <8 x double> %39, %42
  %46 = fadd <8 x double> %43, %45
  %47 = fadd <8 x double> %43, %46
  %48 = fadd <8 x double> %44, %47
  %49 = fadd <8 x double> %13, %38
  %50 = fsub <8 x double> %49, %13
  %51 = fsub <8 x double> %49, %50
  %52 = fsub <8 x double> %13, %51
  %53 = fsub <8 x double> %38, %50
  %54 = fadd <8 x double> %53, %52
  %55 = fadd <8 x double> %54, %48
  %56 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %33
  %57 = bitcast <8 x double> %56 to <8 x i64>
  %58 = and <8 x i64> %57, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %59 = bitcast <8 x i64> %58 to <8 x double>
  %60 = fsub <8 x double> %56, %59
  %61 = fmul <8 x double> %36, %59
  %62 = fmul <8 x double> %60, %36
  %63 = fmul <8 x double> %37, %59
  %64 = fmul <8 x double> %37, %60
  %65 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %61
  %66 = fsub <8 x double> %65, %62
  %67 = fsub <8 x double> %66, %63
  %68 = fsub <8 x double> %67, %64
  %69 = fmul <8 x double> %56, %68
  %70 = bitcast <8 x double> %49 to <8 x i64>
  %71 = and <8 x i64> %70, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %72 = bitcast <8 x i64> %71 to <8 x double>
  %73 = fsub <8 x double> %49, %72
  %74 = fmul <8 x double> %56, %49
  %75 = fmul <8 x double> %59, %72
  %76 = bitcast <8 x double> %74 to <8 x i64>
  %77 = xor <8 x i64> %76, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %78 = bitcast <8 x i64> %77 to <8 x double>
  %79 = fmul <8 x double> %73, %59
  %80 = fmul <8 x double> %60, %72
  %81 = fmul <8 x double> %60, %73
  %82 = fmul <8 x double> %49, %69
  %83 = fmul <8 x double> %56, %55
  %84 = fadd <8 x double> %75, %78
  %85 = fadd <8 x double> %79, %84
  %86 = fadd <8 x double> %80, %85
  %87 = fadd <8 x double> %81, %86
  %88 = fadd <8 x double> %87, %82
  %89 = fadd <8 x double> %83, %88
  %90 = fadd <8 x double> %74, %89
  %91 = fmul <8 x double> %14, %90
  %92 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %93 = bitcast i8 %92 to <8 x i1>
  %94 = select <8 x i1> %93, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %91
  %95 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %96 = bitcast i8 %95 to <8 x i1>
  %97 = select <8 x i1> %96, <8 x double> %13, <8 x double> %94
  ret <8 x double> %97
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_hypotd8_u05avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %11 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %10, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %12 = fmul <8 x double> %9, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %13 = bitcast i8 %11 to <8 x i1>
  %14 = select <8 x i1> %13, <8 x double> %12, <8 x double> %9
  %15 = fmul <8 x double> %10, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %16 = select <8 x i1> %13, <8 x double> %15, <8 x double> %10
  %17 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %16
  %18 = bitcast <8 x double> %16 to <8 x i64>
  %19 = and <8 x i64> %18, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %20 = bitcast <8 x i64> %19 to <8 x double>
  %21 = fsub <8 x double> %16, %20
  %22 = bitcast <8 x double> %17 to <8 x i64>
  %23 = and <8 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %24 = bitcast <8 x i64> %23 to <8 x double>
  %25 = fsub <8 x double> %17, %24
  %26 = bitcast <8 x double> %14 to <8 x i64>
  %27 = and <8 x i64> %26, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = fsub <8 x double> %14, %28
  %30 = fmul <8 x double> %14, %17
  %31 = fmul <8 x double> %28, %24
  %32 = fsub <8 x double> %31, %30
  %33 = fmul <8 x double> %25, %28
  %34 = fmul <8 x double> %29, %24
  %35 = fmul <8 x double> %29, %25
  %36 = fmul <8 x double> %20, %24
  %37 = fmul <8 x double> %25, %20
  %38 = fmul <8 x double> %21, %24
  %39 = fmul <8 x double> %21, %25
  %40 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %36
  %41 = fsub <8 x double> %40, %37
  %42 = fsub <8 x double> %41, %38
  %43 = fsub <8 x double> %42, %39
  %44 = fmul <8 x double> %30, %43
  %45 = fadd <8 x double> %32, %33
  %46 = fadd <8 x double> %34, %45
  %47 = fadd <8 x double> %35, %46
  %48 = fadd <8 x double> %47, %44
  %49 = fmul <8 x double> %30, zeroinitializer
  %50 = fsub <8 x double> zeroinitializer, %49
  %51 = fmul <8 x double> %17, %50
  %52 = fadd <8 x double> %51, %48
  %53 = bitcast <8 x double> %30 to <8 x i64>
  %54 = and <8 x i64> %53, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %55 = bitcast <8 x i64> %54 to <8 x double>
  %56 = fsub <8 x double> %30, %55
  %57 = fmul <8 x double> %30, %30
  %58 = fmul <8 x double> %55, %55
  %59 = bitcast <8 x double> %57 to <8 x i64>
  %60 = xor <8 x i64> %59, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %61 = bitcast <8 x i64> %60 to <8 x double>
  %62 = fadd <8 x double> %55, %55
  %63 = fmul <8 x double> %62, %56
  %64 = fmul <8 x double> %56, %56
  %65 = fadd <8 x double> %52, %52
  %66 = fmul <8 x double> %30, %65
  %67 = fadd <8 x double> %58, %61
  %68 = fadd <8 x double> %67, %63
  %69 = fadd <8 x double> %64, %68
  %70 = fadd <8 x double> %69, %66
  %71 = fadd <8 x double> %57, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %72 = fsub <8 x double> %71, %57
  %73 = fsub <8 x double> %71, %72
  %74 = fsub <8 x double> %57, %73
  %75 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %72
  %76 = fadd <8 x double> %75, %74
  %77 = fadd <8 x double> %76, %70
  %78 = fadd <8 x double> %71, %77
  %79 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %78, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %80 = bitcast <8 x double> %79 to <8 x i64>
  %81 = and <8 x i64> %80, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %82 = bitcast <8 x i64> %81 to <8 x double>
  %83 = fsub <8 x double> %79, %82
  %84 = fmul <8 x double> %79, %79
  %85 = fmul <8 x double> %82, %82
  %86 = bitcast <8 x double> %84 to <8 x i64>
  %87 = xor <8 x i64> %86, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %88 = bitcast <8 x i64> %87 to <8 x double>
  %89 = fmul <8 x double> %83, %82
  %90 = fmul <8 x double> %83, %83
  %91 = fadd <8 x double> %85, %88
  %92 = fadd <8 x double> %89, %91
  %93 = fadd <8 x double> %89, %92
  %94 = fadd <8 x double> %90, %93
  %95 = fadd <8 x double> %84, %71
  %96 = fsub <8 x double> %95, %71
  %97 = fsub <8 x double> %95, %96
  %98 = fsub <8 x double> %71, %97
  %99 = fsub <8 x double> %84, %96
  %100 = fadd <8 x double> %99, %98
  %101 = fadd <8 x double> %94, %77
  %102 = fadd <8 x double> %100, %101
  %103 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %79
  %104 = bitcast <8 x double> %103 to <8 x i64>
  %105 = and <8 x i64> %104, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %106 = bitcast <8 x i64> %105 to <8 x double>
  %107 = fsub <8 x double> %103, %106
  %108 = fmul <8 x double> %82, %106
  %109 = fmul <8 x double> %107, %82
  %110 = fmul <8 x double> %83, %106
  %111 = fmul <8 x double> %83, %107
  %112 = fsub <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %108
  %113 = fsub <8 x double> %112, %109
  %114 = fsub <8 x double> %113, %110
  %115 = fsub <8 x double> %114, %111
  %116 = fmul <8 x double> %103, %115
  %117 = bitcast <8 x double> %95 to <8 x i64>
  %118 = and <8 x i64> %117, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %119 = bitcast <8 x i64> %118 to <8 x double>
  %120 = fsub <8 x double> %95, %119
  %121 = fmul <8 x double> %103, %95
  %122 = fmul <8 x double> %106, %119
  %123 = bitcast <8 x double> %121 to <8 x i64>
  %124 = xor <8 x i64> %123, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %125 = bitcast <8 x i64> %124 to <8 x double>
  %126 = fmul <8 x double> %120, %106
  %127 = fmul <8 x double> %107, %119
  %128 = fmul <8 x double> %107, %120
  %129 = fmul <8 x double> %95, %116
  %130 = fmul <8 x double> %103, %102
  %131 = fadd <8 x double> %122, %125
  %132 = fadd <8 x double> %126, %131
  %133 = fadd <8 x double> %127, %132
  %134 = fadd <8 x double> %128, %133
  %135 = fadd <8 x double> %129, %134
  %136 = fadd <8 x double> %135, %130
  %137 = fmul <8 x double> %121, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %138 = fmul <8 x double> %136, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %139 = bitcast <8 x double> %137 to <8 x i64>
  %140 = and <8 x i64> %139, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %141 = bitcast <8 x i64> %140 to <8 x double>
  %142 = fsub <8 x double> %137, %141
  %143 = bitcast <8 x double> %10 to <8 x i64>
  %144 = and <8 x i64> %143, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %145 = bitcast <8 x i64> %144 to <8 x double>
  %146 = fsub <8 x double> %10, %145
  %147 = fmul <8 x double> %10, %137
  %148 = fmul <8 x double> %145, %141
  %149 = bitcast <8 x double> %147 to <8 x i64>
  %150 = xor <8 x i64> %149, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %151 = bitcast <8 x i64> %150 to <8 x double>
  %152 = fmul <8 x double> %142, %145
  %153 = fmul <8 x double> %146, %141
  %154 = fmul <8 x double> %146, %142
  %155 = fmul <8 x double> %10, %138
  %156 = fadd <8 x double> %148, %151
  %157 = fadd <8 x double> %152, %156
  %158 = fadd <8 x double> %153, %157
  %159 = fadd <8 x double> %154, %158
  %160 = fadd <8 x double> %159, %155
  %161 = fadd <8 x double> %147, %160
  %162 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %161, <8 x double> %161, i32 4, i8 -1, i32 4) #7
  %163 = bitcast i8 %162 to <8 x i1>
  %164 = select <8 x i1> %163, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %161
  %165 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %166 = bitcast i8 %165 to <8 x i1>
  %167 = select <8 x i1> %166, <8 x double> %10, <8 x double> %164
  %168 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> %5, i32 4, i8 -1, i32 4) #7
  %169 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %170 = or i8 %169, %168
  %171 = bitcast i8 %170 to <8 x i1>
  %172 = select <8 x i1> %171, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %167
  %173 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %174 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %175 = or i8 %174, %173
  %176 = bitcast i8 %175 to <8 x i1>
  %177 = select <8 x i1> %176, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %172
  ret <8 x double> %177
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_hypotd8_u35avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %10 = tail call <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double> %5, <8 x double> %8, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %11 = fdiv <8 x double> %9, %10
  %12 = fmul <8 x double> %11, %11
  %13 = fadd <8 x double> %12, <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %14 = tail call <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double> %13, <8 x double> zeroinitializer, i8 -1, i32 4) #7
  %15 = fmul <8 x double> %10, %14
  %16 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %9, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %17 = bitcast i8 %16 to <8 x i1>
  %18 = select <8 x i1> %17, <8 x double> %10, <8 x double> %15
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> %5, i32 4, i8 -1, i32 4) #7
  %20 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> %8, i32 4, i8 -1, i32 4) #7
  %21 = or i8 %20, %19
  %22 = bitcast i8 %21 to <8 x i1>
  %23 = select <8 x i1> %22, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %18
  %24 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %25 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %26 = or i8 %25, %24
  %27 = bitcast i8 %26 to <8 x i1>
  %28 = select <8 x i1> %27, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, <8 x double> %23
  ret <8 x double> %28
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_fmodd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000, double 0x10000000000000>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %5
  %13 = fmul <8 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %8
  %15 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %16 = bitcast <8 x double> %15 to <8 x i64>
  %17 = add <8 x i64> %16, <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1>
  %18 = bitcast <8 x i64> %17 to <8 x double>
  %19 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %15, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %20 = bitcast i8 %19 to <8 x i1>
  %21 = select <8 x i1> %20, <8 x double> zeroinitializer, <8 x double> %18
  %22 = fmul <8 x double> %14, <double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00, double 3.000000e+00>
  %23 = fadd <8 x double> %14, %14
  %24 = bitcast <8 x double> %14 to <8 x i64>
  %25 = xor <8 x i64> %24, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %26 = bitcast <8 x i64> %25 to <8 x double>
  %27 = and <8 x i64> %25, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %28 = bitcast <8 x i64> %27 to <8 x double>
  %29 = fsub <8 x double> %26, %28
  br label %30

; <label>:30:                                     ; preds = %30, %2
  %31 = phi i32 [ 0, %2 ], [ %83, %30 ]
  %32 = phi <8 x double> [ zeroinitializer, %2 ], [ %80, %30 ]
  %33 = phi <8 x double> [ %12, %2 ], [ %78, %30 ]
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = add <8 x i64> %34, <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %33, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %38 = bitcast i8 %37 to <8 x i1>
  %39 = select <8 x i1> %38, <8 x double> zeroinitializer, <8 x double> %36
  %40 = fmul <8 x double> %21, %39
  %41 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %40, i32 11, <8 x double> %40, i8 -1, i32 4) #7
  %42 = bitcast <8 x double> %41 to <8 x i64>
  %43 = and <8 x i64> %42, <i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2>
  %44 = bitcast <8 x i64> %43 to <8 x double>
  %45 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %22, <8 x double> %33, i32 30, i8 -1, i32 4) #7
  %46 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %33, <8 x double> %14, i32 29, i8 -1, i32 4) #7
  %47 = and i8 %46, %45
  %48 = bitcast i8 %47 to <8 x i1>
  %49 = select <8 x i1> %48, <8 x double> <double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00, double 2.000000e+00>, <8 x double> %44
  %50 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %23, <8 x double> %33, i32 30, i8 -1, i32 4) #7
  %51 = and i8 %50, %46
  %52 = bitcast i8 %51 to <8 x i1>
  %53 = select <8 x i1> %52, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %49
  %54 = bitcast <8 x double> %53 to <8 x i64>
  %55 = and <8 x i64> %54, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %56 = bitcast <8 x i64> %55 to <8 x double>
  %57 = fsub <8 x double> %53, %56
  %58 = fmul <8 x double> %53, %26
  %59 = fmul <8 x double> %28, %56
  %60 = bitcast <8 x double> %58 to <8 x i64>
  %61 = xor <8 x i64> %60, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %62 = bitcast <8 x i64> %61 to <8 x double>
  %63 = fmul <8 x double> %57, %28
  %64 = fmul <8 x double> %29, %56
  %65 = fmul <8 x double> %29, %57
  %66 = fadd <8 x double> %59, %62
  %67 = fadd <8 x double> %63, %66
  %68 = fadd <8 x double> %64, %67
  %69 = fadd <8 x double> %65, %68
  %70 = fadd <8 x double> %33, %58
  %71 = fsub <8 x double> %70, %33
  %72 = fsub <8 x double> %70, %71
  %73 = fsub <8 x double> %33, %72
  %74 = fsub <8 x double> %58, %71
  %75 = fadd <8 x double> %74, %73
  %76 = fadd <8 x double> %32, %69
  %77 = fadd <8 x double> %75, %76
  %78 = fadd <8 x double> %70, %77
  %79 = fsub <8 x double> %70, %78
  %80 = fadd <8 x double> %77, %79
  %81 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %78, <8 x double> %14, i32 17, i8 -1, i32 4) #7
  %82 = icmp ne i8 %81, -1
  %83 = add nuw nsw i32 %31, 1
  %84 = icmp ult i32 %83, 21
  %85 = and i1 %84, %82
  br i1 %85, label %30, label %86

; <label>:86:                                     ; preds = %30
  %87 = select <8 x i1> %11, <8 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %88 = fmul <8 x double> %87, %78
  %89 = fadd <8 x double> %78, %80
  %90 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %89, <8 x double> %14, i32 0, i8 -1, i32 4) #7
  %91 = bitcast i8 %90 to <8 x i1>
  %92 = bitcast <8 x double> %88 to <8 x i64>
  %93 = select <8 x i1> %91, <8 x i64> zeroinitializer, <8 x i64> %92
  %94 = and <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %95 = xor <8 x i64> %93, %94
  %96 = bitcast <8 x i64> %95 to <8 x double>
  %97 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %12, <8 x double> %14, i32 17, i8 -1, i32 4) #7
  %98 = bitcast i8 %97 to <8 x i1>
  %99 = select <8 x i1> %98, <8 x double> %0, <8 x double> %96
  %100 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %14, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %101 = bitcast i8 %100 to <8 x i1>
  %102 = select <8 x i1> %101, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %99
  ret <8 x double> %102
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_remainderd8_avx512fnofma(<8 x double>, <8 x double>) local_unnamed_addr #1 {
  %3 = bitcast <8 x double> %0 to <8 x i64>
  %4 = and <8 x i64> %3, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %5 = bitcast <8 x i64> %4 to <8 x double>
  %6 = bitcast <8 x double> %1 to <8 x i64>
  %7 = and <8 x i64> %6, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %8 = bitcast <8 x i64> %7 to <8 x double>
  %9 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000, double 0x20000000000000>, i32 17, i8 -1, i32 4) #7
  %10 = fmul <8 x double> %5, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %11 = bitcast i8 %9 to <8 x i1>
  %12 = select <8 x i1> %11, <8 x double> %10, <8 x double> %5
  %13 = fmul <8 x double> %8, <double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000, double 0x4350000000000000>
  %14 = select <8 x i1> %11, <8 x double> %13, <8 x double> %8
  %15 = select <8 x i1> %11, <8 x double> <double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000, double 0x3C90000000000000>, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>
  %16 = fdiv <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, %14
  %17 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> zeroinitializer, <8 x double> zeroinitializer, i32 4, i8 -1, i32 4) #7
  %18 = zext i8 %17 to i16
  %19 = fmul <8 x double> %14, <double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00, double 1.500000e+00>
  %20 = fmul <8 x double> %14, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %21 = bitcast <8 x double> %14 to <8 x i64>
  %22 = xor <8 x i64> %21, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %23 = bitcast <8 x i64> %22 to <8 x double>
  %24 = and <8 x i64> %22, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %25 = bitcast <8 x i64> %24 to <8 x double>
  %26 = fsub <8 x double> %23, %25
  br label %27

; <label>:27:                                     ; preds = %57, %2
  %28 = phi i32 [ 0, %2 ], [ %101, %57 ]
  %29 = phi i16 [ %18, %2 ], [ %73, %57 ]
  %30 = phi <8 x double> [ zeroinitializer, %2 ], [ %100, %57 ]
  %31 = phi <8 x double> [ %12, %2 ], [ %98, %57 ]
  %32 = fmul <8 x double> %16, %31
  %33 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %32, i32 8, <8 x double> %32, i8 -1, i32 4) #7
  %34 = bitcast <8 x double> %33 to <8 x i64>
  %35 = and <8 x i64> %34, <i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2, i64 -2>
  %36 = bitcast <8 x i64> %35 to <8 x double>
  %37 = bitcast <8 x double> %31 to <8 x i64>
  %38 = and <8 x i64> %37, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %39 = bitcast <8 x i64> %38 to <8 x double>
  %40 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %19, i32 17, i8 -1, i32 4) #7
  %41 = bitcast i8 %40 to <8 x i1>
  %42 = select <8 x i1> %41, <8 x double> <double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00, double 1.000000e+00>, <8 x double> %36
  %43 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %20, i32 17, i8 -1, i32 4) #7
  %44 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %39, <8 x double> %20, i32 0, i8 -1, i32 4) #7
  %45 = zext i8 %44 to i16
  %46 = bitcast i16 %29 to <16 x i1>
  %47 = bitcast i16 %45 to <16 x i1>
  %48 = xor <16 x i1> %46, <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef, i1 undef>
  %49 = and <16 x i1> %48, %47
  %50 = bitcast <16 x i1> %49 to <2 x i8>
  %51 = extractelement <2 x i8> %50, i32 0
  %52 = or i8 %51, %43
  %53 = bitcast i8 %52 to <8 x i1>
  %54 = select <8 x i1> %53, <8 x double> zeroinitializer, <8 x double> %42
  %55 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %54, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %56 = icmp eq i8 %55, -1
  br i1 %56, label %103, label %57

; <label>:57:                                     ; preds = %27
  %58 = fmul <8 x double> %54, %23
  %59 = bitcast <8 x double> %58 to <8 x i64>
  %60 = and <8 x i64> %59, <i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807, i64 9223372036854775807>
  %61 = bitcast <8 x i64> %60 to <8 x double>
  %62 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %61, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %63 = and <8 x i64> %37, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %64 = xor <8 x i64> %63, <i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400, i64 -4616189618054758400>
  %65 = bitcast <8 x i64> %64 to <8 x double>
  %66 = fadd <8 x double> %54, %65
  %67 = bitcast i8 %62 to <8 x i1>
  %68 = select <8 x i1> %67, <8 x double> %66, <8 x double> %54
  %69 = fmul <8 x double> %68, <double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01, double 5.000000e-01>
  %70 = tail call <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double> %69, i32 11, <8 x double> %69, i8 -1, i32 4) #7
  %71 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %70, <8 x double> %69, i32 4, i8 -1, i32 4) #7
  %72 = zext i8 %71 to i16
  %73 = xor i16 %29, %72
  %74 = bitcast <8 x double> %68 to <8 x i64>
  %75 = and <8 x i64> %74, <i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728, i64 -134217728>
  %76 = bitcast <8 x i64> %75 to <8 x double>
  %77 = fsub <8 x double> %68, %76
  %78 = fmul <8 x double> %68, %23
  %79 = fmul <8 x double> %25, %76
  %80 = bitcast <8 x double> %78 to <8 x i64>
  %81 = xor <8 x i64> %80, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %82 = bitcast <8 x i64> %81 to <8 x double>
  %83 = fmul <8 x double> %77, %25
  %84 = fmul <8 x double> %26, %76
  %85 = fmul <8 x double> %26, %77
  %86 = fadd <8 x double> %79, %82
  %87 = fadd <8 x double> %83, %86
  %88 = fadd <8 x double> %84, %87
  %89 = fadd <8 x double> %85, %88
  %90 = fadd <8 x double> %31, %78
  %91 = fsub <8 x double> %90, %31
  %92 = fsub <8 x double> %90, %91
  %93 = fsub <8 x double> %31, %92
  %94 = fsub <8 x double> %78, %91
  %95 = fadd <8 x double> %94, %93
  %96 = fadd <8 x double> %30, %89
  %97 = fadd <8 x double> %95, %96
  %98 = fadd <8 x double> %90, %97
  %99 = fsub <8 x double> %90, %98
  %100 = fadd <8 x double> %97, %99
  %101 = add nuw nsw i32 %28, 1
  %102 = icmp ult i32 %101, 21
  br i1 %102, label %27, label %103

; <label>:103:                                    ; preds = %27, %57
  %104 = phi <8 x double> [ %31, %27 ], [ %98, %57 ]
  %105 = fmul <8 x double> %15, %104
  %106 = bitcast <8 x double> %105 to <8 x i64>
  %107 = and <8 x i64> %3, <i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808, i64 -9223372036854775808>
  %108 = xor <8 x i64> %107, %106
  %109 = bitcast <8 x i64> %108 to <8 x double>
  %110 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %8, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %111 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %5, <8 x double> <double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000, double 0x7FF0000000000000>, i32 0, i8 -1, i32 4) #7
  %112 = bitcast i8 %111 to <8 x i1>
  %113 = select <8 x i1> %112, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %0
  %114 = bitcast i8 %110 to <8 x i1>
  %115 = select <8 x i1> %114, <8 x double> %113, <8 x double> %109
  %116 = tail call i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double> %14, <8 x double> zeroinitializer, i32 0, i8 -1, i32 4) #7
  %117 = bitcast i8 %116 to <8 x i1>
  %118 = select <8 x i1> %117, <8 x double> <double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000, double 0x7FF8000000000000>, <8 x double> %115
  ret <8 x double> %118
}

; Function Attrs: nounwind uwtable
define <8 x double> @Sleef_cinz_tgammad8_u10avx512fnofma(<8 x double>) local_unnamed_addr #3 {
  %2 = tail call <8 x double> @Sleef_tgammad8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind uwtable
define <8 x double> @Sleef_cinz_lgammad8_u10avx512fnofma(<8 x double>) local_unnamed_addr #3 {
  %2 = tail call <8 x double> @Sleef_lgammad8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_erfd8_u10avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_erfd8_u10avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind readnone uwtable
define <8 x double> @Sleef_cinz_erfcd8_u15avx512fnofma(<8 x double>) local_unnamed_addr #1 {
  %2 = tail call <8 x double> @Sleef_erfcd8_u15avx512fnofma(<8 x double> %0)
  ret <8 x double> %2
}

; Function Attrs: nounwind uwtable
define i32 @Sleef_getIntd8_avx512fnofma(i32) local_unnamed_addr #3 {
  %2 = alloca [4 x i32], align 16
  %3 = add i32 %0, -1
  %4 = icmp ult i32 %3, 10
  br i1 %4, label %5, label %13

; <label>:5:                                      ; preds = %1
  %6 = bitcast [4 x i32]* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %6) #7
  %7 = getelementptr inbounds [4 x i32], [4 x i32]* %2, i64 0, i64 0
  call void @Sleef_x86CpuID(i32* nonnull %7, i32 7, i32 0) #7
  %8 = getelementptr inbounds [4 x i32], [4 x i32]* %2, i64 0, i64 1
  %9 = load i32, i32* %8, align 4, !tbaa !33
  %10 = and i32 %9, 65536
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %6) #7
  %11 = icmp eq i32 %10, 0
  %12 = select i1 %11, i32 0, i32 3
  br label %13

; <label>:13:                                     ; preds = %1, %5
  %14 = phi i32 [ %12, %5 ], [ 0, %1 ]
  ret i32 %14
}

; Function Attrs: norecurse nounwind readnone uwtable
define i8* @Sleef_getPtrd8_avx512fnofma(i32) local_unnamed_addr #0 {
  %2 = icmp eq i32 %0, 0
  %3 = select i1 %2, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str, i64 0, i64 0), i8* null
  ret i8* %3
}

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.getexp.pd.512(<8 x double>, <8 x double>, i8, i32) #4

; Function Attrs: nounwind readnone
declare i8 @llvm.x86.avx512.mask.cmp.pd.512(<8 x double>, <8 x double>, i32, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x i32> @llvm.x86.avx512.mask.cvtpd2dq.512(<8 x double>, <8 x i32>, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.rndscale.pd.512(<8 x double>, i32, <8 x double>, i8, i32) #4

; Function Attrs: argmemonly nounwind readonly
declare <8 x double> @llvm.x86.avx512.gather.dpd.512(<8 x double>, i8*, <8 x i32>, i8, i32) #5

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.sqrt.pd.512(<8 x double>, <8 x double>, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.getmant.pd.512(<8 x double>, i32, <8 x double>, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.max.pd.512(<8 x double>, <8 x double>, <8 x double>, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.min.pd.512(<8 x double>, <8 x double>, <8 x double>, i8, i32) #4

; Function Attrs: nounwind readnone
declare <8 x double> @llvm.x86.avx512.mask.permvar.df.512(<8 x double>, <8 x i64>, <8 x double>, i8) #4

declare void @Sleef_x86CpuID(i32*, i32, i32) local_unnamed_addr #6

attributes #0 = { norecurse nounwind readnone uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+avx512f,+f16c,+fma,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind readnone uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+avx512f,+f16c,+fma,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { argmemonly nounwind }
attributes #3 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+avx512f,+f16c,+fma,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { argmemonly nounwind readonly }
attributes #6 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+avx,+avx2,+avx512f,+f16c,+fma,+fxsr,+mmx,+popcnt,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)"}
!2 = !{!"branch_weights", i32 2000, i32 1}
!3 = !{!4}
!4 = distinct !{!4, !5, !"rempi: argument 0"}
!5 = distinct !{!5, !"rempi"}
!6 = !{!7}
!7 = distinct !{!7, !8, !"rempi: argument 0"}
!8 = distinct !{!8, !"rempi"}
!9 = !{!10}
!10 = distinct !{!10, !11, !"rempi: argument 0"}
!11 = distinct !{!11, !"rempi"}
!12 = !{!13}
!13 = distinct !{!13, !14, !"rempi: argument 0"}
!14 = distinct !{!14, !"rempi"}
!15 = !{!16}
!16 = distinct !{!16, !17, !"rempi: argument 0"}
!17 = distinct !{!17, !"rempi"}
!18 = !{!19}
!19 = distinct !{!19, !20, !"rempi: argument 0"}
!20 = distinct !{!20, !"rempi"}
!21 = !{!22}
!22 = distinct !{!22, !23, !"rempi: argument 0"}
!23 = distinct !{!23, !"rempi"}
!24 = !{!25}
!25 = distinct !{!25, !26, !"rempi: argument 0"}
!26 = distinct !{!26, !"rempi"}
!27 = !{!28}
!28 = distinct !{!28, !29, !"Sleef_sincospid8_u35avx512fnofma: argument 0"}
!29 = distinct !{!29, !"Sleef_sincospid8_u35avx512fnofma"}
!30 = !{!31}
!31 = distinct !{!31, !32, !"Sleef_modfd8_avx512fnofma: argument 0"}
!32 = distinct !{!32, !"Sleef_modfd8_avx512fnofma"}
!33 = !{!34, !34, i64 0}
!34 = !{!"int", !35, i64 0}
!35 = !{!"omnipotent char", !36, i64 0}
!36 = !{!"Simple C/C++ TBAA"}
